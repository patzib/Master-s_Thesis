question,ground_truth_answer,generated_answer,retrieved_context,response_time_seconds,relevance_score,relevance_reasoning,faithfulness_score,faithfulness_reasoning,correctness_score,correctness_reasoning,,
"In the paper about the Centaur foundation model, what happens to the model's internal representations after being fine-tuned on the Psych-101 dataset?",The model's internal representations become more aligned with human neural activity.,"The provided text doesn't detail what happens to the Centaur model‚Äôs internal representations after being fine-tuned on the Psych-101 dataset. It focuses on the overall methodology, the importance of simpler models, and the concept of moderation.","Modelle
aus ganz unterschiedlichen
Disziplinen zusammengenommen und
haben jahrelang rumgewerkelt, um 
zu schauen,
was sind eigentlich die latent 
√§hnlichen Faktoren,
was k√∂nnen wir irgendwie 
zusammenfassen und
was sind Faktoren,
die m√∂glichst orthogonal einzeln 
gesehen
unterschiedlich sind und
viel Erkl√§rungsgehalt daf√ºr 
haben
in der Vorhersage,
ob ein Mensch die Technologie 
nutzen wird oder nicht.
Und das haben Sie das Modell, 
was entwickelt haben
letztlich auf ganz viele 
empirische Daten
gelegt und gezeigt,
dass dieses Modell um die 70¬†% 
der Variation darin,
ob Leute mit Technologie 
interagieren, dass GPT auf die Art und
Weise funktionieren wird, wie es 
funktioniert.
Da mussten massiv Ressourcen 
reingesteckt werden,
auch um zu experimentieren.
Letztlich. Und Ockhams Razor ist 
eher dieses diese Idee.
Wenn ich zwei Modelle trainiert 
habe und
diese beiden Modelle 
nebeneinander lege und die 
gleiche
Performance habe,
dann sollte ich als Daumenregel 
nochmal
wirklich betont als Daumenregel
eher das Modell nehmen, was 
einfacher ist.
Der Gedanke, der dahinter 
steckt,
ist, dass wir vermeiden wollen,
dass die zuf√§lligen Schwankungen 
in den
Daten mit h√∂herer 
Modellkomplexit√§t
in dem Modell erkannt werden als Wir werden jetzt in den ersten
Vorlesungen und es wird so
bis zur f√ºnften Vorlesung gehen.
Da werden wir langsam anfangen,
auch in den zweiten Teil 
√ºberzugehen.
Aber zun√§chst mal interessiert 
uns gar nicht,
wie wir auf dieses Modell 
kommen,
was dieses Modell genau ist.
Wir werden erstmal annehmen,
da ist irgendein Modell,
das f√§llt sozusagen vom Himmel.
Und was macht dieses Modell mit 
uns?
Was macht dieses Modell mit 
Organisationen?
Was macht dieses Modell mit 
Personen?
Was macht dieses Modell mit der 
Gesellschaft?
Und um so ein bisschen
eine Hands on Vorstellung zu 
haben,
was Machine Learning Modelle Breakdowns.
Genau das ist eine andere 
Diskussion,
die wir zu sp√§teren Zeit f√ºhren 
m√ºssen,
wenn wir angeschaut haben,
wie diese Modelle funktionieren.
Aber grunds√§tzlich gibt es
das Problem Wenn ich auf 
Predictions weiter
lerne und nichts weiter mit dem 
Predictions mache,
dann kann es zu Model Kollaps 
f√ºhren,
weil die Modelle inh√§rent 
irgendwelche Muster
in ihren eigenen.
Daten, die sie selber erzeugt 
findet.
Dann kann man sich so ein 
bisschen vorstellen
die Inmates Running the Asylum,
Also die der eine Tor erz√§hlt 
dem anderen Tor,
wie die Sachen zu laufen haben 
und dann erz√§hlen sich Modell.
Kommen wir jetzt zur heutigen 
Vorlesung.
Immer mit diesem Gedanken im 
Kopf.
Wir haben Inputdaten, wir haben
ein Modell und dieses Modell
macht auf den Inputdaten 
letztlich uns eine Vorhersage,
die m√∂glichst pr√§zise ist f√ºr 
Daten,
die Sie noch nicht gesehen 
haben.
Fangen wir jetzt wirklich an,
in diesem Teil eins rein zu 
gehen, um zu verstehen,
was k√∂nnen diese Modelle
eigentlich liefern aus einer 
√∂konomischen,
betriebswirtschaftlichen, 
gesellschaftlichen Perspektive?
Wir werden jetzt in den ersten
Vorlesungen und es wird so
bis zur f√ºnften Vorlesung gehen.
Da werden wir langsam anfangen, System zu nutzen,
definieren diese Faktoren dann 
√ºber diesen
Mediationsweg ihre Bereitschaft 
tats√§chlich
oder ihre tats√§chliche Nutzung 
des Systems,
ihre tats√§chliche Akzeptanz des 
Systems.
Wer wei√ü, was es neben Mediation 
noch gibt?
Was haben wir noch in diesen 
Modellen,
um etwas zu konzeptionalisieren?
Ja, exactly.
Wissen Sie, was Moderation 
bedeutet?
Moderator ist eine Variable,
die die Richtung oder die St√§rke 
des Effekts.
Sehr gut. Wie Ihre Kommilitonin 
hier gesagt hat,
haben wir nicht nur eine 
Mediation.
Wenn wir sagen, der Effekt von 
Performance expectancy
auf actual use wird",6.165130377,0,The context is a collection of generic machine learning concepts and does not mention the specific model (Centaur) or the dataset (Psych-101) mentioned in the question.,1,"All claims in the generated answer are verifiable from the retrieved context. The context does not mention the Centaur model or Psych-101, and it does discuss simpler models (Ockham's Razor) and the concept of moderation.",0,"The generated answer incorrectly states that the information is not available, while the ground truth provides a specific, factual answer to the question.",,
"In the study on capturing human cognition, how does the Centaur model's performance compare to existing cognitive models?",Centaur captures the behaviour of held-out participants better than existing cognitive models.,"According to the text, the Centaur model (referenced as ""we"") can train ""different rules"" and ""various Machine Learning Models."" These models can have ""better or worse performance."" However, if the models achieve ""the same performance,"" the researchers can choose between them. The text doesn‚Äôt explicitly state how the Centaur model‚Äôs performance compares to *existing* cognitive models, only that it can produce varying levels of performance.","10. Juli 2025
A mathematical model of a brain cell: perceptron
10
#ùë¶!=ùëì%""ùë§""‚ãÖùë•""+ùëè
Weighted linear combination of inputsOutput
Non-linearization(activation function) Intercept
Representation   +Evaluation+Optimization Unlike our study, the nudges that they examined pro -
vide direct information about products under consider -
ation by online shoppers. To our knowledge, we are the 
first to design and test the efficacy of making the envi -
ronmental consequences of postpurchase behavior 
salient in reducing product returns through a large- 
scale field experiment.
2.2. Nudging
As a cognitive intervention, nudging aims to subtly 
alter human behavior through modifications in the 
choice architecture (Thaler and Sunstein 2009 ). Cru -
cially, nudges guide behavior without restricting Das war eines der fundamentalen 
Ergebnisse,
die Sie hier gefunden haben in 
der Studie.
Und dann Sie haben gesagt okay, 
wenn ich wei√ü,
dass wir die Menschen in
ihrer Kognition √ºberzeugen 
m√ºssen,
dass sie das System nutzen 
sollten und akzeptieren
sollten entweder √ºber System
eins oder √ºber System zwei 
Aktivierungen,
dann lass uns doch mal dr√ºber 
nachdenken,
welche Faktoren denn hier eine 
besondere Rolle spielen.
Und da haben Sie insgesamt in
diesem Modell vier verschiedene 
Faktoren identifiziert.
Einer der Faktoren nennen Sie 
die Performance Expectancy.
Das k√∂nnen Sie sich vorstellen. Feedback Loops in Machine Learning 
 
811 
3.2 Previous Empirical Studies 
We buil t our simulations on two secondary datasets, 
collected by several authors of this paper as part of 
different empirical studies. Study A was an incentivized 
field study conducted over three years from 2016 to 
2019. Study A measured participant s‚Äô behavior in the 
investment game  defined above  in their  role as 
borrowers. The data from Study A allow ed us to 
develop an ML model predicting borrowers‚Äô repayment 
decision and serves as the foundation for simulating 
borrower behavior. Study B, conducted in December besser als eine auf einem 
Papier.
Das ist sehr, sehr gute Frage.
Da gibt es verschiedene Theorien 
zu.
Grunds√§tzlich, wie wir sehen 
werden,
f√ºr den technischen Teil der 
Vorlesung.
Wir k√∂nnen f√ºr das gleiche
Problem verschiedene Regeln 
identifizieren.
Verschiedene Machine Learning 
Modelle trainieren.
Diese Machine Learning Modelle 
k√∂nnen bessere oder
schlechtere Performance 
aufweisen.
Wenn sie aber genau die gleiche 
Performance aufweisen,
dann haben wir nat√ºrlich in 
einer gewissen Art und
Weise die Wahl, immer darauf 
achtend,
dass die einzige Performance, 
die wir sehen,
aktuell immer Performance auf eins
und System zwei geh√∂rt?
Marketing wahrscheinlich eines 
der wohl
bekanntesten 
Konzeptionalisierung,
wie unsere Kognition 
funktioniert.
Wir haben ein sehr schnelles 
heuristisches System.
Im Denken entscheiden das System 
eins
und wir haben das System Zwei,
was tiefer nachdenkt,
was mehr kognitive Ressourcen 
ben√∂tigt,
aber auch komplexere Probleme 
l√∂sen kann.
Und das spielt alles hier rein.
Und diese Systeme haben ein
Zusammenspiel dann was bestimmt,
ob ich eigentlich das System 
nutze.
Das war eines der fundamentalen 
Ergebnisse,
die Sie hier gefunden haben in 
der Studie.
Und dann Sie haben gesagt okay,",9.778652668,0.1,"The context vaguely mentions cognitive models (System eins/zwei) and the concept of model performance but fails to mention the ""Centaur model"" or provide any comparison to existing models.",0.6,"The generation incorrectly claims that the ""Centaur model"" is referenced as ""we"" in the text. The rest of the claims about model performance and choice are faithful to the context.",0,"The generated answer claims that the text doesn't explicitly compare the Centaur model's performance to existing models, whereas the ground truth provides a direct and specific comparison, stating that Centaur performs better.",,
"According to the paper on the Centaur foundation model, what is it designed to predict and simulate regarding human cognition?",It can predict and simulate human behaviour in any experiment expressible in natural language.,"According to the provided text, the model is designed to predict and simulate whether a person will use technology, specifically focusing on factors related to human interaction with systems. It aims to understand the factors that influence whether someone will adopt a technology.","Das war eines der fundamentalen 
Ergebnisse,
die Sie hier gefunden haben in 
der Studie.
Und dann Sie haben gesagt okay, 
wenn ich wei√ü,
dass wir die Menschen in
ihrer Kognition √ºberzeugen 
m√ºssen,
dass sie das System nutzen 
sollten und akzeptieren
sollten entweder √ºber System
eins oder √ºber System zwei 
Aktivierungen,
dann lass uns doch mal dr√ºber 
nachdenken,
welche Faktoren denn hier eine 
besondere Rolle spielen.
Und da haben Sie insgesamt in
diesem Modell vier verschiedene 
Faktoren identifiziert.
Einer der Faktoren nennen Sie 
die Performance Expectancy.
Das k√∂nnen Sie sich vorstellen. 10. Juli 2025
A mathematical model of a brain cell: perceptron
10
#ùë¶!=ùëì%""ùë§""‚ãÖùë•""+ùëè
Weighted linear combination of inputsOutput
Non-linearization(activation function) Intercept
Representation   +Evaluation+Optimization for more details). Computer simulations serve as a 
robust and widely  accepted tool across multiple 
scientific fields, facilitating the analysis of dynamic 
processes (Kahal√©, 2020). Such simulations also 
enable the generation of proofs of concept for novel 
ideas (Wong & Kwong, 2018). We opt for this research 
methodology primarily because the exogenous 
introduction of discrimination, particularly by humans, 
is not only ethically untenable but also practically 
unfeasible in experimental or field settings. 
Our simulation employs a modified version of the 
investment game (Berg et al., 1995). This game Modelle
aus ganz unterschiedlichen
Disziplinen zusammengenommen und
haben jahrelang rumgewerkelt, um 
zu schauen,
was sind eigentlich die latent 
√§hnlichen Faktoren,
was k√∂nnen wir irgendwie 
zusammenfassen und
was sind Faktoren,
die m√∂glichst orthogonal einzeln 
gesehen
unterschiedlich sind und
viel Erkl√§rungsgehalt daf√ºr 
haben
in der Vorhersage,
ob ein Mensch die Technologie 
nutzen wird oder nicht.
Und das haben Sie das Modell, 
was entwickelt haben
letztlich auf ganz viele 
empirische Daten
gelegt und gezeigt,
dass dieses Modell um die 70¬†% 
der Variation darin,
ob Leute mit Technologie 
interagieren, wie Sicherheitsmechanismen, die 
dazu f√ºhren,
dass diese Systeme 
vertrauensw√ºrdig
und responsible accountable 
sind,
aber immer wieder mit diesem 
Fokus.
Daher diese Idee von human
centered den Menschen besser zu 
machen,
Menschliche Aktivit√§ten zu 
vereinfachen,
den Menschen zu helfen,
sei es durch automatische 
Prozesse,
sei es durch Decision Support 
Prozesse.
Tolles Buch. Hier w√§re eine 
Buchempfehlung f√ºr
die vorlesungsfreie Zeit 
braucht.
Kann ich nur empfehlen zu lesen.
Ist echt einfach auch 
geschrieben.
Das kann man nebenbei im Urlaub 
mal lesen.
Nat√ºrlich gibt es irgendwie von
den ganzen gro√üen Modell.
Kommen wir jetzt zur heutigen 
Vorlesung.
Immer mit diesem Gedanken im 
Kopf.
Wir haben Inputdaten, wir haben
ein Modell und dieses Modell
macht auf den Inputdaten 
letztlich uns eine Vorhersage,
die m√∂glichst pr√§zise ist f√ºr 
Daten,
die Sie noch nicht gesehen 
haben.
Fangen wir jetzt wirklich an,
in diesem Teil eins rein zu 
gehen, um zu verstehen,
was k√∂nnen diese Modelle
eigentlich liefern aus einer 
√∂konomischen,
betriebswirtschaftlichen, 
gesellschaftlichen Perspektive?
Wir werden jetzt in den ersten
Vorlesungen und es wird so
bis zur f√ºnften Vorlesung gehen.
Da werden wir langsam anfangen,",7.250867605,0.5,"The context describes a model designed to predict ""ob ein Mensch die Technologie nutzen wird oder nicht"" (whether a person will use technology or not)[cite: 50], which is directly related to predicting and simulating human cognition. However, it does not explicitly name the ""Centaur"" model.",1,"All claims made in the generated answer can be directly verified from the provided context, which describes a model for predicting technology adoption and the factors influencing it.",0.1,"The generated answer is far too narrow, claiming the model predicts only technology use. The ground truth states a much broader capability: predicting human behavior in any experiment expressible in natural language. The generation misses the core, powerful function of the model.",,
"For the Centaur model, what is the name and scale of the dataset used for fine-tuning to capture human cognition?","Psych-101, which covers trial-by-trial data from over 60,000 participants in 160 experiments.","The provided text does not contain information about the Centaur foundation model or any dataset used for fine-tuning to capture human cognition. It discusses general concepts related to machine learning, neural networks, and data preparation.","und es gibt bestimmte Machine 
Learning Modelle,
die sind sehr sch√∂n,
die viel dieser Arbeit durch
bestimmte algorithmische 
Lernverfahren abfangen.
Zum Beispiel der 
Entscheidungsbaum
oder auch der Random Forest.
Aber es gibt andere Methoden und 
insbesondere die
most sophisticated Methoden wie 
neuronale Netze,
die auf jede Kleinigkeit in
den Daten massiv sensitiv 
reagieren,
m√ºssen Daten standardisieren.
Wir m√ºssen auf eine bestimmte 
Art und
Weise sampeln m√ºssen
bestimmte Observationen 
rausschmei√üen.
All das, wie Sie hier sehen,
braucht ungef√§hr 60 bis
80¬†% der Zeit eines solchen Data 
Science Projekts. 10. Juli 2025
A mathematical model of a brain cell: perceptron
10
#ùë¶!=ùëì%""ùë§""‚ãÖùë•""+ùëè
Weighted linear combination of inputsOutput
Non-linearization(activation function) Intercept
Representation   +Evaluation+Optimization wo Sie KI einsetzen k√∂nnen,
wann und wo m√∂gliche 
Problemstellungen sind.
Aus diesem ersten Teil hier 
zumindest,
dass Sie uns das strukturiert 
wiedergeben
k√∂nnen und uns zeigen,
dass Sie diese Denkweise 
verstanden haben.
Wenn wir heute dann wie gesagt,
einsteigen und das Thema des 
ersten Blockes abschlie√üen.
K√ºmmern wir uns jetzt noch mal 
darum,
was eigentlich der Mensch in 
diesem ganzen System
weiterhin noch macht und k√ºmmern 
uns
um diese Mensch Maschine 
Interaktion.
Wenn Sie sich erinnern Sehr fr√ºh
in der zweiten Vorlesung haben 
wir festgestellt,
dass die meisten Machine 
Learning Anwendungen Modelle
aus ganz unterschiedlichen
Disziplinen zusammengenommen und
haben jahrelang rumgewerkelt, um 
zu schauen,
was sind eigentlich die latent 
√§hnlichen Faktoren,
was k√∂nnen wir irgendwie 
zusammenfassen und
was sind Faktoren,
die m√∂glichst orthogonal einzeln 
gesehen
unterschiedlich sind und
viel Erkl√§rungsgehalt daf√ºr 
haben
in der Vorhersage,
ob ein Mensch die Technologie 
nutzen wird oder nicht.
Und das haben Sie das Modell, 
was entwickelt haben
letztlich auf ganz viele 
empirische Daten
gelegt und gezeigt,
dass dieses Modell um die 70¬†% 
der Variation darin,
ob Leute mit Technologie 
interagieren, und
Testdaten. Aber Sie haben 
vollkommen recht.
Es sind trotzdem historische 
Daten.
Aber diese Testdaten.
Daher kommt der Name.
Die geben uns zumindest eine 
Idee,
wie gut dieses Modell 
funktionieren sollte.
Angenommen.
Der grundlegende Prozess 
ver√§ndert sich nicht.
Da war noch eine Frage. Hier 
irgendwo.
Genau da. Will ich alle 
Informationen reinschreiben?
K√∂nnte auch.
Wenn man die manchmal sehen 
k√∂nnte,
kann es ja die Interaktionen 
zwischen den
Relationen gar nicht 
einsch√§tzen.
Das schon. Das ist das Coole an 
Machine Learning.
Sorry, wenn ich jetzt happy bin,
aber das ist eins der 
Kernsachen. Das schon. Das ist das Coole an 
Machine Learning.
Sorry, wenn ich jetzt happy bin,
aber das ist eins der 
Kernsachen.
Neuronale Netze haben
eine inh√§rente Struktur 
beispielsweise oder
andere Modelle wie Random 
Forest,
aber auch Gradient Boosting 
Methods.
Die haben eine inh√§rente
M√∂glichkeit, Nichtlinearit√§ten 
zu lernen,
ohne dass ich sie explizit 
spezifiziere,
indem ich einfach genug 
Beispiele reinschmei√üe.
Aber es kann ja nicht f√ºr die 
Zukunft sagen,
wie genau diese Informationen 
genau wiedergegeben werden,
In einer. In einer.
Wir reden jetzt super 
theoretisch,
wenn ich nur die Mathematik",7.236591339,0,"The provided context discusses general machine learning concepts, data preparation, and neural networks but contains no information about the ""Centaur foundation model"" or any specific dataset used for fine-tuning.",1,"All claims in the generated answer are verifiable. The context is generic and discusses machine learning, neural networks, and data preparation, but it contains no specific information about the Centaur model or fine-tuning datasets.",0,"The generated answer incorrectly claims the information is not available, while the ground truth provides the specific name and details of the dataset.",,
In the paper 'A foundation model to predict and capture human cognition' what is the name of the computational model introduced?,Centaur.,"The text refers to a mathematical model of a brain cell called a ""perceptron."" It also mentions a model that explains ""System eins"" and ""System zwei."" However, it doesn't explicitly state a single, overarching name for the computational model being discussed.","10. Juli 2025
A mathematical model of a brain cell: perceptron
10
#ùë¶!=ùëì%""ùë§""‚ãÖùë•""+ùëè
Weighted linear combination of inputsOutput
Non-linearization(activation function) Intercept
Representation   +Evaluation+Optimization Das war eines der fundamentalen 
Ergebnisse,
die Sie hier gefunden haben in 
der Studie.
Und dann Sie haben gesagt okay, 
wenn ich wei√ü,
dass wir die Menschen in
ihrer Kognition √ºberzeugen 
m√ºssen,
dass sie das System nutzen 
sollten und akzeptieren
sollten entweder √ºber System
eins oder √ºber System zwei 
Aktivierungen,
dann lass uns doch mal dr√ºber 
nachdenken,
welche Faktoren denn hier eine 
besondere Rolle spielen.
Und da haben Sie insgesamt in
diesem Modell vier verschiedene 
Faktoren identifiziert.
Einer der Faktoren nennen Sie 
die Performance Expectancy.
Das k√∂nnen Sie sich vorstellen. Modelle
aus ganz unterschiedlichen
Disziplinen zusammengenommen und
haben jahrelang rumgewerkelt, um 
zu schauen,
was sind eigentlich die latent 
√§hnlichen Faktoren,
was k√∂nnen wir irgendwie 
zusammenfassen und
was sind Faktoren,
die m√∂glichst orthogonal einzeln 
gesehen
unterschiedlich sind und
viel Erkl√§rungsgehalt daf√ºr 
haben
in der Vorhersage,
ob ein Mensch die Technologie 
nutzen wird oder nicht.
Und das haben Sie das Modell, 
was entwickelt haben
letztlich auf ganz viele 
empirische Daten
gelegt und gezeigt,
dass dieses Modell um die 70¬†% 
der Variation darin,
ob Leute mit Technologie 
interagieren, die Modellstruktur, die 
Modellauswahl,
sogar die Auswahl der relevanten
Inputinformationen durch 
bestimmte sogenannte
Cross Validation Verfahren durch
die Daten selber identifizieren 
lassen.
Ich hasse diesen Satz,
aber hier passiert dann sehr 
h√§ufig dieses Let
the data speak so wenig anhaben 
wie m√∂glich machen.
Wir versuchen einfach, das beste 
Modell zu finden.
Und auch das sei wieder betont, 
ist fundamental.
Uns geht es darum, ein Modell zu 
finden,
was nicht unsere historischen
Daten so gut es geht erkl√§rt,
sondern sobald das Modell da 
ist,
m√∂chten wir ein Modell haben,
was es uns erm√∂glicht, Modell.
Kommen wir jetzt zur heutigen 
Vorlesung.
Immer mit diesem Gedanken im 
Kopf.
Wir haben Inputdaten, wir haben
ein Modell und dieses Modell
macht auf den Inputdaten 
letztlich uns eine Vorhersage,
die m√∂glichst pr√§zise ist f√ºr 
Daten,
die Sie noch nicht gesehen 
haben.
Fangen wir jetzt wirklich an,
in diesem Teil eins rein zu 
gehen, um zu verstehen,
was k√∂nnen diese Modelle
eigentlich liefern aus einer 
√∂konomischen,
betriebswirtschaftlichen, 
gesellschaftlichen Perspektive?
Wir werden jetzt in den ersten
Vorlesungen und es wird so
bis zur f√ºnften Vorlesung gehen.
Da werden wir langsam anfangen, Wir werden jetzt in den ersten
Vorlesungen und es wird so
bis zur f√ºnften Vorlesung gehen.
Da werden wir langsam anfangen,
auch in den zweiten Teil 
√ºberzugehen.
Aber zun√§chst mal interessiert 
uns gar nicht,
wie wir auf dieses Modell 
kommen,
was dieses Modell genau ist.
Wir werden erstmal annehmen,
da ist irgendein Modell,
das f√§llt sozusagen vom Himmel.
Und was macht dieses Modell mit 
uns?
Was macht dieses Modell mit 
Organisationen?
Was macht dieses Modell mit 
Personen?
Was macht dieses Modell mit der 
Gesellschaft?
Und um so ein bisschen
eine Hands on Vorstellung zu 
haben,
was Machine Learning Modelle",7.387245655,0.2,"The context mentions several computational models, such as a ""perceptron"" [cite: 80] and one that explains ""System eins"" and ""System zwei""[cite: 81], but it does not contain the specific name ""Centaur"" that the question asks for.",1,"All claims in the generated answer are directly supported by the provided context. The context mentions a perceptron and the System 1/2 model, and it's true that no single, overarching model name is given.",0,"The generated answer incorrectly claims that no single name is given for the model and mentions other models like 'perceptron,' while the ground truth provides the specific correct name, 'Centaur.'",,
The paper 'Algorithmic Bias?' concludes that optimizing for what factor can lead to apparently discriminatory outcomes in ad delivery?,An algorithm that simply optimizes for cost-effectiveness.,"According to the paper 'Algorithmic Bias?', limited raw data sets and biased algorithm designers can lead to apparently discriminatory outcomes in the display of stem career ads.","work. However, algorithmic bias results in discriminatory hiring practices based on gender,
race, color, and personality traits. The study indicates that algorithmic bias stems from
limited raw data sets and biased algorithm designers. To mitigate this issue, it is recom-
mended to implement technical measures, such as unbiased dataset frameworks and
improved algorithmic transparency, as well as management measures like internal corporate
ethical governance and external oversight. Employing Grounded Theory, the study conducted
survey analysis to collectÔ¨Årsthand data on respondents‚Äô experiences and perceptions of AI- Conference on Artificial Intelligence and 
Statistics (pp. 166-175).  
Lambrecht, A., & Tucker, C. (2019). Algorithmic 
bias? an empirical study of apparent gender -
based discrimination in the display of stem 
career ads. Management Science, 65(7), 2966-
2981.  
Langer, N., Gopal, R. D., & Bapna, R. (2020). Onward 
and upward? An empirical investigation of 
gender and promotions in Information 
Technology Services. Information Systems 
Research, 31(2), 383-398.  
Leavy, S. (2018). Gender bias in artificial intelligence: 
The need for diversity and gender theory in 
machine learning. Proceedings of the 1st 15. Mai 2025
Consequences of algorithmic biasIndividual consequences include‚Ä¢rejection or discontinuance of ML tools.‚Ä¢customers paying higher prices than usual Organisational consequences include ‚Ä¢violating equal opportunity policies‚Ä¢high customer churn rate Societal-level consequences include ‚Ä¢increased gaps between historically disadvantaged groups and others‚Ä¢Fostered polarization and human discrimination
17 relevant in situations where false negatives have 
significant consequences, such as in healthcare, loan 
approval, hiring, or criminal justice systems. 
Mitigating algorithmic discrimination : The 
expansive literature on algorithmic discrimination 
proposes various methods to identify and alleviate 
such biases. According to d ‚ÄôAlessandro et al. (2017), 
we can divide these mitigation strategies into three 
categories: pre -processing, in -processing, and post -
processing. Pre -processing strategies strive to 
eliminate disparities inherent in the dataset. Methods that nonobjective variables, such as inadequate information,
contribute to biased outcomes (Dickinson and Oaxaca, 2009).
Lastly, we have the antecedent market discrimination hypothesis
as the fourth category.
Statistical discrimination theory. Statistical discrimination refers
to prejudice from assessment criteria that generalize group
characteristics to individuals (Tilcsik, 2021). It arises due to
limitations in employers‚Äôresearch techniques or the cost con-
straint of obtaining information in the asymmetry between
employers and job seekers. Even without monopolistic power, quently, the issue of algorithmic hiring discrimination has
emerged, shifting the focus of statistical discrimination theory
from traditional hiring to intelligent hiring. The mechanisms that
give rise to hiring discrimination problems remain similar, as
both rely on historical data of speciÔ¨Åc populations to predict
future hiring outcomes.
While AI recruiting offers numerous bene Ô¨Åts, it is also
susceptible to algorithmic bias. Algorithmic bias refers to the
systematic and replicable errors in computer systems that lead to
unequally and discrimination based on legally protected char-",6.615876675,1,"The context directly addresses the question. Source [114] explicitly mentions that statistical discrimination can arise from the ""cost constraint of obtaining information,"" which aligns with the concept of optimizing for cost-effectiveness leading to discriminatory outcomes. The context also correctly cites the relevant paper[cite: 103].",1,The generated answer is a direct summary of a claim made in source [100] of the retrieved context.,0,"The generated answer provides general causes of algorithmic bias (limited data, biased designers) but fails to identify the specific factor the paper concluded was the cause: optimizing for cost-effectiveness.",,
"In the context of the STEM career ad study, what was the difference in click behavior between men and women who were shown the ad?","Among those who saw the ad, women were more likely to click on it than men.","According to the paper ""Algorithmic Bias?"", Munson‚Äôs research indicated that ‚Äúoccupational picture search outcomes slightly exaggerate gender stereotypes, portraying minority-gender occupations as less professional.‚Äù This resulted in women clicking on STEM career ads less frequently than men.","Conference on Artificial Intelligence and 
Statistics (pp. 166-175).  
Lambrecht, A., & Tucker, C. (2019). Algorithmic 
bias? an empirical study of apparent gender -
based discrimination in the display of stem 
career ads. Management Science, 65(7), 2966-
2981.  
Langer, N., Gopal, R. D., & Bapna, R. (2020). Onward 
and upward? An empirical investigation of 
gender and promotions in Information 
Technology Services. Information Systems 
Research, 31(2), 383-398.  
Leavy, S. (2018). Gender bias in artificial intelligence: 
The need for diversity and gender theory in 
machine learning. Proceedings of the 1st uences how the algorithm
responds to the data.
Theme III. Which algorithmic recruitment discrimination
exists
In the recruitment process, algorithmic bias can be manifested in
terms of gender, race, color, and personality.
Gender. Gender stereotypes have inÔ¨Åltrated the ‚Äúlexical embed-
ding framework‚Äù utilized in natural language processing (NLP)
techniques and machine learning (ML). Munson ‚Äôs research
indicates that ‚Äúoccupational picture search outcomes slightly
exaggerate gender stereotypes, portraying minority-gender occu-
pations as less professional‚Äù((Avery et al.,2023; Kay et al.,2015). that impact the hiring process. It would be interesting to analyze
the psychological effects of applying this algorithmic recruitment
technique on various populations (gender, age, education level)
from an organizational behavior perspective. While recent studies
have primarily discussed discrimination theory in the traditional
economy‚Äôs hiring market, future theoretical research should
consider how advanced technology affects equity in hiring within
the digital economy.
Conclusion
The study concludes that the fo urth industrial revolution
introduced technological innovations signiÔ¨Åcantly affecting the was based on the belief that the reminder displayed 
after the purchase posed a lower risk of negatively 
impacting sales.
3.1.3. Study Details. We conducted a large-scale, ran -
domized field experiment over seven weeks in our 
industry partner‚Äôs German online shop to test the dual- 
nudge and single-nudge interventions.
2
The study ran -
domly assigned website visitors using stationary 
devices to one of three groups upon their first view of 
the shopping cart: the control group (no nudging), the 
single-nudge group (reminder prompt), or the dual- 
nudge group (cart and reminder prompt). During the according to the trends of other minority or female applicants,
which may differ from the features identi Ô¨Åed as successful
representatives.
Word embedding. Microsoft researchers found that words
exhibit distinct associations in news and web data. For instance,
words like ‚Äúfashion‚Äù and ‚Äúknitting‚Äù are more closely related to
females, while ‚Äúhero‚Äù and ‚Äúgenius‚Äù are more closely related to
males (36KE, 2020). Microsoft suggests a simple solution by
removing the gender-speciÔ¨Åc measures in word embedding to
reduce ‚Äúpresentation bias.‚Äù
Differential testing. Scientists at Columbia University devel- present randomization checks for the predictors in 
Table 5 in Online Appendix A.2.
The initial customer cart and browsing data, including 
product types, quantities added to the cart, and visited 
shop categories, offer valuable insights into customer 
characteristics and preferences. We focus on the catego -
ries ‚ÄúWomen,‚Äù ‚ÄúKids,‚Äù and ‚ÄúSale‚Äù (discounted pro -
ducts). The ‚ÄúWomen‚Äù category likely indicates female 
customers, whereas the ‚ÄúKids‚Äù category suggests infor -
mation about the customer‚Äôs age and family status. Fre -
quent choices from the ‚ÄúSale‚Äù category may indicate",7.732778549,0.2,"The context cites the correct paper [cite: 120] and discusses related themes of gender stereotypes in search results. However, it does not contain the specific empirical finding about the difference in click behavior between men and women who were shown the ad, making it irrelevant for answering the direct question.",0.5,"The first half of the generation is a direct, faithful quote from the context. However, the second half (""This resulted in women clicking on STEM career ads less frequently than men"") is a hallucination; the context does not provide this information or establish this causal link.",0,"The generated answer is factually the opposite of the ground truth. It claims women clicked less frequently, while the ground truth states women were more likely to click.",,
"In the empirical study of gender-based discrimination in STEM ad display, what reason is given for why fewer women saw the advertisement?","Younger women are a prized demographic and are more expensive to show ads to, so a cost-optimizing algorithm shows the ad to them less often.","According to the paper ""Algorithmic Bias?"", the reason given for fewer women seeing the advertisements is that the algorithm perceived candidates with keywords such as ‚Äúfemale‚Äù as less professional.","of success, resulting in discrimination against female applicants
(Langenkamp et al. 2019). The algorithm even downgraded
applicants with keywords such as ‚Äúfemale‚Äù (Faragher, 2019).
These Ô¨Åndings compelled Amazon to withdraw the tool and
develop a new unbiased algorithm. However, this discrimination
was inadvertent, revealing theÔ¨Çaws inherent in algorithmic bias
that perpetuates existing gender inequalities and social biases
(O‚Äôneil, 2016).
Race. Microsoft‚Äôs chatbot Tay learned to produce sexist and racist
remarks on Twitter. By interacting with users on the platform, Conference on Artificial Intelligence and 
Statistics (pp. 166-175).  
Lambrecht, A., & Tucker, C. (2019). Algorithmic 
bias? an empirical study of apparent gender -
based discrimination in the display of stem 
career ads. Management Science, 65(7), 2966-
2981.  
Langer, N., Gopal, R. D., & Bapna, R. (2020). Onward 
and upward? An empirical investigation of 
gender and promotions in Information 
Technology Services. Information Systems 
Research, 31(2), 383-398.  
Leavy, S. (2018). Gender bias in artificial intelligence: 
The need for diversity and gender theory in 
machine learning. Proceedings of the 1st pations as less professional‚Äù((Avery et al.,2023; Kay et al.,2015).
The impact of gender stereotypes on AI hiring poses genuine
risks (Beneduce,2020). In 2014, Amazon developed an ML-based
hiring tool, but it exhibited gender bias. The system did not
classify candidates neutrally for gender (Miasato and Silva,2019).
The bias stemmed from training the AI system on predominantly
male employees ‚Äô CVs (Beneduce, 2020). Accordingly, the
recruitment algorithm perceived this biased model as indicative
of success, resulting in discrimination against female applicants
(Langenkamp et al. 2019). The algorithm even downgraded uences how the algorithm
responds to the data.
Theme III. Which algorithmic recruitment discrimination
exists
In the recruitment process, algorithmic bias can be manifested in
terms of gender, race, color, and personality.
Gender. Gender stereotypes have inÔ¨Åltrated the ‚Äúlexical embed-
ding framework‚Äù utilized in natural language processing (NLP)
techniques and machine learning (ML). Munson ‚Äôs research
indicates that ‚Äúoccupational picture search outcomes slightly
exaggerate gender stereotypes, portraying minority-gender occu-
pations as less professional‚Äù((Avery et al.,2023; Kay et al.,2015). that at the maximum label imbalance (x-axis), the share 
of positive predictions (y-axis) for women increases from 
0% in Iterations 1 (left panel) to 22% in Iteration 100 
(right panel) if there is no human discrimination (z-axis). 
However, this growth is significantly curtailed, reaching 
merely 1.2%, 6.9%, 14.3% under very high, high, and 
medium human discrimination, respectively. 
Conversely, human discrimination against women does 
not alter the share of positive predictions for male 
borrowers (see Figure A7 in the Appendix), regardless of 
the initial label imbalance. For example, at maximum according to the trends of other minority or female applicants,
which may differ from the features identi Ô¨Åed as successful
representatives.
Word embedding. Microsoft researchers found that words
exhibit distinct associations in news and web data. For instance,
words like ‚Äúfashion‚Äù and ‚Äúknitting‚Äù are more closely related to
females, while ‚Äúhero‚Äù and ‚Äúgenius‚Äù are more closely related to
males (36KE, 2020). Microsoft suggests a simple solution by
removing the gender-speciÔ¨Åc measures in word embedding to
reduce ‚Äúpresentation bias.‚Äù
Differential testing. Scientists at Columbia University devel-",6.516428232,0.1,"The context cites the correct paper but provides information about a different study (Amazon's hiring tool) where applicants were downgraded for keywords like ""female""[cite: 139]. It does not contain the specific reason from the STEM ad paper, which is related to the advertising cost of different demographics.",0,The generated answer incorrectly applies a finding from a different case mentioned in the context (Amazon's hiring tool) to the specific study asked about in the question (the STEM ad display study). The context does not state that this was the reason given in the STEM ad paper.,0,"The generated answer provides a completely incorrect reason for the phenomenon. The ground truth states the reason is the high cost of advertising to younger women, while the generation incorrectly claims it's due to the perception of keywords.",,
"Regarding the display of STEM career ads, what was the empirical result of the ad's delivery in the 'Algorithmic Bias?' paper?",Fewer women saw the ad than men.,"According to the provided text, the empirical result of the ad delivery in the ‚ÄúAlgorithmic Bias?‚Äù paper was that apparent gender-based discrimination was observed in the display of STEM career ads. Specifically, the study found that female applicants were less likely to see ads for STEM careers compared to male applicants.","Conference on Artificial Intelligence and 
Statistics (pp. 166-175).  
Lambrecht, A., & Tucker, C. (2019). Algorithmic 
bias? an empirical study of apparent gender -
based discrimination in the display of stem 
career ads. Management Science, 65(7), 2966-
2981.  
Langer, N., Gopal, R. D., & Bapna, R. (2020). Onward 
and upward? An empirical investigation of 
gender and promotions in Information 
Technology Services. Information Systems 
Research, 31(2), 383-398.  
Leavy, S. (2018). Gender bias in artificial intelligence: 
The need for diversity and gender theory in 
machine learning. Proceedings of the 1st work. However, algorithmic bias results in discriminatory hiring practices based on gender,
race, color, and personality traits. The study indicates that algorithmic bias stems from
limited raw data sets and biased algorithm designers. To mitigate this issue, it is recom-
mended to implement technical measures, such as unbiased dataset frameworks and
improved algorithmic transparency, as well as management measures like internal corporate
ethical governance and external oversight. Employing Grounded Theory, the study conducted
survey analysis to collectÔ¨Årsthand data on respondents‚Äô experiences and perceptions of AI- The study concludes that the fo urth industrial revolution
introduced technological innovations signiÔ¨Åcantly affecting the
recruitment industry. It extends the analysis of statistical dis-
crimination theory in the digital age and adopts a literature
review approach to explore four themes related to AI-based
recruitment. The study argues that algorithmic bias remains an
issue while AI recruitment tools offer beneÔ¨Åts such as improved
recruitment quality, cost reduction, and increased ef Ô¨Åciency.
Recruitment algorithms ‚Äôbias is evident in gender, race, color, algorithmic hiring. This study contends that resolving algorithmic
discrimination in recruitment requires technical solutions and the
implementation of internal ethical governance and external
regulations.
The subsequent study is structured intoÔ¨Åve parts. The Ô¨Årst
section provides the theoretical background for this research. The
following section outlines the research methodology employed in
the literature review and identiÔ¨Åes four key themes. The third
section delves into a detailed discussion of these four themes:
applications and beneÔ¨Åts of AI-based recruitment, factors con- that impact the hiring process. It would be interesting to analyze
the psychological effects of applying this algorithmic recruitment
technique on various populations (gender, age, education level)
from an organizational behavior perspective. While recent studies
have primarily discussed discrimination theory in the traditional
economy‚Äôs hiring market, future theoretical research should
consider how advanced technology affects equity in hiring within
the digital economy.
Conclusion
The study concludes that the fo urth industrial revolution
introduced technological innovations signiÔ¨Åcantly affecting the quently, the issue of algorithmic hiring discrimination has
emerged, shifting the focus of statistical discrimination theory
from traditional hiring to intelligent hiring. The mechanisms that
give rise to hiring discrimination problems remain similar, as
both rely on historical data of speciÔ¨Åc populations to predict
future hiring outcomes.
While AI recruiting offers numerous bene Ô¨Åts, it is also
susceptible to algorithmic bias. Algorithmic bias refers to the
systematic and replicable errors in computer systems that lead to
unequally and discrimination based on legally protected char-",8.212214231,1,"The context directly cites the paper in question [cite: 158] and its title, ""Algorithmic bias? an empirical study of apparent gender-based discrimination in the display of stem career ads,"" which directly supports the answer that fewer women saw the ad.",0.5,"The first claim, that the result was ""apparent gender-based discrimination,"" is faithful as it is directly stated in the paper's title cited in the context [158]. The second, more specific claim that ""female applicants were less likely to see ads"" is an inference not explicitly stated in the provided text.",1,"The generated answer captures the essential fact of the ground truth, stating that fewer women saw the ad compared to men. The answers are semantically consistent.",,
"In the study on gender-based discrimination in STEM career ads, what was the explicit intention for the ad's delivery?",The ad was explicitly intended to be gender-neutral in its delivery.,"According to the text, the explicit intention of the ad‚Äôs delivery in the ‚ÄúAlgorithmic Bias?‚Äù paper was to conduct an ‚Äúempirical study of apparent gender-based discrimination in the display of STEM career ads.‚Äù (Lambrecht & Tucker, 2019).","15. Mai 2025
Algorithmic bias
Algorithmic bias: outputs of an algorithm benefit or disadvantage certain individuals or groupsmore than others without a justified reasonfor such unequal impacts ‚Ä¢Ethical concern is the replication and reinforcement of social biasesthat exist in society‚Ä¢Algorithmic bias is a socio-technical constructthat involves technology and human actors‚Ä¢Social aspect: biases that have long existed in society‚Ä¢Technical facet: the manifestation of social biases in models‚Äô outcomes
14 Conference on Artificial Intelligence and 
Statistics (pp. 166-175).  
Lambrecht, A., & Tucker, C. (2019). Algorithmic 
bias? an empirical study of apparent gender -
based discrimination in the display of stem 
career ads. Management Science, 65(7), 2966-
2981.  
Langer, N., Gopal, R. D., & Bapna, R. (2020). Onward 
and upward? An empirical investigation of 
gender and promotions in Information 
Technology Services. Information Systems 
Research, 31(2), 383-398.  
Leavy, S. (2018). Gender bias in artificial intelligence: 
The need for diversity and gender theory in 
machine learning. Proceedings of the 1st data already reÔ¨Çects social prejudices, and the algorithm also
incorporates biased relationships, leading to the‚Äúbias in and bias
out‚Äù phenomenon (36KE, 2020). This phenomenon means that
discrimination and disparities exist, just like in forecasting, where
historical inequalities are projected into the future and may even
be ampliÔ¨Åed (Mayson, 2018).
A research team at Princeton University discovered that
algorithms lack access to the absolute truth. The machine corpus
contains biases that closely resemble the implicit biases observed
in the human brain. ArtiÔ¨Åcial intelligence has the potential to uences how the algorithm
responds to the data.
Theme III. Which algorithmic recruitment discrimination
exists
In the recruitment process, algorithmic bias can be manifested in
terms of gender, race, color, and personality.
Gender. Gender stereotypes have inÔ¨Åltrated the ‚Äúlexical embed-
ding framework‚Äù utilized in natural language processing (NLP)
techniques and machine learning (ML). Munson ‚Äôs research
indicates that ‚Äúoccupational picture search outcomes slightly
exaggerate gender stereotypes, portraying minority-gender occu-
pations as less professional‚Äù((Avery et al.,2023; Kay et al.,2015). ).
Theme II. Why is there algorithmic recruitment
discrimination
Algorithms are not inherently discriminatory, and engineers
rarely intentionally introduce bias into algorithms. However, bias
can still arise in algorithmic recruitment. This issue is closely
linked to the fundamental technology behind AI and ML. The ML
process can be simpliÔ¨Åed into several stages, each involving three
key components contributing to algorithmic bias: dataset con-
struction, the engineer‚Äôs target formulation, and feature selection
(36KE, 2020). When the dataset lacks diverse representation from labels. If inappropriate goals are set, bias may be introduced from
the outset (36KE,2020).
An engineer is responsible for developing the algorithmic model.
If they hold certain beliefs and preconceptions, those personal
biases can be transmitted to the machine (Njoto,2020). Although
the device is responsible for selecting employee resumes, it operates
based on underlying programming. The programmer guides the AI
in making decisions about the best candidate, which can still result
in discrimination (Miasato and Silva,2019).
Furthermore, personal biases can manifest in the selection of",7.52754879,0,"The context fails to mention the explicit intention for the ad's delivery. The ground truth is that the ad was intended to be gender-neutral, but the context does not contain this information.",0,"The generation completely misinterprets the context. It presents the title of the research paper as the ""explicit intention"" of the ad's delivery, which is incorrect. The context does not state what the advertiser's intention was.",0,The generated answer completely misrepresents the intention. It confuses the goal of the research paper (to study discrimination) with the advertiser's intention for the ad's delivery (to be gender-neutral).,,
The findings of the 'Feeback Loops in Machine Learing' paper underscore the complex nature of algorithmic discrimination as what kind of phenomenon?,A sociotechnological phenomenon.,"According to the text, the findings highlight algorithmic discrimination as a ‚Äúbias in and bias out‚Äù phenomenon, where existing social prejudices are incorporated into the algorithm, and the algorithm then amplifies those biases through feedback loops.","Feedback Loops in Machine Learning 
 
807 
2.1 Algorithmic Discrimination 
Algorithmic discrimination: Discrimination involves 
statements or actions that unjustifiably disadvantage 
members of particular social groups. These actions 
typically stem from conscious or subconscious attitudes, 
prejudices, or emotional associations tied to 
characteristics such as  gender, age, disability, race, 
language, religion, or sexual identity (Scherr, 2008). In 
today‚Äôs era, where algorithmic systems based on ML 
models frequently aid human decisions, researchers and 
practitioners often employ the te rm ‚Äúalgorithmic discrimination (Favaretto et al., 2019; Kordzadeh & 
Ghasemaghaei, 2022). The social component often 
originates from societal and economic structural biases, 
which can foster the differential treatment and 
marginalization of certain groups. On the other hand, the 
technological element emanates from the perpetuated 
discriminatory behaviors of algorithmic systems. 
Algorithmic feedback loops: Feedback loops play a 
significant role in algorithmic discrimination in the 
context of continuously updated ML models. These loops 
arise when the outcomes of algorithmic decisions provide Feedback Loops in Machine Learning 
 
815 
 
Note: Panel (i) illustrates outcomes where the initial label imbalance for the minority class was at the maximum, whereas Panel (ii) corresponds 
to conditions with no initial label imbalance 
Figure 4. Progression of the Mean Share of Positive Predictions and False-Negative Error Rates  
across Iterations, Differentiated by Gender over Time 
4.1 Continuous Updating and 
Algorithmic Discrimination 
Figure 4 illustrates the temporal evolution of mean 
shares of positive predictions and false-negative errors 
in the absence of human discrimination . We present updating remains an underexplored area in the literature.  
Second, our paper complements the nascent body of 
studies exploring the origins and impacts of 
algorithmic feedback loops (Burghardt & Lerman, 
2022; Cowgill, 2018). For instance, Lum and Isaac 
(2016) revealed that the iterative updates of a 
predictive poli cing system led to increased 
discrimination against minority groups. Similarly, 
Ensign et al. (2017) showed how feedback loops could back into the model as new training data may 
compound the system‚Äôs discrimination, engendering a 
cycle of persistent discrimination (Silva & Kenney, 
2019; Williams et al., 2018). Such feedback loops have 
been discussed in various domains, such as hiring, 
policing, and recidivism decisions (e.g., Hoffman et al., 
2018; Kleinberg et al., 2018; Ensign et al., 2017; 
Cowgill, 2018). 
Measuring algorithmic discrimination: A considerable 
body of work in information systems (IS) and computer 
science focuses on creating methods to measure 
algorithmic discrimination (see, for example, Hardt et al., data already reÔ¨Çects social prejudices, and the algorithm also
incorporates biased relationships, leading to the‚Äúbias in and bias
out‚Äù phenomenon (36KE, 2020). This phenomenon means that
discrimination and disparities exist, just like in forecasting, where
historical inequalities are projected into the future and may even
be ampliÔ¨Åed (Mayson, 2018).
A research team at Princeton University discovered that
algorithms lack access to the absolute truth. The machine corpus
contains biases that closely resemble the implicit biases observed
in the human brain. ArtiÔ¨Åcial intelligence has the potential to",6.99853611,1,"The context explicitly states that the paper's findings ""underscore the sociotechnological nature of algorithmic discrimination""[cite: 231], which directly answers the question.",1,"The generated answer is faithful, as it accurately identifies the ‚Äúbias in and bias out‚Äù phenomenon mentioned in the context [210]. This is a verifiable claim from the provided text.",1,"The generated answer and the ground truth are semantically equivalent, both identifying the issue as a sociotechnological phenomenon.",,
What type of setting was used in the simulations of the 'Feedback Loops in Machine Learning' paper to examine the ML model's evolution?,"A setting that mirrors sequential interactions, such as loan approval decisions.","Yes, that‚Äôs correct. According to the provided text, the simulations were conducted ‚Äúusing comprehensive simulations based on secondary empirical data, we examine the dynamic evolution of an ML model ‚Äôs fairness and economic consequences in a setting that mirrors sequential interactions, such as loan approval decisions.‚Äù","Feedback Loops in Machine Learning 
 
811 
3.2 Previous Empirical Studies 
We buil t our simulations on two secondary datasets, 
collected by several authors of this paper as part of 
different empirical studies. Study A was an incentivized 
field study conducted over three years from 2016 to 
2019. Study A measured participant s‚Äô behavior in the 
investment game  defined above  in their  role as 
borrowers. The data from Study A allow ed us to 
develop an ML model predicting borrowers‚Äô repayment 
decision and serves as the foundation for simulating 
borrower behavior. Study B, conducted in December Feedback Loops in Machine Learning 
 
813 
Armed with this information, the investor decided 
whether to invest. Notably, in our simulation , we 
mimicked investor decisions using a trained model (see 
below for more information). If an investment was 
made, the borrower decided on repayment, and a new 
observation encapsulating a borrower‚Äôs specific 
personal traits (features) and actual repayment decision 
(label) was appended to the dataset used to train the ML 
model predicting repayment. 
Importantly, to avoid inappropriate overfitting and 
spillover effects, this observation was only included if Feedback Loops in Machine Learning 
 
805 
generate predictions (Parisi et al., 2019). However, in 
dynamic, nonstationary environments, the underlying 
data-generating process that ML models aim to 
approximate can change over time. This phenomenon, 
referred to as drift (Lu et al., 2018), can lead to  
progressively poorer predictions. The decrease in 
prediction performance can originate from changes in 
the underlying relationship between the input features 
and the target variable ‚Äîconcept drift (Widmer & 
Kubat, 1996)‚Äîor changes in the distributions of t he Feedback Loops in Machine Learning 
 
859 
Appendix C: Technical Details on Simulation 
C.1 Details on the Repayment-Predicting ML Model in Simulations 
To gain insights into the determinants of the predictions of the ML model that aims to forecast whether borrowers will 
make a repayment, we use the popular SHAP (Shapley additive explanations) explainability method (Lundberg & Lee, 
2017). Notably, we show results for the models ‚Äô behaviors before any updating takes place. SHAP is inspired by 
cooperative game theory explaining individual predictions by assuming that each feature value of the instance is a availability of this data point for future model updates and potentially affecting the model ‚Äôs 
performance. This paper delves into the relationship between the continuous updating of ML models 
and algorithmic discrimination in environments where predictions endogenously influence the 
creation of new training data. Using comprehensive simulations based on secondary empirical data, 
we examine the dynamic evolution of an ML model ‚Äôs fairness and economic consequences in a 
setting that mirrors sequential interactions, such as loan approval decisions. Our findings indicate context of continuously updated ML models. These loops 
arise when the outcomes of algorithmic decisions provide 
new endogenous training data for subsequent model 
updates (Cowgill, 2018). Such loops iteratively weave 
together the social environment ‚Äôs outcomes and the 
technical performance of the algorithmic output. For 
instance, take the loan approval process depicted in 
 
1 Since the biased or disparate treatment of particular groups 
typically yields discrimination and unfairness, researchers 
often use the terms algorithmic bias, algorithmic 
Figure 1. If an ML model‚Äôs prediction of creditworthiness",7.86926198,1,"The context directly answers the question, stating that the study examines the ML model's evolution ""in a setting that mirrors sequential interactions, such as loan approval decisions""[cite: 224].",1,"The generated answer is a direct quote from the provided context [224], making it entirely faithful.",1,"The generated answer correctly identifies that the simulations used a setting mirroring sequential interactions like loan approval decisions, which is semantically identical to the ground truth.",,
What is the key finding regarding the continuous updating of ML models?,Continuous updating can help mitigate algorithmic discrimination and enhance economic efficiency over time.,"That‚Äôs not entirely accurate. According to the text, the key finding is that continuous updating of ML models *loses its ability to mitigate algorithmic discrimination and improve economic efficiency when human decision makers who use ML predictions as decision support continue to discriminate against the minority class (female borrowers).*

The text describes a feedback loop where biases can be incorporated and amplified, but it doesn‚Äôt frame it as a simple ‚Äúbias in and bias out‚Äù phenomenon. It highlights the crucial role of human decision-makers in perpetuating or correcting biases within the continuously updating models.","dynamic consequences of continuously updating ML 
models in the presence of algorithmic and human 
discrimination. We highlight that continuous updating, 
absent enduring human discrimination, may stimulate  
self-correcting mechanisms. Theoretically, our findings 
underscore the sociotechnological nature of algorithmic 
discrimination. We extend the existing literature by 
revealing how algorithmic discrimination can diminish 
or emerge due to the interaction bet ween ML systems 
and human users in environments where continuous ly 
updating ML models is essential. We f ound evidence making over time. 
Result 2: The continuous updating of ML models loses 
its ability to mitigate algorithmic discrimination 
and improve economic efficiency when human 
decision makers who use ML predictions as 
decision support continue to discriminate against 
the minority class (female borrowers).  
5 Discussion and Conclusion 
5.1 Summary of Main Findings  
Drawing on extensive simulations, our paper 
demonstrates that the continuous updating of machine 
learning (ML) models, based on data they 
endogenously help generate, can enhance 
performance, alleviate algorithmic discrimination, and context of continuously updated ML models. These loops 
arise when the outcomes of algorithmic decisions provide 
new endogenous training data for subsequent model 
updates (Cowgill, 2018). Such loops iteratively weave 
together the social environment ‚Äôs outcomes and the 
technical performance of the algorithmic output. For 
instance, take the loan approval process depicted in 
 
1 Since the biased or disparate treatment of particular groups 
typically yields discrimination and unfairness, researchers 
often use the terms algorithmic bias, algorithmic 
Figure 1. If an ML model‚Äôs prediction of creditworthiness continuously updated, the behavior of human decision  
makers who observe ML predictions but have the final 
say may be a crucial factor in understanding and 
potentially even anticipating persistent algorithmic 
discrimination. Biases in human decision-making may 
directly influence the behavior of continuously 
updated ML models. While modern machine learning 
models inherently possess the capability to  ‚Äúunlearn‚Äù 
initial biases over time given sufficiently diverse and 
unbiased data, human bias es can impede this process. 
This insight is especially relevant in the current era of temporal progression and economic implications of 
algorithmic discrimination in scenarios involving 
continuous ML model updating, an area lacking 
comprehensive empirical investigation (Kordzadeh & 
Ghasemaghaei, 2022). Grasping this dynamic is critical, 
as many ML models might degrade over time‚Äîdue, for 
example, to concept or data drifts, which respectively 
reflect fundamental shifts in the latent data -generating 
process and the distribution of incoming data (Lu et al., 
2018)‚Äînecessitating continuous updating based on 
newly collected data. We provide a more comprehensive Implications  
Our study responds to recent calls for empirical 
investigations into the sociotechnological nature of 
algorithmic discrimination in environments where ML 
models continue to learn based on data they help to 
generate (e.g., Kordzadeh & Ghasemaghaei, 2022; 
Dolata et al., 2022). Our results highlight the vital role 
of continuously updating ML models in the evolution 
of algorithmic discrimination over time. We provide 
empirical evidence that modern ML models, initially 
producing biased outcomes due to imbalances  in the 
training data, can self -correct if they regularly receive",12.9834516,1,"The context directly addresses the key finding. Source [233] explicitly states that the ability of continuous updating to mitigate discrimination is lost when human decision-makers continue to discriminate. This provides the nuanced answer required, making the context perfectly relevant.",1,"All claims in the generated answer are directly supported by the context. The key finding is explicitly stated [233], and the context clarifies that the concept is more complex than a simple ‚Äúbias in and bias out‚Äù phenomenon by highlighting the role of human decision-makers [229].",0,"The generated answer is the opposite of the ground truth. The generation claims continuous updating loses its ability to mitigate discrimination when humans are biased, while the ground truth states that continuous updating *helps* mitigate discrimination.",,
How do ML models endogenously shape their future training data?,"By influencing human decisions, which then generate new data points (or a lack thereof) for future model training.","According to the text, ML models endogenously shape their future training data through the following process:

1.  **Predictions Influence Data Availability:** When an ML model makes a prediction (like rejecting a loan application), it affects the data that becomes available for future training. For example, if a loan application is rejected, the bank doesn't record the applicant's actual creditworthiness, removing that data point.

2.  **Concept Drift:** If the initial ML model is inaccurate, and human decision-makers (like loan officers) continue to make decisions based on those predictions, they can introduce bias. This bias shifts the composition of the training data, leading to a ""concept drift"" where the model progressively becomes less biased as it updates with new data influenced by those biased decisions.

In essence, the model‚Äôs predictions, combined with human actions based on those predictions, create a feedback loop that shapes the data it learns from over time.","4Goethe University Frankfurt, Germany, kosfeld@econ.uni-frankfurt.de  
 
Abstract 
Machine learning (ML) models often endogenously shape the data available for future updates. This 
is important because of their role in influencing human decisions, which then generate new data 
points for training. For instance, if an ML prediction results in the rejection of a loan application, the 
bank forgoes the opportunity to record the applicant‚Äôs actual creditworthiness, thereby impacting the 
availability of this data point for future model updates and potentially affecting the model ‚Äôs applicants would have repaid the loan‚Äîa vital piece of 
information required for model updating. This 
endogenous composition of future training data, a 
problem referred to as selective labeling (Lakkaraju et 
al., 2017; Little & Rubin, 2019), can maintain or even 
exacerbate inaccurate or discriminatory predictions. 
In this paper, we explore the dynamic interplay 
between the continuous updating of ML models and 
algorithmic discrimination when ML predictions 
endogenously shape the composition of additional data 
available for model updating. In particular, our work availability of this data point for future model updates and potentially affecting the model ‚Äôs 
performance. This paper delves into the relationship between the continuous updating of ML models 
and algorithmic discrimination in environments where predictions endogenously influence the 
creation of new training data. Using comprehensive simulations based on secondary empirical data, 
we examine the dynamic evolution of an ML model ‚Äôs fairness and economic consequences in a 
setting that mirrors sequential interactions, such as loan approval decisions. Our findings indicate used to train the ML model. This enriched training data 
is used to periodically update the ML model. 
Subsequent lending decisions rely on the prediction of 
the upd ated ML model for decision support. In our 
simulation, we introduce d initial algorithmic 
discrimination by the ML model and persistent 
discrimination against female applicants by the loan 
officers exogenously.  
In essence, our simulations indicate that the continuous 
updating of ML models using endogenously generated 
data enables the model to ‚Äúunlearn‚Äù existing algorithmic 
discrimination and boost economic efficiency over time. endogenously help generate, can enhance 
performance, alleviate algorithmic discrimination, and 
boost the economic efficiency of ML models initially 
grappling with label imbalances in the original training 
dataset. The ability for self -correction inversely 
depends on the degree of initial label imbalance: the 
more biased the ML model ‚Äôs predictions are at the 
outset, the le ss capacity it has for recovery through 
continuous updating over time. Crucially, our research 
indicates that persistent discrimination by humans ‚Äî
who make the final decisions in ML-supported tasks‚Äî a data -generating process distinct from subsequent 
simulation iterations, then the ML model‚Äôs bias against 
women essentially emerges from a concept dri ft 
(Widmer & Kubat, 1996). This means the initial ML 
model approximates a once-accurate but now outdated 
data-generating process. The observed feedback loop, 
where the ML model progressively becomes less 
biased, then demonstrates its ability to overcome 
concept drifts when updated with new training data it 
influences. Conversely, persistent human 
discrimination shifts the training data ‚Äôs gender 
composition, increasingly diverging from the borrower",15.66564131,1,"The context provides a direct and clear explanation, stating that ML models influence ""human decisions, which then generate new data points for training""[cite: 249]. It gives the specific example of a rejected loan application, where the applicant's actual creditworthiness is not recorded, thus shaping the future training data[cite: 250].",0.5,"The first claim about predictions influencing data availability is faithful [245]. However, the explanation of ""Concept Drift"" [247] is incorrect and not supported by the context. The context defines concept drift as a change in the relationship between input and target variables [262-263], not as a process where a model becomes less biased.",1,"Both the generated answer and the ground truth explain the same core concept: the model's predictions influence human decisions, which in turn determines what data becomes available for future training. They are semantically consistent.",,
What effect can human decision-makers have on the self-correction of discriminatory models when they are kept in the loop?,Human decision-makers in the loop may impede the self-correction of discriminatory models and can even cause initially unbiased models to become discriminatory over time.,"According to the text, human decision-makers in the loop can impede the self-correction of discriminatory models and even induce initially unbiased models to become discriminatory over time. This happens because their ongoing discriminatory practices interfere with the model‚Äôs ability to learn and correct itself.","setting that mirrors sequential interactions, such as loan approval decisions. Our findings indicate 
that continuous updating can help mitigat e algorithmic discrimination and enhance economic 
efficiency over time. Importantly, we provide evidence that human decision makers in the loop who 
possess the authority to override ML predictions may impede the self -correction of discriminatory 
models and even induce initially unbiased models to become discriminatory with time. These 
findings underscore the complex sociotechnological nature of algori thmic discrimination and data enables the model to ‚Äúunlearn‚Äù existing algorithmic 
discrimination and boost economic efficiency over time. 
However, this self-correcting mechanism suffers under 
the influence of ongoing discrimination by the human 
decision maker in the loop. Notably, this enduring 
human discrimination can even adversely affect the 
fairness of initially unbiased models, as they effectively 
adopt biased human behaviors. 
Our primary contribution resides in illuminating the 
dynamic consequences of continuously updating ML 
models in the presence of algorithmic and human individuals engage in discriminatory practices and the 
models update continuously, there is a risk of 
unintentionally perpetuating or amplifying algorithmic 
discrimination, as human discrimination hinders the self-
correcting capacities of ML models. Therefore, in 
conjunction with these regulations, we advocate 
measures aimed at identifying and mitigating 
(subconscious) discriminatory practices by 
organizational decision makers. These measures could 
serve as essential complementary elements to ensure that 
continuously updated ML models demonstrate desirable 
behaviors when organizations implement regulatory indicates that persistent discrimination by humans ‚Äî
who make the final decisions in ML-supported tasks‚Äî
significantly impedes the self -correction abilities 
associated with the continuous updating of ML 
models. Our findings even suggest that ongoing human 
discrimination can lead ML models, originally trained 
on balanced data and demonstrating no algorithmic 
discrimination, to exhibit increasingly discriminatory 
behavior over time. 
5.2 Theoretical Contributions and 
Implications  
Our study responds to recent calls for empirical 
investigations into the sociotechnological nature of includes the degree of the system ‚Äôs initial bias and, 
perhaps more importantly, the persistence of biased 
decision-making by humans in the loop. We found that 
the greater the extent of human discrimination in a 
dynamic system where ML models are continuously 
updated, the less likely it is that self-correcting 
mechanisms will occur . We even observe d that 
unbiased models learn biased behaviors from humans 
over time. This happens because humans interfere with 
the endogenous creation of new observations, further 
reducing the chance that the existing training data can enhance economic efficiency over time. The self -
correction capabilities are contingent on the degree 
of the initial level of algorithmic discrimination.  
Despite our findings suggesting that the continuous 
updating of the ML model reduces algorithmic 
discrimination and enhances economic efficiency, a 
pivotal question remains: If human decision makers who 
use the ML prediction as a decision aid continue to 
discriminate against women, would the ML model learn 
to perpetuate these discriminatory patterns under 
continuous updating? If this were to prove true, continuous",7.618781805,1,"The context directly and repeatedly answers the question. For instance, source [268] states that human decision-makers ""may impede the self-correction of discriminatory models and even induce initially unbiased models to become discriminatory with time.""",1,"All claims in the generated answer are directly supported by the provided context. The context states that human decision-makers can ""impede the self-correction of discriminatory models and even induce initially unbiased models to become discriminatory with time"" [268] because their discriminatory practices interfere with the model's learning process [279].",1,"The generated answer and the ground truth are semantically identical, both stating that human decision-makers can impede the self-correction of discriminatory models.",,
What is a key challenge with opaque algorithmic designs in recruitment?,"They hinder the detection and correction of biases, making it difficult for HR teams to ensure equitable hiring.","According to the provided text, a key challenge with opaque algorithmic designs in recruitment is that they can perpetuate existing biases or introduce new ones based on the data they are fed. The text doesn't detail *how* this happens, but it highlights the risk of bias stemming from unbalanced datasets and the influence of engineer‚Äôs target formulation and feature selection.",").
Theme II. Why is there algorithmic recruitment
discrimination
Algorithms are not inherently discriminatory, and engineers
rarely intentionally introduce bias into algorithms. However, bias
can still arise in algorithmic recruitment. This issue is closely
linked to the fundamental technology behind AI and ML. The ML
process can be simpliÔ¨Åed into several stages, each involving three
key components contributing to algorithmic bias: dataset con-
struction, the engineer‚Äôs target formulation, and feature selection
(36KE, 2020). When the dataset lacks diverse representation from algorithmic hiring. This study contends that resolving algorithmic
discrimination in recruitment requires technical solutions and the
implementation of internal ethical governance and external
regulations.
The subsequent study is structured intoÔ¨Åve parts. The Ô¨Årst
section provides the theoretical background for this research. The
following section outlines the research methodology employed in
the literature review and identiÔ¨Åes four key themes. The third
section delves into a detailed discussion of these four themes:
applications and beneÔ¨Åts of AI-based recruitment, factors con- in its decision-making, a mistake known as algorithmic bias
(Jackson, 2021).
AI-based recruitment stage. The recruitment procedure is a series
of events that may be divided into four signi Ô¨Åcant steps:
searching, screening, interviewing, and selection (Bogen and
Rieke, 2018). Each phase includes various activities, and artiÔ¨Åcial
intelligence technology can inÔ¨Çuence the execution of each stage.
The searching phase aims at a system for searching web
content. It screens passive job applicants online through social
media and recruitment platforms, analyzing their pro Ô¨Åles Recruitment algorithms ‚Äôbias is evident in gender, race, color,
and personality. The primary source of algorithmic bias lies in
partial historical data. The personal preferences of algorithm
engineers also contribute to algorithmic bias. Technical mea-
sures like constructing unbiased datasets and enhancing
Table 3 Summary of nodes and reference points at all levels after coding of interview data.
Level 3 nodes Level 2 nodes Level 1 nodes Number of
sources
Number of coding
reference points
AI-driven recruitment
application
Sourcing Online review of job applicants 4 4
Analysis of personal data 3 4 uences how the algorithm
responds to the data.
Theme III. Which algorithmic recruitment discrimination
exists
In the recruitment process, algorithmic bias can be manifested in
terms of gender, race, color, and personality.
Gender. Gender stereotypes have inÔ¨Åltrated the ‚Äúlexical embed-
ding framework‚Äù utilized in natural language processing (NLP)
techniques and machine learning (ML). Munson ‚Äôs research
indicates that ‚Äúoccupational picture search outcomes slightly
exaggerate gender stereotypes, portraying minority-gender occu-
pations as less professional‚Äù((Avery et al.,2023; Kay et al.,2015). Theme IV. How decreasing algorithmic recruitment
discrimination
Changes should be made at the technical and regulatory levels to
ensure that AI algorithms do not replicate existing biases or
introduce new ones based on the provided data (Raub,2018).
Building fair algorithms from a technical perspective
Constructing a more unbiased dataset. Unfair datasets are the root
cause of bias. Therefore, a direct approach to addressing algo-
rithmic bias is reconÔ¨Åguring unbalanced datasets. Using multiple
data points can yield more accurate results while carefully elim-
inating data points that re Ô¨Çect past biases. However, this",8.049834013,0.4,"The context explains the sources of algorithmic bias in recruitment (e.g., dataset construction, feature selection) [cite: 286] but does not explicitly mention the challenge of ""opacity"" or how it hinders the detection and correction of these biases.",0.8,"The generation claims the challenge is that opaque designs can perpetuate or introduce new biases, which is supported by the context [301]. It also correctly identifies that the context mentions this risk stems from unbalanced datasets and feature selection [286]. The only unfaithful part is the claim that the text ""doesn't detail *how* this happens,"" when the text does provide some detail on the 'how' (e.g., dataset construction).",0.5,"The generated answer identifies a related but different challenge (perpetuating existing biases). It fails to mention the core issue from the ground truth, which is that opacity hinders the *detection and correction* of these biases, making it difficult for teams to ensure fairness.",,
"According to some studies cited, what are two benefits of AI-supported recruitment?",It can reduce costs and save time.,"According to the provided text, two benefits of AI-supported recruitment are:

1.  It can reduce costs.
2.  It can save time.","studies point out that AI-supported recruitment has
beneÔ¨Åts. Beattie et al. (2012), Newell (2015), Raub (2018),
Miasato and Silva (2019), Beneduce (2020), and Johnson
et al. (2020) state that it can reduce costs; Hmoud and
Laszlo (2019), Johansson and Herranen (2019), Raveendra
et al. (2020), Black and van Esch (2020), and Allal-Ch√©rif
et al. ( 2021) suggest it saves time; Upadhyay and
Khandelwal (2018) and Johansson and Herranen (2019)
present it reducing transactional workload.
2. The second theme is the causes of algorithmic discrimina-
tion. McFarland and McFarland (2015), Mayson (2018), REVIEW ARTICLE
Ethics and discrimination in artiÔ¨Åcial intelligence-
enabled recruitment practices
Zhisheng Chen 1‚úâ
This study aims to address the research gap on algorithmic discrimination caused by AI-
enabled recruitment and explore technical and managerial solutions. The primary research
approach used is a literature review. TheÔ¨Åndings suggest that AI-enabled recruitment has
the potential to enhance recruitment quality, increase efÔ¨Åciency, and reduce transactional
work. However, algorithmic bias results in discriminatory hiring practices based on gender, perspectives align with the thematic directions identiÔ¨Åed through
our literature review.
Firstly, AI-driven hiring applications impact various aspects,
such as reviewing applicant proÔ¨Åles online, analyzing applicant
information, scoring assessments based on hiring criteria, and
generating preliminary rankings automatically.
Secondly, interviewers perceive beneÔ¨Åts in AI-driven recruit-
ment for job seekers. It eliminates subjective human bias,
facilitates automated matchmaking between individuals and
positions, and provides autom ated response services. More-
over, AI reduces the workload on humans and enhances Silva (2019), and Beneduce (2020), Johnson et al. (2020).
Claim that AI-supported recruitment can reduce
costs
Hmoud and Laszlo (2019), Johansson and Herranen (2019),
Raveendra et al. (2020), Black and van Esch (2020), and Allal-
Ch√©rif et al. (2021)
Suggests that AI support can save time
Upadhyay and Khandelwal (2018), Johansson and Herranen
(2019)
Propose that AI support can reduce transactional
workload
2. Causes of algorithmic
discrimination
McFarland and McFarland (2015), Mayson (2018), Raso et al.
(2018), Raub (2018), Raghavan et al. (2020), Njoto (2020),
Zixun (2020), and Jackson (2021) believed; however, algorithms and AI can result in unfair
employment opportunities and the potential for discrimination
without accountability. To harness the beneÔ¨Åts of AI in recruiting,
organizations should exercise careful selection of their programs,
promote the adoption of accountable algorithms, and advocate
for improvements in racial and gender diversity within high-tech
companies.
The general construct of this study is,Ô¨Årst, an extension of
statistical discrimination theory in the context of the algorithmic
economy; second, a synthesis of the current literature on the recruiters, thus changing the traditional practices of the recruit-
ment industry (Upadhyay and Khandelwal,2018). Most profes-
sionals believe that AI is bene Ô¨Åcial to recruiters in terms of
reducing routine and administrative tasks (Johansson and
Herranen, 2019). Recruiters will hand over time-consuming
administrative tasks like recruiting, screening, and interviewing to
AI, allowing more scope for recruiters to concentrate on strategic
affairs (Upadhyay and Khandelwal,2018
).
Theme II. Why is there algorithmic recruitment
discrimination
Algorithms are not inherently discriminatory, and engineers",6.295720816,1,"The context explicitly lists and cites the two benefits asked for in the question: it can ""reduce costs"" [cite: 303] and ""saves time""[cite: 305].",1,"The claims are directly supported by the context, which cites studies stating that AI-supported recruitment can reduce costs [303] and save time [305].",1,"The generated answer and the ground truth are semantically identical, both listing cost reduction and time savings as two key benefits.",,
What are two recommended categories of measures to mitigate algorithmic bias in recruitment?,Technical measures (like unbiased dataset frameworks and improved transparency) and management measures (like internal ethical governance and external oversight).,"According to the text, the two recommended categories of measures to mitigate algorithmic bias in recruitment are:

1.  **Technical measures:** such as constructing unbiased datasets and enhancing algorithmic transparency.
2.  **Management measures:** like internal corporate ethical governance and external oversight.","work. However, algorithmic bias results in discriminatory hiring practices based on gender,
race, color, and personality traits. The study indicates that algorithmic bias stems from
limited raw data sets and biased algorithm designers. To mitigate this issue, it is recom-
mended to implement technical measures, such as unbiased dataset frameworks and
improved algorithmic transparency, as well as management measures like internal corporate
ethical governance and external oversight. Employing Grounded Theory, the study conducted
survey analysis to collectÔ¨Årsthand data on respondents‚Äô experiences and perceptions of AI- REVIEW ARTICLE
Ethics and discrimination in artiÔ¨Åcial intelligence-
enabled recruitment practices
Zhisheng Chen 1‚úâ
This study aims to address the research gap on algorithmic discrimination caused by AI-
enabled recruitment and explore technical and managerial solutions. The primary research
approach used is a literature review. TheÔ¨Åndings suggest that AI-enabled recruitment has
the potential to enhance recruitment quality, increase efÔ¨Åciency, and reduce transactional
work. However, algorithmic bias results in discriminatory hiring practices based on gender, Theme IV. How decreasing algorithmic recruitment
discrimination
Changes should be made at the technical and regulatory levels to
ensure that AI algorithms do not replicate existing biases or
introduce new ones based on the provided data (Raub,2018).
Building fair algorithms from a technical perspective
Constructing a more unbiased dataset. Unfair datasets are the root
cause of bias. Therefore, a direct approach to addressing algo-
rithmic bias is reconÔ¨Åguring unbalanced datasets. Using multiple
data points can yield more accurate results while carefully elim-
inating data points that re Ô¨Çect past biases. However, this algorithmic hiring. This study contends that resolving algorithmic
discrimination in recruitment requires technical solutions and the
implementation of internal ethical governance and external
regulations.
The subsequent study is structured intoÔ¨Åve parts. The Ô¨Årst
section provides the theoretical background for this research. The
following section outlines the research methodology employed in
the literature review and identiÔ¨Åes four key themes. The third
section delves into a detailed discussion of these four themes:
applications and beneÔ¨Åts of AI-based recruitment, factors con- ).
Theme II. Why is there algorithmic recruitment
discrimination
Algorithms are not inherently discriminatory, and engineers
rarely intentionally introduce bias into algorithms. However, bias
can still arise in algorithmic recruitment. This issue is closely
linked to the fundamental technology behind AI and ML. The ML
process can be simpliÔ¨Åed into several stages, each involving three
key components contributing to algorithmic bias: dataset con-
struction, the engineer‚Äôs target formulation, and feature selection
(36KE, 2020). When the dataset lacks diverse representation from Recruitment algorithms ‚Äôbias is evident in gender, race, color,
and personality. The primary source of algorithmic bias lies in
partial historical data. The personal preferences of algorithm
engineers also contribute to algorithmic bias. Technical mea-
sures like constructing unbiased datasets and enhancing
Table 3 Summary of nodes and reference points at all levels after coding of interview data.
Level 3 nodes Level 2 nodes Level 1 nodes Number of
sources
Number of coding
reference points
AI-driven recruitment
application
Sourcing Online review of job applicants 4 4
Analysis of personal data 3 4",7.067743301,1,"The context directly answers the question by recommending the implementation of ""technical measures...and management measures"" and provides examples for each category[cite: 328].",1,"The claims are directly supported by the context, which explicitly recommends implementing ""technical measures, such as...unbiased datasets and enhancing algorithmic transparency"" and ""management measures: like internal corporate ethical governance and external oversight"" [328].",1,"The generated answer is a perfect match for the ground truth, listing the exact same two categories of measures (technical and management) with the same examples.",,
"Besides gender and race, what other characteristic is mentioned as a basis for discriminatory hiring practices by AI?",Personality traits.,"According to the text, personality traits are also mentioned as a characteristic that can lead to discriminatory hiring practices by AI.","REVIEW ARTICLE
Ethics and discrimination in artiÔ¨Åcial intelligence-
enabled recruitment practices
Zhisheng Chen 1‚úâ
This study aims to address the research gap on algorithmic discrimination caused by AI-
enabled recruitment and explore technical and managerial solutions. The primary research
approach used is a literature review. TheÔ¨Åndings suggest that AI-enabled recruitment has
the potential to enhance recruitment quality, increase efÔ¨Åciency, and reduce transactional
work. However, algorithmic bias results in discriminatory hiring practices based on gender, work. However, algorithmic bias results in discriminatory hiring practices based on gender,
race, color, and personality traits. The study indicates that algorithmic bias stems from
limited raw data sets and biased algorithm designers. To mitigate this issue, it is recom-
mended to implement technical measures, such as unbiased dataset frameworks and
improved algorithmic transparency, as well as management measures like internal corporate
ethical governance and external oversight. Employing Grounded Theory, the study conducted
survey analysis to collectÔ¨Årsthand data on respondents‚Äô experiences and perceptions of AI- pations as less professional‚Äù((Avery et al.,2023; Kay et al.,2015).
The impact of gender stereotypes on AI hiring poses genuine
risks (Beneduce,2020). In 2014, Amazon developed an ML-based
hiring tool, but it exhibited gender bias. The system did not
classify candidates neutrally for gender (Miasato and Silva,2019).
The bias stemmed from training the AI system on predominantly
male employees ‚Äô CVs (Beneduce, 2020). Accordingly, the
recruitment algorithm perceived this biased model as indicative
of success, resulting in discrimination against female applicants
(Langenkamp et al. 2019). The algorithm even downgraded Thirdly, concerns are raised regarding potential hiring
discrimination perpetrated by machines. This can arise from AI
tools, such as partial source data, or users unfamiliar with user
interfaces and operations.
Fourthly, intrinsic factors like personality and IQ, as well as
extrinsic factors like gender and nationality, have been observed
to inÔ¨Çuence the accurate identi Ô¨Åcation and judgment of AI
systems concerning hiring discrimination.
Fifthly, respondents offer recommendations for combating
discrimination by machines, including technical and non-
technical approaches.
Recommendations for future studies quently, the issue of algorithmic hiring discrimination has
emerged, shifting the focus of statistical discrimination theory
from traditional hiring to intelligent hiring. The mechanisms that
give rise to hiring discrimination problems remain similar, as
both rely on historical data of speciÔ¨Åc populations to predict
future hiring outcomes.
While AI recruiting offers numerous bene Ô¨Åts, it is also
susceptible to algorithmic bias. Algorithmic bias refers to the
systematic and replicable errors in computer systems that lead to
unequally and discrimination based on legally protected char- believed; however, algorithms and AI can result in unfair
employment opportunities and the potential for discrimination
without accountability. To harness the beneÔ¨Åts of AI in recruiting,
organizations should exercise careful selection of their programs,
promote the adoption of accountable algorithms, and advocate
for improvements in racial and gender diversity within high-tech
companies.
The general construct of this study is,Ô¨Årst, an extension of
statistical discrimination theory in the context of the algorithmic
economy; second, a synthesis of the current literature on the",5.491199732,1,"The context explicitly lists the characteristics, stating that discriminatory hiring practices are based on ""gender, race, color, and personality traits""[cite: 349].",1,"The generated answer is a direct and accurate statement from the retrieved context, which lists ""personality traits"" as a basis for discriminatory hiring practices [349].",1,The generated answer is identical to the ground truth.,,
"According to the study of the paper 'Ethics and discrimination in artificial intelligence-enabled recruitment practices', what are two primary sources from which algorithmic bias stems?",Algorithmic bias stems from limited raw data sets and biased algorithm designers.,"According to the study, the two primary sources from which algorithmic bias stems are:

1.  **Limited raw data sets**
2.  **Biased algorithm designers** (including the personal preferences of those designing the algorithms)","REVIEW ARTICLE
Ethics and discrimination in artiÔ¨Åcial intelligence-
enabled recruitment practices
Zhisheng Chen 1‚úâ
This study aims to address the research gap on algorithmic discrimination caused by AI-
enabled recruitment and explore technical and managerial solutions. The primary research
approach used is a literature review. TheÔ¨Åndings suggest that AI-enabled recruitment has
the potential to enhance recruitment quality, increase efÔ¨Åciency, and reduce transactional
work. However, algorithmic bias results in discriminatory hiring practices based on gender, work. However, algorithmic bias results in discriminatory hiring practices based on gender,
race, color, and personality traits. The study indicates that algorithmic bias stems from
limited raw data sets and biased algorithm designers. To mitigate this issue, it is recom-
mended to implement technical measures, such as unbiased dataset frameworks and
improved algorithmic transparency, as well as management measures like internal corporate
ethical governance and external oversight. Employing Grounded Theory, the study conducted
survey analysis to collectÔ¨Årsthand data on respondents‚Äô experiences and perceptions of AI- quently, the issue of algorithmic hiring discrimination has
emerged, shifting the focus of statistical discrimination theory
from traditional hiring to intelligent hiring. The mechanisms that
give rise to hiring discrimination problems remain similar, as
both rely on historical data of speciÔ¨Åc populations to predict
future hiring outcomes.
While AI recruiting offers numerous bene Ô¨Åts, it is also
susceptible to algorithmic bias. Algorithmic bias refers to the
systematic and replicable errors in computer systems that lead to
unequally and discrimination based on legally protected char- algorithmic hiring. This study contends that resolving algorithmic
discrimination in recruitment requires technical solutions and the
implementation of internal ethical governance and external
regulations.
The subsequent study is structured intoÔ¨Åve parts. The Ô¨Årst
section provides the theoretical background for this research. The
following section outlines the research methodology employed in
the literature review and identiÔ¨Åes four key themes. The third
section delves into a detailed discussion of these four themes:
applications and beneÔ¨Åts of AI-based recruitment, factors con- Recruitment algorithms ‚Äôbias is evident in gender, race, color,
and personality. The primary source of algorithmic bias lies in
partial historical data. The personal preferences of algorithm
engineers also contribute to algorithmic bias. Technical mea-
sures like constructing unbiased datasets and enhancing
Table 3 Summary of nodes and reference points at all levels after coding of interview data.
Level 3 nodes Level 2 nodes Level 1 nodes Number of
sources
Number of coding
reference points
AI-driven recruitment
application
Sourcing Online review of job applicants 4 4
Analysis of personal data 3 4 ).
Theme II. Why is there algorithmic recruitment
discrimination
Algorithms are not inherently discriminatory, and engineers
rarely intentionally introduce bias into algorithms. However, bias
can still arise in algorithmic recruitment. This issue is closely
linked to the fundamental technology behind AI and ML. The ML
process can be simpliÔ¨Åed into several stages, each involving three
key components contributing to algorithmic bias: dataset con-
struction, the engineer‚Äôs target formulation, and feature selection
(36KE, 2020). When the dataset lacks diverse representation from",7.321454763,1,"The context directly answers the question, stating that ""algorithmic bias stems from limited raw data sets and biased algorithm designers"" [cite: 367] and reiterates this with ""partial historical data"" and ""personal preferences of algorithm engineers""[cite: 377].",1,"All claims in the generated answer are directly verifiable from the context. The context states that algorithmic bias stems from ""limited raw data sets and biased algorithm designers"" [367] and also mentions ""partial historical data"" and the ""personal preferences of algorithm engineers"" [377].",1,"The generated answer is semantically identical to the ground truth, correctly identifying the two primary sources of bias.",,
What does the CRISP-DM User Guide provide that the Reference Model does not?,"The User Guide gives more detailed tips and hints for each phase and task on how to do a data mining project, whereas the Reference Model describes what to do.","According to the text, the Reference Model doesn‚Äôt provide a user-friendly process description suitable for those moving into normal business processes. The User Guide provides a more detailed description that guides the user as much as possible, while also enabling them to handle difficult, unexpected situations.","15. Mai 2025
Structuring an AI project: CRISP-DM 
6
1. Business Understanding2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment
Data 
Cross Industry Standard Process for Data Mining 15. Mai 2025
Overview CRISP-DM
9 erogeneous treatment effects on unseen test data, and 
thus, it underscores its utility as an effective tool for 
personalization. However, the degree to which a CML- 
based ‚Äúsmart green nudging‚Äù policy amplifies the over -
all decrease in returns warrants further investigation, 
which we address in the subsequent analysis.
4.2.2. Gain from Smart Green Nudging. How effec -
tively does the ‚Äúsmart‚Äù CML-based policy reduce 
returns? We explore the overall effectiveness by evalu -
ating the IPS estimator from Equations ( 3 ) and ( 4 ) in 
our test data and report the results in Table 4 . level description like the generic C R ISP-D M , is not a solution either. W hile it covers the w hole
process and is useful for experienced people, it is not suitable for the kind of users one is
confronted w ith w hen m oving into norm al business processes. The resulting process description
should guide the user as m uch as possible but, at the sam e tim e, enable him  to handle difficult
unexpected situations.
O ne of our basic decisions w as to follow  the C R ISP-D M  m ethodology as m uch as possible. W e
used the generic reference m odel for planning the case studies, for com m unication w ithin the developed during these initial projects. These tem plates proved to be quite helpful especially for
people w ho are not proficient w ith our particular data m ining tool.
5 L essons learned
In this section, w e try to sum m arize som e of the experiences w e m ade in both applying the
generic C R ISP-D M  process m odel and in developing a specialized process m odel.
W e expected the generic process m odel to be useful for planning and docum entation, and this
turned out to be the case. H ow ever, the use of the m odel for com m unication both w ithin and useful criteria. So far, w e have not yet a com plete, satisfactory and operational set of criteria in
our application.
In our first case studies, w e encountered an unexpected difficulty w ith the generic process m odel.
A lthough in the C R ISP-D M  docum ents it is stated at several places, that the phases and tasks are
not supposed to be strictly sequential, the clear and obvious presentation of the process m odel
inevitably created this im pression in our decision m akers. D espite our argum ents, w e found
ourselves forced to very tight deadlines, w hich in the end let to sub-optim al solutions. In our",6.932044506,1,"The context explicitly contrasts the two documents, stating that the Reference Model describes ""what to do,"" while the ""User Guide gives more detailed tips and hints"" [cite: 419] on how to perform the tasks.",0.5,"The claim that the User Guide provides a more detailed description is faithful [391]. However, the claim that the Reference Model doesn't provide a user-friendly description for business processes is an interpretation, not a direct statement. The context says a ""high-level description... is not a solution either"" [390], which is less definitive than the generation's claim.",1,The generated answer and the ground truth are semantically consistent. Both explain that the Reference Model describes 'what to do' while the User Guide provides more detailed 'tips and hints' on 'how to do' it.,,
Which task is mentioned as often being the lengthiest in the Data Preparation phase?,The 'Clean data' task.,"According to the text, the data preparation phase is ‚Äúlikely to be performed multiple times, and not in any prescribed order. Tasks include table, record, and‚Ä¶ **the most tedious part of the work (approx. 60-80% of time)**‚Äù.","form ulation  of the data m ining problem  and the project plan require at least som e
understanding of the available data.
‚Ä¢ D ata Preparation
The data preparation phase covers all activities to construct the final dataset (data that w ill be
fed into the m odeling tool(s)) from  the initial raw  data. D ata preparation tasks are likely to be
perform ed m ultiple tim es, and not in any prescribed order. Tasks include table, record, and 15. Mai 2025
Building & evaluating AI3. Prepare data‚Ä¢Most tedious part of the work (approx. 60-80% of time)‚Ä¢Selection, integration, transformation, cleaning of data4. Training the ML model‚Ä¢Build and optimize a model (in our case: with DL algorithms)‚Ä¢Some methods require additional data collection and preparation5. Define decision logic and evaluate AI system ‚Ä¢Define how predictions translate into decisions‚Ä¢Evaluate system against business objectives‚Ä¢Go back several steps or deploy model
8
1. Business Understanding2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment
Data process instances (see figure 1).
A t the top level, the data m ining process is organized into a sm all num ber of phases. Each phase
consists of several second-level generic tasks. This second level is called generic, because it is
intended to be general enough to cover all possible data m ining situations. The generic tasks are
designed to be as com plete and stable as possible. C om plete m eans to cover both the w hole
process of data m ining and all possible data m ining applications. Stable m eans that w e w ant the
m odel be valid for yet unforeseen developm ents like new  m odeling techniques. The description of phases and tasks as discrete steps perform ed in a specific order represents an
idealized sequence of events. In practice, m any of the tasks can be perform ed in a different order
and it w ill often be necessary to backtrack to previous tasks and repeat certain actions. The
C R ISP-D M  process m odel does not attem pt to capture all of these possible routes through the
data m ining process because this w ould require an overly com plex process m odel and the
expected benefits w ould be very low .
The fourth level, the process instance level, is a record of actions, decisions, and results of an G eneric
Tasks
Specialized
Tasks
C ontextC ontext
R eference M odel U ser G uide
‚Ä¢ check lists
‚Ä¢ questionaires
‚Ä¢ tools and techniques
‚Ä¢ sequences of steps
‚Ä¢ decision points
‚Ä¢ pitfalls
Phases
Process
Instances
Figure 1: Four Level B reakdow n of the C R ISP-D M  M ethodology for D ata M ining
The C R ISP-D M  m ethodology distinguishes betw een the Reference M odel and the U ser G uide.
W hereas the R eference M odel presents a quick overview  of phases, tasks, and their outputs, and
describes w hat to do in a data m ining project, the U ser G uide gives m ore detailed tips and hints m ining tasks, suggest appropriate data transform ations and data m ining techniques, and provide
m eans for evaluating the effectiveness of the results and docum enting the experience.
The C R ISP-D M  (C R oss Industry Standard Process for D ata M ining) project1 addressed parts of
these problem s by defining a process m odel w hich provides a fram ew ork for carrying out data
                                                          
1 The C R ISP-D M  process m odel is being developed by a consortium  of leading data m ining users and suppliers: D aim lerC hrysler",7.141366959,0.3,"The context states that the ""Prepare data"" *phase* is the ""most tedious part of the work (approx. 60-80% of time)""[cite: 406], but it does not single out the specific *task* of 'Clean data' as being the lengthiest within that phase.",1,"The claim is a direct quote from the context, which states that data preparation is the ""most tedious part of the work (approx. 60-80% of time)"" [406].",0,"The generated answer is incorrect. It identifies the entire 'Data Preparation' phase as the lengthiest part, while the ground truth correctly identifies the specific task 'Clean data' within that phase as being the most time-consuming.",,
What is the stated aim of the CRISP-DM process model?,"To make large data mining projects less costly, more reliable, more repeatable, more manageable, and faster.","According to the text, the stated aim of the CRISP-DM process model is:

‚Äúto specify a process which can be reliably and efficiently repeated by different people and adapted to different situations.‚Äù 

It also aims to provide a framework for carrying out data mining tasks, suggesting appropriate data transformations and techniques, and evaluating the effectiveness of the results.","15. Mai 2025
Structuring an AI project: CRISP-DM 
6
1. Business Understanding2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment
Data 
Cross Industry Standard Process for Data Mining for carrying out data m ining projects. The process m odel is independent of both the industry sector and the technology
used. In this paper w e argue in favor of a standard process m odel for data m ining and report som e experiences w ith the
C R ISP-D M  process m odel in practice.
W e applied and tested the C R ISP-D M  m ethodology in a response m odeling application project. The final goal of the
project w as to specify a process w hich can be reliably and efficiently repeated by different people and adapted to m ining tasks, suggest appropriate data transform ations and data m ining techniques, and provide
m eans for evaluating the effectiveness of the results and docum enting the experience.
The C R ISP-D M  (C R oss Industry Standard Process for D ata M ining) project1 addressed parts of
these problem s by defining a process m odel w hich provides a fram ew ork for carrying out data
                                                          
1 The C R ISP-D M  process m odel is being developed by a consortium  of leading data m ining users and suppliers: D aim lerC hrysler The description of phases and tasks as discrete steps perform ed in a specific order represents an
idealized sequence of events. In practice, m any of the tasks can be perform ed in a different order
and it w ill often be necessary to backtrack to previous tasks and repeat certain actions. The
C R ISP-D M  process m odel does not attem pt to capture all of these possible routes through the
data m ining process because this w ould require an overly com plex process m odel and the
expected benefits w ould be very low .
The fourth level, the process instance level, is a record of actions, decisions, and results of an project w as to specify a process w hich can be reliably and efficiently repeated by different people and adapted to
different situations. The initial projects w ere perform ed by experienced data m ining people; future projects are to be
perform ed by people w ith low er technical skills and w ith very little tim e to experim ent w ith different approaches. It
turned out, that the C R ISP-D M  m ethodology w ith its distinction of generic and specialized process m odels provides
both the structure and the flexibility necessary to suit the needs of both groups. D ata
U nderstanding
D ata
Preparation
M odelling
D ataD ataD ata
B usiness
U nderstanding
D eploym ent
Evaluation
Figure 2: Phases of the C urrent C R ISP-D M  Process M odel for D ata M ining
In the follow ing, w e outline each phase briefly:
‚Ä¢ Business U nderstanding
This initial phase focuses on understanding the project objectives and requirem ents from  a
business perspective, and then converting this know ledge into a data m ining problem
definition, and a prelim inary project plan designed to achieve the objectives.
‚Ä¢ D ata U nderstanding",7.849202633,1,"The context directly states a primary goal of the project was ""to specify a process which can be reliably and efficiently repeated by different people and adapted to different situations""[cite: 427], which clearly defines the aim of the process model.",1,"All claims made in the generated answer are directly verifiable from the provided context, which states that the goal is to ""specify a process which can be reliably and efficiently repeated"" [422] and that it provides a framework for carrying out data mining tasks [428].",0,"The generated answer provides a different, less comprehensive aim ('to specify a process which can be reliably and efficiently repeated'). The ground truth gives the full, multi-faceted aim of making projects 'less costly, more reliable, more repeatable, more manageable, and faster'.",,
What does CRISP-DM stand for?,Cross Industry Standard Process for Data Mining.,CRISP-DM stands for Cross Industry Standard Process for Data Mining.,"15. Mai 2025
Structuring an AI project: CRISP-DM 
6
1. Business Understanding2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment
Data 
Cross Industry Standard Process for Data Mining 15. Mai 2025
Overview CRISP-DM
9 m ining tasks, suggest appropriate data transform ations and data m ining techniques, and provide
m eans for evaluating the effectiveness of the results and docum enting the experience.
The C R ISP-D M  (C R oss Industry Standard Process for D ata M ining) project1 addressed parts of
these problem s by defining a process m odel w hich provides a fram ew ork for carrying out data
                                                          
1 The C R ISP-D M  process m odel is being developed by a consortium  of leading data m ining users and suppliers: D aim lerC hrysler both the structure and the flexibility necessary to suit the needs of both groups.
The generic C R ISP-D M  process m odel is useful for planning, com m unication w ithin and outside the project team , and
docum entation. The generic check-lists are helpful even for experienced people. The generic process m odel provides an
excellent foundation for developing a specialized process m odel w hich prescribes the steps to be taken in detail and
w hich gives practical advice for all these steps.
1 Introduction
D ata m ining is a creative process w hich requires a num ber of different skills and know ledge. Brucher, M., Perrot, M., & Duchesnay, E. 
(2011). Scikit -learn: Machine learning in 
Python. Journal of Machine Learning 
Research, 12, 2825-2830. 
Pessach, D., & Shmueli, E. (2022). A review on 
fairness in machine learnin g. ACM Computing 
Surveys, 55(3), 1-44.  
Pianykh, O. S., Langs, G., Dewey, M., Enzmann, D. 
R., Herold, C. J., Schoenberg, S. O., & Brink, J. 
A. (2020). Continuous learning AI in radiology: 
implementation principles and early 
applications. Radiology, 297(1), 6-14.  
Phelps, E. S. (1972). The statistical theory of racism 
and sexism. The American Economic Review , 
62(4), 659-661. Also General Purpose und
vorher war mal und ich finde den 
Namen furchtbar.
Aber um sie nicht zu verwirren,
habe ich eine andere als die 
herk√∂mmliche Abk√ºrzung,
die Sie in vielen √∂konomischen
B√ºchern noch finden, n√§mlich 
GPT.
Das ist General Purpose.
Technologie hat nat√ºrlich Open 
AI
uns alle so ein bisschen 
versaut.
Dieses Wort zu benutzen,
insbesondere wenn man irgendwie 
an der
Schnittstelle zu Machine 
Learning arbeitet,
weil alle direkt an das 
Sprachmodell denken.
Deswegen hier diese furchtbare
Abk√ºrzung General purpose
Tonnen general purpose 
technology.
Diese Technologien haben",4.051290274,1,"The context explicitly provides the full name in multiple sources: ""Cross Industry Standard Process for Data Mining""[cite: 438, 439].",1,The generated answer is a direct statement found in the provided context [438].,1,The generated answer is identical to the ground truth.,,
What are the six phases of the CRISP-DM process model?,"The six phases are Business Understanding, Data Understanding, Data Preparation, Modeling, Evaluation, and Deployment.","Based on the text provided, the six phases of the CRISP-DM process model are:

1.  Business Understanding
2.  Data Understanding
3.  Data Preparation
4.  Modeling
5.  Evaluation
6.  Deployment","15. Mai 2025
Structuring an AI project: CRISP-DM 
6
1. Business Understanding2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment
Data 
Cross Industry Standard Process for Data Mining D ata
U nderstanding
D ata
Preparation
M odelling
D ataD ataD ata
B usiness
U nderstanding
D eploym ent
Evaluation
Figure 2: Phases of the C urrent C R ISP-D M  Process M odel for D ata M ining
In the follow ing, w e outline each phase briefly:
‚Ä¢ Business U nderstanding
This initial phase focuses on understanding the project objectives and requirem ents from  a
business perspective, and then converting this know ledge into a data m ining problem
definition, and a prelim inary project plan designed to achieve the objectives.
‚Ä¢ D ata U nderstanding The description of phases and tasks as discrete steps perform ed in a specific order represents an
idealized sequence of events. In practice, m any of the tasks can be perform ed in a different order
and it w ill often be necessary to backtrack to previous tasks and repeat certain actions. The
C R ISP-D M  process m odel does not attem pt to capture all of these possible routes through the
data m ining process because this w ould require an overly com plex process m odel and the
expected benefits w ould be very low .
The fourth level, the process instance level, is a record of actions, decisions, and results of an process instances (see figure 1).
A t the top level, the data m ining process is organized into a sm all num ber of phases. Each phase
consists of several second-level generic tasks. This second level is called generic, because it is
intended to be general enough to cover all possible data m ining situations. The generic tasks are
designed to be as com plete and stable as possible. C om plete m eans to cover both the w hole
process of data m ining and all possible data m ining applications. Stable m eans that w e w ant the
m odel be valid for yet unforeseen developm ents like new  m odeling techniques. m ining tasks, suggest appropriate data transform ations and data m ining techniques, and provide
m eans for evaluating the effectiveness of the results and docum enting the experience.
The C R ISP-D M  (C R oss Industry Standard Process for D ata M ining) project1 addressed parts of
these problem s by defining a process m odel w hich provides a fram ew ork for carrying out data
                                                          
1 The C R ISP-D M  process m odel is being developed by a consortium  of leading data m ining users and suppliers: D aim lerC hrysler 15. Mai 2025
Overview CRISP-DM
9",6.518276453,1,"The context provides a clear, numbered list and a diagram explicitly naming the six phases: Business Understanding, Data Understanding, Data Preparation, Modeling, Evaluation, and Deployment[cite: 455, 456].",1,The generated answer accurately lists the six phases which are explicitly shown in a diagram and a list in the provided context [455].,1,The generated answer and the ground truth are identical.,,
What three characteristics define a General Purpose Technology (GPT)?,"They are pervasive, improve over time, and lead to complementary innovation.","That is correct. Based on the text provided, the six phases of the CRISP-DM process model are:

1.  Business Understanding
2.  Data Understanding
3.  Data Preparation
4.  Modeling
5.  Evaluation
6.  Deployment","15. Mai 2025
Structuring an AI project: CRISP-DM 
6
1. Business Understanding2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment
Data 
Cross Industry Standard Process for Data Mining D ata
U nderstanding
D ata
Preparation
M odelling
D ataD ataD ata
B usiness
U nderstanding
D eploym ent
Evaluation
Figure 2: Phases of the C urrent C R ISP-D M  Process M odel for D ata M ining
In the follow ing, w e outline each phase briefly:
‚Ä¢ Business U nderstanding
This initial phase focuses on understanding the project objectives and requirem ents from  a
business perspective, and then converting this know ledge into a data m ining problem
definition, and a prelim inary project plan designed to achieve the objectives.
‚Ä¢ D ata U nderstanding 15. Mai 2025
Building & evaluating AI3. Prepare data‚Ä¢Most tedious part of the work (approx. 60-80% of time)‚Ä¢Selection, integration, transformation, cleaning of data4. Training the ML model‚Ä¢Build and optimize a model (in our case: with DL algorithms)‚Ä¢Some methods require additional data collection and preparation5. Define decision logic and evaluate AI system ‚Ä¢Define how predictions translate into decisions‚Ä¢Evaluate system against business objectives‚Ä¢Go back several steps or deploy model
8
1. Business Understanding2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment
Data process instances (see figure 1).
A t the top level, the data m ining process is organized into a sm all num ber of phases. Each phase
consists of several second-level generic tasks. This second level is called generic, because it is
intended to be general enough to cover all possible data m ining situations. The generic tasks are
designed to be as com plete and stable as possible. C om plete m eans to cover both the w hole
process of data m ining and all possible data m ining applications. Stable m eans that w e w ant the
m odel be valid for yet unforeseen developm ents like new  m odeling techniques. m ining tasks, suggest appropriate data transform ations and data m ining techniques, and provide
m eans for evaluating the effectiveness of the results and docum enting the experience.
The C R ISP-D M  (C R oss Industry Standard Process for D ata M ining) project1 addressed parts of
these problem s by defining a process m odel w hich provides a fram ew ork for carrying out data
                                                          
1 The C R ISP-D M  process m odel is being developed by a consortium  of leading data m ining users and suppliers: D aim lerC hrysler finished once a solution is deployed. The lessons learned during the process and from  the
deployed solution can trigger new , often m ore focused business questions. Subsequent data
m ining processes w ill benefit from  the experiences of previous ones (cf. the virtuous cycle of
(B erry and Linoff, 1997)).",9.213625193,0,"The question asks for the three characteristics of a General Purpose Technology (GPT), but the provided context is about the six phases of the CRISP-DM model. The context is completely irrelevant.",1,"The generated answer is a direct, accurate statement based on the list of CRISP-DM phases provided in the context [469].",0,"The generated answer is completely incorrect. It lists the six phases of the CRISP-DM process model, not the three characteristics of a General Purpose Technology.",,
"In the paper 'THE PRODUCTIVITY J-CURVE: HOW INTANGIBLES COMPLEMENT GENERAL PURPOSE TECHNOLOGIES', by how much higher was the adjusted measure of Total Factor Productivity (TFP) compared to official measures at the end of 2017?",The adjusted TFP was 15.9% higher than official measures at the end of 2017.,"The paper states that, at the end of 2017, the adjusted measure of Total Factor Productivity (TFP) was approximately **0.1-0.2** higher than official measures.","weitere Innovationen.
Wir reden √ºber General Purpose 
Technologien,
komplement√§re Investitionen 
anzuregen.
Und das f√ºhrt nat√ºrlich dazu, 
dass viele Ressourcen,
die eigentlich vielleicht auf 
der Produktivit√§t
per se gelegen haben,
abgezogen werden und in
diese Produktivit√§tssteigerung 
investiert werden.
Und damit haben wir immer so ein 
bisschen.
Wir brauchen erstmal viel Zeit
und sollten nicht zu ungeduldig 
sein,
bis wir die Effekte dieser
neuen Technologie wirklich 
sehen.
Ich habe ihn letztes
Mal schon gesagt der gro√üe 
Missglauben
bei vielen Unternehmen ist 
weiterhin Ich nehme ei, haben uns √ºberlegt, aus einer 
√∂konomischen Perspektive,
was Prediction bedeuten k√∂nnte,
wenn wir bei General Purpose 
Technologien gesprochen.
Wir haben dar√ºber gesprochen,
dass wir uns, wie
es bei so vielen General Purpose 
Technologien ist,
aktuell auf einen bestimmten 
Teil der Kurve,
die noch befinden,
die Kurve als die Darstellung, 
die fundamentale Idee,
dass wir nicht in gro√üe 
Technologie Investitionen habe,
dass sich die nicht sofort 
auszahlt.
Das ist immer so ein bisschen 
Verz√∂gerung gibt,
am Anfang sogar die marginale
Produktivit√§tsver√§nderungen 
negativ sein kann.
Das ist so dieser untere also wie viel habe ich 
investiert in
Technologie und dann mir 
schauen.
F√ºr jeden der Punkte sind 
einzelne Unternehmen,
wie sie relativ zur Industrie 
produktiv sind.
Jetzt k√∂nnen Sie eine Sache 
sehen.
Auf der einen Seite,
wir haben hier irgendwie eine 
positive Linie,
also eine positive slope eine 
lineare Linie,
die mir sagt, naja,
im Durchschnitt umso mehr
ich in Technologie investiert 
habe.
Hier sehen Sie die 
Regressionsgerade habe ich auch 
eine
h√∂here Produktivit√§t im 
Durchschnitt.
Aber was sehen Sie noch,
wenn Sie sich f√ºr ein bestimmtes
Level hier von Technologie 
Investment einfach mal und
das sind immer die Effekte auf 
die Produktivit√§t hier.
Und Sie sehen, das hier ist der 
Zeitpunkt,
wann eben ein GPT √§hnliches 
System eingef√ºhrt worden ist.
Das ist die Produktivit√§t,
relativ, also der Wechsel.
Also wenn ich, bevor ich KI 
eingef√ºhrt habe,
habe ich nat√ºrlich
Produktivit√§tsschwankungen pro 
Monat immer
im Vergleich zum Vorjahr im 
Vergleich zum Durchschnitt.
Sobald aber diese Technologie 
eingef√ºhrt wurde,
sehen sie, dass die 
Produktivit√§t massiv ansteigt.
0.1. 0.2. Wir sehen das.
Hier haben Sie drei Gruppen.
Die Gruppe, die neu angestellt 
wurde,
das ist die, die Monate, Wie identifiziere ich, ob
die Maschine eigentlich etwas 
besser macht?
Mache ich das darauf basierend,
ob der Mitarbeiter l√§nger im 
Unternehmen bleibt?
Mache ich das, indem ich
mir selber M√∂glichkeiten 
√ºberlege zu tracken,
wie produktiv der einzelne 
Mitarbeiter ist.
Das hei√üt, Measurement innerhalb 
der Organisation ist
hier zentral und sollte
auf jeden Fall in dem 
allerersten Schritt dieses
Modells durchgedacht werden.
Denn sobald ich es implementiert 
haben
und am Ende feststellen ja,
ich habe eigentlich irgendwas 
gemessen,
was gar nicht so wichtig f√ºr die 
Organisation ist,
dann k√∂nnen sie sehr, sehr viel Problem,
dass ich nicht genau wei√ü,
was ist eigentlich der 
unterliegende
Trend? Hilft Ihnen das?
Cool. So General Purpose 
Technology,
Technology, Technology oder 
Technology? Eins von beiden.
Das ist eine Technologie,
die es uns √ºber alle m√∂glichen 
Industrien erlaubt,
diese massiven Kostenreduktion 
zu erfahren.
Eine Technologie, die nicht nur
in einer bestimmten Dom√§ne,
in einem bestimmten Bereich 
angewendet werden kann,
sondern eben in verschiedenen 
Sektoren.
Es wird √ºberall gebraucht.
Also General Purpose und
vorher war mal und ich finde den 
Namen furchtbar.
Aber um sie nicht zu verwirren,",9.182702303,0.2,"The context discusses a study where productivity massively increases after a technology is introduced, mentioning figures like ""0.1. 0.2."" [cite: 497-498]. This is somewhat related to measuring productivity changes but does not provide the specific figure of 15.9% or directly compare an 'adjusted' TFP to 'official' measures.",1,"The generated answer accurately reports that the paper states the adjusted TFP was approximately 0.1-0.2 higher, which is directly supported by the context [497-498].",0,"The generated answer is factually incorrect, stating the adjusted TFP was 0.1-0.2 higher, while the ground truth states it was 15.9% higher. These are significantly different values.",,
What did Robert Solow's productivity paradox state?,That one 'can see in the computer age everywhere but in the productivity statistics',"The provided text doesn't contain any information about Robert Solow or his productivity paradox. It discusses a ""curve"" related to technology adoption and productivity changes, but it doesn't reference Solow's work.","5
‚ÄúTechnology per se can‚Äôt increase or decrease the productivity of workers‚Äô performance, only useof it can.‚Äù -Orlikowski(2000, p.425) - Verz√∂gerung gibt,
am Anfang sogar die marginale
Produktivit√§tsver√§nderungen 
negativ sein kann.
Das ist so dieser untere 
Halbkreis von dem J.
Und das kann verschiedene Gr√ºnde 
haben.
Unter anderem eben, dass diese
Technologien noch nicht 
ausreichend in den
Organisationen mit
komplement√§ren Investitionen 
integriert worden sind.
Und dann sind wir noch 
technischer
geworden aus einer 
mikro√∂konomischen Perspektive.
Wir haben kurz √ºber die Trust 
Game Struktur gesprochen,
wo es darum geht.
Ich mache Entscheidungen, 
√∂konomisch
relevante Entscheidungen unter 
Unsicherheit.
Und in diesen Szenarien kann Frisch R, Waugh FV (1933) Partial time regressions as compared 
with individual trends. Econometrica 1(4):387‚Äì401.
Ghose A, Lee HA, Nam K, Oh W (2023) The effects of pressure and 
self-assurance nudges on product purchases and returns in 
online retailing: Evidence from a randomized field experiment. 
J. Marketing Res. 61(3):517‚Äì535.
Goldstein NJ, Cialdini RB, Griskevicius V (2008) A room with a 
viewpoint: Using social norms to motivate environmental con -
servation in hotels. J. Consumer Res. 35(3):472‚Äì482.
Goldstein NJ, Griskevicius V, Cialdini RB (2007) Invoking social erstmal die Produktivit√§t runter 
geht.
Wir sind sozusagen an der 
unteren dieser Kurve,
diesem unteren Halbkreis von dem 
J.
Und erst danach geht es 
eigentlich nach oben.
Wir haben eine massiven 
Produktivit√§t.
Das ist wie gesagt der die
Ver√§nderung wir sehen hier ist 
erstmal runtergeht,
dann geht steil nach oben und 
das ist ein Ph√§nomen,
was wir diese Kurve nennen.
Und das sehen wir immer wieder 
mit
verschiedenen General purpose 
technology.
Und das hat ganz einfache 
Gr√ºnde, n√§mlich,
dass am Anfang,
wenn wir in diese Technologien 
investieren,
wie in GPT investiert wird,
haben wir erstmal riesige Anstiege in
der Produktion, in der 
Produktivit√§t.
Aber wir sehen es nicht 
grunds√§tzlich √ºberall.
In vielen Organisationen kostet 
bisher einfach nur Geld.
Und das ist ein Ph√§nomen,
das ist gar nicht neu.
Das nennen wir die Kurve.
Wie so ein J. Wie Sie hier sehen 
k√∂nnen,
wo wir bei der Einf√ºhrung der 
Technologie,
wenn wir hier die Jahre auf der 
Achse haben
und hier die Ver√§nderung in
der Produktivit√§t, dann sehen 
wir,
dass am Anfang bei vielen 
Technologien eigentlich
und das ist ein Average
erstmal die Produktivit√§t runter 
geht.
Wir sind sozusagen an der 
unteren dieser Kurve,
diesem unteren Halbkreis von dem und
das sind immer die Effekte auf 
die Produktivit√§t hier.
Und Sie sehen, das hier ist der 
Zeitpunkt,
wann eben ein GPT √§hnliches 
System eingef√ºhrt worden ist.
Das ist die Produktivit√§t,
relativ, also der Wechsel.
Also wenn ich, bevor ich KI 
eingef√ºhrt habe,
habe ich nat√ºrlich
Produktivit√§tsschwankungen pro 
Monat immer
im Vergleich zum Vorjahr im 
Vergleich zum Durchschnitt.
Sobald aber diese Technologie 
eingef√ºhrt wurde,
sehen sie, dass die 
Produktivit√§t massiv ansteigt.
0.1. 0.2. Wir sehen das.
Hier haben Sie drei Gruppen.
Die Gruppe, die neu angestellt 
wurde,
das ist die, die Monate,",6.301453829,0,"The provided context discusses the J-curve phenomenon of technology adoption and productivity changes [cite: 510, 524] but contains no information about Robert Solow or his specific productivity paradox.",1,"The generated answer accurately reflects the content of the retrieved context. The context discusses a ""curve"" related to productivity changes after technology adoption but does not mention Robert Solow or his productivity paradox.",0,"The generated answer incorrectly states that the information about Robert Solow's productivity paradox is not present in the text, while the ground truth provides the specific statement of the paradox.",,
What are some examples of complementary investments required by General Purpose Technologies (GPTs) like AI?,"Business process redesign, co-invention of new products and business models, and investments in human capital.","Based on the provided text, here are some examples of complementary investments required by General Purpose Technologies (GPTs) like AI:

*   **Training people to use the technology:** This includes creating training programs to help people understand and effectively utilize the GPT.
*   **Building the necessary infrastructure:** This involves setting up the systems and connections needed to integrate the GPT, such as linking it to databases.
*   **Creating intangible assets (know-how):** This refers to developing the expertise and understanding needed to leverage the GPT for innovation.

Essentially, it highlights that initial investments aren't just about the core technology itself, but also about the surrounding ecosystem needed to make it truly effective.","AI as General-Purpose technologyWhat is a General-Purpose Technology (GePuT)?‚Ä¢Pervasive: can be applied across sectorsof the economy. ‚Ä¢Rapidly improving & cheaper over time: learning-by-doing, scale economies, Moore-like curves‚Ä¢Complements: sparks waves of follow-on innovations, new business models, organizational redesign.‚Ä¢Previous examples: Steam engine, Electricity, Digital ComputingAI be seen as a GePuTas well ‚Äìwhy?‚Ä¢Core function gets dramatically cheaper: prediction making‚Ä¢Ubiquitous use-cases across every industry.‚Ä¢For the first time: continuous learning of the technology itself with cross industry dass am Anfang,
wenn wir in diese Technologien 
investieren,
wie in GPT investiert wird,
haben wir erstmal riesige 
anf√§ngliche Investitionen,
die sich nicht sofort auszahlen.
Wir haben massive Investitionen,
beispielsweise darin,
dass Leute die Technologie 
richtig nutzen k√∂nnen.
Ich muss Schulungen machen,
ich muss die Infrastruktur 
schaffen,
ich muss die Anbindung an meine 
Datenbank schaffen.
Ich muss ganz viele intangible 
Assets Know how kreieren,
um dann letztlich auch wieder 
weitere Innovationen.
Wir reden √ºber General Purpose 
Technologien,
komplement√§re Investitionen 
anzuregen. weitere Innovationen.
Wir reden √ºber General Purpose 
Technologien,
komplement√§re Investitionen 
anzuregen.
Und das f√ºhrt nat√ºrlich dazu, 
dass viele Ressourcen,
die eigentlich vielleicht auf 
der Produktivit√§t
per se gelegen haben,
abgezogen werden und in
diese Produktivit√§tssteigerung 
investiert werden.
Und damit haben wir immer so ein 
bisschen.
Wir brauchen erstmal viel Zeit
und sollten nicht zu ungeduldig 
sein,
bis wir die Effekte dieser
neuen Technologie wirklich 
sehen.
Ich habe ihn letztes
Mal schon gesagt der gro√üe 
Missglauben
bei vielen Unternehmen ist 
weiterhin Ich nehme ei, Studierende machen sich mit der Funktionsweise von generativen KI-Modellen wie GPT vertraut. Sie lernen, diese durch gezieltes Prompting f√ºr Managemententscheidungen einzusetzen und kritisch zu bewerten, insbesondere unter wirtschaftlichen und ethischen Gesichtspunkten. Also General Purpose und
vorher war mal und ich finde den 
Namen furchtbar.
Aber um sie nicht zu verwirren,
habe ich eine andere als die 
herk√∂mmliche Abk√ºrzung,
die Sie in vielen √∂konomischen
B√ºchern noch finden, n√§mlich 
GPT.
Das ist General Purpose.
Technologie hat nat√ºrlich Open 
AI
uns alle so ein bisschen 
versaut.
Dieses Wort zu benutzen,
insbesondere wenn man irgendwie 
an der
Schnittstelle zu Machine 
Learning arbeitet,
weil alle direkt an das 
Sprachmodell denken.
Deswegen hier diese furchtbare
Abk√ºrzung General purpose
Tonnen general purpose 
technology.
Diese Technologien haben Dar√ºber hinaus wird der Kurs die aufkommende Bedeutung von generativen KI-Modellen wie GPT beleuchten. Studierende lernen, wie diese Modelle durch gezieltes Prompting eingesetzt werden k√∂nnen, um spezifische Managementfragen zu adressieren und Entscheidungsprozesse zu unterst√ºtzen.",12.55913186,1,"The context directly answers the question by giving examples of complementary investments. It mentions the need for training people (""Schulungen machen"") [cite: 535], creating infrastructure (""Anbindung an meine Datenbank schaffen"") [cite: 535], and developing intangible assets and know-how to spur further innovation [cite: 536-537].",1,"All claims in the generated answer are directly supported by the context. The context mentions the need for training people (""Schulungen machen"") [535], building the necessary infrastructure (""Anbindung an meine Datenbank schaffen"") [535], and creating intangible assets (know-how) [536].",1,"The generated answer and the ground truth provide semantically equivalent examples of complementary investments, such as redesigning processes, developing new business models, and training human capital.",,
"According to the text, what is the 'Productivity J-Curve' phenomenon?","It is a phenomenon where, as firms adopt a new General Purpose Technology (GPT), total factor productivity (TFP) growth is initially underestimated because resources are spent on unmeasured intangible capital. Later, measured productivity growth overestimates true productivity as the benefits from those intangibles are realized.","According to the text, the ‚ÄúProductivity J-Curve‚Äù is a pattern where productivity initially falls or stalls due to a ‚ÄúJ-Curve,‚Äù which emerges when investing in a new technology (like GPT). This happens because there‚Äôs a heavy up-front investment in data, skills, process redesign, and complementary tech, diverting resources from current production. However, after this initial dip, productivity eventually rebounds and accelerates as the complementary investments start paying off.","8. Mai 2025
Expect a J-Curve
J-Curve: two-phase productivity pattern that emerges when a GePuTdiffuses‚Ä¢Short-run dipas measured productivity falls or stalls‚Ä¢Heavy up-front investmentin data, skills, process redesign, and complementary tech‚Ä¢Intangible assets (software, know-how) rise, but are poorly captured in standard measures‚Ä¢Resources diverted from current production to capability-building (output forgone)‚Ä¢Long-run rebound as productivity accelerates once complements are in place‚Ä¢Learning effects, scale economies, and network externalities kick in‚Ä¢Complementary investments start paying off measurably8 erstmal die Produktivit√§t runter 
geht.
Wir sind sozusagen an der 
unteren dieser Kurve,
diesem unteren Halbkreis von dem 
J.
Und erst danach geht es 
eigentlich nach oben.
Wir haben eine massiven 
Produktivit√§t.
Das ist wie gesagt der die
Ver√§nderung wir sehen hier ist 
erstmal runtergeht,
dann geht steil nach oben und 
das ist ein Ph√§nomen,
was wir diese Kurve nennen.
Und das sehen wir immer wieder 
mit
verschiedenen General purpose 
technology.
Und das hat ganz einfache 
Gr√ºnde, n√§mlich,
dass am Anfang,
wenn wir in diese Technologien 
investieren,
wie in GPT investiert wird,
haben wir erstmal riesige Anstiege in
der Produktion, in der 
Produktivit√§t.
Aber wir sehen es nicht 
grunds√§tzlich √ºberall.
In vielen Organisationen kostet 
bisher einfach nur Geld.
Und das ist ein Ph√§nomen,
das ist gar nicht neu.
Das nennen wir die Kurve.
Wie so ein J. Wie Sie hier sehen 
k√∂nnen,
wo wir bei der Einf√ºhrung der 
Technologie,
wenn wir hier die Jahre auf der 
Achse haben
und hier die Ver√§nderung in
der Produktivit√§t, dann sehen 
wir,
dass am Anfang bei vielen 
Technologien eigentlich
und das ist ein Average
erstmal die Produktivit√§t runter 
geht.
Wir sind sozusagen an der 
unteren dieser Kurve,
diesem unteren Halbkreis von dem n√§mlich Elektrizit√§t.
Ja, jeder nimmt Elektrizit√§t 
jetzt verkantet
einfach hier an den Stecker 
gehen
und Elektrizit√§t Energie ziehen.
Und das ist nat√ºrlich ein 
massiver Treiber von Wachstum,
von Produktivit√§t.
War aber nicht immer so.
Am Anfang hat es super lange 
gedauert,
bis diese Elektrizit√§t irgendwas
gebracht hat und die
Frage werde ich ihn gleich 
stellen,
Wie lange sie denn glauben,
dass es gedauert hat, wenn wir 
auf der n√§chsten
Slide zu den JWs sind
auch wieder mikro√∂konomisch 
motiviert?
Ja, alles. Aber lassen Sie uns
ganz kurz noch mal dar√ºber 
nachdenken.
Warum ist denn eigentlich KI implications and potential remedies. The 
British Journal of Radiology, 96(1150), Article 
20220878. 
Schelter, S., & Stoyanovich, J. (2020). Taming 
technical bias in machine learning pipelines. 
Bulletin of the Technical Committee on Data 
Engineering, 43(4), 39-50.  
Scherr, A. (2008). Diskriminierung: eine eigenst√§ndige 
Kategorie f√ºr die soziologische Analyse der (Re-) 
Produktion sozialer Ungleichheiten in der 
Einwanderungsgesellschaft? In K.-S. Rehberg 
(Ed.), Die Natur der Gesellschaft: Verhandlungen 
des 33. Kongresses der Deutschen Gesellschaft 
f√ºr Soziologie in Kassel 2006. (Vol. 1, pp. 2007- benutzt oder nicht?
Und diese Maschine m√∂glichst auf 
Delph geachtet hat
und das super richtig war,
ja, dann
funktioniert die Maschine heute 
nicht mehr so gut,
weil sie ihr Verhalten ver√§ndert 
haben.
Und diese Probleme nennen
wir grunds√§tzlich Drift Probleme
und davon haben wir zwei Typen.
Der eine Typ ist, dass sich die 
Verteilung in
den Daten √§ndert und der andere 
ist,
dass ich fundamental in dem 
Verhalten etwas √§ndert.
Hier an dem Beispiel von 
Marketing,
von Sales auf der einen Seite 
den sogenannten Data Drift.
Wir haben eine einen Shift
in der Verteilung der Typen der 
Observation,
die wir haben in der",10.1185286,1,"The context explicitly describes the J-Curve as a phenomenon where productivity initially goes down (""erstmal die Produktivit√§t runter geht"") [cite: 558-559] due to large initial investments [cite: 534] and the diversion of resources [cite: 538], before it later goes up (""dann geht steil nach oben"")[cite: 553].",1,"All claims in the generated answer are directly supported by the context. The context describes a ""J-Curve"" pattern where productivity initially dips due to heavy up-front investments in complementary assets [551] before rebounding and accelerating as those investments pay off.",1,"The generated answer and the ground truth are semantically equivalent. Both describe the phenomenon as an initial underestimation or dip in productivity growth, followed by a later surge as the benefits of unmeasured intangible investments are realized.",,
"What societal benefit, in terms of CO2 emissions, would a 2.6% return decrease translate to based on U.S. figures from 2022?","It would result in a reduction of 624,000 metric tons of CO2 emissions.","Based on U.S. figures from 2022, a 2.6% return decrease would result in a reduction of 624,000 metric tons of CO2 emissions.","intending to return some. For our industry partner, this 
effect corresponds to annual savings in processing costs 
of approximately $340,000 and translates into an 8.7% 
increase in profits. From an industry-wide perspective, 
based on a projected $25.1 billion in online returns pro -
cessing expenses in the United States for 2023 (Zheng 
2023 ), the decrease would translate to annual cost sav -
ings of approximately $650 million. From a societal per -
spective, based on U.S. figures from 2022, the 2.6% 
return decrease would result in a reduction of 624,000 
metric tons of CO
2 return decrease would result in a reduction of 624,000 
metric tons of CO
2 
emissions (Calma 2023 ). This reduc -
tion is roughly equivalent to the annual emissions from 
the electricity consumption of 121,000 U.S. homes.
1
Second, further analyses using the CML model 
reveal that the green nudge substantially reduced 
returns for approximately 60% of customers but led to 
an increase for the remaining 40%, suggesting that 
green nudging can occasionally backfire. This backfir -
ing effect, which has also been observed in prior studies 
(e.g., Hagmann et al. 2019 , Osman 2020 ), diminishes green nudging lowers product returns by 2.6% without 
negatively impacting sales. For our industry partner, 
the observed effect translates into an estimated annual 
reduction in processing costs of about $340,000 and an 
8.7% boost in profits. On a larger scale, estimations 
based on public data from the United States suggest 
that the achieved reduction in returns could signifi -
cantly decrease U.S. fashion industry-wide costs by 
$650 million (Zheng 2023 ) and carbon emissions by 
624,000 metric tons (Calma 2023 ). Additionally, our 
causal machine learning model identifies notable varia - menting smart green nudging could potentially double 
the cost savings compared with the naive strategy. 
Equally significant is the environmental benefit. 
Applied across the United States in logistics, this 
approach could double the effect on CO
2 
emissions to 
an impressive total of more than 1 million tons annu -
ally (Calma 2023 ). These dual advantages underscore 
Table 4. Summary Statistics from the Analyses of Smart Green Nudging on Test Data
Share treated, %
Returns (shipment) Returns (value) Cart conversion Sales
Mean (SE) Mean (SE) Mean (SE) Mean (SE) 24. April 2025
Summary and impact: what ML does
https://www.readycloud.com/info/14-facts-about-ecommerce-product-returns
up to 4.6% decrease
‚Ä¢Our green nudges can be easily implemented at low costin all online shops ‚Ä¢Our ""smart"" implementation uses open-source libraries and may predict impact on individual-level profit of any nudge‚Ä¢Our return reduction on global scale would save‚Ä¶‚Ä¢‚Ä¶up to 200,000 tons of CO2 emissions ‚Ä¢‚Ä¶up to 120,000 tons of waste
Annual impact for industry partner: in the six figures when examining the net sales on an individual level, we 
find positive, albeit statistically insignificant, treatment 
effects (+1.48%, p ÔøΩ 0.29, Mann‚ÄìWhitney U test).
Taken together, these results show the effectiveness of 
the dual green nudge from both the environmental 
perspective‚Äîa significant reduction in return shipments‚Äî 
and the business perspective‚Äîa significant reduction in 
the value of returned products with equal sales.
Putting these measures into context, by using annual 
carbon dioxide emissions attributable to the logistics of 
returns in the United States alone (e.g., Calma 2023 ),",8.091142178,1,"The context directly answers the question. It states that based on U.S. figures from 2022, a 2.6% return decrease would result in a reduction of 624,000 metric tons of CO2 emissions[cite: 571, 576].",1,"The generated answer is a direct claim that can be verified from the context, which states, ""the 2.6% return decrease would result in a reduction of 624,000 metric tons of CO2 emissions (Calma 2023)"" [571].",1,The generated answer is identical to the ground truth.,,
What is the estimated annual savings in processing costs for the industry partner due to the green nudge?,"The effect corresponds to annual savings in processing costs of approximately $340,000.","The estimated annual savings in processing costs for the industry partner due to the green nudge is approximately $340,000.","field experiment demonstrates that our green nudge 
successfully reduces product returns. In particular, 
administering a green nudge during and toward the 
end of a shopping experience for every customer yields 
a significant and economically relevant decrease in 
return shipments (ÔøΩ 2.6%, p < 0.03) without adversely 
affecting sales. Further analyses indicate that this effect 
primarily results from reducing bracketing behaviors, 
where customers order multiple variants of items, 
intending to return some. For our industry partner, this 
effect corresponds to annual savings in processing costs green nudging lowers product returns by 2.6% without 
negatively impacting sales. For our industry partner, 
the observed effect translates into an estimated annual 
reduction in processing costs of about $340,000 and an 
8.7% boost in profits. On a larger scale, estimations 
based on public data from the United States suggest 
that the achieved reduction in returns could signifi -
cantly decrease U.S. fashion industry-wide costs by 
$650 million (Zheng 2023 ) and carbon emissions by 
624,000 metric tons (Calma 2023 ). Additionally, our 
causal machine learning model identifies notable varia - profit increase quickly amortizes costs associated with 
the development, implementation, and maintenance of 
green nudging. In fact, the developed dual nudge 
turned out to be so successful that our industry partner 
opted to keep the green nudge running in the German 
online shop. The project‚Äôs success is affirmed by a prac -
tice executive who corroborates the effectiveness of the 
implemented dual-nudge approach by stating that
[t]he reduction in returns without a negative impact 
on revenue was huge for us. So huge, in fact, that we 
opted for keeping the experiment live and showing the potential of smart green nudging as an effective 
personalization strategy for both businesses and the 
environment.
5. Discussion and Conclusion
5.1. Contribution
Our study addresses the challenge of product returns 
by developing and empirically validating a green 
nudging intervention. Green nudging prompts shop -
pers toward more environmentally conscious and 
thoughtful behavior, effectively reducing product 
returns. Our large-scale field experiment shows that 
green nudging lowers product returns by 2.6% without 
negatively impacting sales. For our industry partner, menting smart green nudging could potentially double 
the cost savings compared with the naive strategy. 
Equally significant is the environmental benefit. 
Applied across the United States in logistics, this 
approach could double the effect on CO
2 
emissions to 
an impressive total of more than 1 million tons annu -
ally (Calma 2023 ). These dual advantages underscore 
Table 4. Summary Statistics from the Analyses of Smart Green Nudging on Test Data
Share treated, %
Returns (shipment) Returns (value) Cart conversion Sales
Mean (SE) Mean (SE) Mean (SE) Mean (SE) stantially. For example, our analysis reveals substantial 
variation in treatment effects across different states (see 
Online Appendix A.9). However, excluding indivi -
duals from Baden-W ¬®urttemberg who, on average, 
exhibit a notable adverse reaction to the green nudge 
results in a modest improvement of 0.1 percentage 
points in the effectiveness of the green nudge.
Overall, the results for smart green nudging offer an 
optimistic outlook. From a business perspective, imple -
menting smart green nudging could potentially double 
the cost savings compared with the naive strategy.",5.824860334,1,"The context directly answers the question, stating that for the industry partner, the effect corresponds to ""annual savings in processing costs of approximately $340,000"" [cite: 585] and reiterates it as an ""estimated annual reduction in processing costs of about $340,000""[cite: 586].",1,"The generated answer is a direct claim from the provided context, which states that for the industry partner, the effect corresponds to ""annual savings in processing costs of approximately $340,000"" [585].",1,The generated answer and the ground truth are semantically identical.,,
"In the 'Smart Green Nudging' paper, what was the sample size (n) of the randomized field experiment discussed?","The experiment had a sample size of 117,304 participants (n = 117,304).","The sample size (n) of the randomized field experiment discussed in the ‚ÄúSmart Green Nudging‚Äù paper was 117,304 participants.","significant variability in how individuals respond to 
nudging (Hummel and Maedche 2019 ), rendering the 
outcomes of green nudging unpredictable (Lehner et al. 
2016 ). Additionally, few researchers have explored the 
impact of green nudges on a large scale (see He et al. 
2023 for an exception), leaving a gap in our understand -
ing and a need to reconcile these divergent findings.
We extend prior research by conducting a large- 
scale, randomized field experiment to test the effective -
ness of green nudges in reducing product returns. Our 
green nudge effectively leverages customers‚Äô desire to Chandy et al. 2021 ) in a digital setting.
The rest of the paper is structured as follows. Section 
2 provides the theoretical background by reviewing 
related literature. Section 3 presents the setting and 
results of our randomized field experiment. Section 4
details the configuration and results from our causal 
machine learning model, along with the evaluation of 
smart green nudging. Section 5 concludes by discuss -
ing the practical implications of our work, its limita -
tions, and potential avenues for future research.
2. Related Literature
Our work relates to three streams of literature, namely ducted an extensive field experiment with 117,304 par -
ticipants in the retailer‚Äôs online shop to empirically 
validate the green nudge. We then apply modern 
causal machine learning (CML) methods (Athey et al. 
2019 ) to analyze treatment heterogeneities based on 
digital footprint and cart data. We rely on off-policy 
evaluation (Hitsch et al. 2024 ) to assess if delivering the 
green nudge only to certain customers can enhance its 
impact.
We present two main findings. First, the extensive 
field experiment demonstrates that our green nudge 
successfully reduces product returns. In particular, Moritz von Zahn, Kevin Bauer, Cristina Mihale-Wilson, Johanna Jagow, Maximilian
Speicher, Oliver Hinz
To cite this article:
Moritz von Zahn, Kevin Bauer, Cristina Mihale-Wilson, Johanna Jagow, Maximilian Speicher, Oliver Hinz (2024)
Smart Green Nudging: Reducing Product Returns Through Digital Footprints and Causal Machine Learning.
Marketing Science
Published online in Articles in Advance 08 Aug 2024
. https://doi.org/10.1287/mksc.2022.0393
This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International observed across the entire customer base in the field 
study by more than four percentage points. In contrast, 
for the group that the CML model would not expose to 
the nudge (œÄ(x
i
) ÔøΩ 0, 40.7% of test data), green nudging 
seemed to backfire (p ÔøΩ 0.109, t-test) and increased 
return shipments by 1.7 percentage points. Hence, not 
von Zahn et al.: Product Returns, Digital Footprints, and Causal Machine Learning 
10 Marketing Science, Articles in Advance, pp. 1‚Äì16, ¬© 2024 The Author(s) 
Downloaded from informs.org by [141.2.113.143] on 24 April 2025, at 02:36 . For personal use only, all rights reserved. conditions. For each of the 20 conditions, we 
conducted 15 independent simulations with different 
random seeds that ensured the randomized partitioning 
of data from Studies A and B into observations used 
for initially training the ML models and populating the 
pools of investors and borrowers. By  doing so, we 
aimed to mitigate concerns of selection bias. To 
manipulate the initial bias of the ML model predicting 
borrowers‚Äô repayment, we induce d label imbalances 
(Cowgill & Tucker, 2019) for female observations in 
the initial training dataset prior to the simulation‚Äôs first",6.771623373,1,"The context directly answers the question, stating the study was an ""extensive field experiment with 117,304 participants""[cite: 609].",1,"The generated answer is a direct statement that is verifiable from the context, which mentions conducting an ""extensive field experiment with 117,304 participants"" [609].",1,The generated answer is identical to the ground truth.,,
What are the two types of returns mentioned in the context of online shopping?,'Real returns' (where the customer intended to keep the item) and 'opportunistic returns' (where the customer orders multiple options with the intent to return some).,"The two types of returns mentioned in the context are:

1.  **Opportunistic return behaviors**, such as ‚Äúbracketing‚Äù (purchasing multiple variants of an item with the intention of returning some).
2.  **Customer returns** ‚Äì the general act of a customer returning a purchased product.","Keywords: electronic commerce ‚Ä¢ nudging ‚Ä¢ causal forest ‚Ä¢ digital footprint ‚Ä¢ consumer returns ‚Ä¢ artificial intelligence
1. Introduction
In recent years, global e-commerce has experienced sig -
nificant and sustained growth. E-commerce presents 
numerous advantages for both customers and retailers. 
However, the lenient, and frequently free, return poli -
cies introduce drawbacks that complicate this expan -
sion. In the fashion industry, the share of purchases 
returned can reach a staggering 50% (Dzyabura et al. 
2023 ).
Product returns pose a substantial financial burden August 8, 2024 
https://doi.org/10.1287/mksc.2022.0393 
Copyright: ¬© 2024 The Author(s)
Abstract. In e-commerce, product returns have become a costly and escalating issue for 
retailers. Beyond the financial implications for businesses, product returns also lead to 
increased greenhouse gas emissions and the squandering of natural resources. Traditional 
approaches, such as charging customers for returns, have proven largely ineffective in 
curbing returns, thus calling for more nuanced strategies to tackle this issue. This paper 
investigates the effectiveness of informing consumers about the negative environmental marketing researchers and practitioners to examine dri -
vers of product returns (e.g., Harris 2008 , Pei and Paswan 
2018 ) and to seek solutions to curb them (PÀö alsson et al. 
2017 , Abdulla et al. 2019 ). Particularly problematic are 
opportunistic return behaviors. An example for such 
behavior is the practice of ‚Äúbracketing,‚Äù where customers 
purchase multiple variants of an item with the intention 
of returning some (Altug et al. 2021 ). A plausible initial 
approach to address this issue is the adaptation of return 
policies. The literature differentiates between lenient poli - encouraging thoughtful shopping choices. This feature 
appears while customers can still adjust or abandon 
their cart items. The reminder prompt, triggered after 
customers receive their final purchase confirmation, 
highlights the environmental consequences of product 
returns and encourages a commitment to reduce 
returns on a five-point scale.
These two design elements are inspired by both prior 
research demonstrating its efficacy in promoting eco- 
friendlier consumer behavior (Lokhorst et al. 2013 , 
Loock et al. 2013 ) and positive feedback that our indus - groups, 73,235 made a purchase. The conversion rate 
aligns with typical figures in the fashion retail industry. 
It is important to note that customers can view their 
cart at any time but need to do so at least once to com -
plete a purchase.
In our field experiment, we tracked several customer 
outcomes with our industry partner and its service pro -
viders, including sales, returns, and duplicate product 
purchases, as detailed in Table 1 . The key variable of 
interest is the customer‚Äôs decision to return at least one 
purchased product. This approach is driven by our pri - returned can reach a staggering 50% (Dzyabura et al. 
2023 ).
Product returns pose a substantial financial burden 
on retailers (Nageswaran et al. 2020 ). The costs of estab -
lishing return infrastructures (Ofek et al. 2011 ), incur -
ring transportation expenses (Zhou and Hinz 2016 ), 
and preparing returned products for resale (Ambilkar 
et al. 2021 ) erode profitability. Additionally, the chal -
lenge of reselling returned items at their original prices 
often results in discarding the products rather than 
reselling them (Ofek et al. 2011 , Shead 2021 ). However,",7.735938549,0.8,"The context explicitly mentions ""opportunistic return behaviors"" and gives ""bracketing"" as an example where customers purchase multiple variants with the intention of returning some[cite: 629]. It also discusses the general problem of ""customer returns""[cite: 638]. This strongly supports the answer, even if it doesn't use the exact term 'Real returns'.",1,"All claims in the generated answer are directly supported by the context. The context mentions ""opportunistic return behaviors"" [621] such as ‚Äúbracketing‚Äù and the general act of a ""customer's decision to return at least one purchased product"" [621].",1,The generated answer is semantically consistent with the ground truth. It correctly identifies the two types of returns as those where the customer intends to return items from the start (opportunistic) and those where they do not (real).,,
"According to the paper, by how much did the smart green nudge decrease product returns compared to having no nudge at all?",The smart green nudge resulted in a 6.7% decrease in product returns compared to no nudge at all.,"According to the paper, the smart green nudge (dual-nudge intervention) decreased product returns by 5.19% compared to having no nudge at all.","investigates the effectiveness of informing consumers about the negative environmental 
consequences of product returns (‚Äúgreen nudging‚Äù) to curtail product returns through a 
large-scale randomized field experiment (n ÔøΩ 117,304) conducted with a leading European 
fashion retailer‚Äôs online store. Our findings indicate that implementing green nudging can 
decrease product returns by 2.6% without negatively impacting sales. We then develop 
and assess a causal machine learning model designed to identify treatment heterogeneities 
and personalize green nudging (i.e., make nudging ‚Äúsmart‚Äù). Our off-policy evaluation the potential of smart green nudging as an effective 
personalization strategy for both businesses and the 
environment.
5. Discussion and Conclusion
5.1. Contribution
Our study addresses the challenge of product returns 
by developing and empirically validating a green 
nudging intervention. Green nudging prompts shop -
pers toward more environmentally conscious and 
thoughtful behavior, effectively reducing product 
returns. Our large-scale field experiment shows that 
green nudging lowers product returns by 2.6% without 
negatively impacting sales. For our industry partner, field experiment demonstrates that our green nudge 
successfully reduces product returns. In particular, 
administering a green nudge during and toward the 
end of a shopping experience for every customer yields 
a significant and economically relevant decrease in 
return shipments (ÔøΩ 2.6%, p < 0.03) without adversely 
affecting sales. Further analyses indicate that this effect 
primarily results from reducing bracketing behaviors, 
where customers order multiple variants of items, 
intending to return some. For our industry partner, this 
effect corresponds to annual savings in processing costs green nudging lowers product returns by 2.6% without 
negatively impacting sales. For our industry partner, 
the observed effect translates into an estimated annual 
reduction in processing costs of about $340,000 and an 
8.7% boost in profits. On a larger scale, estimations 
based on public data from the United States suggest 
that the achieved reduction in returns could signifi -
cantly decrease U.S. fashion industry-wide costs by 
$650 million (Zheng 2023 ) and carbon emissions by 
624,000 metric tons (Calma 2023 ). Additionally, our 
causal machine learning model identifies notable varia - customers, smart green nudging can approximately 
double the impact, curbing returns by an additional 
3.15%. When compared against no nudging, the reduc -
tion is 5.19%. This decline in returns is not only mean -
ingful from a business standpoint but also holds 
considerable ecological weight.
Although the results from Table 4 look promising, 
we now follow Athey et al. ( 2023 ) and examine varying 
shares of treated customers with accompanying confi -
dence intervals for a more thorough examination. 
Figure 4 presents the mean returned shipments (on the 
vertical axis) as we vary the policy œÄ",6.479269028,1,"The context directly answers the question, stating that when compared against no nudging, the reduction from smart green nudging is 5.19%[cite: 657].",1,"The generated answer's claim that the decrease was 5.19% is directly supported by the context, which states, ""When compared against no nudging, the reduction is 5.19%"" [657].",0,"The generated answer is factually incorrect. It states a decrease of 5.19%, while the ground truth states a decrease of 6.7%.",,
"In the 'Smart Green Nudging' study, which variable was identified by SHAP values as the most pivotal for the prediction?",The initial cart value.,"According to the paper, the initial cart value was identified by SHAP values as the most pivotal for the prediction.","ing insight into how various variables marginally 
contribute to the predictions (Senoner et al. 2022 ). In 
our case, SHAP values indicate that the initial cart 
value is the variable most pivotal for the prediction. We 
report SHAP values from our CML model in Online 
Appendix A.10. However, it is crucial to differentiate 
between variables that predict the treatment effect and 
those that act as causal moderators. We encourage 
future research to rigorously investigate the causal role 
of variables in moderating the effectiveness of green 
nudging.
Our study also underscores the effectiveness of using When implementing interventions based on machine 
learning, managers are typically keen on understand -
ing the factors driving the results. To provide some 
insights into these factors, we employ Shapley additive 
explanations (SHAP) values (Lundberg and Lee 2017 ), 
a method from the field of explainable artificial intelli -
gence (see, e.g., Bauer et al. 2023 ). SHAP values allow 
us to deconstruct a prediction model‚Äôs output, quanti -
fying the influence of each feature and thereby, allow -
ing insight into how various variables marginally 
contribute to the predictions (Senoner et al. 2022 ). In task. In the following, we show SHAP values for initially biased and unbiased ML models. Each figure contains 
information on the overall importance of each feature for the prediction (higher position in the vertical ranking) and 
the features‚Äô marginal effects for predictions about individual instances (position on the x-axis). Each dot represents a 
SHAP value for a feature and an instance. The color of the dots depicts the value of the feature from low (blue dots) 
to high (red dots). Plots jitter identical SHAP values vertically, providing insights into the SHAP value distribution per cooperative game theory explaining individual predictions by assuming that each feature value of the instance is a 
player in a game where the prediction is the payout. Estimated SHAP values describe the average marginal contribution 
of a feature value across all possible feature coalitions of a given instance. By averaging the SHAP values across all 
possible values a feature can take on, we obtain ed a reliable measure of this feature‚Äôs importance for the prediction 
task. In the following, we show SHAP values for initially biased and unbiased ML models. Each figure contains 22. Mai 2025
Shapley scores: weighted average
‚Ä¢Local accuracy: attributions sum (exactly) to the prediction difference‚Ä¢Consistency: if a model changes so that the marginal contribution of a feature value increases or stays the same (regardless of other features), the Shapley value also increases or stays the same.‚Ä¢Missingness: unused features get SHAP value of 0 x*=0‚Üíùúô+‚Ä¢Additivity: SHAP values can be added to show the joint contribution of several features to a prediction
22
ùúô%ùëì,ùë•=	2&!‚äÜ	)!ùëß*!ùëÄ‚àíùëß*‚àí1!ùëÄ! (ùëì)ùëß*‚àíùëì)ùëß*\i)Shapley value for i= savings
Model f
For individual x with a specific combination of features to high (red dots). Plots jitter identical SHAP values vertically, providing insights into the SHAP value distribution per 
feature. Overall, Figures C1 and C2 show the relationship between the features (borrower characteristics) and the 
prediction (likelihood of this person mak ing a repayment) by revealing their marginal contribution to predictions (in 
terms of probability) conditional on feature values. 
 
Figure C1. SHAP Values, Example of Biased ML Model (max. initial label imbalance) 
The figure for the biased ML reveals that prior to any retraining, the gender attribute (0 = female, 1 = male) is the most",5.530512571,1,"The context explicitly states that ""SHAP values indicate that the initial cart value is the variable most pivotal for the prediction""[cite: 665].",1,"The claim is directly supported by the context, which states, ""SHAP values indicate that the initial cart value is the variable most pivotal for the prediction"" [665].",1,The generated answer is identical to the ground truth.,,
"In the field experiment from the 'Smart Green Nudging' paper, what was the initial aim of the academic team members regarding the prompts they were testing?",The initial aim was to isolate the effects of the cart prompt and the reminder prompt.,"According to the text, the academic team members were conducting an extensive field experiment to test the effectiveness of green nudges in reducing product returns. They were testing specific nudges, but the text doesn't detail *what* those specific nudges were. It only states that they were conducting ""an extended decision-making process, marked by thorough discussions about the choice of specific nudges.""","ducted an extensive field experiment with 117,304 par -
ticipants in the retailer‚Äôs online shop to empirically 
validate the green nudge. We then apply modern 
causal machine learning (CML) methods (Athey et al. 
2019 ) to analyze treatment heterogeneities based on 
digital footprint and cart data. We rely on off-policy 
evaluation (Hitsch et al. 2024 ) to assess if delivering the 
green nudge only to certain customers can enhance its 
impact.
We present two main findings. First, the extensive 
field experiment demonstrates that our green nudge 
successfully reduces product returns. In particular, significant variability in how individuals respond to 
nudging (Hummel and Maedche 2019 ), rendering the 
outcomes of green nudging unpredictable (Lehner et al. 
2016 ). Additionally, few researchers have explored the 
impact of green nudges on a large scale (see He et al. 
2023 for an exception), leaving a gap in our understand -
ing and a need to reconcile these divergent findings.
We extend prior research by conducting a large- 
scale, randomized field experiment to test the effective -
ness of green nudges in reducing product returns. Our 
green nudge effectively leverages customers‚Äô desire to Chandy et al. 2021 ) in a digital setting.
The rest of the paper is structured as follows. Section 
2 provides the theoretical background by reviewing 
related literature. Section 3 presents the setting and 
results of our randomized field experiment. Section 4
details the configuration and results from our causal 
machine learning model, along with the evaluation of 
smart green nudging. Section 5 concludes by discuss -
ing the practical implications of our work, its limita -
tions, and potential avenues for future research.
2. Related Literature
Our work relates to three streams of literature, namely their extensive experience in similar randomized trials.
Developing the two design elements involved an 
extended decision-making process, marked by thor -
ough discussions about the choice of specific nudges. 
Despite its length, this process proved beneficial for all 
team members. Our extensive discussions revealed to 
the academic team members the importance of flexibil -
ity and adaptation in applying theoretical frameworks 
to real-world business scenarios. Conversely, the busi -
ness partner gained valuable insights into academic 
research, appreciating the depth and rigor that this erogeneous treatment effects on unseen test data, and 
thus, it underscores its utility as an effective tool for 
personalization. However, the degree to which a CML- 
based ‚Äúsmart green nudging‚Äù policy amplifies the over -
all decrease in returns warrants further investigation, 
which we address in the subsequent analysis.
4.2.2. Gain from Smart Green Nudging. How effec -
tively does the ‚Äúsmart‚Äù CML-based policy reduce 
returns? We explore the overall effectiveness by evalu -
ating the IPS estimator from Equations ( 3 ) and ( 4 ) in 
our test data and report the results in Table 4 . Research methodology. The study is based on Grounded Theory
and qualitative analysis of interview data. Glaser and Strauss
(1965,1968) proposed this theory. The basic idea is constructing a
theory based on empirical data (Charmaz and Thornberg,2021).
Researchers generally do not make any theoretical assumptions
before starting scientiÔ¨Åc research but start directly from a realistic
point of view and summarize several empirical concepts in pri-
mary data, which are then raised to systematic theoretical
knowledge. Grounded Theory must be supported by empirical",9.456167459,0.3,"The context mentions that the team conducted a field experiment to test the effectiveness of green nudges [cite: 689] and that there were extensive discussions about the choice of specific nudges[cite: 696]. However, it does not state that the initial aim was to isolate the effects of the two different prompts.",1,"The generated answer is faithful to the provided context. The context states that the team conducted an experiment to ""test the effectiveness of green nudges"" [689] and that the process involved ""thorough discussions about the choice of specific nudges"" [696], but it does not specify what the initial aim regarding the individual prompts was.",0,"The generated answer is incorrect. It claims the text doesn't detail the specific nudges being tested, while the ground truth states the clear aim was to isolate the effects of the two different prompts.",,
"In the 'Smart Green Nudging' paper, what were the estimated annual savings in processing costs for the industry partner as a result of the green nudging intervention?","The estimated annual savings in processing costs were approximately $340,000.","The estimated annual reduction in processing costs for the industry partner as a result of the green nudging intervention was approximately $340,000.","the potential of smart green nudging as an effective 
personalization strategy for both businesses and the 
environment.
5. Discussion and Conclusion
5.1. Contribution
Our study addresses the challenge of product returns 
by developing and empirically validating a green 
nudging intervention. Green nudging prompts shop -
pers toward more environmentally conscious and 
thoughtful behavior, effectively reducing product 
returns. Our large-scale field experiment shows that 
green nudging lowers product returns by 2.6% without 
negatively impacting sales. For our industry partner, green nudging lowers product returns by 2.6% without 
negatively impacting sales. For our industry partner, 
the observed effect translates into an estimated annual 
reduction in processing costs of about $340,000 and an 
8.7% boost in profits. On a larger scale, estimations 
based on public data from the United States suggest 
that the achieved reduction in returns could signifi -
cantly decrease U.S. fashion industry-wide costs by 
$650 million (Zheng 2023 ) and carbon emissions by 
624,000 metric tons (Calma 2023 ). Additionally, our 
causal machine learning model identifies notable varia - menting smart green nudging could potentially double 
the cost savings compared with the naive strategy. 
Equally significant is the environmental benefit. 
Applied across the United States in logistics, this 
approach could double the effect on CO
2 
emissions to 
an impressive total of more than 1 million tons annu -
ally (Calma 2023 ). These dual advantages underscore 
Table 4. Summary Statistics from the Analyses of Smart Green Nudging on Test Data
Share treated, %
Returns (shipment) Returns (value) Cart conversion Sales
Mean (SE) Mean (SE) Mean (SE) Mean (SE) investigates the effectiveness of informing consumers about the negative environmental 
consequences of product returns (‚Äúgreen nudging‚Äù) to curtail product returns through a 
large-scale randomized field experiment (n ÔøΩ 117,304) conducted with a leading European 
fashion retailer‚Äôs online store. Our findings indicate that implementing green nudging can 
decrease product returns by 2.6% without negatively impacting sales. We then develop 
and assess a causal machine learning model designed to identify treatment heterogeneities 
and personalize green nudging (i.e., make nudging ‚Äúsmart‚Äù). Our off-policy evaluation Kihal et al. 2021 , Pfrang and Spreer 2022 ). This paper 
aims to contribute to this discussion by empirically 
evaluating the effectiveness of an informational inter -
vention, referred to as green nudging, in decreasing 
product returns.
In this study, we partnered with a leading European 
fashion retailer. Like many in the industry, the retailer 
grapples with the challenges and costs arising from 
online product returns. Seeking to align profitability 
with environmental responsibility, we collaborated 
with our partner to craft a strategy that not only curtails profit increase quickly amortizes costs associated with 
the development, implementation, and maintenance of 
green nudging. In fact, the developed dual nudge 
turned out to be so successful that our industry partner 
opted to keep the green nudge running in the German 
online shop. The project‚Äôs success is affirmed by a prac -
tice executive who corroborates the effectiveness of the 
implemented dual-nudge approach by stating that
[t]he reduction in returns without a negative impact 
on revenue was huge for us. So huge, in fact, that we 
opted for keeping the experiment live and showing",6.795792818,1,"The context directly answers the question, stating that the green nudging intervention translates into an ""estimated annual reduction in processing costs of about $340,000""[cite: 711].",1,"The generated answer is a direct and accurate statement that can be verified from the context, which says the intervention translates to an ""estimated annual reduction in processing costs of about $340,000"" [711].",1,"The generated answer is semantically identical to the ground truth, both stating the savings were approximately $340,000.",,
Where is INFORMS located?,"INFORMS is located in Maryland, USA.","INFORMS is located in Maryland, USA.","This article was downloaded by: [141.2.113.143] On: 24 April 2025, At: 02:36
Publisher: Institute for Operations Research and the Management Sciences (INFORMS)
INFORMS is located in Maryland, USA
Marketing Science
Publication details, including instructions for authors and subscription information:
http://pubsonline.informs.org
Smart Green Nudging: Reducing Product Returns
Through Digital Footprints and Causal Machine
Learning
Moritz von Zahn, Kevin Bauer, Cristina Mihale-Wilson, Johanna Jagow, Maximilian
Speicher, Oliver Hinz
To cite this article: Copyright ¬© 2024 The Author(s)
Please scroll down for article‚Äîit is on subsequent pages
With 12,500 members from nearly 90 countries, INFORMS is the largest international association of operations
research (O.R.) and analytics professionals and students. INFORMS provides unique networking and learning
opportunities for individual professionals, and organizations of all types and sizes, to better understand and use
O.R. and analytics tools and methods to transform strategic visions and achieve better outcomes.
For more information on INFORMS, its publications, membership, or meetings visit http://www.informs.org specific permission and/or fee. Request permission to publish from: AIS Administrative Office, P.O. Box 2712 Atlanta, 
GA, 30301-2712 Attn: Reprints, or via email from publications@aisnet.org. Informationen zur Vorlesung: Gehalten am Do. 12:00 bis 16:00; w√∂chentlich vom 24.04.2025 bis 24.07.2025; Ort: H√∂rsaalzentrum Westend - HZ 12 DOI: 10.17705/1jais.00853 
Available at: https://aisel.aisnet.org/jais/vol25/iss4/9 
This material is brought to you by the AIS Journals at AIS Electronic Library (AISeL). It has been accepted for 
inclusion in Journal of the Association for Information Systems by an authorized administrator of AIS Electronic 
Library (AISeL). For more information, please contact elibrary@aisnet.org. Journal of the Association for Information Systems 
 
864",3.354553699,1,"The context provides a clear screenshot from a document that states, ""INFORMS is located in Maryland, USA""[cite: 726].",1,The generated answer is a direct quote from the provided context.,1,The generated answer is identical to the ground truth.,,
What programming language will be used in the course?,Python.,The course will use the programming language Python.,"24. April 2025
General informationLecture and tutorialLecture to introduce topics and cover theoryTutorial to work on applications (case studies & coding)Six tutorials by Charlotte Knickrehm How can you ask questions?Always ask questions on the runSend an e-mailOffice hours by appointmentWhat is expected of you?Prepare readingsIn class participation (lecture & tutorial)
20
This course is discussion-driven and relies a lot on your participation. 24. April 2025
Course material
The course‚Ä¢Is organized on OLAT (MLME); you need to register.‚Ä¢Material is in English because the majority ofthe central terminology is in English.
19Titel der Veranstaltung Ein besonderer Fokus des Kurses liegt auf praxisnahen √úbungen: Mithilfe der Programmiersprache Python werden die Teilnehmer Schritt f√ºr Schritt an die Umsetzung von ML-Projekten herangef√ºhrt. Alle Programmier√ºbungen sind so gestaltet, dass sie auch ohne Vorkenntnisse l√∂sbar sind, und die Studierenden erhalten die notwendige Unterst√ºtzung, um die Inhalte erfolgreich umzusetzen. Ziel ist es, ein solides Verst√§ndnis f√ºr ML-Tools zu entwickeln und deren Nutzen f√ºr Managemententscheidungen zu erkennen. 10. Juli 2025
Our courses neural network for you to try out des 33. Kongresses der Deutschen Gesellschaft 
f√ºr Soziologie in Kassel 2006. (Vol. 1, pp. 2007-
2017). Campus.  
Schmid, T. (2021). Batch-like online learning for more 
robust hybrid artificial intelligence : 
Deconstruction as a machine learning process . 
Proceedings of the AAAI Spring Symposium: 
Combining Machine Learning with Knowledge 
Engineering.  
Shaikh, M., & Vaast, E. (2022). Algorithmic 
Interactions in Open Source Work. Information 
Systems Research, 34(2), 744-765. 
Shrestha, Y. R., Ben-Menahem, S. M., & Von Krogh, 
G. (2019). Organizational decision -making 23. Juli 2025
Yourhelpisappreciated
2
Survey on LearnMateChatbot for this course",3.325960398,1,"The context explicitly states, ""Mithilfe der Programmiersprache Python werden die Teilnehmer Schritt f√ºr Schritt an die Umsetzung von ML-Projekten herangef√ºhrt"" (With the help of the Python programming language, participants will be guided step-by-step through the implementation of ML projects)[cite: 737].",1,"The generated answer is a direct and faithful statement based on the retrieved context, which says that with the help of the programming language Python, participants will be guided in implementing ML projects [737].",1,The generated answer is identical to the ground truth.,,
"According to the text, what are four useful applications of Large Language Models (LLMs) in everyday life?","Four useful applications of LLMs are: synthesizing information (such as summarizing and translating), acting as an argumentative sparring partner to identify weak points in arguments, brainstorming creative ideas, and assisting with code-related tasks like documentation and translation between programming languages.","According to the text, here are four useful applications of Large Language Models (LLMs):

1.  **Synthesizing information:** Summarizing and translating blocks of information.
2.  **Argumentative sparring partner:** Pointing out weak points in arguments.
3.  **Brainstorming:** Co-creation of creative ideas.
4.  **Code documentation or transformation:** Generate docs for software and translate across languages.","23. Juli 2025
Useful in everyday life
20
‚Ä¢Synthesizing information: Summarizing and translating blocks of information, e.g., bullet points, into structured text‚Ä¢Argumentative sparring partner: pointing out weak points in arguments‚Ä¢Brainstorming: co-creation of creative ideas‚Ä¢Code documentation or transformation: generate docs for software and translate across languages 23. Juli 2025
If in-context learning does not work: adjust weights
17
We can fine tune models, training them to‚Ä¢memorize new information (e.g., updating)‚Ä¢become better at certain tasks (e.g., specialization)‚Ä¢produce answers in a desired format (e.g., reasoning)Typically requires additional data and considerable compute‚Ä¢can be extremely costly and even infeasible ‚Ä¢lately fine-tuning often based on data generated with other LLMs: model distillation‚Ä¢increasingly available on demand, e.g., OpenAI
Continue to train
LLM Die Digitalisierung und datengetriebene Transformation ver√§ndern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen √ºber die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends ‚Äì ML bietet vielf√§ltige Ans√§tze, um Managemententscheidungen fundierter und effizienter zu gestalten. Journal of the Association for Information Systems 
 
822 
likely to correct themselves over time . Thus, human 
behavior serves as a channel through which larger 
sociopolitical trends can influence the performance of 
ML technologies. In a broader sense, our work thereby 
underscores that the potential learning of ML systems 
from human decision  makers is a critical factor to 
consider when designing effective sociotechnological 
systems. This complements prior work pointing to the 
dynamic, possibly bidirectional learning processes 
between humans and ML systems (e.g., Ab del-Karim 17. Juli 2025
Learning word embeddings with Word2VecWord2Vec: simple neural networkto generate word embeddings given a text corpus‚Ä¢Idea: predict words from their surrounding context‚Ä¢Learned weights are embeddings‚Ä¢Through optimization: words in similar context have similar embeddings‚Ä¢Gives us a fixed dictionary of vectors for words we can utilizeIntuitive example: assume we have a text corpus with two sentences
15
Training dataPizza is awesomePizza is greatPizzaisgreatawesome
PizzaisgreatawesomeInput layerEmbeddings layer Output layer 17. Juli 2025
A game changer
27
The transformer architecture1.Transform words into numbers ‚ÄìWord embeddings2.Control word positioning of words ‚ÄìPositional encoding3.Represent words in the context of other words ‚ÄìSelf-attention4.Predict the next word using a feed-forward neural net",9.208789349,1,"The context provides a bulleted list that directly names the four applications mentioned in the question: ""Synthesizing information,"" ""Argumentative sparring partner,"" ""Brainstorming,"" and ""Code documentation or transformation""[cite: 748].",1,All four claims in the generated answer are directly supported by the bulleted list in the provided context [746-747].,1,"The generated answer correctly identifies the four useful applications of LLMs listed in the ground truth, making it semantically identical.",,
For what types of tasks are basic chat models the most suitable choice?,Basic chat models are most suitable for low-stake tasks where a fast response is required.,"According to the provided text, basic chat models are the most suitable choice when a task is ‚Äúrather low stake and fast response is required.‚Äù","23. Juli 2025
Many models, but which one should you use?
18
Reasoning model: Choose when task is rather complex, results are important, and time to receive response
Basic chat model: Choose when task is rather low stake and fast response is required.
Example 1: ‚Ä¢Which vegetable has the highest vitamin C amount?‚Ä¢Act as a nutritionist and create a vegetable salad with at least 500ùúáùëîvitamin C and 200ùúáùëîvitamin D.Example 2: ‚Ä¢What is an LLM?‚Ä¢Act as a computer scientist and explain to me what the advantage of a reasoning model over a chat model is. 15. Mai 2025
Recap: a task-based approach
4
Task 1Task 2... Task N-1 Task N
Workflow
Decomposition of workflowsto identify suitable individual tasks that AI can perform‚Ä¢Evaluate AI applicability based on task attributes (routine, analytical, standardized)‚Ä¢Identify (hidden) prediction problemsin tasks, e.g., customer needs, optimal ad textRethink processesand imagine what AI systems can help with‚Ä¢Installation of individual AI often entail further changes, e.g., new tasks for humans‚Ä¢Understand what is necessary for AI systems to work properly‚Ä¢Notion of complements and substitutesin organizational structures 8. Mai 2025
Identifying opportunities for AI: thinking in tasks
Decomposition of workflowsto identify suitable individual tasks that AI can perform‚Ä¢Evaluate AI applicability based on task attributes (routine, analytical, standardized)‚Ä¢Identify (hidden) prediction problemsin tasks, e.g., customer needs, optimal ad textRethink processesand imagine what AI systems can help with‚Ä¢Installation of individual AI often entail further changes, e.g., new tasks for humans‚Ä¢Understand what is necessary for AI systems to work properly‚Ä¢Notion of complementsandsubstitutes in organizational structures
21
Task 1Task 2... Task N-1 Task N alleine
durch ihre Nutzung und das 
Wissen,
was ich reinfide,
ist generell nicht erstmal f√ºr 
sie relevant.
Aber ich nutze Chat GPT 
beispielsweise auf eine
Art und Weise f√ºr ganz 
allgemeine Tasks,
wie ich keine Technologie zuvor 
benutzen konnte
in dieser Breite,
in diesem Selbstlernmechanismus, 
so
dass meine Nutzung letztlich 
ihre Nutzung
und damit auch ihre Existenz in
dem Unternehmen beeinflussen 
kann.
Dass das passiert, wenn ich fAr 
from zu sagen,
dass das praktisch schon der 
Fall ist,
aber ein intern in
einer Marketingabteilung, der 
dieses Tool nutzt.
Weitere Daten zur 
Weiterentwicklung erzeugt, 10. Juli 2025
Zugang zum Chatbot
35
Der Chatbot kann zur Unterst√ºtzung beim Lernen der Inhalte der Vorlesung ‚ÄûMachine Learning f√ºr Management Entscheidungen‚Äú von Prof. Bauer genutzt werden.Der Bot ist unter folgender Adresse erreichbar:‚Ä¢https://kb-learnmate.studiumdigitale.uni-frankfurt.de 
Freiwillig, wenn Sie uns helfen m√∂chten: Geben Sie stets in Ihrem ersten Prompt an, dass Sie eine Student*in sind, die den Kurs besucht und teilen Sie in dem Prompt Ihre Matrikelnummer mit uns 23. Juli 2025
Useful in everyday life
20
‚Ä¢Synthesizing information: Summarizing and translating blocks of information, e.g., bullet points, into structured text‚Ä¢Argumentative sparring partner: pointing out weak points in arguments‚Ä¢Brainstorming: co-creation of creative ideas‚Ä¢Code documentation or transformation: generate docs for software and translate across languages",5.327841759,1,"The context provides a clear description of the two model types. For the basic chat model, it says to choose it ""when task is rather low stake and fast response is required""[cite: 757], which directly answers the question.",1,"The generated answer is a direct and accurate summary of the provided context, which states to choose a basic chat model when the ""task is rather low stake and fast response is required"" [757].",1,The generated answer is semantically identical to the ground truth.,,
"According to the document, what is the population of Munich?","1,578,567","According to the document, the population of Munich is 1,578,567.","Is the following statement true? ‚ÄúMunich‚Äôs population is 2.12 times that of Frankfurt.‚ÄùA potential Human (cognitive) process:‚Ä¢ Think about knowing these numbers; most likely not‚Ä¢ Use Wikipedia tool: get both of these populations‚Ä¢Munich: 1,578,567‚Ä¢Frankfurt: 773,068‚Ä¢ Try to divide the numbers in your head; rough idea bit not exact number‚Ä¢ Use calculator tool: 1,578,567/ 773,068 = 2.042‚Ä¢ Reflection about correctness of result; number sounds reasonable‚Ä¢ Forming an answer‚Ä¢ Start writing an answer: ‚ÄúYes, the statement is correct.‚Äù‚Ä¢ Checking the entire solution process, the answer sentence and maybe rewrite it to ‚ÄúThe 15. Mai 2025
Accurate predictions are often not enough
13
Laws against discrimination in many domains includingCredit (Equal Credit Opportunity Act),Education (Civil Rights Act of 1964; Education Amendments of 1972), Employment (Civil Rights Act of 1964), Housing (Fair Housing Act), Public Accommodation (Civil Rights Act of 1964)
¬ßBorn and raised in Germany¬ß90% of population¬ßdata describes them accurately ¬ßaccurate predictions (95% accurate)
¬ßMigrated to Germany in past years¬ß10% of population¬ßdata describes them poorly¬ßpoor predictions (50% accurate)
90.5% accurate prediction about creditworthiness decisions. We present the exact instructions given in 
these studies in Appendix B.1. 
Study A: At the onset of each semester, first -semester 
economics students from a large German university were 
recruited to participate in an ongoing field study. The study 
was conducted by a subset of this paper ‚Äôs authors and 
aimed to examine correlations between academic 
performance, personal characteristics, and behavioral 
measurements, including outcomes of sequential social 
dilemmas such as the investment game. The study, 
accessible via a link sent to students ‚Äô email addresses, with a particular interest in the theoretical and exper imental analysis of social interaction, human -bounded rational 
decision-making, and the psychology of incentives.  Michael Kosfeld is the director of the Frankfurt Laboratory for 
Experimental Economic Research (FLEX) and the Center for Leadership and Behavior in Organizations (CLBO).  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Copyright ¬© 2024 by the Association for Information Systems. Permission to make digital or hard copies of all or part 
of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for Kreditw√ºrdigkeitsmaschine 
genutzt wird.
10¬†% von Personen,
die erst in den letzten Jahren
nach Deutschland emigriert sind.
F√ºr diese Personen liegen h√§ufig
keine gro√üen Datenmengen vor.
F√ºr diese Personen kann ein 
Mislabeling in den
Daten stattgefunden haben und
f√ºr diese Personen haben wir 
eine Vorhersagegenauigkeit.
Accuracy von 50¬†% bei
zwei m√∂glichen OutComes 
Kreditw√ºrdig oder nicht?
Das ist nicht besser,
als wenn ich mich hinstelle und 
eine M√ºnze
werfe und trotzdem im Aggregat,
weil der Anteil dieser Personen 
in
der Population relativ kleiner 
ist als der,
w√ºrde in der Messung auf dem a large German university over three years (2016 -2019). Most importantly for the experiment at hand, the field study 
included an incentivized one -shot, sequential social dilemma game where we anonymously matched participants in 
pairs of two and initially gave each participant 10 euros. Participants could either keep the 10 euros for themselves or 
transfer them to their opponent. Whenever  one player transferred their 10 euros, we doubled the amount so that the 
other player received 20 euros. Players made their choices sequentially. The second player  made their decision",4.839573145,1,"The context provides a section with the heading ""Use Wikipedia tool: get both of these populations"" followed by the bullet point ""Munich: 1,578,567""[cite: 766], directly answering the question.",1,"The claim is directly verifiable from the context, which includes a bullet point stating ""Munich: 1,578,567"" [766].",1,"The generated answer and the ground truth state the same number, making them identical.",,
How many parameters did GPT-2 have?,1.5B parameters.,"According to the document, GPT-2 had 1.5B parameters.","17. Juli 2025
Evolution of OpenAI‚Äôs GPT modelsGPT:117M parameters (Radford et al., 2018)‚Ä¢Transformer decoder with 12 layers‚Ä¢Trained on BooksCorpus: over 7000 unique books (4.6GB text)GPT-2:1.5B parameters (Radford et al., 2019)‚Ä¢Same architecture as GPT but more flexible‚Ä¢Also: trained on much more data: 40 GB of internet text dataGPT-3:175B parameters (Brown et al., 2020)‚Ä¢Over 600GB of text dataGPT-4:1.76T parameters (undisclosed)‚Ä¢Mixture of Expert: different expert models with >200B parameter each‚Ä¢10 trillion words ~ 40 Billion pages (exact size unknown)
35 dass GPT auf die Art und
Weise funktionieren wird, wie es 
funktioniert.
Da mussten massiv Ressourcen 
reingesteckt werden,
auch um zu experimentieren.
Letztlich. Und Ockhams Razor ist 
eher dieses diese Idee.
Wenn ich zwei Modelle trainiert 
habe und
diese beiden Modelle 
nebeneinander lege und die 
gleiche
Performance habe,
dann sollte ich als Daumenregel 
nochmal
wirklich betont als Daumenregel
eher das Modell nehmen, was 
einfacher ist.
Der Gedanke, der dahinter 
steckt,
ist, dass wir vermeiden wollen,
dass die zuf√§lligen Schwankungen 
in den
Daten mit h√∂herer 
Modellkomplexit√§t
in dem Modell erkannt werden als Produktion und die marginalen 
Kosten,
eine weitere Einheit von 
Komplexit√§t dazuzunehmen,
de facto null sind.
Wir sprechen da dann dr√ºber, so 
ein bisschen.
Wenn wir √ºber GPT Systeme 
sprechen,
weil die da sehen wir nat√ºrlich 
merklich unterschiedlich,
ob ich 60 Gigabyte Text
reinknalle oder das halbe 
Internet.
Dann habe ich nat√ºrlich schon 
unterschiedliche
Kommunikationskosten.
Wobei jetzt in dem neuen Report
war zum Beispiel angezeigt,
dass die Kosten zumindest f√ºr 
die Inferenz,
also wenn Sie GPT benutzen oder
andere Large Language Models,
die Kosten sind seit zwei zwei 
Jahren Haben Die gibt es theoretisch schon 
seit 2017.
Die wurden nat√ºrlich immer 
besser.
Wir hatten am Ende die Version 
drei Punkt irgendwas,
was dann integriert wurde.
Aber es wurde integriert.
Dieses fundamentale KI Modell in
eine ausreichend kompatible und
nutzerfreundliche Umgebung,
n√§mlich Chat GPT, was
noch mal das Grundmodell GPT
plus weitere Systeme sind, die 
hier zusammenspielen.
Das hei√üt Forgeat GPT.
Gab es diese gro√üen 
Sprachmodelle schon?
Die haben sich wie gesagt immer 
weiter verbessert.
Grunds√§tzlich haben
wir aber alle erst damit 
angefangen und
haben eine ganze Industrie 
eigentlich damit angefangen, Faktoren identifiziert.
Einer der Faktoren nennen Sie 
die Performance Expectancy.
Das k√∂nnen Sie sich vorstellen.
Sie haben ein System vor sich 
und ob
Sie eine Bereitschaft 
grunds√§tzlich Formen
in ihrer Kognition des System zu 
benutzen,
h√§ngt damit zusammen, ob sie 
glauben,
dass dieses System Ihnen hilft,
bestimmte Ziele zu erreichen.
Wenn Sie sich die verschiedenen 
GPTsysteme,
die aktuell verf√ºgbar sind,
auch in den √∂ffentlichen 
Versionen,
dann sind da ganz viele 
verschiedene.
Dann gibt es aktuell vier 
Punkte, wo ich glaube,
das ist generell ZugReifbar 
mittlerweile.
Dann haben wir drei, 17. Juli 2025
GPT training
34
Source: State of GPT | BRK216HFS
Stage 1Stage 2 Stage 3",4.582484484,1,"The context contains a slide with a clear breakdown of OpenAI's GPT models, which lists ""GPT-2: 1.5B parameters""[cite: 781].",1,"The generated answer is a direct and accurate statement from the retrieved context, which lists ""GPT-2: 1.5B parameters"" [781].",1,The generated answer is identical to the ground truth.,,
What is the intuition behind how an 'attention head' works in a language model?,"An attention head represents a word as a weighted combination of itself and all the words that came before it. The weights in this combination are based on the similarity between the words, which helps the model understand the context of the sentence.","Okay, let‚Äôs break down the intuition behind ‚Äúattention heads‚Äù in language models, based on the provided text and general understanding of the concept.

**The Core Problem:**

Traditional recurrent neural networks (RNNs) struggled with long sequences. They processed words sequentially, and information from earlier words could get ‚Äúlost‚Äù as the network processed later words. This made it difficult for the model to understand the *relationships* between words that were far apart in a sentence.

**Attention Heads as a Solution:**

Attention heads address this by allowing the model to directly consider *all* words in the input sequence when processing each word.  Here‚Äôs the intuition:

1. **Every Word Matters:**  Instead of just relying on the immediately preceding words, the model asks, ""When I'm trying to understand this current word, which *other* words in the sequence are most relevant?""

2. **Calculating Relevance (Weights):**
   - Each word in the input sequence is transformed into a vector representation.
   - The model then calculates a ‚Äúscore‚Äù or ‚Äúweight‚Äù for each pair of words (the current word and every other word). This score represents how much attention the model should pay to that other word when processing the current word.  The text mentions ‚ÄúTask factors‚Äù and ‚ÄúNatur des Tasks‚Äù ‚Äì the specific task (like recommending a movie or predicting the next word) influences how these weights are determined.

3. **Multiple ‚ÄúHeads‚Äù ‚Äì Diverse Perspectives:** The ‚Äúhead‚Äù part is crucial.  A single attention mechanism doesn‚Äôt just look at all the words. Instead, the model has *multiple* attention heads. Each head learns to focus on different aspects of the relationships between words.  Think of it like having multiple experts analyzing the same text, each with a slightly different focus.

   - One head might focus on grammatical relationships.
   - Another might focus on semantic relationships (meaning).
   - Yet another might focus on stylistic elements.

4. **Weighted Sum:** Finally, the model takes a weighted sum of the representations of all the words, using the attention weights as the coefficients. This creates a context-aware representation of the current word, incorporating information from the entire sequence.

**Connecting to the Text‚Äôs Points:**

*   **‚ÄúTask factors‚Äù:** The specific task influences the weights, determining what relationships the heads prioritize.
*   **‚ÄúMultiple Experts‚Äù:** The multiple heads represent different perspectives on the data.
*   **‚ÄúMarginal Contribution‚Äù:** The text emphasizes that the contribution of any single word or even a small number of parameters is relatively small. The power comes from the collective attention of all the heads.

**In essence, attention heads allow the model to dynamically adjust its focus, capturing long-range dependencies and contextual nuances that would be impossible for traditional RNNs.**

Do you want me to delve deeper into a specific aspect of this explanation, such as how the weights are calculated, or how attention heads relate to the concept of ‚Äúlarge language models‚Äù?","perspectives align with the thematic directions identiÔ¨Åed through
our literature review.
Firstly, AI-driven hiring applications impact various aspects,
such as reviewing applicant proÔ¨Åles online, analyzing applicant
information, scoring assessments based on hiring criteria, and
generating preliminary rankings automatically.
Secondly, interviewers perceive beneÔ¨Åts in AI-driven recruit-
ment for job seekers. It eliminates subjective human bias,
facilitates automated matchmaking between individuals and
positions, and provides autom ated response services. More-
over, AI reduces the workload on humans and enhances betrachten.
Moralit√§t.
Wir sprechen jetzt hier wirklich 
um
Erg√§nzung von F√§higkeiten.
Erstmal die einbringen,
die das Fachwissen und die 
Erfahrung einbringen.
Ja, sehr gut.
Ich fasse es mal zusammen
Auf der einen Seite haben wir 
Zugang zu
unterschiedlichen Datenpunkten, 
Signalen.
Stellen Sie sich vor, Sie sitzen 
im Interview und die
KI hat die hat
sogar ein Video und analysiert
sehr hoch frequentiert jede 
kleine Mimik,
die Ihnen gar nicht auff√§llt.
Sie sitzen aber mit im Raum und 
sie
nehmen Dinge wahr wie Ger√ºche.
Sie nehmen ganz subtil Empathie 
wahr,
auf eine Art und Weise,
wie sie das vielleicht gar nicht Vorhersagen sind.
Immer wieder rekursive
Vorhersagen √ºber das n√§chste 
Wort und
irgendwas kommt raus.
Und ihre Aufgabe ist es,
diese Information richtig zu 
gewichten.
Und im √úbrigen, wenn wir
uns dieses Statement noch mal 
wirklich vor
Augen f√ºhren und uns auch jetzt 
wieder
an GPT im
Speziellen erinnern Es gibt 
viele empirische Belege,
die darauf hindeuten, dass das,
was Open Air tats√§chlich richtig 
gemacht hat,
das User Interface war
die reine Technologie dieser 
gro√üen Sprachmodelle.
Die gibt es theoretisch schon 
seit 2017.
Die wurden nat√ºrlich immer 
besser.
Wir hatten am Ende die Version zumindest durch eine bestimmte
Methode mir ein bisschen 
erkl√§ren kann.
Woher eigentlich diese 
Vorhersage stammt.
Sie sehen auch hier diese Task 
factors.
Die Natur des Tasks ist das,
wor√ºber ich gerade gesprochen 
habe.
Spielt hochgradig eine Rolle,
wo wir tendenziell sehen,
dass Task, die wir als sehr 
subjektiv wahrnehmen,
wie Film Recommendations,
Wenn Menschen sich gegenseitig 
Witze erz√§hlen sollen,
Einsch√§tzungen davon,
ob ein bestimmter Urlaubsort 
interessant ist oder nicht,
diese ganzen sehr
subjektiv wahrgenommenen 
Aufgaben pr√§ferieren
wir eher von Menschen,
Hilfe anzunehmen,
dass von Menschen l√∂sen zu Aber den umgekehrten Effekt.
Wir haben die Behavioral,
diese kognitive Komponente 
davon,
die sich eigentlich in unserem 
Kopf geschaffen wird,
wo wir diese Intention to use 
entwickeln,
die wiederum von diesen drei 
Faktoren in diesem Modell
hier ganz grob auf einem sehr 
hohen Level.
Den Zusammenhang erkl√§rt wird.
Und diese Beziehungen h√§ngen
wiederum von den Moderatoren ab.
Ja, ja, erkl√§ren, warum das was 
Negatives ist.
Muss ich sie an das Papier 
verweisen, dass keine Ahnung,
wann ich das letzte Mal gelesen 
habe,
steht da bestimmt drin. Kann ich 
ihnen hochladen?
Bzw. Das ist glaube ich sogar 
Open Source. wirklich
√ºber gro√üe Sprachmodelle reden,
wo Milliarden von Menschen jeden
Tag riesige Texte da 
reinknallen.
Aber die marginale Beitrag,
dass sie eine Vorhersage machen 
oder
auch die marginale Beitrag von 
einer weiteren Callum,
einem weiteren Wort in
dem Datensatz, ist vollkommen 
ignorierbar.
Das ist wieder die Masse, die es 
letztlich macht.
Ja, und in dem Fall von Demogons 
Razor
sprechen wir nicht davon,
einen Parameter mehr,
sondern tausende von Parametern 
mehr.
Deswegen ist es f√ºr unsere
PC's und auch f√ºr die 
Entscheidung,
welche Modelle Unternehmen 
einsetzen,
ob sie bei tabularen Daten immer",43.18680763,0.3,"The context discusses attention in general terms, mentioning that it allows the model to properly weight information [cite: 827] and consider different signals[cite: 823]. However, it does not provide the clear, intuitive explanation that an attention head represents a word as a weighted combination of itself and preceding words. The provided context is too high-level and fragmented.",0,"The generated answer is a complete hallucination. The provided context does not contain any of the claims made in the generation; it is a collection of fragmented and unrelated text snippets about AI in hiring, decision-making, and language models.",0,"The generated answer is a long, detailed, and incorrect explanation that does not match the concise and correct ground truth. The generation seems to be a complete hallucination about how attention heads work.",,
What is Word2Vec and what is its function?,Word2Vec is a simple neural network that is used to generate word embeddings from a text corpus.,"Based on the provided text, here‚Äôs what we can gather about Word2Vec:

**What is Word2Vec?**

Word2Vec is a technique that generates word embeddings. A word embedding is a vector of numbers that represents a word's meaning.

**What is its function?**

Word2Vec‚Äôs function is to learn these word embeddings from a text corpus. It does this by predicting words from their surrounding context. The learned weights in the neural network become the word embeddings. This allows us to utilize a fixed dictionary of vectors for words, where words in similar contexts have similar embeddings.

Do you want me to elaborate on a specific aspect, like how it's trained or the different versions (like CBOW and Skip-gram)?","17. Juli 2025
Learning word embeddings with Word2VecWord2Vec: simple neural networkto generate word embeddings given a text corpus‚Ä¢Idea: predict words from their surrounding context‚Ä¢Learned weights are embeddings‚Ä¢Through optimization: words in similar context have similar embeddings‚Ä¢Gives us a fixed dictionary of vectors for words we can utilizeIntuitive example: assume we have a text corpus with two sentences
15
Training dataPizza is awesomePizza is greatPizzaisgreatawesome
PizzaisgreatawesomeInput layerEmbeddings layer Output layer 17. Juli 2025
Word2VecIn practice:‚Ä¢Word2Vec has much larger embeddings layer (>100 dimensions)‚Ä¢Trained on large data set, e.g.entire, Wikipedia‚Ä¢Alternative prediction goal is skipgram‚Ä¢Predict surrounding words from word itself (the other way round for CBOW)Training embeddings requires high computational power‚Ä¢Typically, more than 100 dimensionalembedding‚Ä¢Size of dictionary is in the million‚Ä¢w2v speeds up training by negative sampling
18 17. Juli 2025
Word2Vec example (continuous bag of words version)
16
Training dataPizzaisawesomePizza is greatPizzaisgreatawesome
PizzaisgreatawesomeInput layerEmbeddings layerOutput layer
1001
Words √†One-hot Vector One-hot Vector√†Words0100
Training dataPizza is awesomePizzaisgreatPizzaisgreatawesome
PizzaisgreatawesomeInput layerEmbeddings layerOutput layer
1010
Words √†One-hot Vector One-hot Vector√†Words0100 17. Juli 2025
A game changer
27
The transformer architecture1.Transform words into numbers ‚ÄìWord embeddings2.Control word positioning of words ‚ÄìPositional encoding3.Represent words in the context of other words ‚ÄìSelf-attention4.Predict the next word using a feed-forward neural net used the generic reference m odel for planning the case studies, for com m unication w ithin the
project team , for com m unication outside the project, and for docum enting results and
experiences. W hile it w as very useful for these purposes, it is too abstract to describe repeatable
processes for our end users. A ccording to C R ISP-D M , the proper level w ould be a specialized
process m odel, w hose context is response m odeling for acquisition cam paigns using C lem entine2.
B asically, w e used tw o resources for the developm ent of the specialized process m odel, the 17. Juli 2025
Word embeddingsA word embedding a vector of numbers meant to representword meaning.
12
Let‚Äôs move frombag of words‚Ä¶
To wordEmbeddings!",13.52146268,1,"The context explicitly defines Word2Vec as a ""simple neural network to generate word embeddings given a text corpus""[cite: 847], which perfectly matches the question.",1,"All claims in the generated answer are directly supported by the context. The context defines Word2Vec as a technique to generate word embeddings [841], explains that embeddings are vector representations of meaning [842], and states that the function is to learn these embeddings by predicting words from their surrounding context [843].",1,The generated answer is semantically identical to the ground truth.,,
What is one potential problem with representing words as indexed tokens?,Lacking interpretability of distance.,Lacking interpretability of distance.,"17. Juli 2025
TokenizationMost simple view: words are discrete and independent tokens‚Ä¢Represent words as indexed tokens
What is a potential problem here?‚Ä¢Lacking interpretability of distance ‚Ä¢Idea: Employ one-hot-encoding so that distances are all the same
10
WordIndex tokenHello 0‚Ä¶ ‚Ä¶King 145Queen156‚Ä¶ ‚Ä¶
WordIndex tokenOne-hot vectorHello 0 [1,0,‚Ä¶,0,0,‚Ä¶,0]‚Ä¶ ‚Ä¶ ‚Ä¶King 145 [0,0,‚Ä¶,1,0,‚Ä¶,0]Queen156 [0,0,‚Ä¶,0,1,‚Ä¶,0]‚Ä¶ ‚Ä¶ ‚Ä¶ 17. Juli 2025
A simple 3-D example of one-hot-vectors
What are potential issues with this representation?‚Ä¢High dimensionality‚Ä¢No encoding of meaning of words ‚Ä¢Distance should matter 11
Hello[1,0,0]Queen[0,0,1]
King[0,1,0]
Simplified example: In 3-D 23. Juli 2025
Current LLMs
5
These are the two main components:Feed forward: New representation of weighted embedding (~2/3 of weights)Attention head: ‚ÄúLet embeddings talk to each other‚Äù
Predict the likelihood of what the next tokens isOne probability for each possible token
Input sentence 17. Juli 2025
Current LLMs
28
These are the two main components:Feed forward: New representation of weighted embedding (~2/3 of weights)Attention head: ‚ÄúLet embeddings talk to each other‚Äù
Predict the likelihood of what the next tokens isOne probability for each possible token 17. Juli 2025
Word embeddingsA word embedding a vector of numbers meant to representword meaning.
12
Let‚Äôs move frombag of words‚Ä¶
To wordEmbeddings! in den CVS bestimmte W√∂rter zu 
benutzen und
Sie das machen und die
Maschine vorher eigentlich 
anhand
dieser W√∂rter gesagt hat Das ist 
ein guter Bewerber.
Wo die Leute das noch nicht 
strategisch eingesetzt haben,
ist pl√∂tzlich die Maschine nicht 
mehr so gut,
weil das Wort Ich habe es ihnen 
ja gesagt.
Sie sollten jetzt alle Don't 
know delf.
Ja, das sollten Sie m√∂glichst 
vermeiden,
weil das ist ein Indikator 
daf√ºr,
was mit GPT geschrieben worden 
ist.
Wenn Sie das im Kopf behalten, 
wird jetzt wahrscheinlich
die Anzahl der Delf,
also die wie eintauchen.
Da gibt es einen massiven 
Anstieg in den",4.442804098,1,"The context provides a slide titled ""Tokenization"" which asks, ""What is a potential problem here?"" and immediately answers with the bullet point, ""Lacking interpretability of distance""[cite: 854].",1,"The generated answer is a direct claim from the provided context, which has a slide with the title ""Tokenization"" and a bullet point that says ""Lacking interpretability of distance"" [854].",1,The generated answer is identical to the ground truth.,,
"According to the gradient descent, what two steps are taken to decrease a model's error during training?","To decrease the error, the model's weights (w) are changed in the direction of the negative slope, and the size of this change is scaled by the learning rate (Œ∑).","According to the document, the two steps taken during training to reduce a model‚Äôs error are:

1.  Fit weak models to the data and calculate errors for each observation in the training set.
2.  Train the next model on a (re)weighted training set where previously wrongly predicted observations have a higher weight.","3. Juli 2025
Adaptive Boosting (AdaBoost)
12
Training Procedure:
1. All observations in the dataset are initially given equal weights
2. Fit weak to the data and calculate errors for each observation in training set
3. Train next model on (re)weighted training set where previously wrongly predicted observations 
have a higher weight
4. Repeat procedure until convergence is achieved of restrictions are met
Prediction of new instances based on weighted majority vote of ensemble (weights 
according to individual model accuracy) 
Source 12. Juni 2025
Trainingprocessinanutshell
15
Input data ùëã
Model
Outcome prediction: (%ùë¶) Expected output: ùëå
Error ùúñ
Labelled training data ùëã,ùëå
Compare
Updateto reduce error until certain criterion is met
X1 X3X2 Y8 T RedYes12F BlueNo6 T BlueYes‚Ä¶ 12. Juni 2025
Components of supervised MLSupervised machine learning methods fit a model to data based on an evaluation criterion
19
Representation +Evaluation +Optimization
Adjustmodel according to an algorithmic procedure until stop criterionis met.In linear regression: minimize the sum of squares (closed form) or gradient descent (iterative optimization).
OLS: min%‚ÅÑ""&‚àë'ùë¶‚àíùë¶'
ùêøùõΩ
ùõΩ
ùêø
ùõΩ‚àó availability of this data point for future model updates and potentially affecting the model ‚Äôs 
performance. This paper delves into the relationship between the continuous updating of ML models 
and algorithmic discrimination in environments where predictions endogenously influence the 
creation of new training data. Using comprehensive simulations based on secondary empirical data, 
we examine the dynamic evolution of an ML model ‚Äôs fairness and economic consequences in a 
setting that mirrors sequential interactions, such as loan approval decisions. Our findings indicate 12. Juni 2025
Components of supervised MLMachine learning fits a model to data based on an evaluation criterion.
20
Representation+Evaluation+Optimization
argmin!"" '‚àÄ$‚àà&'('errorùë¶$,,ùëìùíôùíä auf das Training des Modells,
dann kann ich ja noch nicht 
werten.
Bevor ich es trainiere, kann ich 
nicht vorhersehen,
ob die zus√§tzlichen Parameter 
wie ein
besseres Modell gehen oder 
nicht.
Wir trainieren uns, um 
rauszufinden.
Das sind jetzt schon sehr 
detaillierte Fragen.
Wir haben unterschiedliche 
Parameter,
wir haben Parameter, wir haben 
Hyperparameter.
Und die Hyperparameter, die 
werden tats√§chlich in
dem Trainingsprozess data driven 
bestimmt die Parameter,
da haben Sie bestimmte 
Freiheitsgrade,
die zu setzen. Zum Beispiel?
Sie k√∂nnen auch entscheiden,
welche Features Sie reinnehmen 
wollen.",8.712447166,0.5,"The context explains the training procedure for AdaBoost, which involves fitting weak models and re-weighting observations that were wrongly predicted[cite: 862]. This is a form of error reduction through iteration, but it does not mention the specific concepts of 'negative slope' or 'learning rate' associated with gradient descent.",1,"All claims in the generated answer are directly supported by the context [861], which outlines a training procedure where weak models are fit to the data, errors are calculated, and the next model is trained on a reweighted set where wrongly predicted observations have a higher weight.",0,"The generated answer describes the steps for Adaptive Boosting (AdaBoost), not gradient descent. The ground truth correctly describes the two steps of gradient descent (changing weights in the direction of the negative slope, scaled by a learning rate).",,
"According to the text, what are hyperparameters and what is their primary function in machine learning?","Hyperparameters are variables that determine the structure of a model and its learning process. Their primary function is to regularize the model, which helps to control for overfitting and underfitting. For example, in a neural network, hyperparameters include the number of layers and neurons.","According to the text, hyperparameters are ‚Äúvariables that determine the structure of the model and the learning process.‚Äù Their primary function is to ‚Äúregularize our model and shape over- and underfitting outcomes,‚Äù and they are ‚Äúfine-tuned‚Äù to find a ‚Äúgood model complexity.‚Äù Specifically, the text lists examples like the number of trees, tree depth, and learning rate as hyperparameters.","3. Juli 2025
Hyperparameters
The number of trees (parameters) and other choices on the model 
architecture (e.g., tree depth) are hyperparameters 
Hyperparameters are variables that 
‚Ä¢ determine the structure of the model and the learning process
‚Ä¢ allow us to regularize our model and shape over- and underfitting outcomes 
‚Ä¢ different models and learning algorithms have different hyperparameters
‚Ä¢ For example: neural networks‚Äô hyperparameters include
‚Ä¢ # layers
‚Ä¢ # neurons per layer
‚Ä¢ activation functions
By tuning hyperparameters, we can find a ‚Äúgood model complexity‚Äù, but 1933 ), uses machine learning functions to flexibly esti -
mate residuals in treatment and outcome prediction 
equations, enhancing the robustness of our treatment 
effect estimates and aligning with accepted practices 
(detailed further in Online Appendix A.6). We further 
conform to data science standards by dividing our data 
into training (80%) and testing (20%) sets (Hastie et al. 
2009 ). We fine-tune the causal forest‚Äôs hyperparameters 
through a grid search with fivefold crossvalidation on 
the training data, focusing on out-of-sample R-score per -
formance (Schuler et al. 2018 ). We provide hyperpara - Journal of the Association for Information Systems 
 
860 
Table C1. Hyperparameters Automatically Optimized in the Training Process of Investor and  
Borrower Repayment Models 
Hyperparameter Range of hyperparameter value 
Learning rate 0.001, 0.01, 0.05 
Minimum child weight 1, 10 
Maximum depth of tree 3, 4, 5, 6, 7, 8 
Subsample of observations to build a tree 0.5, 0.6, 0.7 
Subsample of variables to build a tree 0.5, 0.6 
Subsample of variables to make a split 0.5, 0.6 
Number of trees 100, 300, 500 
Table C2. Overview of Variables Included in the ML Models. 
Variable Mean Std. dev. 12. Juni 2025
Components of supervised MLSupervised machine learning methods fit a model to data based on an evaluation criterion
17
Representation+Evaluation +Optimization
The model architecture that stores the learned knowledge.Now: linear regressionthat comprises learnable the parameters called coefficients.
'ùë¶=)ùëìùíô=+ùõΩ!++ùõΩ""ùë•""+‚ãØ++ùõΩ#ùë•$ Journal of the Association for Information Systems 
 
814 
known to the investor. Again, the underlying model was 
a gradient boosted forest for which we automatically 
optimized the same seven hyperparameters on the current 
training dataset using a threefold cross-validation strategy 
with a directed Bayesian search.11 We used the remaining 
30% of the data from Study A to populate the pool of 
borrowers in our simulation, from which we randomly 
drew and matched 50 borrowers with randomly drawn 
investors from the corresponding investor pool. On 
average, the unbiased ML model‚Äôs accuracy for the share 12. Juni 2025
Components of supervised MLSupervised machine learning methods fit a model to data based on an evaluation criterion
19
Representation +Evaluation +Optimization
Adjustmodel according to an algorithmic procedure until stop criterionis met.In linear regression: minimize the sum of squares (closed form) or gradient descent (iterative optimization).
OLS: min%‚ÅÑ""&‚àë'ùë¶‚àíùë¶'
ùêøùõΩ
ùõΩ
ùêø
ùõΩ‚àó",9.605660915,1,"The context directly defines hyperparameters as variables that ""determine the structure of the model and the learning process"" [cite: 873] and that they ""allow us to regularize our model and shape over- and underfitting outcomes""[cite: 873]. It also provides relevant examples.",1,"All claims in the generated answer are directly supported by the provided context. The context defines hyperparameters as variables that ""determine the structure of the model and the learning process"" [871] and states their function is to ""regularize our model and shape over- and underfitting outcomes"" [871].",1,"The generated answer and the ground truth are semantically equivalent, both identifying hyperparameters as variables that define the model's structure and learning process to control for overfitting.",,
What are the cores advantages of ensemble methods?,"Improved accuracy, Reduction of overfitting and Handling High Dimensionality.","Based on the provided text, the key benefits of using ensemble methods in machine learning are:

*   **Improved Accuracy:** Ensemble methods generally result in a prediction accuracy that is better than any individual model could achieve.
*   **Reduction of Overfitting:** They tend to be more robust and less prone to overfitting.
*   **Handling High Dimensionality:** They can effectively handle large amounts of data with high-dimensional spaces.

","3. Juli 2025
(Dis)advantages of ensembles
Core advantages of ensemble methods include:
1. Improved Accuracy: Ensemble methods result in a prediction accuracy that is better than
any individual model could achieve
2. Reduction of Overfitting: Because they use multiple learners, ensemble methods tend to
be more robust and less prone to overfitting, i.e., typically generalize rather well
3. Handling High Dimensionality: Ensemble methods can effectively handle large amounts
of data with high-dimensional spaces.
Core disadvantages of ensemble methods include: with modern machine learning methods. This integra -
tion enables the estimation of individual-level differ -
ences between actual outcomes and hypothetical 
outcomes that would have occurred without the inter -
vention (Athey and Imbens 2015 ).
Contrasting with traditional machine learning‚Äôs 
focus on predicting outcomes from correlational data 
relationships, CML aims to forecast cause-and-effect 
relationships. This approach enhances the understand -
ing of how interventions affect outcomes of interest 
(Wager and Athey 2018 ). For example, although tradi -
tional machine learning may predict a customer‚Äôs likeli - 12. Juni 2025
Components of supervised MLSupervised machine learning methods fit a model to data based on an evaluation criterion‚Ä¢In very general terms, we can distinguish three components of three training process‚Ä¢We will first talk this through using simple linear regression‚Ä¢Same logic will be applied to more complex models
16
Representation +Evaluation +Optimization 12. Juni 2025
Components of supervised MLSupervised machine learning methods fit a model to data based on an evaluation criterion
18
Representation +Evaluation+Optimization
Improvement in model behavior accordingto a target variableand an evaluation metric.
Example: Change in stock price the next dayTrue outcome ùë¶(Up = 1)Model prediction ""ùë¶(Up = 1)Squared prediction errorùë¶‚àí""ùë¶!1 0 10 0 00 1 11 1 0 und es gibt bestimmte Machine 
Learning Modelle,
die sind sehr sch√∂n,
die viel dieser Arbeit durch
bestimmte algorithmische 
Lernverfahren abfangen.
Zum Beispiel der 
Entscheidungsbaum
oder auch der Random Forest.
Aber es gibt andere Methoden und 
insbesondere die
most sophisticated Methoden wie 
neuronale Netze,
die auf jede Kleinigkeit in
den Daten massiv sensitiv 
reagieren,
m√ºssen Daten standardisieren.
Wir m√ºssen auf eine bestimmte 
Art und
Weise sampeln m√ºssen
bestimmte Observationen 
rausschmei√üen.
All das, wie Sie hier sehen,
braucht ungef√§hr 60 bis
80¬†% der Zeit eines solchen Data 
Science Projekts. 1933 ), uses machine learning functions to flexibly esti -
mate residuals in treatment and outcome prediction 
equations, enhancing the robustness of our treatment 
effect estimates and aligning with accepted practices 
(detailed further in Online Appendix A.6). We further 
conform to data science standards by dividing our data 
into training (80%) and testing (20%) sets (Hastie et al. 
2009 ). We fine-tune the causal forest‚Äôs hyperparameters 
through a grid search with fivefold crossvalidation on 
the training data, focusing on out-of-sample R-score per -
formance (Schuler et al. 2018 ). We provide hyperpara -",9.938764334,1,"The context provides a slide with a clear bulleted list of the ""Core advantages of ensemble methods,"" which includes ""Improved Accuracy,"" ""Reduction of Overfitting,"" and ""Handling High Dimensionality""[cite: 887].",1,"The claims in the generated answer are directly supported by the context, which lists ""Improved Accuracy"" [885], ""Reduction of Overfitting"" [886], and ""Handling High Dimensionality"" [888] as core advantages of ensemble methods.",1,"The generated answer is identical to the ground truth, listing the same three advantages.",,
What are some core disadvantages of decision trees?,"Overfitting, instability, and optimization difficulty.","According to the provided text, some core disadvantages of decision trees include:

1.  **Overfitting:** Can quickly lead to overfitting when the tree is too complex (too many nodes, levels, or leaves).
2.  **Instability:** Decision trees may be remarkably unstable conditional on variation in training data, leading to different trees.
3.  **Optimization difficulty:** Algorithms to build trees are typically heuristics that cannot guarantee global optimality.","3. Juli 2025
Last time: decision trees
Core disadvantages of decision trees include:
1. Overfitting: Can quickly lead to overfitting when tree is too complex, i.e., when it has too 
many nodes, levels, or leaves
2. Instability: Decision trees may be remarkably unstable conditional on variation in training 
data, leading to different trees
3. Optimization difficulty: Algorithms to build tree are typically heuristics that cannot 
guarantee global optimality
2
#  No de fau lt: 1 80  (9 0%)
#  Def au lt: 2 0 ( 10 %)
Ov era ll s ample
#  No de fau lt: 5 3 ( 91 .4 % )
#  Def au lt: 5  (8 .6%) (Dis)advantages of decision / regression treesCore advantages of decision trees include:1.Handling numerical and categorical variables: Easy to implement and do not require a lot of preprocessing2.Non-parametric: No assumptions about distribution of variables and the classifier structure, allowing to non-linearities3.Interpretability: Easy to understand and to interpret so that one can detect possible inconsistenciesCore disadvantages of decision trees include:1.Overfitting:Can quickly lead to overfitting when tree is too complex, i.e., when it has too many nodes, levels, or leaves2.Instability:Decision trees may be overfitting when tree is too complex, i.e., when it has too many nodes, levels, or leaves2.Instability:Decision trees may be remarkably unstable conditional on variation in training data, leading to different trees3.Optimization difficulty:Algorithms to build tree are typically heuristics that cannot guarantee global optimality 26. Juni 2025
Decision tree classifier: terminology
6
Decision trees belong to the hierarchical methods of classification, classifying data through recursive partitioningA decision tree consists of nodes (data) and edges (splits)‚Ä¢Topmost node: root‚Ä¢Connected posterior nodes: children‚Ä¢Connected prior nodes: parents‚Ä¢Node with parent and child: interior node‚Ä¢Node without child: leafAn interior node has at least two child nodesA tree where every non-leaf node has 2 children: binaryEach internal node tests one attribute ùëãand splits data‚Ä¢Branch from internal node selects value of ùëã‚Ä¢Prediction in leaf: ùëù(ùëå!|ùëã!‚ààùëôùëíùëéùëì)
Leaf 13
Different algorithms to construct decision trees such as CART, ID3, C5.0, ‚Ä¶‚Ä¢Methods rely on information gains:‚Ä¢For node t: For each possible feature, compute the information gain we obtain if we use it to split the current data partition‚Ä¢Split data according to the feature with the highest information gain‚Ä¢Highest information gain intuitively: newly resulting partitions should internally be as homogeneous as possible (lowest uncertainty about label ùë¶)Methods typically differ in formula to compute information gain‚Ä¢CART: Gini-Index information gain‚Ä¢ID3: Entropic information gain‚Ä¢C5.0: Entropic information gain ratio correctly recognizes roughly 4 out of 5 people who actually reciprocate in the case of a transfer. In other words, the 
machine learning system‚Äôs prediction might help you better anticipate whether you will receive the 20 monetary units 
if you initially decide to make a transfer. Below you can find additional information about the structure of the system. 
As implied by its name, a g radient boosted random forest consists of a large number of individual decision trees that 
operate as an ensemble. Based on examples, individual decision trees learn logical rules which assign a certain label",8.979493141,1,"The context provides a slide with a clear bulleted list of the ""Core disadvantages of decision trees,"" which includes ""Overfitting,"" ""Instability,"" and ""Optimization difficulty""[cite: 903, 904].",1,"The generated answer accurately lists the disadvantages of decision trees as stated directly in the provided context: ""Overfitting"" [901], ""Instability"" [902], and ""Optimization difficulty"" [902].",1,"The generated answer is identical to the ground truth, listing the same three disadvantages.",,
"According to the document, what is the formula for Balanced Accuracy (Bal. Acc.)?",Bal. Acc. = (Sensitivity + Specificity) / 2,"According to the document, the formula for Balanced Accuracy (Bal. Acc.) is:

Bal. Acc. = (Sensitivity + Specificity) / 2 

And also:

Bal. Acc. = 2 * Sensitivity * Precision","26. Juni 2025
Technical performance on unseen data (2/2)
Accuracy can be misleading, esp. in case of imbalanced samples, hence, we may also want to consider
Combining these measures results in other important measures:
ùë∫ùíÜùíèùíîùíäùíïùíäùíóùíäùíïùíö=ùëªùë∑ùëªùë∑+ùë≠ùëµùë∑ùíìùíÜùíÑùíäùíîùíäùíêùíè=ùëªùë∑ùëªùë∑+ùë≠ùë∑
ùë©ùíÇùíç.	ùë®ùíÑùíÑ.=ùë∫ùíÜùíèùíîùíäùíïùíäùíóùíäùíïùíö+ùë∫ùíëùíÜùíÑùíäùíáùíäùíÑùíäùíïùíöùüê ùë≠ùüè=ùüê‚àóùë∫ùíÜùíèùíîùíäùíïùíäùíóùíäùíïùíö‚àóùë∑ùíìùíÜùíÑùíäùíîùíäùíêùíèùë∫ùíÜùíèùíîùíäùíïùíäùíóùíäùíïùíö+ùë∑ùíìùíÜùíÑùíäùíîùíäùíêùíè
Tree A prediction$ùë¶!	 True outcome(ùë¶) Tree Bprediction$ùë¶""	1 1 11 1 11 0 01 1 01 0 00 1 00 1 00 0 00 0 00 0 0
Confusion matrix
ùë∫ùíëùíÜùíÑùíäùíáùíäùíÑùíäùíïùíö=ùëªùëµùëªùëµ+ùë≠ùë∑
What is the Bal. Acc. And F1for the two models?
ùë¶=1ùë¶=0$ùë¶=13 2$ùë¶=02 3
ùë¶=1ùë¶=0$ùë¶=12 0$ùë¶=03 5
Tree A Tree B 15. Mai 2025
Different types of solutions
10
Balanced Scorecard¬ß√úberarbeitung der Inhalte¬ßWiedereinf√ºhrung der BSC zum kontinuierlichem Controlling
ISO-Zertifizierung¬ßInterne Audits im HWS und FSS¬ßISO INTEGRA 1x1¬ßVerpflichtende Besprechung von Prozessen auf Ressort-/ Stabstreffen 3. Juli 2025
What then?
Consider technical performance metric that is independent of threshold
‚Ä¢ Solution: Receiver Operating Characteristic
‚Ä¢ Simulate thresholds from 0 to 1 and calculate TPR and FPR for every threshold value
‚Ä¢ Plot every (TPR, FPR) tuple with TPR being on the y-axis and FPR on the x-axis
18 3
See https:/ /www.epa.gov/energy/greenhouse-gas-equivalencies- 
calculator.
4
See https:/ /github.com/microsoft/EconML.
5
Note that in our case, the propensity score is independent of X. 
We thus follow Athey et al. ( 2023 ) and set ÀÜe (x
i
) ÔøΩ
P
N
iÔøΩ1
w
i
N
.
6
If we knew this curve beforehand, we could set the optimal to 
around 50% treated (and not 59.3% as in Table 4 ), and we would 
have even stronger results. However, we do not know the curve 
before applying it to test data, so we conservatively refrain from 
highlighting these ‚Äúex post optimized‚Äù results in a table.
7 Journal of the Association for Information Systems 
 
808 
Statistical parity aims to ensure an equal likelihood of 
receiving a positive prediction (e.g., creditworthiness) 
for both disadvantaged and advantaged groups 
(Calders & Verwer, 2010). Therefore, a reduced 
disparity between the two groups indicates enhanced 
fairness (Pessach & Shmueli, 2022). We calculate the 
degree of statistical parity as follows: 
ùëÜùë°ùëéùë†ùëñùë†ùë°ùëñùëêùëéùëô ùëùùëéùëüùëñùë°ùë¶ =  ùëÉ(ùëåÃÇ = 1|ùëÜ = 0) ‚àí ùëÉ(ùëåÃÇ  = 1|ùëÜ = 1). 
S represents a (legally) protected attribute on which the 
discrimination is based on, e.g., race or gender. S = 0 learning rate, data subsample used for each tree, 
maximum depth of a single tree, maximum features by 
tree and level, and the minimum child weight. We 
calibrated the model‚Äôs performance against the ROC -
AUC score. We did so because this score (1) considers 
both the true positive rate and the false positive rate, (2) 
is invariant to the classification threshold, and ( 3) is 
typically a good choice for imba lanced datasets. 
Crucially, we train ed this model, which simulates 
investor choices, only once, right before the first 
iteration of a simulation commenced.",7.363683701,1,"The context provides a slide that explicitly shows the formula ""Bal. Acc. = (Sensitivity + Specificity) / 2""[cite: 914].",0.5,"The first formula, Bal. Acc. = (Sensitivity + Specificity) / 2, is directly supported by the context [911]. The second formula, Bal. Acc. = 2 * Sensitivity * Precision, is not mentioned in the context and appears to be a hallucination.",1,The generated answer provides the correct formula which is identical to the ground truth.,,
"According to the text, what is information gain?",Information gain is the improvement in an evaluation measure (such as the reduction in entropy) that is achieved by splitting the data at a parent node (level t) into its child nodes (level t+1).,"According to the text, information gain is the attribute with the largest information gain, i.e., Income. It‚Äôs used in a causal forest and is calculated as 0.92‚àí46‚ãÖ1+26‚ãÖ0=0.25 and 0.92‚àí56‚ãÖ0.72+16‚ãÖ0=0.32.","26. Juni 2025
Information gain: example
12
We choose the attribute with the largest information gain, i.e., Income
ID AgeIncomeRepayment1 Old HighYes2 YoungHighYes3 Old HighYes4 Old HighNo5 YoungHighYes6 Old LowNo
Data at node tùê∫ùëéùëñùëõ()*=0.92‚àí46‚ãÖ1+26‚ãÖ0=0.25
ùê∫ùëéùëñùëõ+,-./*=0.92‚àí56‚ãÖ0.72+16‚ãÖ0=0.32 integration. The experience highlighted the crucial role 
of early, clear communication on data needs and the 
value of combining academic and business approaches 
to enrich data analysis and consumer insights. For further 
details on the implementation, see Online Appendix A.3.
3.2. Results
In our field experiment, we analyze results in two parts: 
first, the impact of green nudging on key business 
metrics and second, the mechanism underlying the 
effect on customer product returns. Importantly, our 
analyses comprise all customers who viewed their 
shopping cart at least once, even if they did not make a Keywords: electronic commerce ‚Ä¢ nudging ‚Ä¢ causal forest ‚Ä¢ digital footprint ‚Ä¢ consumer returns ‚Ä¢ artificial intelligence
1. Introduction
In recent years, global e-commerce has experienced sig -
nificant and sustained growth. E-commerce presents 
numerous advantages for both customers and retailers. 
However, the lenient, and frequently free, return poli -
cies introduce drawbacks that complicate this expan -
sion. In the fashion industry, the share of purchases 
returned can reach a staggering 50% (Dzyabura et al. 
2023 ).
Product returns pose a substantial financial burden Kosten und die m√∂glichen 
Benefits
in diesen Algorithmen mit 
gelernt wurden.
Zu einem gewissen Grad, was dazu 
f√ºhrt,
dass es f√ºr die Unternehmen 
profitabler ist,
in einer automatisierten Art und 
Weise,
M√§nnern anzeigen, Werbeanzeigen 
f√ºr Stammberufe zu zeigen
und Frauen Anzeigen f√ºr 
bestimmte
Kosmetikprodukte anzuzeigen,
einfach aus einer 
marktwirtschaftlichen 
Perspektive.
Aus einer √∂konomischen 
Perspektive,
was die Unternehmen an Eink√ºnfte 
erzeugen k√∂nnen,
was innerhalb dieser 
algorithmischen,
automatisierten Struktur 
stattfinden kann.
Auch das Papier werde ich Ihnen
hochladen auf Olat f√ºr 
diejenigen, Retrieval Augmented GenerationEven with prompting or fine tuning, domain specific knowledge not necessarily in LLM‚Ä¢internal knowledge in companies‚Ä¢new knowledge after knowledge cutoffSimple idea: provide LLM with additional contextual information that its answer to a prompt refers to‚Ä¢Model frozen and does not learn new knowledge in parameters‚Ä¢Contextual answers to questions that refer to the new information not in training data‚Ä¢Information needs to be in specific formatCan tackle several problems of LLMs‚Ä¢Use of current information‚Ä¢No additional training (cost saving)‚Ä¢Higher accuracy of outputs‚Ä¢No data leaks
27 die Frage stellt.
Das m√ºssen Sie antworten k√∂nnen.
Vielleicht auch in der Klausur.
Naja, wenn ich als 
Wissenschaftler dieses Tool 
nutze,
kreiere ich zum allerersten Mal 
durch dieses
kontinuierliche Lernen neue 
Informationen,
die das System updaten,
die auch die ganzen guten Leute 
dort
hinten in den Tauern 
beeinflussen.
Wir haben zum Ersten Mal massive 
Spill Over
Effekte √ºber Industrien hinweg 
in dem Sinne,
dass durch die Nutzung des 
Systems,
durch die Verbesserung des 
Systems in Academia,
also in der Forschung,
auch die Nutzung dieser Systeme
in den Banken tendenziell besser 
werden,",8.533741474,0.2,The context describes information gain with a specific numerical example [cite: 929] but fails to provide a general definition as requested by the question. It shows an application but does not explain the underlying concept.,1,"The generated answer faithfully describes the content of the context, which provides a numerical example of choosing the attribute with the largest information gain [928] and shows the calculation.",1,"The generated answer is semantically equivalent to the ground truth, both explaining that information gain is the improvement achieved by splitting data at a node.",,
What is KNN used for?,KNN is a supervised learning algorithm used for classification and regression.,"The provided text doesn't contain information about what KNN (K-Nearest Neighbors) is used for. It discusses digital transformation, machine learning, and AI, but it doesn't explain the concept of KNN.","Die Digitalisierung und datengetriebene Transformation ver√§ndern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen √ºber die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends ‚Äì ML bietet vielf√§ltige Ans√§tze, um Managemententscheidungen fundierter und effizienter zu gestalten. mann et al. 2016 ) commonly manifest as design features 
in the user interface. Online marketplaces deploy digi -
tal nudges to stimulate product purchases, with retai -
lers using a variety of persuasive strategies to bolster 
profits (Ghose et al. 2023 ). However, such nudges can 
undermine consumer benefits by exploiting cognitive 
weaknesses (‚Äúdark patterns‚Äù) (Narayanan et al. 2020 , 
Posner et al. 2023 ) (e.g., by inducing fear of missing out 
through signals of scarce product availability (Hu et al. 
2019 )). Our work relates to prior research on digital 
nudging in the customer journey (Sch ¬®ar and Also General Purpose und
vorher war mal und ich finde den 
Namen furchtbar.
Aber um sie nicht zu verwirren,
habe ich eine andere als die 
herk√∂mmliche Abk√ºrzung,
die Sie in vielen √∂konomischen
B√ºchern noch finden, n√§mlich 
GPT.
Das ist General Purpose.
Technologie hat nat√ºrlich Open 
AI
uns alle so ein bisschen 
versaut.
Dieses Wort zu benutzen,
insbesondere wenn man irgendwie 
an der
Schnittstelle zu Machine 
Learning arbeitet,
weil alle direkt an das 
Sprachmodell denken.
Deswegen hier diese furchtbare
Abk√ºrzung General purpose
Tonnen general purpose 
technology.
Diese Technologien haben was letztlich ist die Nutzung 
und
Akzeptanz von der KI 
Technologie.
Wir versuchen uns in der 
Wirtschaftsinformatik
gerade so ein bisschen wieder 
auf das Neue,
auf die neue Kuh, die durchs
Dorf getrieben wird, zu 
konzentrieren.
Und dann schaffen wir meistens
irgendwelche neuen coolen 
Begriffe,
damit man auch sch√∂n 
konzeptionell
unterschiedliche Aspekte,
unterschiedliche Technologien 
und die Idiosynkrasien,
die existieren von diesen 
Technologien
in der Nutzung von Menschen.
Um das mal sehr klar 
abzugrenzen,
was wir haben als Oberbegriffe 
Wenn wir
√ºber Mensch Maschine 
Kollaboration sprechen, die Frage stellt.
Das m√ºssen Sie antworten k√∂nnen.
Vielleicht auch in der Klausur.
Naja, wenn ich als 
Wissenschaftler dieses Tool 
nutze,
kreiere ich zum allerersten Mal 
durch dieses
kontinuierliche Lernen neue 
Informationen,
die das System updaten,
die auch die ganzen guten Leute 
dort
hinten in den Tauern 
beeinflussen.
Wir haben zum Ersten Mal massive 
Spill Over
Effekte √ºber Industrien hinweg 
in dem Sinne,
dass durch die Nutzung des 
Systems,
durch die Verbesserung des 
Systems in Academia,
also in der Forschung,
auch die Nutzung dieser Systeme
in den Banken tendenziell besser 
werden, sollte sich innerhalb
meines Prozesses
innerhalb dieses Workflows auch 
ver√§ndern?
Integriert mehr Integration?
Und ein Beispiel hierf√ºr ist 
Ada. Kennt das jemand?
Hat jemand schon mal geh√∂rt,
es war ein Startup,
was in
der Pre Curve Zeit ein Customer 
Service Angebot hatte?
Die haben die Automatisierung
damals auch nicht mitgenerativen 
KI Systemen.
Aber ein sehr
clever zusammengestelltes 
Applikationssystem,
wo Customer Compliance gehandelt 
worden sind.
Das wurde aufgekauft innerhalb 
der
kurze Zeit von einem uns
allen bekannten gro√üen Provider 
von digitalen Calls,
n√§mlich Zoom Zoom hat 
festgestellt,",6.106919765,0,"The context discusses machine learning, digitalization, and AI in general terms but does not mention or explain the K-Nearest Neighbors (KNN) algorithm.",1,The generated answer is a faithful representation of the context's limitations. The context discusses digital transformation and machine learning applications but does not mention the K-Nearest Neighbors (KNN) algorithm.,1,The generated answer is semantically identical to the ground truth.,,
"According to the document, what are the three components of the training process of supervised machine learning?",Representation +Evaluation +Optimization,"According to the document, the three components of the training process of supervised machine learning are:

*   Representation
*   Evaluation
*   Optimization","12. Juni 2025
Components of supervised MLSupervised machine learning methods fit a model to data based on an evaluation criterion‚Ä¢In very general terms, we can distinguish three components of three training process‚Ä¢We will first talk this through using simple linear regression‚Ä¢Same logic will be applied to more complex models
16
Representation +Evaluation +Optimization 12. Juni 2025
Components of supervised MLSupervised machine learning methods fit a model to data based on an evaluation criterion
17
Representation+Evaluation +Optimization
The model architecture that stores the learned knowledge.Now: linear regressionthat comprises learnable the parameters called coefficients.
'ùë¶=)ùëìùíô=+ùõΩ!++ùõΩ""ùë•""+‚ãØ++ùõΩ#ùë•$ allererste Vorlesung,
wo wir gesagt haben,
dass es nie um einen Selbstzweck 
geht,
sondern Machine Learning immer
eigentlich dazu dienen soll,
bestimmte Entscheidungen zu 
verbessern,
m√∂glicherweise auch ganz neue
Entscheidungssituationen 
herbeizuf√ºhren,
die ich vorher h√§tte nicht 
treffen k√∂nnen,
weil einfach zu viel 
Unsicherheit besteht.
Und dieser Bottom up Approach 
besagt Wir nehmen
uns den gesamten Workflow,
wir teilen den Workflow in 
einzelne
Tasks auf, wir die Composen.
Diesen gesamten Workflow gehen 
in
einem bestimmten Tasks in
ihrem Ablauf hinein und 
versuchen zu identifizieren,
an welcher Stelle eben Modulbeschreibung der Vorlesung 'Machine Learning f√ºr Management Entscheidungen': Lernziele der Vorlesung 'Machine Learning f√ºr Management Entscheidungen': angefangen,
dar√ºber zu sprechen,
was Machine Learning von einer 
ganz,
ganz konzeptionellen Idee 
liefern kann.
Wir haben ein bisschen 
Terminologie
eingef√ºhrt und damit w√ºrde
ich gerne mit Ihnen anfangen.
Sozusagen, um alle hier wach zu 
machen, auch mich selber.
In den Vorlesungsmodus zu 
begeben.
Machen wir einen kurzen Recap 
auf zwei Folien.
Wenn Sie sich erinnern, sind das 
hier
Kernelemente von Machine 
Learning.
Sie k√∂nnen jede Machine Learning 
Funktion,
jedes Modell sogar GPT in
dieser Gleichung hier 
ausdr√ºcken.
Wir haben drei verschiedene 
Komponenten.
Wir haben hier dieses H√ºtchen,",5.426834106,1,"The context provides a slide that explicitly lists and defines the three components: ""Representation + Evaluation + Optimization""[cite: 959].",1,"The generated answer directly reflects the information in the context, which explicitly names the three components as ""Representation"", ""Evaluation"", and ""Optimization"".",1,The generated answer is identical to the ground truth.,,
"In the case study with the Sparkasse, is the combination of a human and a machine advisor better or worse than the machine alone?",Worse.,"According to the document, the combination of a human and a machine advisor is ""a little worse"" than the machine alone in the case study with the Sparkasse. Specifically, ""Human plus Maschine ist die Beratung richtig? In 70¬†% der F√§lle ein bisschen schlechter.""","sogar.
Naja, wenn Mensch plus Maschine 
zusammenarbeitet,
ist das gemeinsame Produkt 
schlechter als das,
was die Maschine alleine macht.
Ist aber egal, weil ich f√ºhle 
mich besser,
wenn der Mensch dabei ist.
Dieser emotionale,
wie wir es hier aus dieser
Theorie von der Elaboration 
likelihood
Model der Peripherie peripheral 
Part in Ihrem Gehirn.
Also diese affektiven Signale, 
da ist jemand,
der h√§lt Ihre Hand,
wenn es schief geht,
auf den k√∂nnen Sie sauer sein, 
wenn es schief geht.
Und dann k√∂nnen wir das hier 
zeigen,
dass es eben nicht darum geht,
dass der Mensch die Beratung 
mehr akzeptiert, Und dann k√∂nnen wir das hier 
zeigen,
dass es eben nicht darum geht,
dass der Mensch die Beratung 
mehr akzeptiert,
mehr bereit ist zu bezahlen am 
Ende.
So suggerieren unsere 
Ergebnisse,
wenn Mensch plus Maschine da 
sind.
Nicht weil es denkt es besser, 
sondern einfach,
weil da jemand da ist, der ihnen 
die Hand h√§lt.
√Ñhm, ja.
Takeaways, das habe ich glaube 
ich,
schon so zusammengefasst.
Es geht vor allem um dieses 
Handholding.
Maschine plus Mensch ist
zumindest nicht sch√§dlich in der 
Beratung,
was die Qualit√§t der Beratung 
angeht.
Aber der Mensch, der Kunde von 
Ihnen,
wird es Ihnen danken Forschung
in unbedingt nahe legen m√∂chte,
ist die Idee von Mensch 
Maschine.
Komplementarit√§ten bedeutet Was 
wir
erreichen wollen ist eigentlich 
ein Setting,
wo Mensch und Maschine auf eine
Art und Weise zusammenarbeiten,
dass die Performance dieses
kollaborativen Systems besser 
ist als
die Performance der einzelnen 
Komponenten.
Und das kann nat√ºrlich
aus verschiedenen Gr√ºnden 
entspringen.
Diese komplement√§ren St√§rken.
Haben Sie eine Idee, was so die 
zwei Faktoren sind,
warum Menschen und Maschinen 
sich erg√§nzen und
warum nicht die Maschine immer 
besser
ist und nicht der Mensch immer 
besser ist? Auf Deutsch gesagt das haben wir
uns angeschaut und wie gesagt,
das ist jetzt der 
Schnelldurchlauf,
weil ich sie hier nicht zu lange 
halten m√∂chte.
Frage Nummer eins Macht der 
Mensch
es besser oder schlechter?
Naja, if anything macht der 
Mensch eher schlechter.
Wir sehen, die Maschine alleine 
hat eine
Accuracy aus den
73¬†% Mensch plus Maschine ist 
die Beratung richtig?
In 70¬†% der F√§lle ein bisschen 
schlechter.
Statistisch gesehen haben unsere 
Tests aber gezeigt,
dass es nicht signifikant ist.
Deswegen ist so ein bisschen die
Message hier If anything macht 
der Mensch nicht besser, vergleichbar sind.
Und grunds√§tzlich ist dieses 
Fehlverhalten von Maschinen,
wenn systematisch basierend auf
bestimmten soziodemographischen 
Faktoren,
die wir rechtlich oder
als Gesellschaft f√ºr wichtig 
erachten.
Wenn dort Unterschiede 
vorliegen,
die in der Realit√§t aber 
eigentlich keine Rolle spielen,
also ohne Rechtfertigung,
unterscheidet die Maschine in
ihrer Vorhersagegenauigkeit,
in welchem Ma√ü auch immer wir 
das jetzt messen,
zwischen diesen beiden Gruppen,
dann sprechen wir von 
algorithmischer Diskriminierung.
Algorithmische Diskriminierungen 
gibt es,
ein ganz tolles Papier hier von 
zwei Es gibt n√§mlich zwei Arten
von Mensch Maschine 
Kollaboration.
Wenn man so grob einteilt auf 
der einen Seite die
Idee von 
Entscheidungsunterst√ºtzung und 
auf
der anderen Seite die Idee von
Entscheidungsautomatisierung.
Aber auch bei der 
Entscheidungsautomatisierung.
Das Konzept von Human in the 
Loop ist,
dass der Mensch entscheidet 
Welche Entscheidungen
lagere ich denn √ºberhaupt an die 
Maschine aus?
Das hei√üt, hier geht es dann 
eben um diesen
Unterschied von Humans in
the loop dahingehend Sie 
entscheiden,
Ich transferiere 
Entscheidungsgewalt in diesen
automatisierten F√§llen oder Sie 
behalten immer",8.649173498,1,"The context directly answers the question. It states, ""Mensch plus Maschine ist die Beratung richtig? In 70 % der F√§lle ein bisschen schlechter"" (Human plus machine, is the advice correct? In 70% of cases, a little worse) [cite: 983-984].",1,"The claim is directly supported by the context, which states, ""Mensch plus Maschine ist die Beratung richtig? In 70 % der F√§lle ein bisschen schlechter"" (Human plus machine, is the advice correct? In 70% of cases, a little worse) [968].",1,"The generated answer and the ground truth are semantically identical, both stating that the combination of human and machine is worse than the machine alone.",,
"What is the concept of 'Mixed Initiative' in human-AI interaction, as exemplified by a smartwatch asking if it should record a workout?","'Mixed Initiative' is a middle ground between full automation and full manual control, where the system proactively suggests an action, but the human still makes the final choice to accept or reject it.","Based on the text, the concept of ‚ÄúMixed Initiative‚Äù in human-AI interaction refers to a shift where humans take a more active and discerning role in the interaction, rather than simply relying on the AI to make decisions for them. 

Here‚Äôs how it‚Äôs illustrated with the smartwatch example:

*   **Initial AI Suggestion:** The smartwatch initially *suggests* recording a workout. This is a purely proactive AI action.
*   **Human Questioning:** The text highlights that the human is then prompted to question the AI: ‚ÄúIst es eine Information, die Sie nutzen sollten in Ihrer Entscheidungsfindung oder nicht?‚Äù (Is it information you should use in your decision-making or not?).

This questioning represents the ‚Äúmixed initiative‚Äù ‚Äì the human isn‚Äôt passively accepting the AI‚Äôs recommendation but actively evaluating it and deciding whether to proceed. It‚Äôs a move towards a collaborative partnership where humans and AI work together, with the human retaining control and critical judgment.

Essentially, it‚Äôs about humans learning to intelligently interact with AI systems, recognizing their limitations (like generative AI‚Äôs reliance on predictions), and using their own knowledge and reasoning to guide the interaction.","So legen wir los. Herzlich 
willkommen.
Vorlesung f√ºnf sozusagen.
Fast schon Bergfest, oder?
Heute ist, glaube ich, Bergfest,
wenn man die restlichen 
Vorlesungen zusammenz√§hlt.
Auch weil ich jetzt schon 
mehrfach gefragt wurde.
Dazu mit der Klausur.
Das hier ist jetzt die letzte
Vorlesung aus diesem ersten 
Teil,
wo es darum geht, ein 
grunds√§tzliches
Verst√§ndnis daf√ºr zu schaffen,
was KI bewirken kann,
wie Menschen mit KI 
zusammenarbeiten k√∂nnen,
was potenzielle Schwachpunkte 
und Probleme sind,
wenn wir KI einsetzen.
Heute sprechen wir √ºber Mensch 
Maschine Interaktion,
bauen sozusagen auf der 
Erkl√§rbarkeit. die auf Social Media trainiert 
worden ist.
Die Idee gibt es nat√ºrlich schon 
l√§nger.
Ich glaube, diese Idee
hat ihn gewisserma√üen vielleicht 
Potenzial zu helfen.
Es gibt tats√§chlich KI Systeme,
die Menschen mit Depressionen,
dass man √ºber die uhr √ºber 
Sensorik merkt,
wenn Menschen in eine bestimmte 
Episode kommen,
eine Vorhersage gemacht wird,
ob das eine Episode ist und dann
auf dem Handy ein Chatbot mit 
einem interagiert,
ganz einfache Fragen stellt.
Und dann gibt es erste 
Andeutungen
aus der medizinischen Forschung,
wo es eben um Mensch Maschine 
Interaktion geht.
Dass das helfen kann, amounts of data that may exceed human analytical capacities, enabling AI to provide decision
recommendations (Shaw, 2019).
Modern technologies, including artiÔ¨Åcial intelligence solutions, have revolutionized work and
contributed to developing human resources management (HRM) for improved outcomes
(Hmoud and Laszlo,2019). One signiÔ¨Åcant area where their impact is felt is in the recruitment
process, where AI implementation can potentially provide a competitive advantage by enabling a
better understanding of talent compared to competitors, thereby enhancing the company‚Äôs
competitiveness (Johansson and Herranen,2019). wo Sie KI einsetzen k√∂nnen,
wann und wo m√∂gliche 
Problemstellungen sind.
Aus diesem ersten Teil hier 
zumindest,
dass Sie uns das strukturiert 
wiedergeben
k√∂nnen und uns zeigen,
dass Sie diese Denkweise 
verstanden haben.
Wenn wir heute dann wie gesagt,
einsteigen und das Thema des 
ersten Blockes abschlie√üen.
K√ºmmern wir uns jetzt noch mal 
darum,
was eigentlich der Mensch in 
diesem ganzen System
weiterhin noch macht und k√ºmmern 
uns
um diese Mensch Maschine 
Interaktion.
Wenn Sie sich erinnern Sehr fr√ºh
in der zweiten Vorlesung haben 
wir festgestellt,
dass die meisten Machine 
Learning Anwendungen System,
wo kein Mensch mehr dabei ist 
oder von Mensch Berater,
der mit der KI zusammenarbeitet
und gemeinsam sozusagen als
Human AI Team diese Beratung an 
den Kunden gibt.
Der Kunde ist eben dar√ºber 
informiert.
Was wir gemacht haben, ist Wir 
haben
eine Feldstudie gemacht, zwei 
Stufen.
Wir haben f√ºr die erste Stufe 
ganz viele Daten gesammelt,
haben KI System gebaut,
was bewertet hat, ob ein 
bestimmtes Investitionsobjekt,
hier eben P2P loans,
also Privatkredite, finanziert 
werden sollten,
also ob ein Kunde 100¬†‚Ç¨ 
beispielsweise in die in
jemand anderen als Privatkredit
investieren m√∂chte mit einem schlecht?
Ist es eine Information,
die Sie nutzen sollten in
Ihrer Entscheidungsfindung oder 
nicht?
Und da sehen wir mehr und mehr,
dass ich eben diese
Idee der ver√§nderten Rolle des 
Menschen
in der Interaktion mit 
Maschinen,
insbesondere mit diesen Systemen 
der generativen KI,
immer mehr dorthin verschiebt.
Dass der Mensch die F√§higkeit 
besitzen muss,
vern√ºnftig mit der ausgegebenen 
Information umzugehen.
Und auch bei generativer
KI haben wir ja schon 
besprochen,
dass es im Kern eigentlich nur 
Vorhersagen sind.
Immer wieder rekursive
Vorhersagen √ºber das n√§chste 
Wort und
irgendwas kommt raus.",19.96328354,0.8,"The context describes a situation where a smartwatch proactively asks the user, ""Soll ich das eigentlich aufzeichnen?"" (Should I actually record this?)[cite: 1024], but the user retains the final decision. This perfectly exemplifies the concept of Mixed Initiative, where both the system and the human initiate actions, even if the term itself isn't explicitly defined in the provided snippets.",0.8,"The generated answer is largely faithful. The context does show that humans take a more active role in questioning the AI's information [994-995]. However, the generation's claim that the smartwatch initially *suggests* recording a workout, which the human then evaluates, is an interpretation. The context frames it more as a question from the watch, which is slightly different.",1,"The generated answer and the ground truth are semantically equivalent. Both describe 'Mixed Initiative' as a collaborative process where the AI can make suggestions, but the human retains the final decision.",,
What did the speaker say about the possibility of the smartwatch automatically starting to record a workout?,The speaker said the smartwatch could estimate the probability that the user wants their sport recorded.,"The speaker discussed the possibility of a smartwatch automatically starting to record a workout. They explained that the smartwatch *could* automatically start recording, but they wanted to avoid that. Instead, the smartwatch would vibrate and ask, ""Should I record?"" This approach was designed to minimize risk, as the user could always decline if they didn't want to be recorded. They also acknowledged that while this approach was designed to be less intrusive, it could also be perceived as slightly annoying.","Nee, muss es nat√ºrlich nicht.
Denken Sie an diejenigen im 
Raum,
die irgendeine Smartwatch haben.
Wenn Sie Sport machen und 
pl√∂tzlich
das System Sie fragt Soll ich 
das eigentlich aufzeichnen?
Sind Sie gerade am Sport machen?
Das ist irgendwie so eine Art 
Mischung davon.
Also weder das System selber 
entschieden,
jetzt irgendwas aufzuzeichnen 
ohne Ihre Einwilligung.
Sie haben also diese 
Entscheidung
des automatisierten 
Aufzeichnungs nicht
an die Maschine delegiert.
Aber Sie haben auch nicht aktiv 
gesagt Na ja,
ich gehe jetzt hin und such das 
raus.
Sondern die Maschine von sich 
entscheidet, wenn ich dieses Ziel nicht habe.
Beziehen Sie das hier drauf.
√úberlegen Sie sich.
Sie sind drau√üen am Sport 
machen.
Und Sie m√∂chten, dass dieser 
Sport aufgezeichnet wird.
Jetzt kann die uhr entweder
automatisiert einfach anfangen 
aufzuzeichnen,
oder die uhr macht einfach 
nichts in Aktion.
In diesen Extremf√§llen Jetzt 
gehen wir gleich
wieder in die Mitte davon.
Aber Sie laufen und Sie m√∂chten,
dass Laufen aufgezeichnet haben 
Sie laufen, m√∂chten,
dass nicht aufgezeichnet haben 
und
die Maschine kann selber die 
Aktion machen,
das aufzuzeichnen oder die uhr 
macht das eben nicht.
Und dann haben wir vier Dann trainiere ich dieses Modell
nur auf diesen vier 
Observationen.
Und dann versuche ich zu
testen auf diesen beiden 
Observationen,
die ich explizit aus dem 
Training rausgehalten habe.
Und diese Daten, die ich aus
dem Training rausgehalten habe,
nenne ich einige werden es 
wahrscheinlich schon wissen.
Sie haben beispielsweise mein 
Seminar
letztes Semester besucht und 
sie, glaube ich, auch.
Was sind das? Was abschneiden?
Testdaten? Ja. Sie wollten 
sagen, n√§chstes Mal.
Unterscheiden zwischen Trainings 
und
Testdaten. Aber Sie haben 
vollkommen recht.
Es sind trotzdem historische 
Daten.
Aber diese Testdaten. dritte Aktion haben.
N√§mlich die schl√§gt ihm was vor.
Die uhr macht nicht einfach 
nicht und
macht nicht einfach Doch,
sondern die uhr vibriert und 
sagt
Ihnen Soll ich aufnehmen?
Ja. Nein ist Suggestion.
Idee, die hier eingebracht wird, 
ist naja,
Suggestion minimiert Risiko,
weil sie k√∂nnen immer abw√§hlen,
wenn sie was nicht wollen.
Aber irgendwie ist auch nervig.
Und wenn etwas automatisiert 
abgeht
und das richtig funktioniert,
ist es schon cooler, als wenn 
ich irgendwie
die ganze Zeit selber irgendwas 
eingeben muss.
Deswegen wurde gesagt naja,
wenn die uhr nicht automatisiert 
die Aktion durchf√ºhrt, Paper auf einer
Informatik Konferenz postuliert 
wird, ist.
Naja, lassen Sie uns mal 
annehmen,
das System k√∂nnte die 
Wahrscheinlichkeit einsch√§tzen,
dass Sie ein bestimmtes Goal 
haben.
Die Maschine hat irgendeine 
M√∂glichkeit vorherzusagen,
was die Wahrscheinlichkeit,
dass Sie gerne Ihren Sport 
aufgezeichnet h√§tten.
Und jetzt haben wir hier noch 
gegebene Evidence.
N Lassen wir mal weg.
Intuition dahinter ist wenn die 
uhr Ihren Puls misst,
kann die uhr eine Vorhersage 
dar√ºber machen.
Was ist denn eigentlich egal?
M√∂chten Sie es aufgezeichnet 
haben?
Gegeben Ihren Puls 
beispielsweise abgehandelt,
habe ich ihn noch mal wieder 
eine Case Study
mitgebracht von einem Papier von 
Olli Hinz,
mir und zwei Kollegen aus Paris 
von der Chaussee,
wo wir uns hier mit der 
Sparkasse tats√§chlich
im Taunus angeschaut haben,
wie Menschen tats√§chlich mit KI 
interagieren.
Ob es eigentlich gut ist,
wenn Ihr Sparkassenberater eine 
KI benutzt,
um Ihnen Investmentberatung zu
geben und wie Sie eigentlich
darauf reagieren oder ob
das Ganze vielleicht 
automatisiert ablaufen sollte.
Das Papier ist jetzt
also kommt bald im Management 
Science Journal raus.
Wie gesagt, die letzten f√ºnf 
Minuten.
Aber vorher noch mal",10.44296312,1,"The context describes a scenario where a smartwatch with a predictive capability asks the user if it should start recording their sport activity, stating ""die uhr vibriert und sagt Ihnen Soll ich aufnehmen?"" (the watch vibrates and tells you, Should I record?)[cite: 1040]. Source [1044-1045] further explains this is based on the system estimating the probability of the user's goal.",0,"The generated answer is not faithful. The context explicitly states the smartwatch does *not* automatically start recording, but instead vibrates and asks, ""Soll ich aufnehmen?"" (Should I record?) [1022]. The generation's claims that the designers wanted to avoid this and that the current approach could be annoying are also not present in the context.",1,The generated answer is semantically identical to the ground truth.,,
The lecture describes two extremes in human-machine collaboration. What is 'Algorithm Aversion'?,"'Algorithm Aversion' is the observation that people often consciously choose not to use a helpful algorithm, even when they know it is objectively more accurate than their own opinion or that of other humans.","According to the lecture, ‚ÄúAlgorithm Aversion‚Äù is the observation that people consciously choose to forgo a useful interaction with a machine.","interagieren.
Diese Beobachtung,
dass Menschen auf diese 
n√ºtzliche
Interaktion mit der Maschine 
bewusst verzichten,
nennen wir Algorithmen Aversion.
Und dann haben wir noch das 
Gegenteil davon,
n√§mlich die sogenannte Algorithm 
appreciation,
wo Sie, wenn ich Ihnen sage,
ein anderer Mensch gibt Ihnen 
eine
Filmempfehlung oder ein KI
basiertes System gibt ihm eine 
Filmempfehlung,
dann tendieren die meisten 
Menschen dazu,
zu sagen Ich m√∂chte mich lieber
auf die Empfehlung von einem 
Menschen konzentrieren.
Dann sprechen wir √ºber Algorithm 
Appreciation.
Aber es gibt eben auch Menschen,
die sagen Naja, meine ganzen wo man quasi die man zur 
Rechenschaft ziehen k√∂nnte,
wenn die Entscheidung 
fehlschl√§gt.
Davor schaltet, auch wenn er 
automatisiert
die ganze Zeit quasi einfach nur 
sagt ja, jetzt ist fein.
Dann hat man zumindest jemanden, 
dem man zutraut.
Das ist grunds√§tzlich richtig.
Behalten Sie den Gedanken bei,
weil n√§chstes Mal sprechen wir 
√ºber
die Idee von Decision Threshold 
nochmal.
Aber das ist grunds√§tzlich auch 
etwas,
was so ein bisschen die 
Forschung andeutet.
Menschen haben
diese Algorithmen Aversion und 
machen es nicht,
weil sie am Ende jemanden l√§hmen 
blamieren m√∂chten.
Wenn eine Maschine etwas macht, Mitigating unwanted biases with adversarial 
learning. Proceedings of the 2018 AAAI/ACM 
Conference on AI, Ethics, and Society (pp. 335-
340).  
Zhao, H., & Gordon, G. (2019). Inherent tradeoffs in 
learning fair representations. Proceedings of the 
33rd Conference on Neural Information 
Processing Systems.  
≈Ωliobaitƒó, I. (2017). Measuring discrimination in 
algorithmic decision making. Data Mining and 
Knowledge Discovery, 31(4), 1060-1089. alters the ‚Äúground truth‚Äù the model aims to predict. In 
a sense, predictions that are incorrect ex ante become a 
self-fulfilling prophecy ex post (Falk & Kosfeld, 2006; 
Bauer & Gill, 2023). The added complexity of this 
endogeneity to the analysis of the evolution of 
algorithmic discrimination is noteworthy, even though 
it was not the focus of this study. We propose this as a 
fruitful avenue for future research because it may 
provide a more holistic view on the dynamic 
consequences of algorithmic discrimination. 
5.5 Concluding Remarks  
A final remark is worth making. Of course, our work Dann sprechen wir √ºber Algorithm 
Appreciation.
Aber es gibt eben auch Menschen,
die sagen Naja, meine ganzen 
Freunde,
die gucken eh ganz andere Sachen 
als ich.
Deswegen ist denen ihre 
Anweisung den
ihre Advice nicht wirklich das,
auf das ich vertraue und 
deswegen
gehe ich mehr auf den 
Algorithmus.
Wenn ich also das vorgelegt 
bekomme
in der Algorithm Appreciation,
w√§hle ich bei √§hnlichen
Performance Beliefs eher dieses 
technische System.
Das sind diese zwei Extremen, 
Ja.
Und irgendwo dazwischen passiert
die eigentliche Mensch Maschine 
Interaktion.
Aber das ist der Rahmen, in dem 
wir uns bewegen. updating remains an underexplored area in the literature.  
Second, our paper complements the nascent body of 
studies exploring the origins and impacts of 
algorithmic feedback loops (Burghardt & Lerman, 
2022; Cowgill, 2018). For instance, Lum and Isaac 
(2016) revealed that the iterative updates of a 
predictive poli cing system led to increased 
discrimination against minority groups. Similarly, 
Ensign et al. (2017) showed how feedback loops could",5.607413769,1,"The context directly defines Algorithm Aversion: ""Diese Beobachtung, dass Menschen auf diese n√ºtzliche Interaktion mit der Maschine bewusst verzichten, nennen wir Algorithmen Aversion"" (This observation, that people consciously forgo this useful interaction with the machine, we call Algorithm Aversion)[cite: 1052].",1,"The generated answer is a direct and accurate summary of the information provided in the context, which states: ""Diese Beobachtung, dass Menschen auf diese n√ºtzliche Interaktion mit der Maschine bewusst verzichten, nennen wir Algorithmen Aversion"" (This observation, that people consciously forgo this useful interaction with the machine, we call Algorithm Aversion).",1,"The generated answer and the ground truth are semantically equivalent, both defining 'Algorithm Aversion' as the tendency for people to avoid using a helpful algorithm.",,
What are the two extremes of observation regarding human-machine collaboration?,Algorithm aversion and Algorithm appreciation.,"According to the text, the two extremes of observation regarding human-machine collaboration are:

*   **Algorithm Aversion:** A preference for human help/decisions over AI ones.
*   **Algorithm Appreciation:** A preference for AI help/decisions over human ones.","5. Juni 2025
Two modes of human-AI collaboration
Human-AI collaboration: the cooperative and coordinated interaction between humans (mostly non-AI experts) and AI to solve complex problems or achieve certain goalsTwo primary collaboration modes‚Ä¢Augmentation: AI serves as a decision support tool; human always makes final decision‚Ä¢Automation: AI serves as a tool to delegate tasksto; human or AI makes final decision8
AI
Human
Decision
Makes final decision
Gives advice
AugmentationAutomation
Task
‚ÄúObserves‚Äú task
Observes task
Task
HumanObserves task
AI
Decision
Human makes final decision(no delegation) 5. Juni 2025
Goal: Human-AI complementarities
9
The objective of human-AI collaboration is achieving complementary performance‚Ä¢Humans plus AI outperform either party acting alone for a set of tasks‚Ä¢Complementary strengths can originate from‚Ä¢Access to different data (e.g., soft signals)‚Ä¢Learning of distinct problem-solving strategies (imperfectly correlated errors) 5. Juni 2025
Many factors shape human-AI collaboration
7
Mahmud et al. 2022
In the context of human-AI collaboration, we often refer to‚Ä¢Algorithm aversion: Preference for human help/decisions over AI ones‚Ä¢Algorithm appreciation: Preference for AI help/decisions over human onesThe occurrence of either depends on many factors that can be sorted under UTAUT subjektiv wahrgenommenen 
Aufgaben pr√§ferieren
wir eher von Menschen,
Hilfe anzunehmen,
dass von Menschen l√∂sen zu 
lassen als von Maschinen.
Wohingegen f√ºr komplexe
objektive Tasks wie Berechnungen 
von Aktienkursen,
Einsch√§tzungen von 
CompanyDefaults etc.
Da tendieren Menschen von dem,
was die Forschung aktuell zeigt 
und es
ist wie gesagt ein sehr aktives 
Feld dazu,
eher Hilfe von Maschinen 
anzunehmen.
Gibt es irgendwelche Fragen 
soweit?
So, jetzt kommen wir zu den zwei 
Modes of Collaboration.
Auch wieder sehr dichotom 
gedacht als √ºber
Kategorien haben wir zwei und es 
gibt eine Str√∂mung, komplexere Zusammenh√§nge.
Sprechen wir dann wieder und das 
fand ich sehr sch√∂n,
die Idee eigentlich Wir haben
ein sehr hochgradiges System 
zwei in der Maschine,
die alle m√∂glichen 
nichtlinearen,
hochkomplexen Muster erkennt,
Wohingegen der Mensch andere 
Muster erkennt,
auf die sich eher fokussieren 
Die System eins Muster.
Eine sehr sch√∂ne Interpretation
dieser grundlegenden Idee,
dass wir unterschiedliche
L√∂sungsstrategien gesucht und 
gefunden haben.
Durch unser Lernen, durch unsere 
Erfahrungen,
die wir im Leben individuell 
gemacht haben.
Beispiele von Mensch Maschine 
Interaktion im Alltag. Probleme hier eine Rolle spielen 
k√∂nnten in Bezug auf
die richtige Gewichtung Ihrer 
eigenen Expertise
und der von der Maschine,
welche Signal Sie bekommen.
Das ist das, womit wir uns heute 
befassen.
Ja. Und wenn es
jetzt um sowas geht wie 
Stellenbesetzung
in der Personalabteilung,
ist das ja verst√§ndlich.
Ja, was ist mit Sektoren,
in denen man sich so schnell,
in denen so schnell
Entscheidungen getroffen werden 
m√ºssen,
dass das √ºberhaupt m√∂glich ist?
Sprechen wir auch dr√ºber.
Es gibt n√§mlich zwei Arten
von Mensch Maschine 
Kollaboration.
Wenn man so grob einteilt auf 
der einen Seite die
Idee von",7.330210924,1,"The context directly defines the two concepts on a slide[cite: 1080]. It lists ""Algorithm aversion: Preference for human help/decisions over AI ones"" and ""Algorithm appreciation: Preference for AI help/decisions over human ones.""",1,"Both claims in the generated answer are directly supported by the context, which defines ""Algorithm aversion"" as a preference for human help over AI and ""Algorithm appreciation"" as a preference for AI help over human [1076].",1,The generated answer is identical to the ground truth.,,
What were the developers struggling with regarding Windows eight?,The developers of Windows 8 were struggling with the bad user interface.,"The developers were struggling with the fact that they had developed Windows 8 almost entirely without involving or considering the actual users. They focused on the system's functionality and features, but didn't adequately consider how users would interact with it. The user interface was considered a ""totale Katastrophe"" (total catastrophe).","5. Juni 2025
Acceptance and appropriate use of technology
2012, Microsoft released Windows 8 that significantly changed the user interface‚Ä¢Many of its features are standard nowadays‚Ä¢Yet, considered one of Microsoft‚Äôs worst OS‚Ä¢In 2021 its market share was about 1% while its predecessor Windows 7 was still at 15%
4
Remember Windows 8?
What does that imply for AI? Desaster f√ºr Microsoft.
Warum? Naja, viele der User 
waren total √ºberfordert.
Das war eigentlich grunds√§tzlich 
ein
tolles System mit ganz vielen 
Neuerungen,
mit ganz vielen Funktionen,
wo sich die Entwickler gedacht 
haben Naja,
das sollte meinen Nutzern 
gefallen.
Das macht alles viel einfacher.
Da soll der Entscheidungsfindung 
Prozessen
arbeiten helfen.
War alles nat√ºrlich well 
intended.
Problem war, wir alle fanden das 
nicht so cool.
Das war bei mir auch der 
Zeitpunkt,
wo ich dann komplett auf Mac 
√ºbergesprungen bin.
Und selbst neun Jahre sp√§ter war 
es immer noch so,
dass der Vorg√§nger Windows 
sieben da.
Die wurden dort entwickelt f√ºr 
Windows acht,
aber die Oberfl√§che war totale 
Katastrophe.
User Interface Wir hatten 
Entwickler,
die sich ausschlie√ülich damit 
besch√§ftigt haben.
Wie kann ich denn ein System 
entwickeln,
was super funktioniert haben,
aber viel zu sp√§t eigentlich
den eigentlichen Nutzer mit 
einbezogen.
Das wurde ja auch als Mobile 
gedacht.
Also wir haben es ja versucht 
auf
dem Microsoft Handy Plattform zu 
machen.
Deshalb ist der Vorsto√ü
ja unterstreicht trotzdem den 
Punkt,
dass die Leute sich nicht 
ausreichend
fr√ºh √ºberlegt haben und der.
Mein Punkt dieser Idee ist 
nat√ºrlich entscheiden,
Ich transferiere 
Entscheidungsgewalt in diesen
automatisierten F√§llen oder Sie 
behalten immer
die Entscheidungsgewalt,
m√ºssen sich aber entscheiden Wie
viel Gewicht geben Sie 
eigentlich?
Der Information von der Maschine 
macht es Sinn.
So fangen wir aber
mal einen Schritt weiter vorne 
an Erinnern Sie sich noch?
Ich wei√ü nicht, ob Sie daf√ºr 
noch zu jung sind, Sogar.
Aber erinnern Sie sich noch
an diese Version von Microsoft?
Microsoft acht kam raus
2012 und es war ein vollkommenes 
Desaster f√ºr Microsoft.
Warum? Naja, viele der User 
waren total √ºberfordert.
Das war eigentlich grunds√§tzlich 
ein √ºbergesprungen bin.
Und selbst neun Jahre sp√§ter war 
es immer noch so,
dass der Vorg√§nger Windows 
sieben
2021 hatte Windows sieben
immer noch 15¬†% Marktanteil von 
Windows Systemen,
wohingegen Windows acht, was
viele neue gute Funktionen 
hatte,
immer noch nur um die 1¬†% war.
Und es ist wieder considered 
eines der
schlechtesten Operating Systeme, 
die es gibt.
weil es einfach niemand benutzt 
hat.
Jetzt nat√ºrlich die Frage Wenn 
ich Ihnen hier
so eine anekdotische Geschichte 
erz√§hle,
um Sie so ein bisschen emotional 
abzuholen,
was glauben Sie, hat das mit KI 
zu tun?
Wie k√∂nnte ich aus dem 
vorherigen Beispiel, abzuholen,
was glauben Sie, hat das mit KI 
zu tun?
Wie k√∂nnte ich aus dem 
vorherigen Beispiel,
dass die KI mir ein Signal gibt?
Ich sehe das und es
ist eigentlich ein hilfreiches 
Signal.
Wie kann ich diese Idee hier auf 
diesen
anekdotischen Fall aus der 
Geschichte
mappen? Wo ist die Verbindung?
Genau hier.
Wir haben ein tolles System. Es 
kann uns helfen.
Viele der Features im
√úbrigen sind heute in einer 
anderen Darstellung,
in einer anderen Art und Weise 
in
den Microsoftsystemen immer noch 
da.
Die wurden dort entwickelt f√ºr 
Windows acht,
aber die Oberfl√§che war totale 
Katastrophe.",7.92121768,1,"The context states that the developers focused on creating a system that worked well technically but failed to involve the user until it was too late (""viel zu sp√§t eigentlich den eigentlichen Nutzer mit einbezogen"")[cite: 1102]. It also explicitly mentions that the user interface was a ""totale Katastrophe"" (total catastrophe)[cite: 1100].",1,"All claims in the generated answer are directly supported by the context. The context states that developers focused on creating a system that worked well functionally but involved the user too late [1092] and that the user interface was a ""totale Katastrophe"" (total catastrophe) [1093].",1,"The generated answer captures the same core reason as the ground truth: the developers failed to consider the end-users during development, leading to a bad user interface.",,
"In a case study about the role of the human, what was the investment amount for the P2P vehicle in the experiment?",100‚Ç¨,The investment amount for the P2P vehicle was 100‚Ç¨.,"5. Juni 2025
Study design (Intuition)
CustomerWants to invest
Bank advisor
Input
Human + AIStage 1 Stage 2
Investment advice
Experiment with 27 bank advisorsAdvice on investment in new P2P vehicle (100‚Ç¨ investment)Without or with AI trained by us for risk predictionField study with 137 bank customers in branchesInvestment decisions on P2P vehicle (100‚Ç¨ investment)Advice from AI, or human + AI
CustomerWould collaborative advice from humans and AI be ‚Äúmore convincing‚Äù compared to pure AI advice?
Hybrid advisoryWould it improve or detract from the quality of advice if human experts had the final say on AI output? decision with that of the investor. For instance, if a 
participant expressed an intention to repay if the investor 
made an investment, and the investor participant indeed 
decided to invest, the game would lead to the socially 
optimal investment-repayment outcome 2  (see, e.g., 
Fischbacher et al., 2012, for the empirical validity of this 
strategy method approach). We employ ed the data 
collected in Study A for two purposes. First, we used it to 
train an ML model that predicts whether a borrower will 
repay based on 10 personal characteristics.3 We introduced Rossum & Drake, 1995), and HTML5 (W3C, 20144). As 
part of Study B, participants played 20 rounds of our 
investment game in the role of the investor, without 
intermediate feedback. In each round, before participants 
made their investment decision, they observed 10 
personal characteristics of a random borrower and an ML 
model‚Äôs forecast about whether the borrower would make 
a repayment. The model was trained using data from 
Study A. Additionally, the borrowers that S tudy B 
participants interacted with were also participants from 
Study A. After they made their decision, the next round the training data, focusing on out-of-sample R-score per -
formance (Schuler et al. 2018 ). We provide hyperpara -
meter tuning details in Online Appendix A.7.
4.1.3. Evaluation of the CML Model. Our evaluation of 
the CML model is based solely on test data and follows 
two steps. First, we assess the CML model‚Äôs predictions 
through group average treatment effects following 
Chernozhukov et al. ( 2018 ), where we separately esti -
mate the treatment effects for individuals who the 
CML model would treat and those who it would not 
treat. Second, we evaluate the CML-based treatment navigate these hurdles using simulations, leveraging 
data from two incentivized empirical studies previously 
conducted as part of our team‚Äôs related research projects, 
i.e., secondary data. In both empirical studies, 
participants engaged in a popular social dilemma game 
that mimics the structure of a sequential investment 
decision used, for example, in loan approval or hiring 
processes (Berg et al., 1995; Fehr & Fischbacher, 2003). 
Our simulation, grounded in empirical data, allowed us 
to avoid making strong theoretical assumptions about 
decision makers‚Äô motives. Instead, we adopted a data- was female. * p < 0.1, ** p < 0.05, *** p < 0.01 denote statistical significance levels. 
 
The regression tables A28 to A32 show results for simulations that were conducted as robustness checks. Specifically, 
for this robustness check, the number of matched investors and borrowers equals 60. By contrast, for the results 
reported in our main text, this number equals 50. As in the simulations whose results we report in the main text, we set 
the size of the minority share of women in the training data used to train the ML model that predicts borrower",5.807467461,1,"The context provides a slide from a presentation that explicitly states, ""Advice on investment in new P2P vehicle (100‚Ç¨ investment)""[cite: 1118].",1,"The generated answer is a direct and accurate statement based on the provided context, which includes a slide stating, ""Advice on investment in new P2P vehicle (100‚Ç¨ investment)"" [1118].",1,The generated answer is identical to the ground truth.,,
"According to the document, what did Eric Horvitz advocate in his 1999 paper?",Elegant coupling of automation with direct manipulation by user.,"According to the document, Eric Horvitz advocated the Mixed-Initiative theory, which he proposed in his 1999 paper. It‚Äôs based on Grounded Theory and qualitative analysis of interview data.","5. Juni 2025
Idea of Mixed-Initiative (Horvitz, 1999) Research methodology. The study is based on Grounded Theory
and qualitative analysis of interview data. Glaser and Strauss
(1965,1968) proposed this theory. The basic idea is constructing a
theory based on empirical data (Charmaz and Thornberg,2021).
Researchers generally do not make any theoretical assumptions
before starting scientiÔ¨Åc research but start directly from a realistic
point of view and summarize several empirical concepts in pri-
mary data, which are then raised to systematic theoretical
knowledge. Grounded Theory must be supported by empirical with a particular interest in the theoretical and exper imental analysis of social interaction, human -bounded rational 
decision-making, and the psychology of incentives.  Michael Kosfeld is the director of the Frankfurt Laboratory for 
Experimental Economic Research (FLEX) and the Center for Leadership and Behavior in Organizations (CLBO).  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Copyright ¬© 2024 by the Association for Information Systems. Permission to make digital or hard copies of all or part 
of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for he was part of the ‚ÄúDigitization of the Financial Industry ‚Äù research group. His primary research interests include 
human-machine interaction, human-centered machine learning, eXplainable AI, generative AI, and applied machine 
learning.  
Rebecca Heigl has been a doctoral student in the chair of Information Systems and Information Management at Goethe 
University since April 2022. She also holds a BS in business studies from Goethe University Frankfurt and an MS in 
management from Johannes Gutenberg University Mainz. Her primary research interests include the economics of IS, findings underscore the complex sociotechnological nature of algori thmic discrimination and 
highlight the role that humans play in addressing it when ML models undergo continuous updating. 
Our results have important practical implications, especially considering the impending regulations 
mandating human involvement in ML-supported decision-making processes. 
Keywords: Continuous Updating, Algorithmic Discrimination, Human Discrimination, Feedback 
Loops, Investment Game 
John Qi Dong  was the accepting senior editor. This research article was submitted on  June 22, 2022 and underwent 
three revisions. √ºber das Unified,
also Unified Theory of 
Acceptance
and Use of Technology geh√∂rt 
haben.
Wer hier hat das in der 
Vorlesung schon mal gesehen?
Leider doch niemand. Sie nicken.
Okay, da muss ich doch ein
paar Minuten l√§nger hier dr√ºber 
sprechen,
weil das war eigentlich, was ich 
sagen wollte.
Okay, da k√∂nnen wir schnell 
dr√ºber gehen,
weil das Grundlagen sind.
Grundlagen, wie Sie hier sehen,
2003 ist eines der
am meistzitierten 
wissenschaftlichen Papiere,
die es √ºberhaupt gibt in der 
Wirtschaftsinformatik,
weil das sehr
viele verschiedene Perspektiven 
zusammenbringt.
Wir haben schon aus den 70er 
Jahren,",6.617161989,0.2,"The context mentions a paper by Eric Horvitz from 1999 and describes its concepts, such as the elegant coupling of automation and user manipulation. However, the retrieved snippets incorrectly associate this with ""Grounded Theory"" , which is a completely different research methodology.",0,"The generated answer is not faithful. The context mentions a classic paper by Eric Horvitz from 1999 [1851]. However, the generation incorrectly links this to ""Grounded Theory"" and ""qualitative analysis of interview data,"" [1137] which are entirely different concepts mentioned in separate, unrelated snippets of the context.",1,"The generated answer and the ground truth are semantically equivalent, both explaining that Eric Horvitz advocated for a combination of automation and user control.",,
What is augmentation in the context of human-AI collaboration?,AI serves as a decision support tool; human always makes final decision.,"According to the text, augmentation is where ‚ÄúAI serves as a decision support tool; human always makes final decision.‚Äù It‚Äôs a mode of collaboration where the AI provides advice, but the human retains control and makes the ultimate decision.","5. Juni 2025
Two modes of human-AI collaboration
Human-AI collaboration: the cooperative and coordinated interaction between humans (mostly non-AI experts) and AI to solve complex problems or achieve certain goalsTwo primary collaboration modes‚Ä¢Augmentation: AI serves as a decision support tool; human always makes final decision‚Ä¢Automation: AI serves as a tool to delegate tasksto; human or AI makes final decision8
AI
Human
Decision
Makes final decision
Gives advice
AugmentationAutomation
Task
‚ÄúObserves‚Äú task
Observes task
Task
HumanObserves task
AI
Decision
Human makes final decision(no delegation) 5. Juni 2025
Goal: Human-AI complementarities
9
The objective of human-AI collaboration is achieving complementary performance‚Ä¢Humans plus AI outperform either party acting alone for a set of tasks‚Ä¢Complementary strengths can originate from‚Ä¢Access to different data (e.g., soft signals)‚Ä¢Learning of distinct problem-solving strategies (imperfectly correlated errors) 5. Juni 2025
Human-Centered Artificial Intelligence
Human-CentredArtificial Intelligence (HCAI) framework advocates for achieving high levels of human control and high levels of AI automation at the same time‚Ä¢Human-centered AI focuses on amplifying, augmenting, and enhancing human performance in ways that make AI systems reliable, safe, and trustworthy‚Ä¢Shift from measuring only algorithm performance to evaluating human performance and satisfaction, with human-centered and participatory approaches (for evaluation, too)19 5. Juni 2025
Many factors shape human-AI collaboration
7
Mahmud et al. 2022
In the context of human-AI collaboration, we often refer to‚Ä¢Algorithm aversion: Preference for human help/decisions over AI ones‚Ä¢Algorithm appreciation: Preference for AI help/decisions over human onesThe occurrence of either depends on many factors that can be sorted under UTAUT amounts of data that may exceed human analytical capacities, enabling AI to provide decision
recommendations (Shaw, 2019).
Modern technologies, including artiÔ¨Åcial intelligence solutions, have revolutionized work and
contributed to developing human resources management (HRM) for improved outcomes
(Hmoud and Laszlo,2019). One signiÔ¨Åcant area where their impact is felt is in the recruitment
process, where AI implementation can potentially provide a competitive advantage by enabling a
better understanding of talent compared to competitors, thereby enhancing the company‚Äôs
competitiveness (Johansson and Herranen,2019). 5. Juni 2025
Guidelines for effective human-AI collaborations
20",5.88080883,1,"The context provides a slide that clearly defines the two primary collaboration modes, with augmentation described as: ""AI serves as a decision support tool; human always makes final decision""[cite: 1157].",1,"The generated answer is a direct and accurate description based on the provided context, which defines augmentation as a mode where ""AI serves as a decision support tool; human always makes final decision"" [1155].",1,The generated answer is identical to the ground truth.,,
What is the mean of the prediction change when considering coalitions of features?,Œî=‚àí0.1,The mean of the prediction change (Œî) across all coalitions is ‚àí0.1.,"22. Mai 2025
Marginal contributions across coalitionsIdea:‚Ä¢Remove feature across all possible coalitions and compute changes in predictions‚Ä¢Compute a feature‚Äôs importance by marginalizing over all its contributionsSimplified example for ‚Äúsavings‚Äù:
21
Coalition of 3 features
Œî=‚àí0.07
Coalitions of 2 features
Œî=‚àí0.3
Œî=‚àí0.02
Coalition of 1 feature
Œî=‚àí0.01
Mean: Œî=‚àí0.1
What is the prediction of no feature is present? Feedback Loops in Machine Learning 
 
805 
generate predictions (Parisi et al., 2019). However, in 
dynamic, nonstationary environments, the underlying 
data-generating process that ML models aim to 
approximate can change over time. This phenomenon, 
referred to as drift (Lu et al., 2018), can lead to  
progressively poorer predictions. The decrease in 
prediction performance can originate from changes in 
the underlying relationship between the input features 
and the target variable ‚Äîconcept drift (Widmer & 
Kubat, 1996)‚Äîor changes in the distributions of t he with modern machine learning methods. This integra -
tion enables the estimation of individual-level differ -
ences between actual outcomes and hypothetical 
outcomes that would have occurred without the inter -
vention (Athey and Imbens 2015 ).
Contrasting with traditional machine learning‚Äôs 
focus on predicting outcomes from correlational data 
relationships, CML aims to forecast cause-and-effect 
relationships. This approach enhances the understand -
ing of how interventions affect outcomes of interest 
(Wager and Athey 2018 ). For example, although tradi -
tional machine learning may predict a customer‚Äôs likeli - availability of this data point for future model updates and potentially affecting the model ‚Äôs 
performance. This paper delves into the relationship between the continuous updating of ML models 
and algorithmic discrimination in environments where predictions endogenously influence the 
creation of new training data. Using comprehensive simulations based on secondary empirical data, 
we examine the dynamic evolution of an ML model ‚Äôs fairness and economic consequences in a 
setting that mirrors sequential interactions, such as loan approval decisions. Our findings indicate often use the terms algorithmic bias, algorithmic 
Figure 1. If an ML model‚Äôs prediction of creditworthiness 
guides loan approval, this prediction will shape the data 
available for future updates. As the bank only observes 
the actual creditworthiness of successful applicants, this 
can induce a bias in the data for subsequent model  
updates, potentially affecting the quality and nature of 
future predictions. Notably, when divergent from the 
incoming data on which predictions are made, this 
endogenous shift in training data composition relates to 
data drift ch allenges. In such scenarios, the feature decision makers against a certain social group 
affect the impact of continuous updating on 
model fairness and economic efficiency?
 
 
Figure 1. Process Where Machine Learning Predictions Endogenously Influence the Availability of Data 
for Future Retraining of the Model",4.408813953,1,"The context provides a clear diagram illustrating the concept. It shows coalitions of features with their corresponding prediction changes (Œî), and at the bottom, it explicitly states, ""Mean: Œî=‚àí0.1""[cite: 1164].",1,"The generated answer is a direct statement based on the provided context, which shows a diagram with the calculation ""Mean: Œî=‚àí0.1"" [1164].",1,"The generated answer and the ground truth state the same value, making them identical.",,
"According to the document, what is interpretability?",The ability to explain or provide the meaning in understandable terms to humans.,"According to the document, interpretability is ‚Äúthe ability to explain or provide the meaning in understandable terms to humans.‚Äù","Some definitionsConfusing nomenclature: explainable / interpretable / transparent models‚Ä¢Interpretability:the ability to explain or provide the meaning in understandable terms to humans‚Ä¢Explainability:explanation as an interface between humans and a decision maker that is both an accurate proxy of the decision maker and comprehensible to humans‚Ä¢Transparency: a model is transparent if by itself it is understandable.Explaining different things:‚Ä¢Predictionsand model behavior (overarching logic the model learned)‚Ä¢Decisions(predictions plus rule that translates into decision)Explanation modes:‚Ä¢Analytic statement:natural told of the study‚Äôs purpose, its methods, its participants‚Äôrights, and any possible dangers.
They were therefore assured of their comprehension and consent.
Additional information
Supplementary informations The online version contains supplementary material
available at https://doi.org/10.1057/s41599-023-02079-x.
Correspondence and requests for materials should be addressed to Zhisheng Chen.
Reprints and permission informationis available athttp://www.nature.com/reprints
Publisher‚Äôs noteSpringer Nature remains neutral with regard to jurisdictional claims in
published maps and institutional afÔ¨Åliations. treffen.
Wer sieht das nicht?
Noch mal, was ich letztes Mal 
gesagt habe Wenn Sie
was nicht verstehen, ist es 
nicht Ihre Schuld.
Dann habe ich es einfach 
schlecht erkl√§rt.
Deswegen immer raus damit.
Dann gehe ich davon aus, dass 
jeder verstanden hat.
Aber eine andere Frage haben
wir ja theoretisch auch
noch andere 
Entscheidungsm√∂glichkeiten,
Parametern, die dieselbe 
Qualit√§t liefern.
Vollkommen richtig. Da w√§re 
jetzt die Frage,
ob es eine 
Entscheidungsm√∂glichkeit,
die zwei Parameter verwendet,
besser als eine auf einem 
Papier.
Das ist sehr, sehr gute Frage.
Da gibt es verschiedene Theorien 
zu. √ºber das Unified,
also Unified Theory of 
Acceptance
and Use of Technology geh√∂rt 
haben.
Wer hier hat das in der 
Vorlesung schon mal gesehen?
Leider doch niemand. Sie nicken.
Okay, da muss ich doch ein
paar Minuten l√§nger hier dr√ºber 
sprechen,
weil das war eigentlich, was ich 
sagen wollte.
Okay, da k√∂nnen wir schnell 
dr√ºber gehen,
weil das Grundlagen sind.
Grundlagen, wie Sie hier sehen,
2003 ist eines der
am meistzitierten 
wissenschaftlichen Papiere,
die es √ºberhaupt gibt in der 
Wirtschaftsinformatik,
weil das sehr
viele verschiedene Perspektiven 
zusammenbringt.
Wir haben schon aus den 70er 
Jahren, unequally and discrimination based on legally protected char-
acteristics, such as race and gender (Jackson, 2021). When
assessments consistently overestimate or underestimate a parti-
cular group‚Äôs scores, they produce ‚Äúpredictive bias‚Äù (Raghavan
et al.,2020
). Unfortunately, these discriminatory results are often
overlooked or disregarded due to the misconception that AI
processes are inherently‚Äúobjective‚Äù and ‚Äúneutral.‚Äù
REVIEW ARTICLE HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS | https://doi.org/10.1057/s41599-023-02079-x System zu nutzen,
definieren diese Faktoren dann 
√ºber diesen
Mediationsweg ihre Bereitschaft 
tats√§chlich
oder ihre tats√§chliche Nutzung 
des Systems,
ihre tats√§chliche Akzeptanz des 
Systems.
Wer wei√ü, was es neben Mediation 
noch gibt?
Was haben wir noch in diesen 
Modellen,
um etwas zu konzeptionalisieren?
Ja, exactly.
Wissen Sie, was Moderation 
bedeutet?
Moderator ist eine Variable,
die die Richtung oder die St√§rke 
des Effekts.
Sehr gut. Wie Ihre Kommilitonin 
hier gesagt hat,
haben wir nicht nur eine 
Mediation.
Wenn wir sagen, der Effekt von 
Performance expectancy
auf actual use wird",4.849956274,1,"The context directly defines interpretability on a slide with the heading 'Some definitions', stating it is ""the ability to explain or provide the meaning in understandable terms to humans""[cite: 1180].",1,"The generated answer is a direct quote from the provided context, which defines interpretability as ""the ability to explain or provide the meaning in understandable terms to humans"" [1180].",1,The generated answer is semantically identical to the ground truth.,,
What does the EU AI Act Art 86 demand?,Right to Explanation of Individual Decision-Making.,"According to the document, EU AI Act Art 86 demands that ‚Äúany affected person subject to a decision which is taken by the deployer on the basis of the output from a high-risk AI system listed in Annex III, [‚Ä¶] produces legal effects or similarly significantly affects that person in a way that they consider to have an adverse impact on their health, safety or fundamental rights shall have the right to obtain from the deployer clear and meaningful explanations of the role of the AI‚Äù.","General Data Protection Regulation (GDPR) in the EU demands ‚Äútransparent [data] processing‚Äù and a ‚Äúright to explanation‚Äù EU AI Act Art 86: Right to Explanation of Individual Decision-Making‚ÄúAny affected person subject to a decision which is taken by the deployer on the basis of the output from a high-risk AI system listed in Annex III, [‚Ä¶] produces legal effects or similarly significantly affects that person in a way that they consider to have an adverse impact on their health, safety or fundamental rights shall have the right to obtain from the deployer clear and meaningful explanations of the role of the AI ethics, and responsibility in AI (Zuiderveen Borgesius,2020). The
Organization for Economic Cooperation and Development
(OECD) has provided recommendations on AI, while the
European Commission has drafted proposals regarding
the inÔ¨Çuence of algorithmic systems on human rights. In 2019,
the European Commission established a high-level expert group
on AI, which proposed ethical guidelines and self-regulatory
measures regarding AI and ethics.
Public organizations have played a role in establishing
mechanisms to safeguard algorithmic fairness. The Algorithm
Justice League (AJL) has outlined vital behaviors companies 22. Mai 2025
EU AI act
10 Retailing 97(4):676‚Äì696.
European Union (2016) Regulation EU 2016/679 of the European 
Parliament and of the council of 27 April 2016, article 22. Offi -
cial J. Eur. Union 119:59.
European Union (2021) Proposal for a regulation EU of the Euro -
pean Parliament and of the council of April 21, 2021, laying 
down harmonised rules on artificial intelligence (Artificial Intel -
ligence Act) and amending certain union legislative acts. Official 
J. Eur. Union 119.
Frisch R, Waugh FV (1933) Partial time regressions as compared 
with individual trends. Econometrica 1(4):387‚Äì401. applications and beneÔ¨Åts of AI-based recruitment, factors con-
tributing to algorithmic recruitment discrimination, types of
discrimination in algorithmic recruitment, and measures to
mitigate algorithmic hiring discrimination. The fourth section
involves conducting a survey among respondents and analyzing
the primary data collected to support our study. TheÔ¨Ånal section
concludes by suggesting future directions for research.
Theory background
Discrimination theory. Discrimination in the labor market is
deÔ¨Åned by the ILO‚Äôs Convention 111, which encompasses any 24. April 2025
Let‚Äôs see AI in action: a case study",9.207360506,1,"The context provides a direct quote explaining the law: ""Any affected person... shall have the right to obtain from the deployer clear and meaningful explanations of the role of the AI""[cite: 1203].",1,"The generated answer is a direct quote from the provided context, which cites EU AI Act Art 86 [1202].",1,The generated answer and the ground truth are semantically identical.,,
What is a 'selective labels problem'?,It occurs when a machine learning model's prediction influences decisions that prevent the collection of data needed to evaluate the model's accuracy.,"Based on the provided text, a ""selective labels problem"" refers to the situation where labels within the training data are skewed significantly within specific subgroups. 

Specifically, the text discusses how initial label imbalance (the uneven distribution of labels like ""repaying"" vs. ""not repaying"" in a loan approval example) can influence the effectiveness of continuous model updating in mitigating algorithmic discrimination. It highlights that if the initial training data reflects historical discrimination against a group (like female applicants), the model will likely perpetuate that bias, even with continuous updates.","when labels skew significantly within specific subgroups. 
Third, technical constraints or malpractices during model 
development and training may yield discriminatory 
outputs (Friedman & Nissenbaum, 1996; Williams et al., 
2018). Biases may emerge during data integration due to 
inconsistent data formats or when the integration of 
personal information like ethnicity is mishandled (Schelter 
& Stoyanovich, 2020; Williams et al., 2018). It is critical 
to appreciate the sociotechnological nature of algorithmic 
discrimination (Favaretto et al., 2019; Kordzadeh & 
Ghasemaghaei, 2022). The social component often label imbalance (reference category). 
In summary, our findings highlight that the observed self-
correction properties of continuous updating are 
moderated by the degree of initial label imbalance in the 
training data. This holds, in particular, for algorithmic 
discrimination as measured by the gender gap in false-
negative error rates. These results, when interpreted in the 
context of our loan approval example, suggest that the 
extent of historical discrimination against female 
applicants, as reflected in the training data, influences the 
effectiveness of continuous model updating in mitigating labels. If inappropriate goals are set, bias may be introduced from
the outset (36KE,2020).
An engineer is responsible for developing the algorithmic model.
If they hold certain beliefs and preconceptions, those personal
biases can be transmitted to the machine (Njoto,2020). Although
the device is responsible for selecting employee resumes, it operates
based on underlying programming. The programmer guides the AI
in making decisions about the best candidate, which can still result
in discrimination (Miasato and Silva,2019).
Furthermore, personal biases can manifest in the selection of nearly identical, regardless of the presence or absence of 
initial label imbalances for women in the training data. 
In presenting results for the most extreme label 
imbalance scenario ‚Äîwhere no positive (repaying) 
examples exist for women ‚Äîa question naturally 
arises concerning the role of the initial degree of label 
imbalance. Does the initial degree of label imbalance 
influence the ability of continuous updating to 
mitigate algorithmic discrimination and enhance 
economic efficiency?  
We address this question using regression analyses 
reported in Table 1 (See Figures A1-A6 in the Appendix share of positive predictions; Init. lab. imb. = initial label imbalance; Human discr. = human discrimination. 
Figure A7. Development of the Mean Share of Positive Predictions by Initial Label Imbalance  
and Degree of Human Discrimination negative rate; Init. lab. imb. = initial label imbalance; Human discr. = human discrimination. 
Figure A8. Development of the Mean Share of False-Negative Errors by Initial Label Imbalance  
and Degree of Human Discrimination 
 
Note: We illustrate how the mean share of games that result in the outcome as if the game was played under perfect information in Iterations 1 
and 100 depends on the initial label imbalance in the training data and the degree of human discrimination by the investor. We depict results in",9.722091436,0.6,"The context discusses a related concept, 'label imbalance,' where the training data underrepresents certain groups, which can lead to biased model performance[cite: 1240]. This is closely related to the idea of a selective labels problem, where model decisions prevent the collection of balanced labels, but it does not use the exact term or provide the full definition.",1,"All claims in the generated answer are supported by the context. The context explains that label imbalances occur ""when labels skew significantly within specific subgroups"" [1215]. It also discusses how the initial degree of this imbalance influences the model's ability to mitigate discrimination through continuous updating [1216].",1,"The generated answer and the ground truth are semantically equivalent, both explaining that the model's predictions create a feedback loop by preventing the collection of counterfactual data.",,
"According to the text, what is one way to control for gender when analyzing a dataset?","By running the dataset through without including gender, but then rerunning it while including gender to compare performance.","According to the text, one way to control for gender when analyzing a dataset is to ‚Äúexclude the gender attribute from the features used to make predictions.‚Äù The text describes an example where Amazon excluded gender from the features used to make predictions while still comparing performance within their data.","resulting in a 20-fold reduction in the recognition error ratio
between men and women with darker skin tones and a 9-fold
reduction for women by balancing factors such as skin color, age,
and gender (Grabovskyi and Martynovych,2019).
Integrating ‚Äúsmall data‚Äù and ‚Äúbig data‚Äù can enhance accuracy
(36KE, 2020). Data should not solely rely on extensive collections
but also focus on precision. While big data analysis tends to
emphasize correlations, which can lead to errors when inferring
causation, small data, which is more user-speciÔ¨Åc, offers detailed
information and helps avoid such mistakes. Combining the data (Friedman & Nissenbaum, 1996; Romei & Ruggieri, 
2013; Kleinberg et al., 2018). For example, if a training 
dataset holds more positively labeled examples for men, 
the ML model may predict positive labels less accurately 
for women. Second, it can be created by unrepresentative, 
or imbalanced data (Barocas & Selbst, 2016; Mehrabi et 
al., 2021). When the dataset underrepresents certain 
groups, such as women, the ML model can make more 
errors when predicting for this group. Imbalances occur 
when labels skew significantly within specific subgroups. 
Third, technical constraints or malpractices during model escalating gender bias in the data used to update the 
ML model may exacerbate the model ‚Äôs inaccuracies, 
particularly in its predictions for women. This could 
potentially initiate a self -perpetuating feedback loop, 
where the disparity in prediction quality between men 
and women widens (e.g., Kleinberg et al., 2018) . It is 
important to note that such feedback loops can arise 
not only from initially biased ML models but also from 
loan officers who independently discriminate against 
female applicants, even when using ML predictions. 
As a result, training data can be come increasingly We address this question using regression analyses 
reported in Table 1 (See Figures A1-A6 in the Appendix 
for a graphical illustration). Columns (1) and (2) use the 
gender gap in the ML model ‚Äôs share of positive 
predictions and false-negative error rates as dependent 
variables, respectively. Columns (3) and (4) use the 
share of game outcomes equivalent to the perfect 
information benchmark and the share of investments 
with repaying female borrowers as dependent variables, 
respectively.14 Independent variables comprise the time 
trend, dummy variables indicating the degree of initial in dem man alles angibt,
au√üer das Geschlecht und l√§sst 
das durchlaufen.
Aber hierbei w√ºrden sie Gender 
mit rein nehmen.
Also in einem ersten Schritt,
um das zu kontrollieren.
Genau in diesem Beispiel von dem 
Amazon,
das haben Sie schon richtig 
erfasst,
war es so die haben Gender 
rausgelassen,
hatten aber eine Spalte im 
Datensatz,
wo Gender noch drin war,
haben die Maschine dann
basierend auf allen Features 
au√üer Gender die
Vorhersage machen lassen und 
konnten dann nat√ºrlich
innerhalb ihrer Daten trotzdem 
vergleichen.
Wie ist die Performance dort in 
den Eintr√§gen,
wo wir M√§nner, Second, the use of the gender attribute is an illustrative 
example, reflecting a wide array of characteristics on 
which both algorithms and humans can base 
discrimination. We c hose the gender attribute to 
underscore discrimination consequ ences in 
continuously updated systems based on  the ample 
scientific and anecdotal evidence demonstrating 
algorithmic discrimination against women (e.g., 
Sweeney, 2013; Lambrecht & Tucker, 2019). 
4 Results 
In presenting our results, we first analyze the evolution 
of algorithmic discrimination and economic efficiency 
under continuously updating ML models in a context",7.411752224,0.8,"The context explains that in the Amazon example, gender was excluded from the features for prediction, but was kept as a column in the dataset to allow for performance comparisons between genders after the prediction was made[cite: 1247]. This is a direct description of the process.",0.5,"The claim that Amazon excluded the gender attribute from features is faithful. However, the claim that they did this while still comparing performance *within their data* is an inference not explicitly stated. The context says they could compare performance [1247], but does not specify that this was done on the same dataset post-prediction.",1,"The generated answer and the ground truth describe the same method, making them semantically identical.",,
"According to the text, what is one way large language models can exhibit biased tendencies?",They have been optimized to be overly agreeable and to 'say yes to everything.'.,"According to the text, large language models can exhibit biased tendencies because ‚Äúthese models, when one makes the Wahl O Mat with Chat GPT, then comes out that Chat GPT supports the opinions of the Greens, the Left, and the SPD, less from right-leaning and right-radical views.‚Äù This is due to the models being ‚Äútrained on data‚Äù ‚Äì specifically, the training data reflects social biases.","includes the degree of the system ‚Äôs initial bias and, 
perhaps more importantly, the persistence of biased 
decision-making by humans in the loop. We found that 
the greater the extent of human discrimination in a 
dynamic system where ML models are continuously 
updated, the less likely it is that self-correcting 
mechanisms will occur . We even observe d that 
unbiased models learn biased behaviors from humans 
over time. This happens because humans interfere with 
the endogenous creation of new observations, further 
reducing the chance that the existing training data can data already reÔ¨Çects social prejudices, and the algorithm also
incorporates biased relationships, leading to the‚Äúbias in and bias
out‚Äù phenomenon (36KE, 2020). This phenomenon means that
discrimination and disparities exist, just like in forecasting, where
historical inequalities are projected into the future and may even
be ampliÔ¨Åed (Mayson, 2018).
A research team at Princeton University discovered that
algorithms lack access to the absolute truth. The machine corpus
contains biases that closely resemble the implicit biases observed
in the human brain. ArtiÔ¨Åcial intelligence has the potential to (36KE, 2020). When the dataset lacks diverse representation from
different companies, bias may be introduced during the devel-
opment of algorithmic rules by engineers and when annotators
handle unstructured data (Zixun,2020).
Datasets: bias soil. Datasets serve as the foundation of machine
learning (ML). If an algorithm‚Äôs data collection lacks quantity and
quality, it will fail to represent reality objectively, leading to
inevitable bias in algorithmic decisions. Researchers commonly
use a 95% conÔ¨Ådence level, which provides 95% certainty but still
leaves a one in twenty chance of bias (Raub,2018). Nearly every endogenously shape the composition of additional data 
available for model updating. In particular, our work 
focuses on the role of ongoing discrimination by 
human decision  makers who have the final say in an 
ML-supported decision-making task. A steady stream 
of previous work has examined how algorithmic 
discrimination can reproduce and perpetuate 
discriminatory patterns ingrained in societal structures 
(Lambrecht & Tucker, 2019; Morse et al., 202 2; 
Teodurescu et al., 2021). Some studies have developed 
theoretical arguments concerning the emergence of 
feedback loops when ML models continually learn models frequently aid human decisions, researchers and 
practitioners often employ the te rm ‚Äúalgorithmic 
discrimination‚Äù to refer to system outputs that 
disproportionately benefit or disadvantage specific 
groups, even when no justification for the disparate 
treatment exists from a ground -truth perspective 
(Kordzadeh & Ghasemaghaei, 2022).1  
Algorithmic discrimination can originate from various 
sources. First, it may stem from intentional or 
unintentional social biases encoded within the training 
data (Friedman & Nissenbaum, 1996; Romei & Ruggieri, 
2013; Kleinberg et al., 2018). For example, if a training se Bias,
Es ist ein Fehlverhalten.
Es wurde in eine bestimmte 
Richtung
gedr√ºckt durch bestimmte 
Optimierungsverfahren,
Wenn Sie an Medien
und an politische Einstellungen 
denken.
Es gibt sehr viele Evidenzen 
daf√ºr,
dass viele gro√üe Sprachmodelle
eher linksgerichtet sind in 
ihren Antworten.
Dass diese Modelle, wenn man zum 
Beispiel die den
Wahl O Mat mit Chat GPT macht,
dann kommt er raus,
dass Chat Gpt die Meinungen der 
Gr√ºnen,
der Linken und der SPD 
unterst√ºtzt weniger von den
rechtsgerichteten und 
rechtsradikalen Ansichten.
Was k√∂nnen Sie denken, woran das 
liegt?
Es liegt an den Trainingsdaten.",9.034688234,1,"The context directly addresses the question by stating that evidence shows large language models tend to be left-leaning, and provides the specific example that a 'Wahl O Mat' (a German voting advice application) using ChatGPT shows support for the Greens, the Left, and the SPD[cite: 1270].",1,"The claims in the generated answer are directly supported by the context, which states that when running the 'Wahl O Mat' with ChatGPT, the result is that it supports the opinions of the Greens, the Left, and the SPD, and that this is due to the training data [1251].",0,"The generated answer gives an incorrect reason for bias (political leanings in training data), while the ground truth gives the correct reason (models are optimized to be overly agreeable). The two explanations are entirely different.",,
What did Google do to address concerns about the representation of nurses in image search results?,Google filtered the results so that both men and women are shown when 'nurse' is entered.,"According to the text, Google implemented filters so that when you search for ‚Äúnurse,‚Äù both men and women are shown in the results. However, this change wasn't implemented until relatively recently ‚Äì ‚Äúbis vor zwei Jahren.‚Äù Before that, searches for ‚Äúnurse‚Äù predominantly showed female images, while searches for ‚Äúdoctor‚Äù showed predominantly male images.","dann eher ausgeglichen.
Ich sag mal als Beispiel bis die
haben das nat√ºrlich alles 
mittlerweile
ein bisschen mitigiert,
als diese gro√üen Probleme 
aufgekommen sind bis vorne.
Bis vor zwei Jahren habe ich an 
dieser
Stelle die Studierenden googlen 
lassen.
Arzt und der Gro√üteil der 
Bilder,
die sie immer noch auf Google 
gefunden haben,
waren wei√üe M√§nner.
Das hat Google jetzt anscheinend 
durch Filter so gemacht,
dass wenn man Krankenpfleger 
eingibt,
dass sowohl M√§nner und Frauen 
gezeigt werden.
Aber bis vor zwei Jahren war
es immer noch ein sehr gutes 
Beispiel.
Wenn ich Sie frage, googeln Sie gezeigt werden.
Aber bis vor zwei Jahren war
es immer noch ein sehr gutes 
Beispiel.
Wenn ich Sie frage, googeln Sie 
mal bitte nach Images.
Dann war Krankenpfleger zu 99¬†%
weiblich und Arzt zu 99¬†% 
m√§nnlich,
obwohl diese Bilder nat√ºrlich 
von beiden
eigentlich schon vorhanden sein 
sollen.
Das hei√üt, wir haben hier
irgendwelche gewachsenen 
technischen Grundlagen,
Datenbanken, die das einfach 
noch nicht abbilden k√∂nnen.
Having said that, die 
Unternehmen sind
sehr sensibilisiert durch diese 
ganzen PR Probleme,
die sie damit erlitten haben und 
haben angefangen,
diese Daten zu bereinigen. Journal of the Association for Information Systems 
 
828 
K√∂chling, A., & Wehner, M. C. (2020). Discriminated 
by an algorithm: a systematic review of 
discrimination and fairness by algorithmic 
decision-making in the context of HR 
recruitment and HR development. Business 
Research, 13(3), 795-848.  
Kusner, M. J., & Loftus, J. R. (2020). The long road to 
fairer algorithms. Nature, 578(7793), 34-36. 
Lahey, J. N. (2008). Age, women, and hiring an 
experimental study. Journal of Human 
Resources, 43(1), 30-56.  
Lakkaraju, H., Kleinberg, J., Leskovec, J., Ludwig, J., literature was worth reviewing. This is because this is a relatively
new phenomenon that has become prominent over the past 10
years. In deÔ¨Åning the ‚Äúalgorithmic and hiring discrimination‚Äù
literature, a fairly broad approach was taken based on article
keywords rather than publication sources. Depending on the
focus, keywords related to algorithms and hiring discrimination
were included in the search string. The keyword search algorithm
for this review is as follows. (‚ÄúartiÔ¨Åcial intelligence‚Äù and ‚Äúhiring
discrimination‚Äù), ( ‚Äúalgorithms‚Äù and ‚Äúrecruitment discrimina- crimination resolution.
The process applied for the reviews depicted in Fig.1. After
excluding duplicates and less relevant and outdated literature,
only 45 articles could be used as references for this study (referred
to Table1). The literature review shows that most of the research
on algorithmic hiring discrimination has occurred in recent years.
The research trend indicates that algorithmic hiring discrimina-
tion will be a hot research topic in the coming period.
1. The Ô¨Årst theme is the application of various aspects of
recruitment based on artiÔ¨Åcial intelligence support and its maintained ten years. After applying an initial screening related
to titles, keywords, or abstracts, the literature was selected based
on its relevance to the research topic.
The obtained literature was studied in depth to reveal the
surfaced themes. Several systematic research themes were iden-
tiÔ¨Åed, including AI-based recruitment applications and beneÔ¨Åts,
causes of algorithmic discrimination, which algorithmic recruit-
ment discrimination exists, and algorithmic recruitment dis-
crimination resolution.
The process applied for the reviews depicted in Fig.1. After",8.827886105,1,"The context directly states that Google implemented filters so that when 'Krankenpfleger' (nurse) is entered, both men and women are shown in the results[cite: 1277]. It also notes that before this change, the results were heavily skewed female[cite: 1281].",1,"All claims in the generated answer are directly supported by the context. The context states that Google implemented filters so that searching for ""Krankenpfleger"" (nurse) shows both men and women [1272] and that this was a recent change, as searches ""bis vor zwei Jahren"" (until two years ago) [1273] were heavily stereotyped.",1,The generated answer and the ground truth are semantically identical.,,
"According to the document, what was the reason Amazon's AI recruitment system discriminated against women?","It recognized correlations between hobbies, universities attended, and gender due to historical data showing fewer women attending certain universities and pursuing technical fields.","According to the document, Amazon‚Äôs AI recruitment system discriminated against women because it was trained on recruitment data that was biased against women. The AI recognized this bias in the previous recruiter data and subsequently adopted it as a pattern.","pations as less professional‚Äù((Avery et al.,2023; Kay et al.,2015).
The impact of gender stereotypes on AI hiring poses genuine
risks (Beneduce,2020). In 2014, Amazon developed an ML-based
hiring tool, but it exhibited gender bias. The system did not
classify candidates neutrally for gender (Miasato and Silva,2019).
The bias stemmed from training the AI system on predominantly
male employees ‚Äô CVs (Beneduce, 2020). Accordingly, the
recruitment algorithm perceived this biased model as indicative
of success, resulting in discrimination against female applicants
(Langenkamp et al. 2019). The algorithm even downgraded of success, resulting in discrimination against female applicants
(Langenkamp et al. 2019). The algorithm even downgraded
applicants with keywords such as ‚Äúfemale‚Äù (Faragher, 2019).
These Ô¨Åndings compelled Amazon to withdraw the tool and
develop a new unbiased algorithm. However, this discrimination
was inadvertent, revealing theÔ¨Çaws inherent in algorithmic bias
that perpetuates existing gender inequalities and social biases
(O‚Äôneil, 2016).
Race. Microsoft‚Äôs chatbot Tay learned to produce sexist and racist
remarks on Twitter. By interacting with users on the platform, racial diversity and organizational 
performance. Journal of Applied Social 
Psychology, 39(6), 1445-1460.  
d‚ÄôAlessandro, B., O ‚ÄôNeil, C., & LaGatta, T. (2017). 
Conscientious classification: A data scientist ‚Äôs 
guide to discrimination -aware classification. 
Big Data, 5(2), 120-134.  
Dastin, J. (2018). Amazon scraps secret AI recruiting 
tool that showed bias against women. In K. 
Martin (Ed.), Ethics of data and analytics (pp. 
296-299). Auerbach Publications.  
Domnich, A., & Anbarjafari, G. (2021). Responsible 
AI: Gender bias assessment in emotion 
recognition. https://arxiv.org/abs/2103.11436 in discrimination (Miasato and Silva,2019).
Furthermore, personal biases can manifest in the selection of
data characteristics. For example, engineers may prioritize speciÔ¨Åc
features or variables based on how they want the machine to
behave (Miasato and Silva, 2019)). The Amazon hiring case
illustrates this, where engineers considered education, occupation,
and gender when assigning labels to the algorithm. When gender
is considered the crucial criterion, it inÔ¨Ç
uences how the algorithm
responds to the data.
Theme III. Which algorithmic recruitment discrimination
exists REVIEW ARTICLE
Ethics and discrimination in artiÔ¨Åcial intelligence-
enabled recruitment practices
Zhisheng Chen 1‚úâ
This study aims to address the research gap on algorithmic discrimination caused by AI-
enabled recruitment and explore technical and managerial solutions. The primary research
approach used is a literature review. TheÔ¨Åndings suggest that AI-enabled recruitment has
the potential to enhance recruitment quality, increase efÔ¨Åciency, and reduce transactional
work. However, algorithmic bias results in discriminatory hiring practices based on gender, M√∂glichkeiten
ist es da zu einem gro√üen 
Skandal gekommen,
die man von diesem Skandal 
damals geh√∂rt.
M√ºsste ungef√§hr in die Zeit, wo 
sie alle
Abitur gemacht haben, gewesen 
sein.
Ja, das war weil die.
Also ich bin mir nicht mehr 
sicher.
Ich glaube, da wurden die 
fr√ºheren
Recruitingdaten von Amazon 
genommen,
in eine AI eingespeist.
Und da die fr√ºheren Recruiter
biased gegen√ºber Frauen waren,
hat die AI das Muster erkannt 
und ebenso √ºbernommen.
Genau.
Wir haben ein System
gehabt und ich w√ºrde gar nicht 
mal sagen,
dass die Recruiter per se 
gebeizt waren.
Ich wahrscheinlich auch ein 
Teil.",7.107023954,1,"The context provides a direct explanation of the incident. It states that the bias stemmed from training the AI system on predominantly male employees' CVs, which led the algorithm to perceive this as indicative of success and discriminate against female applicants[cite: 1891].",1,All claims in the generated answer are directly supported by the provided context. The context states that Amazon's tool was trained on biased recruiting data and that the AI recognized the pattern of recruiters being biased against women and adopted it [1295].,0,"The generated answer provides an incorrect reason for the discrimination. The ground truth correctly states that the system was trained on biased historical data, not that it recognized correlations between hobbies and gender.",,
"According to the lecture, what is the CRISP-DM model and what is its first and most important step?","The CRISP-DM (Cross-Industry Standard Process for Data Mining) is a blueprint for developing machine learning applications. Its first and most important step is Business Understanding, which involves clearly defining the business problem you are trying to solve.","According to the lecture, the CRISP-DM model is a cross-industry standard process for data mining. 

Its first and most important step is **1. Business Understanding**.","15. Mai 2025
Structuring an AI project: CRISP-DM 
6
1. Business Understanding2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment
Data 
Cross Industry Standard Process for Data Mining conditions. For each of the 20 conditions, we 
conducted 15 independent simulations with different 
random seeds that ensured the randomized partitioning 
of data from Studies A and B into observations used 
for initially training the ML models and populating the 
pools of investors and borrowers. By  doing so, we 
aimed to mitigate concerns of selection bias. To 
manipulate the initial bias of the ML model predicting 
borrowers‚Äô repayment, we induce d label imbalances 
(Cowgill & Tucker, 2019) for female observations in 
the initial training dataset prior to the simulation‚Äôs first 15. Mai 2025
Overview CRISP-DM
9 developed during these initial projects. These tem plates proved to be quite helpful especially for
people w ho are not proficient w ith our particular data m ining tool.
5 L essons learned
In this section, w e try to sum m arize som e of the experiences w e m ade in both applying the
generic C R ISP-D M  process m odel and in developing a specialized process m odel.
W e expected the generic process m odel to be useful for planning and docum entation, and this
turned out to be the case. H ow ever, the use of the m odel for com m unication both w ithin and dass GPT auf die Art und
Weise funktionieren wird, wie es 
funktioniert.
Da mussten massiv Ressourcen 
reingesteckt werden,
auch um zu experimentieren.
Letztlich. Und Ockhams Razor ist 
eher dieses diese Idee.
Wenn ich zwei Modelle trainiert 
habe und
diese beiden Modelle 
nebeneinander lege und die 
gleiche
Performance habe,
dann sollte ich als Daumenregel 
nochmal
wirklich betont als Daumenregel
eher das Modell nehmen, was 
einfacher ist.
Der Gedanke, der dahinter 
steckt,
ist, dass wir vermeiden wollen,
dass die zuf√§lligen Schwankungen 
in den
Daten mit h√∂herer 
Modellkomplexit√§t
in dem Modell erkannt werden als Chandy et al. 2021 ) in a digital setting.
The rest of the paper is structured as follows. Section 
2 provides the theoretical background by reviewing 
related literature. Section 3 presents the setting and 
results of our randomized field experiment. Section 4
details the configuration and results from our causal 
machine learning model, along with the evaluation of 
smart green nudging. Section 5 concludes by discuss -
ing the practical implications of our work, its limita -
tions, and potential avenues for future research.
2. Related Literature
Our work relates to three streams of literature, namely",6.422221184,1,"The context provides a slide that clearly lists the six phases in order, with the first being ""1. Business Understanding""[cite: 1317].",1,"The generated answer is a direct and accurate summary based on the provided context, which details the first and most important step of the CRISP-DM model as ""1. Business Understanding"" [1316].",1,The generated answer and the ground truth are semantically identical.,,
The lecture describes three levels of integrating machine learning solutions into an organization. What is a 'System Solution' (the third level)?,"A 'System Solution' is the deepest level of integration, where machine learning fundamentally changes the entire organizational structure and business model, requiring a complete rethinking of processes. The example given is Amazon's 'Anticipatory Shipping' patent.","According to the lecture, a ‚ÄúSystem Solution‚Äù (the third level) is:

‚ÄúA comprehensive, integrated set of applications and technologies that work together to address complex, organization-wide problems. It‚Äôs highly integrated with multiple components and data flows.‚Äù

It goes beyond a single prediction and incorporates multiple points solutions, integrating them into broader processes within an organization.","System solutions‚Ä¢Definition:Comprehensive, integrated set of applications and technologies that work together to address complex, organization-wide problems.‚Ä¢Scope:Broad; enterprise-level‚Ä¢Integration:Highly integrated with multiple components and data flows.‚Ä¢Use case:Innovation must transform or optimize an entire organization‚Ä¢Example:Amazon‚Äôs ‚ÄúShip then Shop‚Äù (Prediction + Inventory + Logistics + ‚Ä¶) die Systeme,
die m√ºssen ausreichend 
performant und gut sein.
Aber wir brauchen eben auch
diese Einbettung der Systeme der
technischen Systeme in das Sozio 
system.
Deswegen sprechen wir 
grunds√§tzlich dann
von diesen soziotechnischen 
Systemen,
wo diese Systeme wirklich 
genutzt
werden und letztlich 
Ver√§nderungen hervorrufen.
Und viel davon passiert eben 
hier
Information Systems auf Deutsch 
aus
der Perspektive der 
Wirtschaftsinformatik.
Was immer so eine 
Schnittstellendisziplin ist,
wo wir aus ganz verschiedenen 
Blickwinkeln Psychologie,
Management, √ñkonomie,
Verhaltens√∂konomie, Neurologie der Mitte stehende Dampfmaschine 
mit bestimmten Kolben,
wo Kraft√ºbertragung stattfindet, 
aufgebaut sein,
sondern wir konnten viel 
kleinere Dinge haben.
Wir konnten mehr uns 
spezialisieren Das ist genau die
Idee von diesen System Solutions 
Fragen.
Dann kommen wir jetzt zu dem 
schon angedeuteten Teil.
Wir haben jetzt so ein bisschen 
geschaut bisher.
Was kann Machine Learning uns 
bieten?
Predictions Wie k√∂nnen wir √ºber 
Predictions nachdenken
als Treiber von √∂konomischem 
Wert?
Sie helfen uns, bessere 
Einsch√§tzungen zu haben,
bessere Entscheidungen letztlich 
zu treffen,
genauere Probabilities zu haben. Technologie
in meine anderen Prozesse 
hinein,
denn ich gucke immer
nur auf diesen einen bestimmten 
Task,
auf diese eine bestimmte 
Vorhersage, die gemacht wird.
Und wenn wir einen Schritt 
weiter gehen,
dann haben wir die n√§chste 
Stufe,
die wir innerhalb der 
Organisation die
Applikation oder 
Anwendungsl√∂sung nennen.
Bei so einer L√∂sung haben
wir jetzt nicht einfach nur eine 
einzige Vorhersage,
die durch ein Modell √ºbernommen 
wird,
die es vorher schon gab,
sondern wir haben ein System,
was mehrere h√§ufig von diesen
Points Solutions zusammen nutzt 
Zusammenf√ºhrt,
was mehr in meine Prozesse 
integriert wird. Umfeld,
wie das Umfeld diese Technologie 
wahrnimmt,
was f√ºr Attitude das Umfeld 
dar√ºber hat,
ob es vielleicht auch sogar eine
Art soziale Norm geworden ist,
ein bestimmtes System zu nutzen 
und zur Hand zu haben.
So dass Hier nennt man ein 
sogenanntes Mediationsmodell.
Wir haben hier grundlegende 
Faktoren
die Performance und Effort,
expectancy und Social Influence.
Diese drei Faktoren beeinflussen 
unsere Kognition,
unsere im Kopf geformte 
Intention,
ein System zu nutzen
und durch diese
im Kopf geformte Intention das 
System zu nutzen,
definieren diese Faktoren dann 
√ºber diesen
Mediationsweg ihre Bereitschaft System zu nutzen,
definieren diese Faktoren dann 
√ºber diesen
Mediationsweg ihre Bereitschaft 
tats√§chlich
oder ihre tats√§chliche Nutzung 
des Systems,
ihre tats√§chliche Akzeptanz des 
Systems.
Wer wei√ü, was es neben Mediation 
noch gibt?
Was haben wir noch in diesen 
Modellen,
um etwas zu konzeptionalisieren?
Ja, exactly.
Wissen Sie, was Moderation 
bedeutet?
Moderator ist eine Variable,
die die Richtung oder die St√§rke 
des Effekts.
Sehr gut. Wie Ihre Kommilitonin 
hier gesagt hat,
haben wir nicht nur eine 
Mediation.
Wenn wir sagen, der Effekt von 
Performance expectancy
auf actual use wird",8.627248287,1,"The context directly describes the third level of integration, using the term 'System solutions'. It defines it as a comprehensive and integrated set of technologies that can transform an entire organization, giving Amazon's 'Ship then Shop' as a prime example[cite: 1336].",1,"All claims in the generated answer are directly supported by the provided context. The context defines a System Solution as a ""Comprehensive, integrated set of applications and technologies that work together to address complex, organization-wide problems"" [1335] and notes that it is ""Highly integrated with multiple components and data flows"" [1336].",1,"The generated answer captures the same core meaning as the ground truth, explaining that a System Solution involves a deep integration of ML that fundamentally alters the business model.",,
"According to the text, what is one thing machine learning models currently cannot do?",Machine learning models currently cannot provide a valuation of the consequences of a particular state of the world.,"According to the text, one thing machine learning models currently cannot do is perfectly predict things. The text states, ‚ÄúIn keiner Welt gibt es eine Maschine, die perfekt Sachen vorhersagen wird.‚Äù (There is no world in which a machine will predict things perfectly.)","aufgeschrieben habe.
Daten per se sind immer neu.
Sie ist immer sehr viel.
Verschiedene Faktoren, die dazu 
f√ºhren k√∂nnen,
dass Daten zum Beispiel
nicht perfekt aufgeschrieben 
werden,
dass Daten subjektiv gemessen 
werden.
Und das sind fundamentale 
Probleme f√ºr Machine Learning,
aber auch eine der Sachen,
die wir sehen, wenn wir √ºber die 
Technik sprechen.
Wir wollen gar nicht,
dass unsere Machine Learning
Modelle diese zuf√§lligen Muster
in den Daten abbilden.
Das hei√üt, wenn wir hier jetzt 
in
unserem Trainingsbeispiel unsere 
Regel aufstellen,
wann immer es mild und naiv ist,
dann sage ich Hi und ansonsten gut wie keine Machine Learning 
Modelle Ihnen liefern,
sondern die Machine Learning 
Modelle
geben Ihnen in der ersten
Stufe immer eine bessere 
Einsch√§tzung dar√ºber,
an welcher State of
the World mit welcher 
Wahrscheinlichkeit eintreten 
wird.
Dann sind wir ein bisschen 
weiter gegangen und
haben uns √ºberlegt Wie kann ich 
denn nachdenken dar√ºber,
dass Machine Learning in
meiner Organisation eingesetzt 
wird
und eine Perspektive darauf ist,
dass wir uns anschauen von einer 
Bottom up Perspektive.
Wo in meinen Tasks habe ich
eigentlich implizit oder 
explizit Vorhersagen?
Mache ich eine explizite oder In keiner Welt gibt es eine 
Maschine,
die perfekt Sachen vorhersagen 
wird.
Da kann ich Ihnen hier und jetzt 
die Hand drauf geben.
Sie werden keinen
Machine Learning Modell 
entwickeln k√∂nnen,
egal welche Daten ich Ihnen 
gebe,
egal wie komplex Sie dieses 
Modell machen,
in der Realit√§t werden Sie das 
nicht schaffen.
Modelle werden immer wieder 
Fehler haben,
sei es dadurch gegeben.
Da werden wir n√§chste Woche 
dr√ºber sprechen.
Sogenannte Driftprobleme.
Sie haben Modell gebaut,
was heute super gut 
funktioniert.
Jetzt passiert aber irgendwas
Unvorhergesehenes in der Welt,
sei es irgendwelche neuen 
geopolitischen allererste Vorlesung,
wo wir gesagt haben,
dass es nie um einen Selbstzweck 
geht,
sondern Machine Learning immer
eigentlich dazu dienen soll,
bestimmte Entscheidungen zu 
verbessern,
m√∂glicherweise auch ganz neue
Entscheidungssituationen 
herbeizuf√ºhren,
die ich vorher h√§tte nicht 
treffen k√∂nnen,
weil einfach zu viel 
Unsicherheit besteht.
Und dieser Bottom up Approach 
besagt Wir nehmen
uns den gesamten Workflow,
wir teilen den Workflow in 
einzelne
Tasks auf, wir die Composen.
Diesen gesamten Workflow gehen 
in
einem bestimmten Tasks in
ihrem Ablauf hinein und 
versuchen zu identifizieren,
an welcher Stelle eben muss.
Wir hoffen, dass sie so akkurat 
wie m√∂glich ist.
Das ist aber nicht zwangsl√§ufig 
gegeben.
Und wer erinnert sich an das 
Ziel von
Machine Learning aus einer 
konzeptionellen Perspektive?
Wenn wir √ºber die overarching 
Objectives reden,
was wollen wir damit erreichen?
Wof√ºr ist dieses ganze Modell 
gebastelt etc.
da? Die bestm√∂glichen 
Vorhersagen?
Genau, Und f√ºr welche Daten?
Ja, und eine Sache will ich noch 
rauskitzeln.
Was sind die Inputdaten am 
besten?
Daten, die das Modell noch nicht 
kennt? Genau das.
Es geht uns nicht darum,
dass wir ein Modell haben,
was uns optimal erkl√§rt, angeschaut,
sind dann in eine Case Study 
gemacht,
wo ich ihnen gezeigt habe,
wie man Machine Learning 
anwenden kann.
Nicht immer nur zu negativen 
Aspekten,
aber diese Predictions,
die Machine Learning uns liefern 
kann,
wie man die auch dazu nutzen 
kann,
zum Beispiel zur Vorhersage,
welcher Kunde wie auf welches 
Messaging reagiert,
um letztlich die
R√ºcksenderaten von Produkten zu 
verringern.
Letzte Woche sind wir dann mehr 
ins
Detail schon reingesprungen, 
Eingesprungen,
haben uns √ºberlegt, aus einer 
√∂konomischen Perspektive,
was Prediction bedeuten k√∂nnte,
wenn wir bei General Purpose",7.616875887,0.9,"The context states, ""In keiner Welt gibt es eine Maschine, die perfekt Sachen vorhersagen wird"" (In no world is there a machine that will predict things perfectly)[cite: 1364]. While the ground truth answer is more conceptual ('valuation of consequences'), the context provides a direct and fundamental limitation mentioned in the source material.",1,"The generated answer is a direct claim from the context, which states, ""In keiner Welt gibt es eine Maschine, die perfekt Sachen vorhersagen wird"" (In no world is there a machine that will predict things perfectly) [1355-1356].",0,"The generated answer is incorrect. It claims models cannot predict things perfectly, while the ground truth states they cannot provide a valuation of consequences, which is a different and more nuanced limitation.",,
What are two types of bias metrics?,Individual-level metrics and group-level metrics.,"According to the text, the two types of bias metrics are:

*   **Individual-level metrics:** These ensure that people with similar qualifications receive similar outcomes.
*   **Group-level metrics:** These ensure that algorithmic outcomes do not disproportionately and negatively affect particular groups.","15. Mai 2025
Measurement of algorithmic fairness
‚Ä¢There is no single agreed-upon measure for discrimination/fairness‚Ä¢There are different types of bias metrics that we can distinguish‚Ä¢Individual-level metrics:ensure that people who have similar qualifications with respect to a task receive similar outcomes‚Ä¢Group-level metrics:ensure that algorithmic outcomes do not disproportionately and negatively affect particular groups
15
Verma & Rubin, 2018 that nonobjective variables, such as inadequate information,
contribute to biased outcomes (Dickinson and Oaxaca, 2009).
Lastly, we have the antecedent market discrimination hypothesis
as the fourth category.
Statistical discrimination theory. Statistical discrimination refers
to prejudice from assessment criteria that generalize group
characteristics to individuals (Tilcsik, 2021). It arises due to
limitations in employers‚Äôresearch techniques or the cost con-
straint of obtaining information in the asymmetry between
employers and job seekers. Even without monopolistic power, discrimination (Favaretto et al., 2019; Kordzadeh & 
Ghasemaghaei, 2022). The social component often 
originates from societal and economic structural biases, 
which can foster the differential treatment and 
marginalization of certain groups. On the other hand, the 
technological element emanates from the perpetuated 
discriminatory behaviors of algorithmic systems. 
Algorithmic feedback loops: Feedback loops play a 
significant role in algorithmic discrimination in the 
context of continuously updated ML models. These loops 
arise when the outcomes of algorithmic decisions provide (36KE, 2020). When the dataset lacks diverse representation from
different companies, bias may be introduced during the devel-
opment of algorithmic rules by engineers and when annotators
handle unstructured data (Zixun,2020).
Datasets: bias soil. Datasets serve as the foundation of machine
learning (ML). If an algorithm‚Äôs data collection lacks quantity and
quality, it will fail to represent reality objectively, leading to
inevitable bias in algorithmic decisions. Researchers commonly
use a 95% conÔ¨Ådence level, which provides 95% certainty but still
leaves a one in twenty chance of bias (Raub,2018). Nearly every data already reÔ¨Çects social prejudices, and the algorithm also
incorporates biased relationships, leading to the‚Äúbias in and bias
out‚Äù phenomenon (36KE, 2020). This phenomenon means that
discrimination and disparities exist, just like in forecasting, where
historical inequalities are projected into the future and may even
be ampliÔ¨Åed (Mayson, 2018).
A research team at Princeton University discovered that
algorithms lack access to the absolute truth. The machine corpus
contains biases that closely resemble the implicit biases observed
in the human brain. ArtiÔ¨Åcial intelligence has the potential to unequally and discrimination based on legally protected char-
acteristics, such as race and gender (Jackson, 2021). When
assessments consistently overestimate or underestimate a parti-
cular group‚Äôs scores, they produce ‚Äúpredictive bias‚Äù (Raghavan
et al.,2020
). Unfortunately, these discriminatory results are often
overlooked or disregarded due to the misconception that AI
processes are inherently‚Äúobjective‚Äù and ‚Äúneutral.‚Äù
REVIEW ARTICLE HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS | https://doi.org/10.1057/s41599-023-02079-x",7.091706514,1,"The context provides a slide that clearly distinguishes between the two types of metrics, defining individual-level and group-level metrics exactly as stated in the answer[cite: 1379].",1,"All claims in the generated answer are directly supported by the provided context, which distinguishes between ""Individual-level metrics"" and ""Group-level metrics"" and provides a definition for each [1378].",1,The generated answer and the ground truth are identical.,,
"According to the CRISP-DM framework, what is the approximate percentage of time spent on data preparation within the CRISP-DM process?",Approximately 60-80% of time.,"According to the text, data preparation typically takes around 60 to 80% of the time in a data science project.","form ulation  of the data m ining problem  and the project plan require at least som e
understanding of the available data.
‚Ä¢ D ata Preparation
The data preparation phase covers all activities to construct the final dataset (data that w ill be
fed into the m odeling tool(s)) from  the initial raw  data. D ata preparation tasks are likely to be
perform ed m ultiple tim es, and not in any prescribed order. Tasks include table, record, and 15. Mai 2025
Structuring an AI project: CRISP-DM 
6
1. Business Understanding2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment
Data 
Cross Industry Standard Process for Data Mining m ining tasks, suggest appropriate data transform ations and data m ining techniques, and provide
m eans for evaluating the effectiveness of the results and docum enting the experience.
The C R ISP-D M  (C R oss Industry Standard Process for D ata M ining) project1 addressed parts of
these problem s by defining a process m odel w hich provides a fram ew ork for carrying out data
                                                          
1 The C R ISP-D M  process m odel is being developed by a consortium  of leading data m ining users and suppliers: D aim lerC hrysler und es gibt bestimmte Machine 
Learning Modelle,
die sind sehr sch√∂n,
die viel dieser Arbeit durch
bestimmte algorithmische 
Lernverfahren abfangen.
Zum Beispiel der 
Entscheidungsbaum
oder auch der Random Forest.
Aber es gibt andere Methoden und 
insbesondere die
most sophisticated Methoden wie 
neuronale Netze,
die auf jede Kleinigkeit in
den Daten massiv sensitiv 
reagieren,
m√ºssen Daten standardisieren.
Wir m√ºssen auf eine bestimmte 
Art und
Weise sampeln m√ºssen
bestimmte Observationen 
rausschmei√üen.
All das, wie Sie hier sehen,
braucht ungef√§hr 60 bis
80¬†% der Zeit eines solchen Data 
Science Projekts. rausschmei√üen.
All das, wie Sie hier sehen,
braucht ungef√§hr 60 bis
80¬†% der Zeit eines solchen Data 
Science Projekts.
Es ist teilweise √ºber Wochen, 
Monate.
Wenn wir Daten von Unternehmen 
bekommen,
mit denen wir zusammenarbeiten,
um Forschungsprojekte zu machen,
dass wir erst mal eine Idee 
bekommen,
was diese Daten alles bedeuten.
Sie haben bei mir in der im 
Seminar
gesessen letztes Semester diese 
Daten,
die Sie da erhalten haben, von 
der Firma.
Totales Chaos.
Muss man sich erstmal reindenken 
und
das braucht massiv viel Zeit.
Wenn wir aber dann die Daten 
sauber gemacht haben,
dann geht es endlich an den, und
das braucht massiv viel Zeit.
Wenn wir aber dann die Daten 
sauber gemacht haben,
dann geht es endlich an den,
den sag ich mal aus meiner
Sicht coolsten Teil dieses 
Prozesses, wo wir versuchen,
das anf√§nglich definierte 
Vorhersageproblem
durch Modelle zu l√∂sen.
Hier passiert jetzt in
Anf√ºhrungsstrichen eigentlich 
die Magic,
Hier haben wir unsere 
Algorithmen,
hier haben wir unsere 
verschiedenen Modelle,
die wir alle ausprobieren,
um zu sehen,
wie k√∂nnen wir denn
eigentlich aus den Daten, die 
wir haben,
unsere Features,
eine m√∂glichst genaue Vorhersage 
√ºber
diesen Teil der Daten,
unser Outcome, unser Label?",6.256866455,1,"The context explicitly states that data preparation takes ""ungef√§hr 60 bis 80 % der Zeit eines solchen Data Science Projekts"" (approximately 60 to 80% of the time of such a data science project) [cite: 1408-1409].",1,"The claim is directly supported by the context, which states that data preparation takes ""ungef√§hr 60 bis 80 % der Zeit eines solchen Data Science Projekts"" (approximately 60 to 80% of the time of such a data science project).",1,"The generated answer and the ground truth both state the time spent is approximately 60-80%, making them semantically identical.",,
What does the document state about the impact of Generative AI on employee happiness?,"The document states that employees became happier, with less escalation and longer tenure.","The provided text does not contain any information about the impact of Generative AI on employee happiness. It focuses on the use of AI in recruitment, including concerns about algorithmic discrimination and potential biases.","amounts of data that may exceed human analytical capacities, enabling AI to provide decision
recommendations (Shaw, 2019).
Modern technologies, including artiÔ¨Åcial intelligence solutions, have revolutionized work and
contributed to developing human resources management (HRM) for improved outcomes
(Hmoud and Laszlo,2019). One signiÔ¨Åcant area where their impact is felt is in the recruitment
process, where AI implementation can potentially provide a competitive advantage by enabling a
better understanding of talent compared to competitors, thereby enhancing the company‚Äôs
competitiveness (Johansson and Herranen,2019). perspectives align with the thematic directions identiÔ¨Åed through
our literature review.
Firstly, AI-driven hiring applications impact various aspects,
such as reviewing applicant proÔ¨Åles online, analyzing applicant
information, scoring assessments based on hiring criteria, and
generating preliminary rankings automatically.
Secondly, interviewers perceive beneÔ¨Åts in AI-driven recruit-
ment for job seekers. It eliminates subjective human bias,
facilitates automated matchmaking between individuals and
positions, and provides autom ated response services. More-
over, AI reduces the workload on humans and enhances that impact the hiring process. It would be interesting to analyze
the psychological effects of applying this algorithmic recruitment
technique on various populations (gender, age, education level)
from an organizational behavior perspective. While recent studies
have primarily discussed discrimination theory in the traditional
economy‚Äôs hiring market, future theoretical research should
consider how advanced technology affects equity in hiring within
the digital economy.
Conclusion
The study concludes that the fo urth industrial revolution
introduced technological innovations signiÔ¨Åcantly affecting the Die haben eine Riesenstudie 
gemacht,
wo sie Generative KI Systeme
in Unternehmen eingesetzt haben
und wirklich mal gemessen haben 
hier
im Service Customer Service 
Bereich.
Was bringt das f√ºr die Firma?
Was bringt das f√ºr den 
Mitarbeiter?
Was bringt es f√ºr den Kunden?
Und die Message, Die Details 
erspare ich Ihnen.
Wie gesagt, kann ich Ihnen nur 
empfehlen,
das durchzulesen.
Die Message sind eigentlich drei 
Bilder.
Auf der einen Seite sehen wir, 
dass die.
Hier sehen wir die
Monate bis zum Deployment von AI 
und
das sind immer die Effekte auf 
die Produktivit√§t hier.
Und Sie sehen, das hier ist der 
Zeitpunkt, applications and beneÔ¨Åts of AI-based recruitment, factors con-
tributing to algorithmic recruitment discrimination, types of
discrimination in algorithmic recruitment, and measures to
mitigate algorithmic hiring discrimination. The fourth section
involves conducting a survey among respondents and analyzing
the primary data collected to support our study. TheÔ¨Ånal section
concludes by suggesting future directions for research.
Theory background
Discrimination theory. Discrimination in the labor market is
deÔ¨Åned by the ILO‚Äôs Convention 111, which encompasses any Thirdly, concerns are raised regarding potential hiring
discrimination perpetrated by machines. This can arise from AI
tools, such as partial source data, or users unfamiliar with user
interfaces and operations.
Fourthly, intrinsic factors like personality and IQ, as well as
extrinsic factors like gender and nationality, have been observed
to inÔ¨Çuence the accurate identi Ô¨Åcation and judgment of AI
systems concerning hiring discrimination.
Fifthly, respondents offer recommendations for combating
discrimination by machines, including technical and non-
technical approaches.
Recommendations for future studies",6.304227352,0,"The retrieved context discusses the use of AI in recruitment and the productivity effects of generative AI in a customer service setting. It makes no mention of employee happiness, escalations, or tenure.",1,"The generated answer is faithful because the retrieved context does not contain any information about Generative AI's impact on employee happiness. Therefore, stating that it's not present is an accurate reflection of the provided text.",1,The generated answer is identical to the ground truth.,,
What did Amazon patent in 2014?,A 'Chip Shop' (patent).,"You are absolutely correct. My apologies. The text does mention Amazon‚Äôs work on predicting customer preferences and a patent from 2014, but it doesn‚Äôt provide specific details about the patent itself. I was focusing on the general concept and didn‚Äôt accurately reflect the content. 

Thank you for pointing out my error.","kommen,
die alle miteinander hoch 
integriert sind,
aber eben zu einer komplett
anderen Organisation f√ºhren 
k√∂nnen.
Das Beispiel, das ich Ihnen 
mitgebracht
habe hier ist die Idee von 
Amazon.
Die haben es kurz schon mal 
angesprochen,
glaube ich in der letzten 
Vorlesung.
Oder war es in der Business 
School,
dass ich mich nicht mehr ganz 
sicher.
Aber Amazon hat seit 2014 ein 
Patent,
das hei√üt schieb den Job.
Aktuell gehen Sie auf die 
Website, sie shoppen,
dann wird es geschickt und Sie 
kriegen aktuell,
damit Sie auch sch√∂n viel auf 
Amazon einkaufen,
eine Recommendation, was Sie 
denn ben√∂tigen. Aktienkurs,
wenn ich als Manager einen
bestimmten Merger und 
Acquisition zustimme?
Ich kann aber auch komplett neue
Entscheidungen erm√∂glichen.
Da sprechen wir auch n√§chste
Vorlesung dr√ºber √ºber 
verschiedene Level von 
Innovationen
und L√∂sungen,
die KI uns anbieten kann.
Auch hier schon mal als Spoiler.
Amazon arbeitet an einem Patent 
oder
hat schon seit 2014 ein Patent.
Was hei√üt Chip Shop bedeutet.
Sie versuchen anscheinend,
eine Vorhersage √ºber Ihre 
Pr√§ferenzen √ºber
Ihre zuk√ºnftigen K√§ufe zu bauen 
zu kreieren,
so dass sie Ihnen erst die 
Sachen zuschickt.
Erst Shipping und dann
machen Sie die of success, resulting in discrimination against female applicants
(Langenkamp et al. 2019). The algorithm even downgraded
applicants with keywords such as ‚Äúfemale‚Äù (Faragher, 2019).
These Ô¨Åndings compelled Amazon to withdraw the tool and
develop a new unbiased algorithm. However, this discrimination
was inadvertent, revealing theÔ¨Çaws inherent in algorithmic bias
that perpetuates existing gender inequalities and social biases
(O‚Äôneil, 2016).
Race. Microsoft‚Äôs chatbot Tay learned to produce sexist and racist
remarks on Twitter. By interacting with users on the platform, Gedankenexperiment akkurat w√§re,
Amazon w√ºrde wissen, was sie 
eigentlich kaufen wollen,
ohne dass sie auf die Website
gehen oder auf die App gehen,
dann braucht Amazon nicht mehr
diesen Zwischenschritt von 
Ihnen,
dass Sie sich bereit erkl√§ren,
in einer bestimmten Situation 
auf die
App zu gehen, etwas 
durchzusuchen,
dort draufzuklicken, auf Order 
zu
klicken und dieses Produkt dann 
zu bestellen,
was Amazon dann machen k√∂nnte.
In diesem Gedankenexperiment, 
wenn alles 100¬†% akkurat
w√§re Ihnen einfach regelm√§√üig 
M√§√üig das,
was vorhergesagt wird, was
sie ben√∂tigen, automatisiert 
zuzusenden. published maps and institutional afÔ¨Åliations.
Open Access This article is licensed under a Creative Commons
Attribution 4.0 International License, which permits use, sharing,
adaptation, distribution and reproduction in any medium or format, as long as you give
appropriate credit to the original author(s) and the source, provide a link to the Creative
Commons license, and indicate if changes were made. The images or other third party
material in this article are included in the article‚Äôs Creative Commons license, unless
indicated otherwise in a credit line to the material. If material is not included in the anstellen.
Ich wollte noch sagen, dass 
vielleicht auch andere
Ideen also nicht identifizieren 
w√ºrde.
Ich wei√ü es nicht.
Amazon wird wahrscheinlich nicht 
K√∂rpergr√∂√üe benutzen,
aber beschnittene M√§nner eher 
gr√∂√üer.
Und dann so welche Daten genau 
in die Richtung?
Das sind andere Korrelationen.
Ich muss nicht genau ihr 
Geschlecht
wissen oder ihre Identifikation
mit einem bestimmten Geschlecht.
Ich kann √ºber ganz viele andere
korrelative Ma√üe ein sehr
guter Einsch√§tzung davon 
bekommen,
ob sie sich mit
einem bestimmten Geschlecht 
identifizieren.
Hier in diesem Fall war es 
tats√§chlich die",8.453054905,0.4,"The context correctly states that Amazon has a patent from 2014, but it incorrectly names it ""schieb den Job"" [cite: 1445], which seems to be a mistranslation or misinterpretation of ""Ship then Shop""[cite: 1450]. The relevance is partial because it identifies the company and year but gets the patent's name wrong.",1,"The generated answer is faithful to the provided context, including the error. The context does mention a patent from 2014 but contains no information about a 'Chip Shop' patent, so the generation correctly states that it was unable to verify the claim from the text.",0,"The generated answer incorrectly identifies the patent as 'Chip Shop', while the ground truth states it is for 'Anticipatory Shipping'.",,
The lecture identifies two fundamental aspects that make AI different from previous General Purpose Technologies like electricity. What are they?,"First, it is a technology that can improve itself through its own use (self-learning). Second, this self-learning creates massive cross-industry spillover effects, where use in one industry can improve the system for another.","According to the text, the two fundamental aspects that make AI different from previous General Purpose Technologies like electricity are:

1.  **The breadth of its applications:** AI is being used for predictions across many industries.
2.  **Continuous learning of the technology itself:** AI systems are capable of continuous learning, unlike previous technologies.","AI as General-Purpose technologyWhat is a General-Purpose Technology (GePuT)?‚Ä¢Pervasive: can be applied across sectorsof the economy. ‚Ä¢Rapidly improving & cheaper over time: learning-by-doing, scale economies, Moore-like curves‚Ä¢Complements: sparks waves of follow-on innovations, new business models, organizational redesign.‚Ä¢Previous examples: Steam engine, Electricity, Digital ComputingAI be seen as a GePuTas well ‚Äìwhy?‚Ä¢Core function gets dramatically cheaper: prediction making‚Ä¢Ubiquitous use-cases across every industry.‚Ä¢For the first time: continuous learning of the technology itself with cross industry some plants. After the mid-1990s, artiÔ¨Åcial intelligence software
saw signiÔ¨Åcant advances. Until today‚Äôs digital economy, AI has
been commonly used in various industries (Hmoud and Laszlo,
2019).
ArtiÔ¨Åcial intelligence is deÔ¨Åned as the ability of something like
a machine to understand, learn, and interpret on its own in a
human-like manner (Johansson and Herranen,2019). ArtiÔ¨Åcial
intelligence aims ‚Äúto understand and simulate human thought
processes and to design machines that mimic this behavior.‚ÄùIt is
designed to be a thinking machine with a level of human
Table 1 Research theme, papers, and main content. 24. April 2025
Let‚Äôs do the formal course introduction nowThis course is about understanding the impact of AI systems from a management perspective and developing them braucht aber weitere 
Innovationen,
dass wir es wirklich gut nutzen 
k√∂nnen.
Was glauben Sie denn,
wenn Sie KI mit den vorherigen 
Innovationen vergleichen?
Was macht KI besonders?
Was ist ganz fundamental
unterschiedlich
zu allen vorherigen General 
Purpose Technologies.
Und ich habe es gerade schon 
gezeigt Ja,
man braucht keine neue Hardware 
als Nutzer.
Am Ende doch die.
Also man braucht immer wieder 
andere Hardware.
Irgendwann reiben sich auch 
GPU's zum Beispiel auf,
geht aber in die richtige 
Richtung,
in das Technische zu denken.
Yes, das ist ein Teil davon.
Wir haben zum Ersten Mal Systeme motiviert?
Ja, alles. Aber lassen Sie uns
ganz kurz noch mal dar√ºber 
nachdenken.
Warum ist denn eigentlich KI
allgemein wahrgenommen als 
General Purpose Technologie?
Warum glauben Sie, ist es eine 
Technologie,
wo alle immer von einer 
Kerninnovation dar√ºber sprechen?
Vollkommen richtig, ja. Es ist 
die Breite.
√úberall sind Vorhersagen. Was 
noch?
Automatisierung? Ja. Ich kann 
√ºber
diese pr√§ziseren
Vorhersagen sehr viel 
automatisieren. Andere Ideen.
Jeder kann es nutzen.
Ja, wir haben diese Laws
of Rapidly Improving und Keeper 
Overtime.
Jeder kann jetzt irgendwie KI
sich teilweise zusammenbauen. Im Rahmen der Veranstaltung werden zahlreiche Praxisbeispiele und Fallstudien aus verschiedenen Industrien behandelt, die die Anwendung von ML und generativer KI im gesch√§ftlichen Kontext beleuchten. Insbesondere in den angebotenen √úbungen und praktischen Programmieraufgaben lernen Studierende, das erlangte Wissen anzuwenden, auch ohne vorherige Programmiererfahrung.",8.087225914,1,"The context directly addresses the question. It states that what makes AI fundamentally different is that it is a system that can improve itself through use (""selbst lernend"") [cite: 1588] and that this creates massive spillover effects across industries[cite: 942].",1,"All claims in the generated answer are directly supported by the context. The context states that AI is different because of its ability for ""continuous learning of the technology itself with cross industry"" applications [1467] and its ubiquity for predictions.",1,"The generated answer and the ground truth are semantically identical, both highlighting the self-learning nature of AI and the resulting cross-industry spillover effects as the key differentiators.",,
"From a purely economic perspective, what is the single most important function that machine learning technology provides?","It is a technology that massively lowers the cost of making high-quality, accurate predictions.","Based on the provided text, from a purely economic perspective, the single most important function that machine learning technology provides is **a better prediction of outcomes, particularly regarding the likelihood of a return (like a startup's repayment).** 

The text repeatedly emphasizes using machine learning to improve predictions, specifically referencing a ""return"" (likely a repayment) with a certain probability. It frames this as a way to move beyond simple uncertainty and make more informed decisions, ultimately aiming for a more economically sound outcome.","three revisions.  
1 Introduction 
With the aim of bolstering economic efficiency and 
societal welfare (Benbya et al., 2020; Teodurescu et al., 
2021), machine learning (ML) systems are augmenting 
human decision -making across diverse domains, 
including bail decisions (Kleinberg et al., 2018), hiring 
processes and student admissions (Horton, 2017; Zhao 
et al., 2020), banking (Fu et al., 2021), and medicine 
(Jussupow et al., 2021). In Europe, Big Data analytics 
software revenue reached US$14.6 billion in 2018 
alone. Wells and Spinoni‚Äôs projections (2019) indicate Die Digitalisierung und datengetriebene Transformation ver√§ndern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen √ºber die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends ‚Äì ML bietet vielf√§ltige Ans√§tze, um Managemententscheidungen fundierter und effizienter zu gestalten. wie bisher.
Deswegen Quick Win.
Ich sehe die M√∂glichkeit,
eine bereits get√§tigte 
Vorhersage
auf die eine oder andere
Art und Weise durch Machine 
Learning Technologie
so massiv zu verbessern,
so dass es sich f√ºr mein 
Business letztlich lohnt.
Aber dabei ist es immer sehr eng 
und sehr fokussiert.
Diese Nutzung von Machine 
Learning.
Ich habe wirklich nur diesen 
einen Vorhersagetest und den
ersetze ich und ansonsten lasse 
ich
alles genauso wie es ist.
Ich habe also keine
starke Integration der 
Technologie
in meine anderen Prozesse 
hinein,
denn ich gucke immer
nur auf diesen einen bestimmten 
Task, Sobald Sie einen Task 
identifiziert haben,
wo Machine Learning bestimmte 
Vorhersagen liefern kann.
Um ihre Entscheidungen zu 
verbessern,
sollten wir nicht nur in einer
optimalen Welt diese eine 
Entscheidung,
dieser eine Vorhersage durch
Machine Learning besser machen,
sondern wir sollten auch dar√ºber 
nachdenken,
was eigentlich ben√∂tigt wird
innerhalb meines gesamten 
Workflows wieder,
damit diese Maschine gut 
funktioniert.
Welche Daten brauche ich, welche 
Data Pipelines?
Welche Hardware? Wie ver√§ndern 
sich vielleicht
andere Teile dieses gesamten 
Workflows?
Wenn ich anfange,
eine bestimmte Vorhersage durch Machine Learning rein?
Was ist das Wichtige hier?
Was ver√§ndert Machine Learning 
auf der einen Seite und
was ver√§ndert Machine Learning?
Eben nicht in dieser Gleichung
aus dieser wirklich 
√∂konomischen,
spieltheoretischen Perspektive. 
Wer wei√ü das noch?
Ja, genau.
Wir haben hier unsere eigene 
initiale Einsch√§tzung.
Wir sehen das Startup und sagen 
Na ja,
mit einer bestimmten 
Wahrscheinlichkeit P wird sich
das Startup anstrengen und dann
kriegen wir eben diese 
R√ºckzahlung.
Und mit der Wahrscheinlichkeit
eins P wird das nicht passieren.
Und was Machine Learning uns 
letztlich geben kann,
ist eine bessere allererste Vorlesung,
wo wir gesagt haben,
dass es nie um einen Selbstzweck 
geht,
sondern Machine Learning immer
eigentlich dazu dienen soll,
bestimmte Entscheidungen zu 
verbessern,
m√∂glicherweise auch ganz neue
Entscheidungssituationen 
herbeizuf√ºhren,
die ich vorher h√§tte nicht 
treffen k√∂nnen,
weil einfach zu viel 
Unsicherheit besteht.
Und dieser Bottom up Approach 
besagt Wir nehmen
uns den gesamten Workflow,
wir teilen den Workflow in 
einzelne
Tasks auf, wir die Composen.
Diesen gesamten Workflow gehen 
in
einem bestimmten Tasks in
ihrem Ablauf hinein und 
versuchen zu identifizieren,
an welcher Stelle eben",10.44520116,0.9,"The context explains that from an economic perspective, machine learning's key function is to provide a better estimation of probabilities, such as the likelihood that a startup will be successful and provide a return [cite: 1499-1500]. This massively reduces uncertainty, which is equivalent to lowering the cost of prediction.",1,"The claims in the generated answer are directly supported by the context. The context explains that machine learning provides a better prediction of outcomes, specifically using the example of estimating the probability 'p' that a startup will be successful and provide a return on an investment [1484].",1,"The generated answer and the ground truth are semantically equivalent, both identifying that ML's key economic function is to lower the cost of making accurate predictions.",,
"According to the text, what does the 'J-curve' represent?","The 'J-curve' represents a phenomenon where, with many technologies, productivity initially decreases before eventually increasing.","The text doesn't mention a ""J-curve."" It discusses concepts like approximations, models, and error, but it doesn't refer to a J-curve.","aber die zentrale Aufgabe ist 
eigentlich,
die Wahrscheinlichkeit richtig 
einzusch√§tzen.
Das, was hier auf der Achse ist
und den Nutzen richtig 
einzusch√§tzen.
Das was auf der Y Achse ist.
Hier haben wir irgendwelche 
Annahmen
getroffen gerade und ich habe 
auch
f√ºr Sie irgendwelche Annahmen 
hier
√ºber die Verbindung dieser 
Punkte hier als
gerade Linie getroffen.
Die Grundidee des Ganzen ist 
aber weiterhin die gleiche.
Wenn ich in so einen Graphen in
der Klausur geben w√ºrde und ich 
w√ºrde sie fragen,
an welchen Stellen denn in 
Aktion,
Suggestion und Aktion 
empfehlenswert w√§re,
hoffe ich, dass jeder diesen dieser Gleichung hier 
ausdr√ºcken.
Wir haben drei verschiedene 
Komponenten.
Wir haben hier dieses H√ºtchen,
wir haben das fix und wir haben 
hier dieses Y H√ºtchen.
Meine erste Frage an Sie Was war 
das? F H√ºtchen.
Yes, genau richtig.
Wir haben hier das erlernte 
Machine Learning Modell,
was die Muster, die wir in 
historischen
Daten durch Algorithmen erkannt 
haben, abspeichert.
Hier in diesem F. Steckt unser 
gesamtes Wissen drin,
was wir irgendwie extrahieren
und wie genau wir das 
extrahieren.
Das wird der zweite Teil unserer 
Vorlesung sein.
Wichtig hierbei H√ºtchen ist 
immer daf√ºr ein Indikator, i
) ÔøΩ 1 
(59.3% of the test data). The vertical lines represent the 95% confi -
dence intervals.
von Zahn et al.: Product Returns, Digital Footprints, and Causal Machine Learning 
Marketing Science, Articles in Advance, pp. 1‚Äì16, ¬© 2024 The Author(s) 11 
Downloaded from informs.org by [141.2.113.143] on 24 April 2025, at 02:36 . For personal use only, all rights reserved. kennt dieses
Symbol? Was bedeutet das?
Genau. Das ist aus der 
Mathematik der Logik.
Wenn Sie dieses seitlich 
gedrehte Liter sehen,
hei√üt das immer Nicht immer.
Nicht a, nicht Action.
Sie k√∂nnen eigentlich hier,
um das Beispiel zu 
vervollst√§ndigen.
Sie m√∂chten gerne, dass 
aufgezeichnet wird,
aber die uhr macht es nicht 
automatisch.
Not Action.
Und ein anderer Fall ist,
Sie m√∂chten es nicht und die uhr 
macht es nicht.
Diese vier Extremf√§lle haben wir 
jetzt wieder.
Und die Idee, die hier in diesem 
Paper auf einer
Informatik Konferenz postuliert 
wird, ist.
Naja, lassen Sie uns mal 
annehmen, 10. Juli 2025
Gradient descent: the intuition
18
Imagine a data set with three observations:
Can you spot the relationship between ùë•and ùë¶?We train a perceptron with one weight ùë§and no bias
Assume ùëìùë§‚ãÖùë•=ùë§‚ãÖùë•(linear activation function). What is the optimal ùë§?
ùë• ùë¶3 -0.21-5 0.359 -0.63
ùëì(ùë§‚ãÖùë•)ùë• Aùë¶ extrahieren.
Das wird der zweite Teil unserer 
Vorlesung sein.
Wichtig hierbei H√ºtchen ist 
immer daf√ºr ein Indikator,
dass wir von einer Approximation 
sprechen.
Das ist ein Modell.
Das ist nicht der wahre 
unterliegende Prozess,
der die Daten generiert.
Das ist nicht die Landschaft von 
Frankfurt sozusagen,
sondern es ist die Landkarte.
Es ist ein explizit abstrakteres 
Modell,
eine Darstellung der Realit√§t.
Und da k√∂nnen eben Fehler drin 
sein.
Es ist ganz wichtig, sich
immer wieder vor Augen zu 
halten.
Dann haben wir die zweite 
Komponente.
Das war das XML. Was ist das?.X. 
Jemand eine Idee?",6.191572189,0,"The context does not mention a 'J-curve'. It discusses concepts related to machine learning models, such as approximations, errors, and their components [cite: 1506-1524], but the specific term 'J-curve' is absent.",1,The generated answer is faithful as it accurately states that the provided context does not mention a 'J-curve'.,1,"The generated answer captures the same meaning as the ground truth, explaining that the 'J-curve' shows an initial decrease in productivity followed by an increase.",,
What is a potential new attack vector related to large language models?,"Systems can be hacked, leading to false or harmful code being written into company codebases.","According to the text provided, a potential new attack vector is:

‚ÄúIf I now have a large language model that is somehow hacked, it can write false or even malicious code into the company‚Äôs codebase‚Ä¶ by distributing data online that triggers this behavior, I can suddenly start to operate and evolve these systems.‚Äù","hat das einen komplett neuen 
Angriffsvektor.
Die neueste Studien zeigen,
dass mittlerweile in den gro√üen 
Unternehmen wie
Microsoft und Google 40 bis
50¬†% des gesamten Codes
von GPT oder von gro√üen 
Sprachmodellen geschrieben wird.
Wenn ich jetzt nat√ºrlich ein 
gro√ües Sprachmodell habe,
das in irgendeiner Weise gehackt 
wurde,
das falschen oder sogar 
sch√§dlichen Code
in die Codebasis der Unternehmen 
reinschreibt,
k√∂nnen pl√∂tzlich diese Systeme 
dadurch,
dass ich Daten online verbreitet 
habe,
die dieses Verhalten 
hervorrufen,
kann ich pl√∂tzlich anfangen,
diese Systeme auf eine ganz neue 
Art operate and evolve. Our results suggest that continuous 
model updating could serve as a mechanism for 
mitigating bias in ML systems and might act as a force 
to supplement traditional data cleaning and debiasing 
efforts (Shrestha et al., 2019) to reduce discrimination 
risks. 
On the other hand, our simulations reveal that the 
positive impact of continuous updating on algorithmic 
discrimination (and economic efficiency) largely 
hinges on the sociotechnological environment, which 
includes the degree of the system ‚Äôs initial bias and, 
perhaps more importantly, the persistence of biased 17. Juli 2025
Word2VecIn practice:‚Ä¢Word2Vec has much larger embeddings layer (>100 dimensions)‚Ä¢Trained on large data set, e.g.entire, Wikipedia‚Ä¢Alternative prediction goal is skipgram‚Ä¢Predict surrounding words from word itself (the other way round for CBOW)Training embeddings requires high computational power‚Ä¢Typically, more than 100 dimensionalembedding‚Ä¢Size of dictionary is in the million‚Ä¢w2v speeds up training by negative sampling
18 17. Juli 2025
A game changer
27
The transformer architecture1.Transform words into numbers ‚ÄìWord embeddings2.Control word positioning of words ‚ÄìPositional encoding3.Represent words in the context of other words ‚ÄìSelf-attention4.Predict the next word using a feed-forward neural net 17. Juli 2025
Learning word embeddings with Word2VecWord2Vec: simple neural networkto generate word embeddings given a text corpus‚Ä¢Idea: predict words from their surrounding context‚Ä¢Learned weights are embeddings‚Ä¢Through optimization: words in similar context have similar embeddings‚Ä¢Gives us a fixed dictionary of vectors for words we can utilizeIntuitive example: assume we have a text corpus with two sentences
15
Training dataPizza is awesomePizza is greatPizzaisgreatawesome
PizzaisgreatawesomeInput layerEmbeddings layer Output layer adjusting model predictions by suitably editing 
protected attributes. 
2.2 Contribution to the Literature 
This paper enhances two streams of research in the IS 
literature. First, it augments the existing body of work on 
algorithmic discrimination. Scholars have rigorously 
examined how modern ML systems can produce 
unfavorable outcomes for particular groups, often those 
marginalized. Such discrimination manifests across 
various contexts, from recidivism risk assessments 
(Dressel & Farid, 2018) and education (Baker & Hawn, 
2021) to recruitment (Leicht -Deobald et al., 2019),",7.412039518,1,"The context directly addresses the question, stating that a new attack vector is that a hacked large language model could write ""falschen oder sogar sch√§dlichen Code in die Codebasis der Unternehmen"" (false or even malicious code into the company's codebase)[cite: 1526].",1,"All claims in the generated answer are directly supported by the context. The context explains that a hacked large language model can write ""falschen oder sogar sch√§dlichen Code in die Codebasis der Unternehmen"" (false or even malicious code into the codebase) [1526] and that this can be triggered by distributing certain data online.",1,"The generated answer and the ground truth are semantically identical, both identifying the hacking of systems to insert malicious code as a new attack vector.",,
"According to the text, what is a problem with relying on a perfect machine learning model to predict future outcomes?","It would shift us into a situation where there appears to be no risk, but this is conceptually problematic.","According to the text, a key problem with relying on a machine learning model ‚Äì specifically one predicting creditworthiness ‚Äì is that ‚Äúthis Output [the model‚Äôs prediction] is not necessarily right.‚Äù The model‚Äôs output is a prediction, not a definitive truth, and the text highlights the potential for inaccuracies.","1933 ), uses machine learning functions to flexibly esti -
mate residuals in treatment and outcome prediction 
equations, enhancing the robustness of our treatment 
effect estimates and aligning with accepted practices 
(detailed further in Online Appendix A.6). We further 
conform to data science standards by dividing our data 
into training (80%) and testing (20%) sets (Hastie et al. 
2009 ). We fine-tune the causal forest‚Äôs hyperparameters 
through a grid search with fivefold crossvalidation on 
the training data, focusing on out-of-sample R-score per -
formance (Schuler et al. 2018 ). We provide hyperpara - 12. Juni 2025
Components of supervised MLSupervised machine learning methods fit a model to data based on an evaluation criterion
18
Representation +Evaluation+Optimization
Improvement in model behavior accordingto a target variableand an evaluation metric.
Example: Change in stock price the next dayTrue outcome ùë¶(Up = 1)Model prediction ""ùë¶(Up = 1)Squared prediction errorùë¶‚àí""ùë¶!1 0 10 0 00 1 11 1 0 decision makers against a certain social group 
affect the impact of continuous updating on 
model fairness and economic efficiency?
 
 
Figure 1. Process Where Machine Learning Predictions Endogenously Influence the Availability of Data 
for Future Retraining of the Model 12. Juni 2025
Remember the following case study from lecture 1.(a) Explain in your own words what the central machine learning prediction helps to do. (b)Provide a brief discussion about the potential dangers associated using ML models for such purposes in the context of misinformation.
5 Das ist unsere Pr√§diktion,
auf Englisch auch wieder 
indiziert durch das H√ºtchen.
Das H√ºtchen zeigt uns an dieser 
Stelle,
dass wir nicht ganz explizit 
wissen,
ob das eigentlich das reale 
Outcome ist.
Wenn Sie eine Machine Learning 
System haben,
was Ihnen basierend auf den
Soziodemografischen Faktoren 
einer Person
eine Vorhersage gibt dar√ºber,
ob diese Person tats√§chlich 
kreditw√ºrdig ist oder nicht.
Ist dieser Output der
Maschine das Y immer eine 
Prediction,
eine Vorhersage, die nicht
notwendigerweise richtig sein 
muss.
Wir hoffen, dass sie so akkurat 
wie m√∂glich ist.
Das ist aber nicht zwangsl√§ufig 
gegeben. angeschaut,
sind dann in eine Case Study 
gemacht,
wo ich ihnen gezeigt habe,
wie man Machine Learning 
anwenden kann.
Nicht immer nur zu negativen 
Aspekten,
aber diese Predictions,
die Machine Learning uns liefern 
kann,
wie man die auch dazu nutzen 
kann,
zum Beispiel zur Vorhersage,
welcher Kunde wie auf welches 
Messaging reagiert,
um letztlich die
R√ºcksenderaten von Produkten zu 
verringern.
Letzte Woche sind wir dann mehr 
ins
Detail schon reingesprungen, 
Eingesprungen,
haben uns √ºberlegt, aus einer 
√∂konomischen Perspektive,
was Prediction bedeuten k√∂nnte,
wenn wir bei General Purpose",7.923881531,0.9,"The context states that the model's output (Y-hat) is a prediction that is ""nicht notwendigerweise richtig sein muss"" (does not necessarily have to be correct)[cite: 1544]. This directly supports the idea that relying on it as a perfect predictor is a problem, as it is inherently uncertain.",1,"The claim is directly supported by the context, which states that a machine learning model's output ""ist dieser Output der Maschine das Y immer eine Prediction, eine Vorhersage, die nicht notwendigerweise richtig sein muss"" (this output of the machine, the Y, is always a prediction, a forecast, that does not necessarily have to be correct) [1534].",0,"The generated answer is incorrect. It claims the problem is that the model's output isn't necessarily right, which is a general limitation of any predictive model. The ground truth points to a more profound conceptual problem: a perfect model would eliminate the perception of risk, which is fundamentally problematic for decision-making frameworks.",,
How much have the costs for inference (using GPT or other Large Language Models) decreased in the last two years?,The costs have decreased by a factor of 34.,"You are absolutely correct. The text does not provide information about the decrease in costs for inference with Large Language Models. It discusses model complexity, scaling laws, and the use of Ockham‚Äôs Razor, but it doesn‚Äôt detail any specific cost reductions.","Produktion und die marginalen 
Kosten,
eine weitere Einheit von 
Komplexit√§t dazuzunehmen,
de facto null sind.
Wir sprechen da dann dr√ºber, so 
ein bisschen.
Wenn wir √ºber GPT Systeme 
sprechen,
weil die da sehen wir nat√ºrlich 
merklich unterschiedlich,
ob ich 60 Gigabyte Text
reinknalle oder das halbe 
Internet.
Dann habe ich nat√ºrlich schon 
unterschiedliche
Kommunikationskosten.
Wobei jetzt in dem neuen Report
war zum Beispiel angezeigt,
dass die Kosten zumindest f√ºr 
die Inferenz,
also wenn Sie GPT benutzen oder
andere Large Language Models,
die Kosten sind seit zwei zwei 
Jahren Haben die Inferenz,
also wenn Sie GPT benutzen oder
andere Large Language Models,
die Kosten sind seit zwei zwei 
Jahren Haben
die sich bei einem Faktor 34 
verringert?
Ja, das wird massiv effizienter.
Wir sehen jetzt so ein bisschen 
die
Laws of Scaling einsetzen.
Ganz kurz noch hat das Ihre 
Frage.
Das ist die beantwortet mit 
Ockhams Razor.
Wenn wir jetzt nur nach 
Temperatur entscheiden,
w√§re nach diesem Gesetz kein 
Gesetz,
das vorsichtig sein. Das ist so 
eine.
Ich w√ºrde es als Daumenregel 
bezeichnen.
Deswegen hat man auch davon 
abgesehen,
dass irgendwie Rule zu nennen.
Aber grunds√§tzlich so ein 
bisschen aus der 22. Mai 2025
A frequent trade-off
Model complexity, prediction accuracy, and model interpretability‚Ä¢Linear models simple to interpret as input-output relationships can be quantified in magnitude and direction, see, e.g., OLS coefficients‚Ä¢More complex models typically more accurate in predictions‚Ä¢Often a tradeoff; but not always (Sometimes ‚ÄúOccam‚Äôs Razor‚Äù seems to apply)
12
Model complexity / ability to capture pattern
Interpretability
BayesLinear regressionDecision tree
Deep NNEnsemble methods (e.g., RF)SVM
NOTE: Graph just an illustration without precise scales; exact relationship highly dependent on actual problem 17. Juli 2025
Learning word embeddings with Word2VecWord2Vec: simple neural networkto generate word embeddings given a text corpus‚Ä¢Idea: predict words from their surrounding context‚Ä¢Learned weights are embeddings‚Ä¢Through optimization: words in similar context have similar embeddings‚Ä¢Gives us a fixed dictionary of vectors for words we can utilizeIntuitive example: assume we have a text corpus with two sentences
15
Training dataPizza is awesomePizza is greatPizzaisgreatawesome
PizzaisgreatawesomeInput layerEmbeddings layer Output layer 17. Juli 2025
Word2VecIn practice:‚Ä¢Word2Vec has much larger embeddings layer (>100 dimensions)‚Ä¢Trained on large data set, e.g.entire, Wikipedia‚Ä¢Alternative prediction goal is skipgram‚Ä¢Predict surrounding words from word itself (the other way round for CBOW)Training embeddings requires high computational power‚Ä¢Typically, more than 100 dimensionalembedding‚Ä¢Size of dictionary is in the million‚Ä¢w2v speeds up training by negative sampling
18 10. Juli 2025
Learning in deep networks
26
Updating differs only in number of parameters and way to compute influence of parameters on cost function‚Ä¢BUT: Computation of gradient ùõªùê∂is much more complex; bottleneck for several decades‚Ä¢Computed using backpropagation algorithm ‚Ä¢BPA is about understanding how changing the weights and biases in different layers changes the cost function
ùë§‚Ä≤=ùë§‚àíùúÇùõª%ùê∂(ùë§)ùëè‚Ä≤=ùëè‚àíùúÇùõª&ùê∂(ùëè)
Neural Networks: Universal function approximator for highly complex relationships that can theoretically learn any non-linear functional form",7.33015275,1,"The context directly answers the question, stating that the costs for inference ""sind seit zwei zwei Jahren Haben die sich bei einem Faktor 34 verringert"" (have decreased by a factor of 34 in the last two years)[cite: 1553].",1,The generated answer is faithful as it correctly reports that the provided text does not contain the requested information. The text discusses model complexity but not specific cost reductions.,0,"The generated answer is factually incorrect. It states the cost decreased by a factor of 34, while the ground truth says it decreased by 99%.",,
"What is the idea behind using simpler models, according to Ockhams Razor?",To prefer a model that needs less information to make a good prediction.,"According to Ockham‚Äôs Razor, the idea behind using simpler models is to favor the model that requires less information to make a good prediction. Essentially, if two models perform equally well, the simpler model should be preferred because it‚Äôs less likely that random fluctuations in the data are being mistaken for meaningful patterns.","dass GPT auf die Art und
Weise funktionieren wird, wie es 
funktioniert.
Da mussten massiv Ressourcen 
reingesteckt werden,
auch um zu experimentieren.
Letztlich. Und Ockhams Razor ist 
eher dieses diese Idee.
Wenn ich zwei Modelle trainiert 
habe und
diese beiden Modelle 
nebeneinander lege und die 
gleiche
Performance habe,
dann sollte ich als Daumenregel 
nochmal
wirklich betont als Daumenregel
eher das Modell nehmen, was 
einfacher ist.
Der Gedanke, der dahinter 
steckt,
ist, dass wir vermeiden wollen,
dass die zuf√§lligen Schwankungen 
in den
Daten mit h√∂herer 
Modellkomplexit√§t
in dem Modell erkannt werden als ein Modell so einfach wie 
m√∂glich zu belassen.
Bedeutet in unserem Beispiel ich 
sollte ein Modell
laut diesem Ockhams Razor 
bevorzugen,
was weniger Informationen 
ben√∂tigt,
um eine gute Vorhersage zu 
machen.
W√§re das nicht auch teilweise 
√∂konomischer?
In dem Modell, eine Menge 
Energie zu verbrauchen,
w√ºrden vielleicht weniger Daten
das gleiche Ergebnis bringen.
Das ist auch ein wichtiger Punkt 
grunds√§tzlich,
den wir aber in den Datenmengen,
√ºber die wir alle sprechen,
wenn wir √ºber tabulare Daten
insbesondere sprechen, 
ignorieren k√∂nnen,
weil die Kosten daf√ºr so gering 
sind,
dass das keine Rolle spielt, Modelle
aus ganz unterschiedlichen
Disziplinen zusammengenommen und
haben jahrelang rumgewerkelt, um 
zu schauen,
was sind eigentlich die latent 
√§hnlichen Faktoren,
was k√∂nnen wir irgendwie 
zusammenfassen und
was sind Faktoren,
die m√∂glichst orthogonal einzeln 
gesehen
unterschiedlich sind und
viel Erkl√§rungsgehalt daf√ºr 
haben
in der Vorhersage,
ob ein Mensch die Technologie 
nutzen wird oder nicht.
Und das haben Sie das Modell, 
was entwickelt haben
letztlich auf ganz viele 
empirische Daten
gelegt und gezeigt,
dass dieses Modell um die 70¬†% 
der Variation darin,
ob Leute mit Technologie 
interagieren, unterschiedliche Anzahl von 
Input Informationen.
W√ºrde ich jetzt mal ohne zu 
komplex zu
werden direkt sagen k√∂nnen.
Wir benutzen, um diese Regel 
herzuleiten.
Grunds√§tzlich gibt es das
Prinzip Das nennt man Ockhams 
Razor.
Das ist keine Regel.
Es ist kein festgeschriebenes 
Gesetz.
Und jetzt kommt ein √ñkonom 
Spruch.
Es kommt immer drauf an, es 
kommt darauf an,
wie komplex der reale
Datengenerierung sprozess 
tats√§chlich ist.
Grunds√§tzlich spricht dieses 
Ockhams Razor aber daf√ºr,
dass man versuchen sollte,
ein Modell so einfach wie 
m√∂glich zu belassen.
Bedeutet in unserem Beispiel ich 
sollte ein Modell die Entscheidung,
ob wir im Automation oder 
Delegation,
im Automation oder Augmentation 
Setting sind,
auch an die Maschine ab.
Und er hat dann sehr intuitives,
sehr intuitiven, konzeptionellen 
Vorschlag gemacht,
wie wir dar√ºber nachdenken 
k√∂nnen.
Das ist jetzt auch wieder das 
Modelldenken,
was ich glaube sehr wichtig ist 
an Universit√§ten.
Gelernt werden sollte,
dass sie ein grundlegendes 
Schubladendenken haben,
wie sie √ºber solche Probleme 
nachdenken k√∂nnen,
ohne dass wir jetzt keine 
Ahnung.
Ich gebe Ihnen 20 Beispiele,
die m√ºssen Sie f√ºr die Klausur 
auswendig lernen,
sondern die fundamentale Idee, in Unternehmen dazu,
die bereitgestellte Technologie 
zu nutzen?
Es gibt mittlerweile auch zwei
Erweiterungen von diesem Modell
oder auch ein paar mehr kleinere 
Erweiterungen noch,
die es dann mehr auf
die Konsumentenperspektive 
erweitert haben.
Aber das Grundmodell und das 
ist,
was ich Ihnen beibringen m√∂chte.
Und ich dachte eigentlich,
ich k√∂nnte es relativ schnell 
machen,
aber weil es so wichtig ist,
sprechen wir doch ein paar 
Minuten dr√ºber.
Dieses Grundmodell, das ist 
wichtig zu verstehen.
Auf der einen Seite wurde 
argumentiert,
ob meine Mitarbeiter in
meinem Unternehmen eine 
Technologie,",8.279550314,1,"The context directly explains the principle of Ockham's Razor, stating one should prefer a model ""was weniger Informationen ben√∂tigt, um eine gute Vorhersage zu machen"" (that requires less information to make a good prediction) [cite: 1566] to avoid mistaking random fluctuations for real patterns[cite: 1565].",1,"All claims in the generated answer are directly supported by the context. The context explains that according to Ockham's Razor, one should prefer a model that ""weniger Informationen ben√∂tigt, um eine gute Vorhersage zu machen"" (needs less information to make a good prediction) [1562] to avoid learning from random fluctuations in the data.",1,"The generated answer and the ground truth are semantically identical, both explaining that the principle of Ockham's Razor favors simpler models that use less information for the same performance.",,
"In the paper 'The Productivity J-Curve' by Brynjolfsson et al., what does the Fortune 500 enterprise software company specialize in?",The company specializes in providing business process software for small and medium-sized U.S. businesses.,"You are correct. The text focuses on machine learning, its application in management decisions, and the challenges of implementing it within organizations. It does not contain any information about the specialization of Fortune 500 enterprise software companies.","Die Digitalisierung und datengetriebene Transformation ver√§ndern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen √ºber die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends ‚Äì ML bietet vielf√§ltige Ans√§tze, um Managemententscheidungen fundierter und effizienter zu gestalten. fundamental
die Strukturen dieser 
Organisation,
dieser Industrie sich ver√§ndern.
Sie werden nicht redundant
per se in dem Job, den sie 
haben,
weil ich in Academia Starter 
mehr
und mehr benutze und besser 
werde in
Starter und besser in
Starter oder Starter der 
Corporation dabei helfe,
ihr Starter Programm 
weiterzuentwickeln.
Man kann Starter genau wie Exit 
nat√ºrlich
auch als General Purpose 
Technologie sehen.
Aber diese Systeme sind nicht 
selbst lernend.
Sie verbessern sich nicht von 
alleine
durch ihre Nutzung und das 
Wissen,
was ich reinfide,
ist generell nicht erstmal f√ºr 
sie relevant. 23. Juli 2025
MachineLearning f√ºr Management Entscheidungen (MLME)Lecture11Prof. Dr. Kevin BauerLehrstuhl f√ºr Spieltheoretische und Kausale K√ºnstliche Intelligenz 8. Mai 2025
MachineLearning f√ºr Management Entscheidungen (MLME)Lecture2Prof. Dr. Kevin BauerLehrstuhl f√ºr Spieltheoretische und Kausale K√ºnstliche Intelligenz wichtig zu verstehen.
Auf der einen Seite wurde 
argumentiert,
ob meine Mitarbeiter in
meinem Unternehmen eine 
Technologie,
die ich bereitstelle,
benutzen und das gilt auch 
grunds√§tzlich f√ºr Kunden
mit ein paar Abwandlungen ist,
ob es sogenannte Facilitating 
conditions gibt.
Habe ich einen Hilfscenter,
habe ich in meiner Organisation 
ein einen Lehrgang,
nenne ich es jetzt einfach mal
for lack of a better world,
wo mir beigebracht wird,
wie ich mit dem System 
interagiere.
Habe ich einen IQ, habe ich 
Gruppen Arbeitsgruppen,
die sich mit dem System 
besch√§ftigen,
habe ich die M√∂glichkeit, sehen wir wieder dieses Paradox,
was sich aufl√∂st dann, wenn wir 
sagen Naja.
Viele Unternehmen, die
schmei√üen zwar viel Technologie 
rein,
aber mehr machen sie nicht.
Sie geben einfach ihren 
Mitarbeitern Access zu GPT,
ohne zu sagen, wie sie es nutzen 
sollen,
ohne die Prozesse zu ver√§ndern,
ohne komplement√§re Investments 
in
die Infrastruktur zu t√§tigen. 
Fragen dazu.
So der Wert von Predictions.
Wenn wir es ein bisschen 
hochbrechen,
haben wir hier, was die 
Unternehmen
alles schon machen sollten.
Also Daten sammeln √ºber die 
letzten
Jahre deskriptive Analysen 
machen,
verstehen, was eigentlich im",6.576824903,0,The provided context discusses general machine learning principles and the J-curve phenomenon but contains no specific information about the 'Fortune 500 enterprise software company' mentioned in the question.,1,The generated answer is faithful to the context. The context discusses machine learning and its implementation but contains no information about the specialization of a Fortune 500 enterprise software company.,0,"The generated answer incorrectly states that the text does not contain the information, while the ground truth provides the specific answer about the company's specialization.",,
"According to the document, what is the economic decision rule for an investor?","'Invest'¬† if¬† p ‚ãÖU (15,15)+ (1‚àíp) ‚ãÖ U(0,20) ‚â•U (10,0). 'Not invest' otherwise.","According to the document, the economic decision rule for an investor is:

‚ÄúInvest‚Äù iff ‚Äúùëù‚ãÖùëà15,15+1‚àíùëù‚ãÖùëà0,20‚â•ùëà(10,0)‚Äù ‚ÄúNot invest‚Äù otherwise.

Where:

*   ùëù = the probability that the borrower would make a re-transfer
*   ùëà15,15+1 = utility of investing 15 million ‚Ç¨
*   ùëà0,20 = utility of not investing 0 ‚Ç¨
*   ùëà(10,0) = a baseline utility value","8. Mai 2025
Data driven decision-makingWhat you implicitly did (probably) are two parts:‚Ä¢Compared how they feel about certain outcomes‚Ä¢Assigned a probability ùëù that the borrower would make a re-transfer Choose the strategy that maximizes your ‚Äûutility‚Äú (whatever this is)Economic decision rule for investor: ‚ÄûInvest‚Äú  iff  ùëù‚ãÖùëà15,15+1‚àíùëù‚ãÖùëà0,20‚â•ùëà(10,0)  ‚ÄûNot invest‚Äú otherwise
12
Investor: 15 mil ‚Ç¨Startup : 15 mil ‚Ç¨Invest 10 mil ‚Ç¨You(the investor)
Not invest 0 ‚Ç¨
StartupWork hard and pay back
Work a little and run away with moneyInvestor: 0 ‚Ç¨Startup : 20 mil ‚Ç¨
Investor: 10 mil ‚Ç¨Startup : 0 mil ‚Ç¨ 8. Mai 2025
Data driven decision-making: an exampleConsider the following economic transaction
11
Investor: 15 mil ‚Ç¨Startup : 15 mil ‚Ç¨Invest 10 mil ‚Ç¨You(the investor)
Not invest 0 ‚Ç¨
StartupWork hard and pay back
Work a little and run away with moneyInvestor: 0 ‚Ç¨Startup: 20 mil ‚Ç¨
Investor: 10 mil ‚Ç¨Startup: 0 ‚Ç¨
What would you do, and why? Journal of the Association for Information Systems 
 
810 
The investment game captures the structure inherent in 
many transactions occurring in environments where 
contracts cannot be perfectly enforced (Fehr et al., 
1993; Brown et al., 2004). The investor must form 
beliefs about the borrower ‚Äôs trustworthiness, 
specifically whether the borrower will make a 
repayment. In the absence of sufficient trust, the 
investor retains the  funds, foregoing a potentially 
beneficial transaction. This mechanism is mirrored in 
business contexts, such as bankers deciding upon loan decision with that of the investor. For instance, if a 
participant expressed an intention to repay if the investor 
made an investment, and the investor participant indeed 
decided to invest, the game would lead to the socially 
optimal investment-repayment outcome 2  (see, e.g., 
Fischbacher et al., 2012, for the empirical validity of this 
strategy method approach). We employ ed the data 
collected in Study A for two purposes. First, we used it to 
train an ML model that predicts whether a borrower will 
repay based on 10 personal characteristics.3 We introduced as the ‚Äúinvestor.‚Äù Borrower decisions are based on real 
human decisions from a nother prior empirical study 
(Study A, see below for more details) where we used 
the strategy method to measure participants ‚Äô choices 
assuming the investor initially made the investment. 
That is, we kn ew whether each individual borrower 
would or would not make a repayment if an investor 
were to initially invest 10 MU with them. Importantly, 
due to the strategy method , we kn ew the borrower ‚Äôs 
conditional repayment decision regardless of the actual 
investor decision, i.e., we kn ew counterfactual conditional repayment decision regardless of the actual 
investor decision, i.e., we kn ew counterfactual 
outcomes. Game outcomes were determined by pairing 
a simulated investor decision with the borrower ‚Äôs 
actual conditional decision. 
Where do the ML system, selective labels problem, 
and continuous updating come into play? There are 
two pertinent aspects of the investment game. First, 
investors make initial decisions under uncertainty and 
form beliefs about the likelihood of borrowers making 
a repayment. Here, an ML  model prediction can 
decrease information asymmetries (Agrawal et al.,",11.36333489,1,"The context directly provides the economic decision rule in the exact format required, stating the investor should 'Invest' iff 'p ‚ãÖU (15,15)+ (1‚àíp) ‚ãÖ U(0,20) ‚â•U (10,0)' and 'Not invest' otherwise[cite: 1601].",1,"All claims in the generated answer are directly and completely supported by the provided context, which explicitly states the economic decision rule for the investor, including the formula and the variables involved [1599-1600].",1,"The generated answer and the ground truth provide the same economic decision rule, making them identical.",,
"According to the document, what are two phases of a productivity pattern that emerge when a General-Purpose Technology diffuses?",A short-run dip and a long-run rebound.,"According to the document, the two phases of a productivity pattern that emerge when a General-Purpose Technology diffuses are:

1.  **Initially, the productivity goes down.**
2.  **Long-run rebound as productivity accelerates once complements are in place.**

This is described as an ‚ÄúJ-Curve‚Äù pattern.","8. Mai 2025
Expect a J-Curve
J-Curve: two-phase productivity pattern that emerges when a GePuTdiffuses‚Ä¢Short-run dipas measured productivity falls or stalls‚Ä¢Heavy up-front investmentin data, skills, process redesign, and complementary tech‚Ä¢Intangible assets (software, know-how) rise, but are poorly captured in standard measures‚Ä¢Resources diverted from current production to capability-building (output forgone)‚Ä¢Long-run rebound as productivity accelerates once complements are in place‚Ä¢Learning effects, scale economies, and network externalities kick in‚Ä¢Complementary investments start paying off measurably8 erstmal die Produktivit√§t runter 
geht.
Wir sind sozusagen an der 
unteren dieser Kurve,
diesem unteren Halbkreis von dem 
J.
Und erst danach geht es 
eigentlich nach oben.
Wir haben eine massiven 
Produktivit√§t.
Das ist wie gesagt der die
Ver√§nderung wir sehen hier ist 
erstmal runtergeht,
dann geht steil nach oben und 
das ist ein Ph√§nomen,
was wir diese Kurve nennen.
Und das sehen wir immer wieder 
mit
verschiedenen General purpose 
technology.
Und das hat ganz einfache 
Gr√ºnde, n√§mlich,
dass am Anfang,
wenn wir in diese Technologien 
investieren,
wie in GPT investiert wird,
haben wir erstmal riesige weitere Innovationen.
Wir reden √ºber General Purpose 
Technologien,
komplement√§re Investitionen 
anzuregen.
Und das f√ºhrt nat√ºrlich dazu, 
dass viele Ressourcen,
die eigentlich vielleicht auf 
der Produktivit√§t
per se gelegen haben,
abgezogen werden und in
diese Produktivit√§tssteigerung 
investiert werden.
Und damit haben wir immer so ein 
bisschen.
Wir brauchen erstmal viel Zeit
und sollten nicht zu ungeduldig 
sein,
bis wir die Effekte dieser
neuen Technologie wirklich 
sehen.
Ich habe ihn letztes
Mal schon gesagt der gro√üe 
Missglauben
bei vielen Unternehmen ist 
weiterhin Ich nehme ei, haben uns √ºberlegt, aus einer 
√∂konomischen Perspektive,
was Prediction bedeuten k√∂nnte,
wenn wir bei General Purpose 
Technologien gesprochen.
Wir haben dar√ºber gesprochen,
dass wir uns, wie
es bei so vielen General Purpose 
Technologien ist,
aktuell auf einen bestimmten 
Teil der Kurve,
die noch befinden,
die Kurve als die Darstellung, 
die fundamentale Idee,
dass wir nicht in gro√üe 
Technologie Investitionen habe,
dass sich die nicht sofort 
auszahlt.
Das ist immer so ein bisschen 
Verz√∂gerung gibt,
am Anfang sogar die marginale
Produktivit√§tsver√§nderungen 
negativ sein kann.
Das ist so dieser untere Problem,
dass ich nicht genau wei√ü,
was ist eigentlich der 
unterliegende
Trend? Hilft Ihnen das?
Cool. So General Purpose 
Technology,
Technology, Technology oder 
Technology? Eins von beiden.
Das ist eine Technologie,
die es uns √ºber alle m√∂glichen 
Industrien erlaubt,
diese massiven Kostenreduktion 
zu erfahren.
Eine Technologie, die nicht nur
in einer bestimmten Dom√§ne,
in einem bestimmten Bereich 
angewendet werden kann,
sondern eben in verschiedenen 
Sektoren.
Es wird √ºberall gebraucht.
Also General Purpose und
vorher war mal und ich finde den 
Namen furchtbar.
Aber um sie nicht zu verwirren, Anstiege in
der Produktion, in der 
Produktivit√§t.
Aber wir sehen es nicht 
grunds√§tzlich √ºberall.
In vielen Organisationen kostet 
bisher einfach nur Geld.
Und das ist ein Ph√§nomen,
das ist gar nicht neu.
Das nennen wir die Kurve.
Wie so ein J. Wie Sie hier sehen 
k√∂nnen,
wo wir bei der Einf√ºhrung der 
Technologie,
wenn wir hier die Jahre auf der 
Achse haben
und hier die Ver√§nderung in
der Produktivit√§t, dann sehen 
wir,
dass am Anfang bei vielen 
Technologien eigentlich
und das ist ein Average
erstmal die Produktivit√§t runter 
geht.
Wir sind sozusagen an der 
unteren dieser Kurve,
diesem unteren Halbkreis von dem",8.897307634,1,"The context explicitly describes the J-Curve as a two-phase pattern, including a ""Short-run dip as measured productivity falls or stalls"" and a ""Long-run rebound as productivity accelerates once complements are in place""[cite: 1617].",1,"All claims in the generated answer are directly supported by the provided context. The context describes the J-Curve as a ""two-phase productivity pattern"" that includes a ""Short-run dip"" and a ""Long-run rebound"".",1,"The generated answer and the ground truth are semantically equivalent, both describing the two phases as a short-term dip followed by a long-term rebound.",,
What is the date of the first lecture?,24. Apr 25,"The first lecture is on April 24, 2025.","24. April 2025
General informationLecture and tutorialLecture to introduce topics and cover theoryTutorial to work on applications (case studies & coding)Six tutorials by Charlotte Knickrehm How can you ask questions?Always ask questions on the runSend an e-mailOffice hours by appointmentWhat is expected of you?Prepare readingsIn class participation (lecture & tutorial)
20
This course is discussion-driven and relies a lot on your participation. 24. April 2025
Course material
The course‚Ä¢Is organized on OLAT (MLME); you need to register.‚Ä¢Material is in English because the majority ofthe central terminology is in English.
19Titel der Veranstaltung 24. April 2025
Any questions on course structure? decisions. We present the exact instructions given in 
these studies in Appendix B.1. 
Study A: At the onset of each semester, first -semester 
economics students from a large German university were 
recruited to participate in an ongoing field study. The study 
was conducted by a subset of this paper ‚Äôs authors and 
aimed to examine correlations between academic 
performance, personal characteristics, and behavioral 
measurements, including outcomes of sequential social 
dilemmas such as the investment game. The study, 
accessible via a link sent to students ‚Äô email addresses, 24. April 2025
Some textbooks (recommended but not obligatory)
21 Informationen zur Vorlesung: Gehalten am Do. 12:00 bis 16:00; w√∂chentlich vom 24.04.2025 bis 24.07.2025; Ort: H√∂rsaalzentrum Westend - HZ 12",3.845886469,1,"The context explicitly states the lecture schedule is ""w√∂chentlich vom 24.04.2025 bis 24.07.2025"" (weekly from 24.04.2025 to 24.07.2025)[cite: 1643]. The first date in this range is April 24, 2025.",1,"The generated answer is a direct and accurate statement based on the context, which provides the lecture schedule as ""w√∂chentlich vom 24.04.2025 bis 24.07.2025"" (weekly from April 24, 2025 to July 24, 2025) [1643].",1,The generated answer is identical to the ground truth.,,
What is the purpose of the tutorial sessions?,To work on applications (case studies & coding).,"The tutorial sessions are designed to work on applications, specifically through case studies and coding exercises. They aim to help students apply the knowledge they've gained, even without prior programming experience.","24. April 2025
General informationLecture and tutorialLecture to introduce topics and cover theoryTutorial to work on applications (case studies & coding)Six tutorials by Charlotte Knickrehm How can you ask questions?Always ask questions on the runSend an e-mailOffice hours by appointmentWhat is expected of you?Prepare readingsIn class participation (lecture & tutorial)
20
This course is discussion-driven and relies a lot on your participation. Im Rahmen der Veranstaltung werden zahlreiche Praxisbeispiele und Fallstudien aus verschiedenen Industrien behandelt, die die Anwendung von ML und generativer KI im gesch√§ftlichen Kontext beleuchten. Insbesondere in den angebotenen √úbungen und praktischen Programmieraufgaben lernen Studierende, das erlangte Wissen anzuwenden, auch ohne vorherige Programmiererfahrung. 23. Juli 2025
Clear & Specific
10
Before prompting‚Ä¢understand the context and the task you use the LLM for‚Ä¢think about what you want to achieveEffective prompts‚Ä¢clearly define objectives‚Ä¢feature direct and specific instructions‚Ä¢Give context‚Ä¢separate inputs and instructions consistently‚Ä¢Break up complex sentences Ein besonderer Fokus des Kurses liegt auf praxisnahen √úbungen: Mithilfe der Programmiersprache Python werden die Teilnehmer Schritt f√ºr Schritt an die Umsetzung von ML-Projekten herangef√ºhrt. Alle Programmier√ºbungen sind so gestaltet, dass sie auch ohne Vorkenntnisse l√∂sbar sind, und die Studierenden erhalten die notwendige Unterst√ºtzung, um die Inhalte erfolgreich umzusetzen. Ziel ist es, ein solides Verst√§ndnis f√ºr ML-Tools zu entwickeln und deren Nutzen f√ºr Managemententscheidungen zu erkennen. allererste Vorlesung,
wo wir gesagt haben,
dass es nie um einen Selbstzweck 
geht,
sondern Machine Learning immer
eigentlich dazu dienen soll,
bestimmte Entscheidungen zu 
verbessern,
m√∂glicherweise auch ganz neue
Entscheidungssituationen 
herbeizuf√ºhren,
die ich vorher h√§tte nicht 
treffen k√∂nnen,
weil einfach zu viel 
Unsicherheit besteht.
Und dieser Bottom up Approach 
besagt Wir nehmen
uns den gesamten Workflow,
wir teilen den Workflow in 
einzelne
Tasks auf, wir die Composen.
Diesen gesamten Workflow gehen 
in
einem bestimmten Tasks in
ihrem Ablauf hinein und 
versuchen zu identifizieren,
an welcher Stelle eben wichtig zu verstehen.
Auf der einen Seite wurde 
argumentiert,
ob meine Mitarbeiter in
meinem Unternehmen eine 
Technologie,
die ich bereitstelle,
benutzen und das gilt auch 
grunds√§tzlich f√ºr Kunden
mit ein paar Abwandlungen ist,
ob es sogenannte Facilitating 
conditions gibt.
Habe ich einen Hilfscenter,
habe ich in meiner Organisation 
ein einen Lehrgang,
nenne ich es jetzt einfach mal
for lack of a better world,
wo mir beigebracht wird,
wie ich mit dem System 
interagiere.
Habe ich einen IQ, habe ich 
Gruppen Arbeitsgruppen,
die sich mit dem System 
besch√§ftigen,
habe ich die M√∂glichkeit,",5.433653593,1,"The context explicitly states that the purpose of the tutorial is to ""work on applications (case studies & coding)"" [cite: 1645] and that it involves ""praktischen Programmieraufgaben"" (practical programming tasks)[cite: 1647].",1,"All claims in the generated answer are directly supported by the context. The context states that the tutorial is to ""work on applications (case studies & coding)"" [1644] and that students will learn to apply their knowledge through practical programming exercises, even without prior experience [1644].",1,The generated answer is semantically identical to the ground truth.,,
"According to the document, what is a Class 2 customer?",A Profitable customer.,"The document does not define or mention ""Class 2 customer.""","integration. The experience highlighted the crucial role 
of early, clear communication on data needs and the 
value of combining academic and business approaches 
to enrich data analysis and consumer insights. For further 
details on the implementation, see Online Appendix A.3.
3.2. Results
In our field experiment, we analyze results in two parts: 
first, the impact of green nudging on key business 
metrics and second, the mechanism underlying the 
effect on customer product returns. Importantly, our 
analyses comprise all customers who viewed their 
shopping cart at least once, even if they did not make a analyses comprise all customers who viewed their 
shopping cart at least once, even if they did not make a 
Figure 1. (Color online) Elements of Green Nudging 
Notes. The prompt appears when consumers check their carts, whereas the reminder is shown after payment. The dual nudge comprises both 
elements, and the single nudge consists of only the reminder after payment.
Table 1. Outcomes Captured in the Field Experiment for Individual Customers
Outcome Type Description
Returns (shipment) Binary 1 if the customer has returned at least one product, 0 otherwise ness partner gained valuable insights into academic 
research, appreciating the depth and rigor that this 
approach adds to refining marketing strategies. For fur -
ther details on the design process and the considera -
tions made at this point, see Online Appendix A.1.
3.1.2. Treatments. Figure 1 illustrates the timing and 
appearance of our two green nudge elements. In our 
main treatment specification (dual nudge), customers 
observe both design elements throughout their shop -
ping journey. Specifically, when they first visit their 
cart, the cart prompt appears, and after they finish their ping journey. Specifically, when they first visit their 
cart, the cart prompt appears, and after they finish their 
payment, the reminder prompt appears.
To better understand the idiosyncratic impact of the 
two design elements, we further implemented a single- 
nudge treatment condition where customers only 
observe the reminder prompt. By doing so, we can 
explore whether the mere postpurchase intervention, 
which by definition, cannot affect the purchase behav -
ior as such, would suffice to curtail product returns.
Notably, the academic team members initially aimed wichtig zu verstehen.
Auf der einen Seite wurde 
argumentiert,
ob meine Mitarbeiter in
meinem Unternehmen eine 
Technologie,
die ich bereitstelle,
benutzen und das gilt auch 
grunds√§tzlich f√ºr Kunden
mit ein paar Abwandlungen ist,
ob es sogenannte Facilitating 
conditions gibt.
Habe ich einen Hilfscenter,
habe ich in meiner Organisation 
ein einen Lehrgang,
nenne ich es jetzt einfach mal
for lack of a better world,
wo mir beigebracht wird,
wie ich mit dem System 
interagiere.
Habe ich einen IQ, habe ich 
Gruppen Arbeitsgruppen,
die sich mit dem System 
besch√§ftigen,
habe ich die M√∂glichkeit, 24. April 2025
Data to characterize customers
30
Initial cartBrowsing""Digital footprint"" (Berg et al. 2020)‚Ä¢Cart value‚Ä¢# of products‚Ä¢# of eco-friendly products‚Ä¢# of duplicate products
‚Ä¢Visited category ""Women""‚Ä¢Visited category ""Kids""‚Ä¢Visited category ""Sale""‚Ä¢Visited category ""Sport""‚Ä¢Visit during working hours
‚Ä¢Operating system‚Ä¢Internet Browser‚Ä¢Internet Provider‚Ä¢State (IP geolocation)",4.320397377,0,"The context discusses green nudging, customer returns, and data used to characterize customers[cite: 1660, 1674], but it does not define or mention a 'Class 2 customer'.",1,"The generated answer is faithful because it correctly states that the provided context does not contain a definition for ""Class 2 customer"".",0,"The generated answer incorrectly states that the document does not mention or define a 'Class 2 customer', while the ground truth provides a specific definition ('A Profitable customer').",,
What companies were mentioned as having faced discrimination and harassment allegations in 2020?,"Amazon, McDonald‚Äôs, and Pinterest.",You are correct. The document does not mention any companies that faced discrimination and harassment allegations in 2020.,"Discrimination theory. Discrimination in the labor market is
deÔ¨Åned by the ILO‚Äôs Convention 111, which encompasses any
unfavorable treatment based on race, ethnicity, color, and gender
that undermines employment equality (Ruwanpura, 2008).
Economist Samuelson (1952) offers a similar deÔ¨Ånition, indicat-
ing that discrimination involves differential treatment based on
personal characteristics, such as ethnic origin, gender, skin color,
and age.
Various perspectives on the causes and manifestations of
discrimination can be broadly categorized into four theoretical discrimination by machines, including technical and non-
technical approaches.
Recommendations for future studies
This study conducted a literature review to analyze algorithmic
recruitment discrimination‚Äôs causes, types, and solutions. Future
research on algorithmic recruitment discrimination could explore
quantitative analysis or experimental methods across different
countries and cultures. Additionally, future studies could examine
the mechanics of algorithmic recruitment and the technical rules
that impact the hiring process. It would be interesting to analyze the hiring process. We conducted a thorough review of 49 papers
published between 2007 and 2023 and found that there is cur-
rently a fragmented understanding of discrimination in algo-
rithmic hiring. Building on this literature review, our study aims
to offer a comprehensive and systematic examination of the
sources, categorization, and possible solutions for discriminatory
practices in algorithmic recruitment.
Thirdly, we take a comprehensive approach that considers
technical and managerial aspects to tackle discrimination in
algorithmic hiring. This study contends that resolving algorithmic quently, the issue of algorithmic hiring discrimination has
emerged, shifting the focus of statistical discrimination theory
from traditional hiring to intelligent hiring. The mechanisms that
give rise to hiring discrimination problems remain similar, as
both rely on historical data of speciÔ¨Åc populations to predict
future hiring outcomes.
While AI recruiting offers numerous bene Ô¨Åts, it is also
susceptible to algorithmic bias. Algorithmic bias refers to the
systematic and replicable errors in computer systems that lead to
unequally and discrimination based on legally protected char- that nonobjective variables, such as inadequate information,
contribute to biased outcomes (Dickinson and Oaxaca, 2009).
Lastly, we have the antecedent market discrimination hypothesis
as the fourth category.
Statistical discrimination theory. Statistical discrimination refers
to prejudice from assessment criteria that generalize group
characteristics to individuals (Tilcsik, 2021). It arises due to
limitations in employers‚Äôresearch techniques or the cost con-
straint of obtaining information in the asymmetry between
employers and job seekers. Even without monopolistic power, Various perspectives on the causes and manifestations of
discrimination can be broadly categorized into four theoretical
groups. TheÔ¨Årst is the competitive market theory, which explains
discriminatory practices within an equilibrium of perfect
competition (Lundberg and Startz, 1983). This view attributes
discrimination primarily to personal prejudice. The second is the
monopoly model of discrimination, which posits that mono-
polistic power leads to discriminatory behavior (Cain,1986). The
third is the statistical theory of discrimination, which suggests
that nonobjective variables, such as inadequate information,",5.235814333,0,"The context discusses various aspects of discrimination in hiring and recruitment algorithms but does not mention Amazon, McDonald's, or Pinterest, nor does it refer to allegations from the year 2020.",1,"The generated answer is faithful because the provided context, which discusses discrimination theory in hiring, does not mention any of the listed companies or allegations from 2020.",0,"The generated answer incorrectly states that the document does not mention any companies, while the ground truth provides a specific list: Amazon, McDonald‚Äôs, and Pinterest.",,
What is the URL for the document by Cowgill and Tucker (2019)?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3361280,The URL for the document by Chandy et al. (2021) is: https://aisel.aisnet.org/jais/vol25/iss4/9,"Informationen zur Vorlesung: Gehalten am Do. 12:00 bis 16:00; w√∂chentlich vom 24.04.2025 bis 24.07.2025; Ort: H√∂rsaalzentrum Westend - HZ 12 Chandy et al. 2021 ) in a digital setting.
The rest of the paper is structured as follows. Section 
2 provides the theoretical background by reviewing 
related literature. Section 3 presents the setting and 
results of our randomized field experiment. Section 4
details the configuration and results from our causal 
machine learning model, along with the evaluation of 
smart green nudging. Section 5 concludes by discuss -
ing the practical implications of our work, its limita -
tions, and potential avenues for future research.
2. Related Literature
Our work relates to three streams of literature, namely DOI: 10.17705/1jais.00853 
Available at: https://aisel.aisnet.org/jais/vol25/iss4/9 
This material is brought to you by the AIS Journals at AIS Electronic Library (AISeL). It has been accepted for 
inclusion in Journal of the Association for Information Systems by an authorized administrator of AIS Electronic 
Library (AISeL). For more information, please contact elibrary@aisnet.org. ness partner gained valuable insights into academic 
research, appreciating the depth and rigor that this 
approach adds to refining marketing strategies. For fur -
ther details on the design process and the considera -
tions made at this point, see Online Appendix A.1.
3.1.2. Treatments. Figure 1 illustrates the timing and 
appearance of our two green nudge elements. In our 
main treatment specification (dual nudge), customers 
observe both design elements throughout their shop -
ping journey. Specifically, when they first visit their 
cart, the cart prompt appears, and after they finish their work as ‚ÄúMarketing Science. Copyright ¬© 2024 The Author(s). https:/ /doi.org/10.1287/mksc.2022. 
0393, used under a Creative Commons Attribution License: https:/ /creativecommons.org/licenses/ 
by-nc-nd/4.0/.‚Äù 
Funding: Partial financial support was received from the Leibniz Institute for Financial Research SAFE 
and the Deutsche Forschungsgemeinschaft [Grant 449023539]. 
Supplemental Material: The online appendix and data files are available at https:/ /doi.org/10.1287/mksc. 
2022.0393. 
Keywords: electronic commerce ‚Ä¢ nudging ‚Ä¢ causal forest ‚Ä¢ digital footprint ‚Ä¢ consumer returns ‚Ä¢ artificial intelligence This article was downloaded by: [141.2.113.143] On: 24 April 2025, At: 02:36
Publisher: Institute for Operations Research and the Management Sciences (INFORMS)
INFORMS is located in Maryland, USA
Marketing Science
Publication details, including instructions for authors and subscription information:
http://pubsonline.informs.org
Smart Green Nudging: Reducing Product Returns
Through Digital Footprints and Causal Machine
Learning
Moritz von Zahn, Kevin Bauer, Cristina Mihale-Wilson, Johanna Jagow, Maximilian
Speicher, Oliver Hinz
To cite this article:",6.106733322,0.3,"The question asks for the URL for a document by Cowgill and Tucker (2019), but the provided context gives URLs for documents by Chandy et al. (2021) [cite: 1702] and a marketing science paper[cite: 1709]. It does not contain the requested URL.",0,"The generated answer is not faithful. The question asks for the URL for a document by Cowgill and Tucker (2019), but the generation provides the URL for a different document by Chandy et al. (2021) [1702].",0,"The generated answer provides the incorrect URL, while the ground truth provides the correct one.",,
"In the 'Feedback Loops in Machine Learning' study, what did the authors note about the batch learning methodology?",This technique retrains the learning algorithm on all the currently available training data.,"The provided text doesn't detail any specific observations about batch learning methodology within the ""Feedback Loops in Machine Learning"" study. It primarily discusses concepts like data drift, concept drift, and updating models with new data through retraining or incremental learning procedures.","Feedback Loops in Machine Learning 
 
805 
generate predictions (Parisi et al., 2019). However, in 
dynamic, nonstationary environments, the underlying 
data-generating process that ML models aim to 
approximate can change over time. This phenomenon, 
referred to as drift (Lu et al., 2018), can lead to  
progressively poorer predictions. The decrease in 
prediction performance can originate from changes in 
the underlying relationship between the input features 
and the target variable ‚Äîconcept drift (Widmer & 
Kubat, 1996)‚Äîor changes in the distributions of t he 15. Mai 2025
(Unwanted) feedback loops
A core benefit of machine learning: continued learning‚Ä¢Tackles data drift issues ‚Ä¢Update model using newly collected data regularly‚Ä¢Retraining v. incremental learning proceduresHowever, ML predictions influence decisions‚Ä¢Selective labels problems(Lakkarajuet al. 2017)‚Ä¢Can endogenize dataavailable for updates19
DataML ModelPredictionDecision
Feedback Feedback Loops in Machine Learning 
 
817 
Despite this result, the left panel in Figure 5 indicates 
that continuous updating could not entirely restore 
economic efficiency to the level it would have attained 
in the absence of initial label imbalances in the training 
data. Nevertheless, our findings underscore significant 
and noteworthy improvements in economic efficiency 
concerning female borrowers. For male borrowers, the 
development of both economic efficiency measures was 
nearly identical, regardless of the presence or absence of 
initial label imbalances for women in the training data. Feedback Loops in Machine Learning 
 
811 
3.2 Previous Empirical Studies 
We buil t our simulations on two secondary datasets, 
collected by several authors of this paper as part of 
different empirical studies. Study A was an incentivized 
field study conducted over three years from 2016 to 
2019. Study A measured participant s‚Äô behavior in the 
investment game  defined above  in their  role as 
borrowers. The data from Study A allow ed us to 
develop an ML model predicting borrowers‚Äô repayment 
decision and serves as the foundation for simulating 
borrower behavior. Study B, conducted in December Feedback Loops in Machine Learning 
 
859 
Appendix C: Technical Details on Simulation 
C.1 Details on the Repayment-Predicting ML Model in Simulations 
To gain insights into the determinants of the predictions of the ML model that aims to forecast whether borrowers will 
make a repayment, we use the popular SHAP (Shapley additive explanations) explainability method (Lundberg & Lee, 
2017). Notably, we show results for the models ‚Äô behaviors before any updating takes place. SHAP is inspired by 
cooperative game theory explaining individual predictions by assuming that each feature value of the instance is a Feedback Loops in Machine Learning 
 
829 
in an algorithm used to manage the health of 
populations. Science, 366(6464), 447-453.  
Oliphant, T. E. (2006). A guide to NumPy . Trelgol 
Publishing. 
O‚ÄôNeil, C. (2017). Weapons of math destruction: How 
big data increases inequality and threatens 
democracy. Crown.  
Pedregosa, F., Varoquaux, G., Gramfort , A., Michel, 
V., Thirion, B., Grisel, O., Blondel, M., 
Prettenhofer, P., Weiss, R., Dubourg, V., 
Vanderplas, J., Passos, A., Cournapeau, D., 
Brucher, M., Perrot, M., & Duchesnay, E. 
(2011). Scikit -learn: Machine learning in 
Python. Journal of Machine Learning",6.995356321,0.2,"The context discusses related concepts such as model updating, data drift, and the difference between retraining and incremental learning procedures[cite: 1712], but it does not specifically state what the authors noted about the ""batch learning methodology"" itself.",1,The generated answer is faithful because it accurately reports that the provided context does not contain specific notes from the authors about the batch learning methodology. The context mentions related terms but does not offer the authors' observations on the methodology itself.,0,"The generated answer incorrectly claims the text doesn't detail the observations about batch learning, while the ground truth states the specific note that the technique retrains the algorithm on all currently available data.",,
"According to the document, what is one practical implication for organizations regarding continuously updated ML models?",Organizations should invest in comprehensive anti-discrimination and unconscious bias training for their decision makers.,"According to the document, one practical implication for organizations is that they should consider developing guidelines and protocols for their decision-makers that explicitly detail how to interact with ML models and their predictions.","Initiatives like these could be instrumental in creating 
an awareness of biases, reducing their influence on 
human decision -making and, consequently, on 
continuously updated ML models. In addition, 
organizations should consider developing guidelines 
and protocols for their decision  makers that explicitly 
detail how to interact with ML models and their 
predictions. Furthermore, our results highlight 
additional technical benefits of organizational policies 
and procedures that emphasize the importance of 
diversity and inclusiveness. The se may help mitigate continuously updated ML models demonstrate desirable 
behaviors when organizations implement regulatory 
requirements that involve humans in the decision loop. 
5.4 Limitations and Future Research  
Like any study, this study also has limitations‚Äîwhich, 
we believe , provide valuable directions for future 
research to enhance our understanding of how 
algorithmic discrimination evolves in environments 
where ML models undergo continuous updates. One temporal progression and economic implications of 
algorithmic discrimination in scenarios involving 
continuous ML model updating, an area lacking 
comprehensive empirical investigation (Kordzadeh & 
Ghasemaghaei, 2022). Grasping this dynamic is critical, 
as many ML models might degrade over time‚Äîdue, for 
example, to concept or data drifts, which respectively 
reflect fundamental shifts in the latent data -generating 
process and the distribution of incoming data (Lu et al., 
2018)‚Äînecessitating continuous updating based on 
newly collected data. We provide a more comprehensive operate and evolve. Our results suggest that continuous 
model updating could serve as a mechanism for 
mitigating bias in ML systems and might act as a force 
to supplement traditional data cleaning and debiasing 
efforts (Shrestha et al., 2019) to reduce discrimination 
risks. 
On the other hand, our simulations reveal that the 
positive impact of continuous updating on algorithmic 
discrimination (and economic efficiency) largely 
hinges on the sociotechnological environment, which 
includes the degree of the system ‚Äôs initial bias and, 
perhaps more importantly, the persistence of biased making over time. 
Result 2: The continuous updating of ML models loses 
its ability to mitigate algorithmic discrimination 
and improve economic efficiency when human 
decision makers who use ML predictions as 
decision support continue to discriminate against 
the minority class (female borrowers).  
5 Discussion and Conclusion 
5.1 Summary of Main Findings  
Drawing on extensive simulations, our paper 
demonstrates that the continuous updating of machine 
learning (ML) models, based on data they 
endogenously help generate, can enhance 
performance, alleviate algorithmic discrimination, and contemporary ML models. Theoretically, this self -
correction mechanism underscores the dynamic nature 
inherent to these models, adding a new dimension to 
the algorithmic fairness literature by shifting from 
static, one-time biases to a more temporal perspective: 
a comprehensive understanding of algorithmic 
discrimination and fairness must incorporate not just 
the initial conditions under which a model is trained, 
but also the dynamic environments where these models 
operate and evolve. Our results suggest that continuous 
model updating could serve as a mechanism for",5.752523422,1,"The context directly answers the question, stating that ""organizations should consider developing guidelines and protocols for their decision makers that explicitly detail how to interact with ML models and their predictions""[cite: 1729].",0.5,"The generated answer is an overstatement and not fully supported by the context. The context suggests organizations should consider developing guidelines for decision-makers on how to interact with ML models [1729]. It does not, however, explicitly state that they should invest in ""comprehensive anti-discrimination and unconscious bias training,"" which is a much more specific and stronger recommendation.",1,"The generated answer is semantically equivalent to the ground truth, as developing guidelines and protocols is a form of investing in training for decision makers.",,
"According to the document, what is one impact of human discrimination on the self-correction capabilities of continuously updated ML models?",It impedes the self-correction abilities.,"According to the document, persistent human discrimination significantly impedes the self-correcting abilities of continuously updated ML models. It can cause ML models, originally trained on balanced data, to exhibit increasingly discriminatory behavior over time, and the capacity for self-correction inversely depends on the degree of initial label imbalance.","indicates that persistent discrimination by humans ‚Äî
who make the final decisions in ML-supported tasks‚Äî
significantly impedes the self -correction abilities 
associated with the continuous updating of ML 
models. Our findings even suggest that ongoing human 
discrimination can lead ML models, originally trained 
on balanced data and demonstrating no algorithmic 
discrimination, to exhibit increasingly discriminatory 
behavior over time. 
5.2 Theoretical Contributions and 
Implications  
Our study responds to recent calls for empirical 
investigations into the sociotechnological nature of individuals engage in discriminatory practices and the 
models update continuously, there is a risk of 
unintentionally perpetuating or amplifying algorithmic 
discrimination, as human discrimination hinders the self-
correcting capacities of ML models. Therefore, in 
conjunction with these regulations, we advocate 
measures aimed at identifying and mitigating 
(subconscious) discriminatory practices by 
organizational decision makers. These measures could 
serve as essential complementary elements to ensure that 
continuously updated ML models demonstrate desirable 
behaviors when organizations implement regulatory dynamic consequences of continuously updating ML 
models in the presence of algorithmic and human 
discrimination. We highlight that continuous updating, 
absent enduring human discrimination, may stimulate  
self-correcting mechanisms. Theoretically, our findings 
underscore the sociotechnological nature of algorithmic 
discrimination. We extend the existing literature by 
revealing how algorithmic discrimination can diminish 
or emerge due to the interaction bet ween ML systems 
and human users in environments where continuous ly 
updating ML models is essential. We f ound evidence human discrimination (see Columns 4 and 5).  
In sum, these results emphasize that the capacity of 
continuous ML model updating to mitigate algorithmic 
discrimination critically relies on the absence of 
discriminatory behavior by human decision makers. If 
such behaviors persist ‚Äîpotentially giving rise to the 
initial label imbalance in the training data‚Äîcontinuous 
updating has a minimal effect on improving the ML 
model‚Äôs behavior toward the discriminated group. Our 
findings even suggest that human discrimination can 
cause ML models, originally trained on balanced data and endogenously help generate, can enhance 
performance, alleviate algorithmic discrimination, and 
boost the economic efficiency of ML models initially 
grappling with label imbalances in the original training 
dataset. The ability for self -correction inversely 
depends on the degree of initial label imbalance: the 
more biased the ML model ‚Äôs predictions are at the 
outset, the le ss capacity it has for recovery through 
continuous updating over time. Crucially, our research 
indicates that persistent discrimination by humans ‚Äî
who make the final decisions in ML-supported tasks‚Äî Journal of the Association for Information Systems 
 
824 
Indeed, self-correcting mechanisms may require time 
to take effect, during which disadvantaged social 
groups may continue to endure discriminatory 
practices. Rather, we perceive our findings as a 
testament to the substantial learning capabilities of 
modern ML models undergoing continuous updating. 
We argue that these capabilities can complement other 
interventions aimed at addressing algorithmic 
discrimination, such as the proper preprocessing of 
training data. This approach is particularly effective",7.661820889,1,"The context directly and repeatedly addresses the question. For example, it states that persistent discrimination by humans ""significantly impedes the self-correction abilities associated with the continuous updating of ML models"" [cite: 1742] and that human discrimination ""hinders the self-correcting capacities of ML models""[cite: 1744].",1,"All claims in the generated answer are directly supported by the context, which states that persistent human discrimination ""significantly impedes the self-correcting abilities"" of ML models [1741] and that the capacity for self-correction is inversely dependent on the initial label imbalance [1753].",1,The generated answer is semantically identical to the ground truth.,,
"According to the document, what is the approximate percentage point change in the share of positive predictions for female borrowers when there is no human discrimination and the maximum label imbalance is present?",22%,"According to the document, the approximate percentage point change in the share of positive predictions for female borrowers with no human discrimination and maximum label imbalance is +0.15 percentage points per iteration.","Figure 6. Development of the Mean Share of Positive Predictions and False-Negative Error Rates 
Figure 6 also shows that an increase in human 
discrimination undermines the reduction in false -
negative error rates for female borrowers over time. 
For instance, the lower two panels show that with a 
high initial label imbalance (x-axis), the false-negative 
error rate (y-axis) for female borrowers decreases from 
55.4% in Iteration 1 (left panel)  to 35.8% in Iteration 
100 (right panel)  if there is no human discrimination  
(z-axis). However, under very high human 
discrimination, this rate only drops to 52.2%  in borrowers (see Figure A7 in the Appendix), regardless of 
the initial label imbalance. For example, at maximum 
label imbalance, the positive predictions  for men 
minimally fluctuate, moving from 34.4% to 36.1% 
without human discrimination and to 33.8% with very 
high human discrimination (36.3% and 34.2% for high 
and medium levels of human discrimination, 
respectively). Our regression analyses (see Table A2 in 
the Appendix) statistically corroborate these findings. 
Regression estimates in Column (1) suggest that for an 
initially unbiased model under high and very high human perfect information benchmark (for female borrowers) is 
consistent across conditions (approx. +0.2 percentage 
points per iteration). However, the initial degree of 
economic efficiency diminishes with increasing label 
imbalance. Regarding the optimal investment with 
repaying female borrowers (Column 3), the positive time 
trend is higher in medium, high, and maximum label 
imbalance conditions (respectively +0.09, +0.13, +0.15 
percentage points) than in situations with low or no initial 
label imbalance (reference category). 
In summary, our findings highlight that the observed self- convergence of the dashed and solid line without 
markets, t his gender disparity in predictions of 
repayment, denoting discrimination according to 
 
13 Notably, we were only able to conduct this analysis because 
we observe d counterfactual borrower decisions; in other 
statistical parity, diminished over time with continuous 
ML model updates. After 100 iterations, the mean 
positive prediction share s for female and male 
borrowers were 22% and 36.1%, respectively. Despite 
this share  for female borrowers remaining 
considerably lower than in the control condition ( - this share  for female borrowers remaining 
considerably lower than in the control condition ( -
47.3%), ongoing updates of the ML model narrowed 
the gender gap by approximately two thirds. 
Regression results depicted in Table 1 statistically 
corroborate the se insights. In the context of our loan 
approval scenario, this suggests that continuous 
updating reduces initial inequality in predicted loan 
repayment of male and female applicants, thereby 
approaching statistical parity. Examining false -
negative error rates , 13  i.e., the share of incorrect 
predictions that a borrower will not make a repayment investor, ( 2) 10 observed characteristics of the 
borrower, and ( 3) a repayment forecast ‚Äîin total,  31 
features against a binary label (see the Appendix for 
more details). We exogenously var ied the 
discrimination of investors against female borrowers 
by successively elevating the probability threshold 
needed to establish if an investor would actually invest 
with a female borrower from 50% to 60%, 70%, and 
80%. We label these conditions as no, medium, high, 
and very high human discrimination, respectively. For 
instance, in the high human discrimination conditio n,",7.395253658,0.8,"The context states that after 100 iterations with no human discrimination, the mean positive prediction share for female borrowers was 22%[cite: 1767]. It also states that in the first iteration with maximum label imbalance, the share was effectively 0%. Therefore, the change is approximately 22 percentage points. The context contains all the necessary information to derive the answer.",0,"The generated answer is a hallucination. The context does not provide a figure of ""+0.15 percentage points per iteration."" It mentions that after 100 iterations, the mean positive prediction share for female borrowers was 22% [1767], but it does not give a per-iteration change rate.",1,The generated answer is identical to the ground truth.,,
"In the 'Feedback Loops in Machine Learning' study, what was the share of game outcomes matching the perfect information benchmark for female borrowers in the first iteration?",42.3%.,"According to the document, the share of game outcomes matching the perfect information benchmark for female borrowers in the first iteration was 42.3%.","in the first iteration were scarce (occurring in 5.7% of 
cases). In stark contrast, these percentages were 
significantly higher in our control condition, with 
values of 61.1% and 47.4% , respectively (see lines 
without markers in Iteration 1 in Panel ii). 
Importantly, indicated by the positive slope of dashed 
lines in Panel (i), continuous updating of the model led 
to substantial improvements in both economic 
efficiency measures for female borrowers over time. 
Specifically, over 100 iterations, the share of game 
outcomes matching the perfect information benchmark instance, a comparison of the upper two panels shows 
that when the initial label imbalance is at its maximum 
(x-axis), the share of game outcomes with female 
borrowers that match the perfect information 
benchmark (y-axis), grows from 42.3% In Iteration 1 
(left panel)  to 62.5% in Iteration 100 (right panel)  if 
there is no human discrimination ( z-axis). A similar 
comparison of the two panels at the bottom reveals that 
the share of investments with repaying borrowers also 
grows from 5.7% in Iteration 1 (left panel) to 34.9% in 
Iteration 100 (right panel). Specifically, over 100 iterations, the share of game 
outcomes matching the perfect information benchmark 
rose to 62.5%, almost a 50% increase. In the context of 
our loan approval example, the continuous updating of 
the ML model thus almost doubled the number of cases 
where loan officers made the decision they would have 
made if they could have foreseen the future, accurately 
identifying which applicants w ould default and which 
would not. The frequency of efficient investments in 
repaying female borrowers, i.e., investments that 
maximize social welfare, skyrocket ed almost seven - imbalance (see Panel ii) . Several crucial insights 
emerged. In the treatment condition,  we observe d a 
considerable negative effect on economic efficiency 
when the borrower was female, resulting from the 
initial label imbalance. As shown by the lines without 
markers in Panel (i), i n the first iteration, game 
outcomes matched the perfect information benchmark 
in only 42.3% of instances , in the case of a female  
borrower. Investments with repaying female borrowers 
in the first iteration were scarce (occurring in 5.7% of 
cases). In stark contrast, these percentages were We address this question using regression analyses 
reported in Table 1 (See Figures A1-A6 in the Appendix 
for a graphical illustration). Columns (1) and (2) use the 
gender gap in the ML model ‚Äôs share of positive 
predictions and false-negative error rates as dependent 
variables, respectively. Columns (3) and (4) use the 
share of game outcomes equivalent to the perfect 
information benchmark and the share of investments 
with repaying female borrowers as dependent variables, 
respectively.14 Independent variables comprise the time 
trend, dummy variables indicating the degree of initial perfect information benchmark (for female borrowers) is 
consistent across conditions (approx. +0.2 percentage 
points per iteration). However, the initial degree of 
economic efficiency diminishes with increasing label 
imbalance. Regarding the optimal investment with 
repaying female borrowers (Column 3), the positive time 
trend is higher in medium, high, and maximum label 
imbalance conditions (respectively +0.09, +0.13, +0.15 
percentage points) than in situations with low or no initial 
label imbalance (reference category). 
In summary, our findings highlight that the observed self-",6.203901291,1,"The context directly answers the question. It states that in the first iteration with initial label imbalance, ""game outcomes matched the perfect information benchmark in only 42.3% of instances, in the case of a female borrower""[cite: 1780].",1,"The generated answer is a direct statement that can be verified from the context, which states that in the first iteration, ""game outcomes matched the perfect information benchmark in only 42.3% of instances, in the case of a female borrower"" [1780].",1,The generated answer and the ground truth are identical.,,
"In the ""Feedback Loops in Machine Learning"" study, what type of model was utilized to predict whether an investment would occur in the investment game simulation?",A gradient boosted forest.,A trained ML model was utilized to predict whether an investment would occur. The specific type of model wasn‚Äôt detailed beyond it being an ‚ÄúML model‚Äù and it used the SHAP (Shapley additive explanations) method for explainability.,"Feedback Loops in Machine Learning 
 
811 
3.2 Previous Empirical Studies 
We buil t our simulations on two secondary datasets, 
collected by several authors of this paper as part of 
different empirical studies. Study A was an incentivized 
field study conducted over three years from 2016 to 
2019. Study A measured participant s‚Äô behavior in the 
investment game  defined above  in their  role as 
borrowers. The data from Study A allow ed us to 
develop an ML model predicting borrowers‚Äô repayment 
decision and serves as the foundation for simulating 
borrower behavior. Study B, conducted in December Feedback Loops in Machine Learning 
 
813 
Armed with this information, the investor decided 
whether to invest. Notably, in our simulation , we 
mimicked investor decisions using a trained model (see 
below for more information). If an investment was 
made, the borrower decided on repayment, and a new 
observation encapsulating a borrower‚Äôs specific 
personal traits (features) and actual repayment decision 
(label) was appended to the dataset used to train the ML 
model predicting repayment. 
Importantly, to avoid inappropriate overfitting and 
spillover effects, this observation was only included if investor choices, only once, right before the first 
iteration of a simulation commenced. 
The second random part of our Study B data populated 
our pool of investors for our simulation (303 unique 
participants from Study B), whose observations we 
excluded from the model‚Äôs training. Each investor was 
characterized by their 20 personal attributes, and their 
investment decisions for a specific borrower were 
simulated. When a certain investor from the pool was 
randomly selected in an iteration and paired with a 
borrower, the trained model predict ed whether an 
investment would occur. The prediction of the conditional repayment decision regardless of the actual 
investor decision, i.e., we kn ew counterfactual 
outcomes. Game outcomes were determined by pairing 
a simulated investor decision with the borrower ‚Äôs 
actual conditional decision. 
Where do the ML system, selective labels problem, 
and continuous updating come into play? There are 
two pertinent aspects of the investment game. First, 
investors make initial decisions under uncertainty and 
form beliefs about the likelihood of borrowers making 
a repayment. Here, an ML  model prediction can 
decrease information asymmetries (Agrawal et al., Feedback Loops in Machine Learning 
 
859 
Appendix C: Technical Details on Simulation 
C.1 Details on the Repayment-Predicting ML Model in Simulations 
To gain insights into the determinants of the predictions of the ML model that aims to forecast whether borrowers will 
make a repayment, we use the popular SHAP (Shapley additive explanations) explainability method (Lundberg & Lee, 
2017). Notably, we show results for the models ‚Äô behaviors before any updating takes place. SHAP is inspired by 
cooperative game theory explaining individual predictions by assuming that each feature value of the instance is a Our simulation employs a modified version of the 
investment game (Berg et al., 1995). This game 
emulates the incentives and informational structure 
inherent in numerous economic transactions that 
transpire in environments lacking robust enforcement 
mechanisms (Dufwenberg & Kirchsteiger, 2004; Feh r 
& Fischbacher, 2003). In our game, two participants, 
an investor and a borrower, each begin with an 
endowment of 10 monetary units (MU). The investor 
first chooses whether to retain or invest the entire 10 
MU with the borrower. If the investor retains the sum, 
the game ends and both parties keep their initial",7.74017024,0.5,"The context states that investor decisions were mimicked using a ""trained model"" [cite: 1791] and that this model's predictions were based on features of the borrower. While the ground truth answer 'gradient boosted forest' is a plausible type of ML model, the provided text does not explicitly name it for the investor prediction model, only for the borrower repayment model.",0,"The generated answer is not faithful. The context states that a trained ML model was used to mimic investor decisions [1791], but it does not specify the type of model. The context mentions a 'gradient boosted forest' in relation to predicting borrower repayment, not investor decisions.",0,"The generated answer is incorrect. It claims the model type wasn't detailed, while the ground truth specifies it was a gradient boosted forest.",,
What are some contexts in which algorithmic discrimination has been observed?,"Algorithmic discrimination has been observed in recidivism risk assessments, education, recruitment, predictive policing, health risk evaluations, targeted advertising, crowdlending scenarios, and facial recognition tasks.","According to the text, algorithmic discrimination has been observed in the following contexts:

*   **Recruitment processes:** Specifically concerning gender, race, color, and personality traits.
*   **Healthcare:** Where false negatives can have significant consequences.
*   **Loan approval processes**
*   **Hiring**
*   **Criminal justice systems**","discrimination (Favaretto et al., 2019; Kordzadeh & 
Ghasemaghaei, 2022). The social component often 
originates from societal and economic structural biases, 
which can foster the differential treatment and 
marginalization of certain groups. On the other hand, the 
technological element emanates from the perpetuated 
discriminatory behaviors of algorithmic systems. 
Algorithmic feedback loops: Feedback loops play a 
significant role in algorithmic discrimination in the 
context of continuously updated ML models. These loops 
arise when the outcomes of algorithmic decisions provide Despite algorithms aiming for objectivity and clarity in their
procedures, they can become biased when they receive partial
input data from humans. Modern algorithms may appear neutral
but can disproportionately harm protected class members, posing
the risk of‚Äúagentic discrimination‚Äù(Prince and Schwarcz,2019).
If mishandled, algorithms can exacerbate inequalities and
perpetuate discrimination against minority groups (Lloyd,2018).
Within the recruitment process, algorithmic bias can manifest
concerning gender, race, color, and personality.
Research methodology 2. The second theme is the causes of algorithmic discrimina-
tion. McFarland and McFarland (2015), Mayson (2018),
Raso et al. (2018), Raub (2018), Raghavan et al. (2020),
Njoto (2020), Zixun (2020), and Jackson (2021) suggest that
the reason for algorithmic discrimination is related to data
selection. Data collection tends to prefer accessible,‚Äúmain-
stream‚Äù organizations unequally dispersed by race and
gender. Inadequate data will screen out groups that have
been historically underrepresented in the recruitment
process. Predicting future hiring outcomes by observing work. However, algorithmic bias results in discriminatory hiring practices based on gender,
race, color, and personality traits. The study indicates that algorithmic bias stems from
limited raw data sets and biased algorithm designers. To mitigate this issue, it is recom-
mended to implement technical measures, such as unbiased dataset frameworks and
improved algorithmic transparency, as well as management measures like internal corporate
ethical governance and external oversight. Employing Grounded Theory, the study conducted
survey analysis to collectÔ¨Årsthand data on respondents‚Äô experiences and perceptions of AI- data already reÔ¨Çects social prejudices, and the algorithm also
incorporates biased relationships, leading to the‚Äúbias in and bias
out‚Äù phenomenon (36KE, 2020). This phenomenon means that
discrimination and disparities exist, just like in forecasting, where
historical inequalities are projected into the future and may even
be ampliÔ¨Åed (Mayson, 2018).
A research team at Princeton University discovered that
algorithms lack access to the absolute truth. The machine corpus
contains biases that closely resemble the implicit biases observed
in the human brain. ArtiÔ¨Åcial intelligence has the potential to relevant in situations where false negatives have 
significant consequences, such as in healthcare, loan 
approval, hiring, or criminal justice systems. 
Mitigating algorithmic discrimination : The 
expansive literature on algorithmic discrimination 
proposes various methods to identify and alleviate 
such biases. According to d ‚ÄôAlessandro et al. (2017), 
we can divide these mitigation strategies into three 
categories: pre -processing, in -processing, and post -
processing. Pre -processing strategies strive to 
eliminate disparities inherent in the dataset. Methods",7.894996881,1,"The context lists several areas where algorithmic bias manifests, including ""hiring practices based on gender, race, color, and personality traits"" [cite: 1819] and situations like ""healthcare, loan approval, hiring, or criminal justice systems""[cite: 1827]. This provides multiple examples that directly answer the question.",1,"The claims in the generated answer are directly supported by the context, which lists ""hiring practices based on gender, race, color, and personality traits"" [1806] and situations like ""healthcare,"" ""loan approval,"" ""hiring,"" and ""criminal justice systems"" [1807].",1,"The generated answer and the ground truth list the same set of contexts where algorithmic discrimination has been observed, making them semantically identical.",,
What is algorithmic discrimination?,Algorithmic discrimination refers to discriminatory hiring practices that arise from algorithmic bias.,"According to the text, algorithmic discrimination is:

‚ÄúDiscrimination involves statements or actions that unjustifiably disadvantage members of particular social groups. These actions typically stem from conscious or subconscious attitudes, prejudices, or emotional associations tied to characteristics such as gender, age, disability, race, language, religion, or sexual identity.‚Äù

More specifically, it arises when algorithms receive partial input data from humans and can disproportionately harm protected class members, posing the risk of ‚Äúagentic discrimination.‚Äù It‚Äôs caused by things like biased data sets and the historical presence of racial and gender prejudices within the algorithms themselves.","Feedback Loops in Machine Learning 
 
807 
2.1 Algorithmic Discrimination 
Algorithmic discrimination: Discrimination involves 
statements or actions that unjustifiably disadvantage 
members of particular social groups. These actions 
typically stem from conscious or subconscious attitudes, 
prejudices, or emotional associations tied to 
characteristics such as  gender, age, disability, race, 
language, religion, or sexual identity (Scherr, 2008). In 
today‚Äôs era, where algorithmic systems based on ML 
models frequently aid human decisions, researchers and 
practitioners often employ the te rm ‚Äúalgorithmic Despite algorithms aiming for objectivity and clarity in their
procedures, they can become biased when they receive partial
input data from humans. Modern algorithms may appear neutral
but can disproportionately harm protected class members, posing
the risk of‚Äúagentic discrimination‚Äù(Prince and Schwarcz,2019).
If mishandled, algorithms can exacerbate inequalities and
perpetuate discrimination against minority groups (Lloyd,2018).
Within the recruitment process, algorithmic bias can manifest
concerning gender, race, color, and personality.
Research methodology work. However, algorithmic bias results in discriminatory hiring practices based on gender,
race, color, and personality traits. The study indicates that algorithmic bias stems from
limited raw data sets and biased algorithm designers. To mitigate this issue, it is recom-
mended to implement technical measures, such as unbiased dataset frameworks and
improved algorithmic transparency, as well as management measures like internal corporate
ethical governance and external oversight. Employing Grounded Theory, the study conducted
survey analysis to collectÔ¨Årsthand data on respondents‚Äô experiences and perceptions of AI- 2. The second theme is the causes of algorithmic discrimina-
tion. McFarland and McFarland (2015), Mayson (2018),
Raso et al. (2018), Raub (2018), Raghavan et al. (2020),
Njoto (2020), Zixun (2020), and Jackson (2021) suggest that
the reason for algorithmic discrimination is related to data
selection. Data collection tends to prefer accessible,‚Äúmain-
stream‚Äù organizations unequally dispersed by race and
gender. Inadequate data will screen out groups that have
been historically underrepresented in the recruitment
process. Predicting future hiring outcomes by observing algorithm analyzes massive data patterns through data mining,
searching, and using ways to predict, like our point of view
encoded in the code. It explores the dataset using agents
representing various traits, such as race, sexual orientation, and
political opinions (Njoto, 2020). The algorithms frequently
contain these biases due to the lengthy history of racial and
gender prejudices, both intentional and unconscious. When
biases exist in algorithmic data, AI may replicate these prejudices
in its decision-making, a mistake known as algorithmic bias
(Jackson, 2021). ).
Theme II. Why is there algorithmic recruitment
discrimination
Algorithms are not inherently discriminatory, and engineers
rarely intentionally introduce bias into algorithms. However, bias
can still arise in algorithmic recruitment. This issue is closely
linked to the fundamental technology behind AI and ML. The ML
process can be simpliÔ¨Åed into several stages, each involving three
key components contributing to algorithmic bias: dataset con-
struction, the engineer‚Äôs target formulation, and feature selection
(36KE, 2020). When the dataset lacks diverse representation from",10.4082377,1,"The context provides a direct definition, stating that discrimination involves ""statements or actions that unjustifiably disadvantage members of particular social groups"" [cite: 1833] and that in the modern era, this is referred to as ""algorithmic discrimination"" when ML systems are involved.",1,"All claims in the generated answer are directly supported by the provided context. The context defines discrimination as actions that unjustifiably disadvantage social groups based on characteristics like gender, race, etc. [1831], and states that this can be caused by partial input from humans, leading to ‚Äúagentic discrimination‚Äù [1832].",0,"The generated answer provides a different and less precise definition than the ground truth. The ground truth specifies that the discrimination arises from algorithmic bias, a key detail missing from the generation.",,
"According to the document, what software was used as an auxiliary tool to clarify ideas and improve work efficiency?",Nvivo 12.0 Plus qualitative analysis software.,"The document doesn't explicitly state which software was used as an auxiliary tool. It mentions having an ""IQ"" (likely referring to an intelligence quotient assessment) and groups working on the system. It also references a ""Lehrgang"" (training course) for interacting with the system. However, it doesn't name a specific software application.","Mixed-initiative: let system decide when to automate, provide advice, or let human take over‚Ä¢Classic paper by Eric Horvitz from 1999 (Chief Scientific Officer, Microsoft)‚Ä¢Advocates elegant coupling of automation with direct manipulation by user‚Ä¢Autonomous actions should be taken only when a system infers that they will have greater expected valuethan inaction for the user.Assume a system can infer p(G|E): likelihood of user goal being G given evidence E‚Ä¢Decide whether to take actionA, based on the utility that action would have in achieving goal G ‚Ä¢rather than other possible outcomes (not-G) 12 zwangsl√§ufige Regel,
die Sie immer anwenden m√ºssen.
Es gibt Ihnen eher eine 
Blaupause, einen Denkansto√ü,
ob Sie diese verschiedenen 
Schritte Durchgegangen sind.
Hei√üt wenn jemand von Ihnen 
letztlich
Projektmanager f√ºr ein 
bestimmtes
Software KI 
Implementierungsprojekt
in einem Unternehmen ist,
dann ist es immer eine gute 
Struktur eines Modells,
an dem man sich lang hangeln 
kann, um zu checken,
ob man diese verschiedenen 
wichtigen Schritte
durchgedacht hat.
Wenn es um die Implementierung 
eines KI Projektes geht.
Und das Wichtige, was ich immer
wieder hervorheben m√∂chte, ist,
dass wir grunds√§tzlich damit in Unternehmen dazu,
die bereitgestellte Technologie 
zu nutzen?
Es gibt mittlerweile auch zwei
Erweiterungen von diesem Modell
oder auch ein paar mehr kleinere 
Erweiterungen noch,
die es dann mehr auf
die Konsumentenperspektive 
erweitert haben.
Aber das Grundmodell und das 
ist,
was ich Ihnen beibringen m√∂chte.
Und ich dachte eigentlich,
ich k√∂nnte es relativ schnell 
machen,
aber weil es so wichtig ist,
sprechen wir doch ein paar 
Minuten dr√ºber.
Dieses Grundmodell, das ist 
wichtig zu verstehen.
Auf der einen Seite wurde 
argumentiert,
ob meine Mitarbeiter in
meinem Unternehmen eine 
Technologie, wichtig zu verstehen.
Auf der einen Seite wurde 
argumentiert,
ob meine Mitarbeiter in
meinem Unternehmen eine 
Technologie,
die ich bereitstelle,
benutzen und das gilt auch 
grunds√§tzlich f√ºr Kunden
mit ein paar Abwandlungen ist,
ob es sogenannte Facilitating 
conditions gibt.
Habe ich einen Hilfscenter,
habe ich in meiner Organisation 
ein einen Lehrgang,
nenne ich es jetzt einfach mal
for lack of a better world,
wo mir beigebracht wird,
wie ich mit dem System 
interagiere.
Habe ich einen IQ, habe ich 
Gruppen Arbeitsgruppen,
die sich mit dem System 
besch√§ftigen,
habe ich die M√∂glichkeit, die Entscheidung,
ob wir im Automation oder 
Delegation,
im Automation oder Augmentation 
Setting sind,
auch an die Maschine ab.
Und er hat dann sehr intuitives,
sehr intuitiven, konzeptionellen 
Vorschlag gemacht,
wie wir dar√ºber nachdenken 
k√∂nnen.
Das ist jetzt auch wieder das 
Modelldenken,
was ich glaube sehr wichtig ist 
an Universit√§ten.
Gelernt werden sollte,
dass sie ein grundlegendes 
Schubladendenken haben,
wie sie √ºber solche Probleme 
nachdenken k√∂nnen,
ohne dass wir jetzt keine 
Ahnung.
Ich gebe Ihnen 20 Beispiele,
die m√ºssen Sie f√ºr die Klausur 
auswendig lernen,
sondern die fundamentale Idee, Zugriff hatten.
Wichtig hier sei darauf 
hingedeutet.
Erste Studien zeigen Das ist 
auch bei Experten.
Das sind alles Leute,
die neu angestellt wurden.
Da sehen wir diese massiven 
Produktivit√§tssteigerung.
Aber erste Studien zeigen,
dass das wohl nicht nur f√ºr 
Offices gilt,
sondern in Tasks wie Software 
Development
anscheinend insbesondere auch 
f√ºr Experten gilt,
so dass wir hier wieder so ein 
bisschen
Evidenz daf√ºr bekommen,
dass diese Technologie eventuell 
diese Schere
in der Produktivit√§t von 
Experten,
Leuten mit viel Humankapital
und mit geringem Humankapital 
ver√§ndert.
Letzter Punkt Auch die Kunden",8.847490311,0,The context discusses machine learning implementation and user interaction but does not mention or define the software 'Nvivo 12.0 Plus qualitative analysis software'.,0,The generated answer is a hallucination. The context makes no mention of 'Nvivo 12.0 Plus qualitative analysis software'. The claims about having an 'IQ' or a 'Lehrgang' (training course) are from unrelated parts of the context.,0,"The generated answer incorrectly states that the document doesn't specify the software, while the ground truth provides the specific name: Nvivo 12.0 Plus.",,
What was the result of Microsoft revising their dataset for training the Face API?,A 20-fold reduction in the recognition error ratio between men and women with darker skin tones.,"According to the text, Microsoft revising their dataset for training the Face API resulted in a 20-fold reduction in the recognition error ratio.","inating data points that re Ô¨Çect past biases. However, this
approach incurs signiÔ¨Åcant costs (Bornstein,2018).
Another method is to correct data imbalances by using more
equitable data sources to ensure fair decision-making (36KE,
2020). Understanding the underlying structure of training data
and adjusting the signi Ô¨Åcance of speci Ô¨Åc data points during
training based on known latent distributions makes it possible to
uncover hidden biases and remove them automatically. For
example, Microsoft revised their dataset for training the Face API,
resulting in a 20-fold reduction in the recognition error ratio updated based on incoming data. Unlike batch 
learning, online learning does not typically retrain the 
model from scratch; it refines the current model using 
only new data. This might reduce the influence of the 
original training data ‚Äôs composition, as updates are 
based solely on novel information. Understanding the 
role of the updating process in self -correcting effe cts 
is crucial, especially in contexts where retraining 
models from scratch is computationally prohibitive.  
A third limitation of our study is that we did not consider 
the impact of continuous model updating when human the currently available training data, essentially 
generating a new model from the full dataset 
(Asatiani et al., 2020). This approach does not 
incorporate new data incrementally but processes the 
entire dataset anew. We chose this method for its 
empirical simplicity and efficiency, particularly with 
tree-based techniques like the gradient  boosted forest  
we used. Future research might explore the 
robustness of our results under online learning 
processes, where model parameters are continuously 
updated based on incoming data. Unlike batch 
learning, online learning does not typically retrain the neously labeled a photo of two black people as gorillas (Jackson,
2021). The algorithm was insuf
Ô¨Åciently trained to recognize
images with dark skin tones (Yarger et al.,2023). The company
publicly apologized and committed to immediately preventing
such errors. However, three years later, Google discontinued its
facial identiÔ¨Åcation service, citing the need to address signiÔ¨Åcant
technical and policy issues before resuming this service. Similarly,
in 2017, an algorithm used for a contactless soap dispenser failed
to correctly identify shades of skin color, resulting in the dis- microsoft face API Service. Electron Inf Technol 12:36‚Äì48
Gulzar MA, Zhu Y, Han X (2019) Perception and practices of differential testing.
In: Conitzer V, HadÔ¨Åeld G, Vallor S (eds) 2019 IEEE/ACM 41st International
Conference on Software Engineering: Software Engineering in Practice
(ICSE-SEIP). Association for Computing Machinery
Hmoud B, Laszlo V (2019) Will artiÔ¨Åcial intelligence take over human resources
recruitment and selection? Netw Intell Stud 7(13):21‚Äì30
AI-driven 
recruitmet 
and 
challenges
AI-
enabled 
hiring
Cause of 
recruitm
ent 
discrimi
nation
Types 
of 
Recruit
ment 
Discrim
ination
Recruiti
ng the growth of the training dataset was limited. We d id so to 
avoid an initial training dataset that would have been 
immediately augmented with too many novel observations so 
that gradual learning c ould occur. Notably, in additional 
simulations, we observe d that our base results on self -
correcting effects accelerated (decelerated) when we increased 
(decreased) the number of pairings to 60 or 70 (30 or 40). The 
main results on the role of initial algorithmic discrimination 
and persistent human discrimination hold ceteris paribus. We 
present these additional analyses in Appendix B.",5.706636429,1,"The context directly answers the question. It states that Microsoft revised their dataset for the Face API, ""resulting in a 20-fold reduction in the recognition error ratio""[cite: 1871].",1,"The claim is directly supported by the context, which states that Microsoft revised their dataset for the Face API, ""resulting in a 20-fold reduction in the recognition error ratio"" [1871].",1,The generated answer is semantically identical to the ground truth.,,
What did Amazon do with their ML-based hiring tool?,Amazon withdrew the tool and developed a new unbiased algorithm.,"According to the text, Amazon withdrew the tool and developed a new, unbiased algorithm after the initial tool exhibited gender bias.","pations as less professional‚Äù((Avery et al.,2023; Kay et al.,2015).
The impact of gender stereotypes on AI hiring poses genuine
risks (Beneduce,2020). In 2014, Amazon developed an ML-based
hiring tool, but it exhibited gender bias. The system did not
classify candidates neutrally for gender (Miasato and Silva,2019).
The bias stemmed from training the AI system on predominantly
male employees ‚Äô CVs (Beneduce, 2020). Accordingly, the
recruitment algorithm perceived this biased model as indicative
of success, resulting in discrimination against female applicants
(Langenkamp et al. 2019). The algorithm even downgraded Punkt,
dass die Leute sich nicht 
ausreichend
fr√ºh √ºberlegt haben und der.
Mein Punkt dieser Idee ist 
nat√ºrlich
f√ºr uns jetzt an dieser
Stelle Ich kann ein super System 
haben.
Worauf es aber wirklich ankommt, 
ist,
ob dieses System so genutzt 
wird,
wie ich mir das vorstelle.
Stellen Sie sich vor, Amazon
h√§tte das beste Recruitment Tool
basierend auf KI entwickelt
und es w√§re immer richtig 
potenziell.
Aber diejenigen, die letztlich
die Entscheidungsgewalt haben,
der Mensch in diesem Loop
w√ºrde nie auf die Maschine 
h√∂ren.
Alle m√∂glichen Effizienzgewinne, 
die wir h√§tten,
werden gar nicht realisiert. in its decision-making, a mistake known as algorithmic bias
(Jackson, 2021).
AI-based recruitment stage. The recruitment procedure is a series
of events that may be divided into four signi Ô¨Åcant steps:
searching, screening, interviewing, and selection (Bogen and
Rieke, 2018). Each phase includes various activities, and artiÔ¨Åcial
intelligence technology can inÔ¨Çuence the execution of each stage.
The searching phase aims at a system for searching web
content. It screens passive job applicants online through social
media and recruitment platforms, analyzing their pro Ô¨Åles in discrimination (Miasato and Silva,2019).
Furthermore, personal biases can manifest in the selection of
data characteristics. For example, engineers may prioritize speciÔ¨Åc
features or variables based on how they want the machine to
behave (Miasato and Silva, 2019)). The Amazon hiring case
illustrates this, where engineers considered education, occupation,
and gender when assigning labels to the algorithm. When gender
is considered the crucial criterion, it inÔ¨Ç
uences how the algorithm
responds to the data.
Theme III. Which algorithmic recruitment discrimination
exists of success, resulting in discrimination against female applicants
(Langenkamp et al. 2019). The algorithm even downgraded
applicants with keywords such as ‚Äúfemale‚Äù (Faragher, 2019).
These Ô¨Åndings compelled Amazon to withdraw the tool and
develop a new unbiased algorithm. However, this discrimination
was inadvertent, revealing theÔ¨Çaws inherent in algorithmic bias
that perpetuates existing gender inequalities and social biases
(O‚Äôneil, 2016).
Race. Microsoft‚Äôs chatbot Tay learned to produce sexist and racist
remarks on Twitter. By interacting with users on the platform, M√∂glichkeiten
ist es da zu einem gro√üen 
Skandal gekommen,
die man von diesem Skandal 
damals geh√∂rt.
M√ºsste ungef√§hr in die Zeit, wo 
sie alle
Abitur gemacht haben, gewesen 
sein.
Ja, das war weil die.
Also ich bin mir nicht mehr 
sicher.
Ich glaube, da wurden die 
fr√ºheren
Recruitingdaten von Amazon 
genommen,
in eine AI eingespeist.
Und da die fr√ºheren Recruiter
biased gegen√ºber Frauen waren,
hat die AI das Muster erkannt 
und ebenso √ºbernommen.
Genau.
Wir haben ein System
gehabt und ich w√ºrde gar nicht 
mal sagen,
dass die Recruiter per se 
gebeizt waren.
Ich wahrscheinlich auch ein 
Teil.",5.26756382,1,"The context directly answers the question, stating that after the tool showed gender bias, Amazon was ""compelled to withdraw the tool and develop a new unbiased algorithm""[cite: 1907].",1,"All claims in the generated answer are directly supported by the context. The context states that after the tool showed gender bias, Amazon was ""compelled to withdraw the tool and develop a new unbiased algorithm"" [1907].",1,The generated answer is semantically identical to the ground truth.,,
"According to the document, what is ‚Äúagent discrimination‚Äù?","When partial human data is provided to a machine, it will eventually lead to the risk of ‚Äúagent discrimination.‚Äù",The document does not define or discuss ‚Äúagent discrimination.‚Äù It primarily focuses on algorithmic bias and discrimination caused by AI-enabled recruitment practices.,"Discrimination theory. Discrimination in the labor market is
deÔ¨Åned by the ILO‚Äôs Convention 111, which encompasses any
unfavorable treatment based on race, ethnicity, color, and gender
that undermines employment equality (Ruwanpura, 2008).
Economist Samuelson (1952) offers a similar deÔ¨Ånition, indicat-
ing that discrimination involves differential treatment based on
personal characteristics, such as ethnic origin, gender, skin color,
and age.
Various perspectives on the causes and manifestations of
discrimination can be broadly categorized into four theoretical facial identiÔ¨Åcation.
Data protection and non-discrimination laws safeguard against
discriminatory practices in algorithmic decision-making. In the
EU region, Article 14 of the European Convention on Human
Rights (ECHR) guarantees the rights and freedoms outlined in
the Convention, prohibiting direct and indirect discrimination
(Zuiderveen Borgesius, 2020). Non-discrimination laws, particu-
larly those about indirect discrimination, serve as a means to
prevent various forms of algorithmic discrimination. The EU
General Data Protection Regulation (GDPR), implemented in work. However, algorithmic bias results in discriminatory hiring practices based on gender,
race, color, and personality traits. The study indicates that algorithmic bias stems from
limited raw data sets and biased algorithm designers. To mitigate this issue, it is recom-
mended to implement technical measures, such as unbiased dataset frameworks and
improved algorithmic transparency, as well as management measures like internal corporate
ethical governance and external oversight. Employing Grounded Theory, the study conducted
survey analysis to collectÔ¨Årsthand data on respondents‚Äô experiences and perceptions of AI- REVIEW ARTICLE
Ethics and discrimination in artiÔ¨Åcial intelligence-
enabled recruitment practices
Zhisheng Chen 1‚úâ
This study aims to address the research gap on algorithmic discrimination caused by AI-
enabled recruitment and explore technical and managerial solutions. The primary research
approach used is a literature review. TheÔ¨Åndings suggest that AI-enabled recruitment has
the potential to enhance recruitment quality, increase efÔ¨Åciency, and reduce transactional
work. However, algorithmic bias results in discriminatory hiring practices based on gender, quently, the issue of algorithmic hiring discrimination has
emerged, shifting the focus of statistical discrimination theory
from traditional hiring to intelligent hiring. The mechanisms that
give rise to hiring discrimination problems remain similar, as
both rely on historical data of speciÔ¨Åc populations to predict
future hiring outcomes.
While AI recruiting offers numerous bene Ô¨Åts, it is also
susceptible to algorithmic bias. Algorithmic bias refers to the
systematic and replicable errors in computer systems that lead to
unequally and discrimination based on legally protected char- discrimination by machines, including technical and non-
technical approaches.
Recommendations for future studies
This study conducted a literature review to analyze algorithmic
recruitment discrimination‚Äôs causes, types, and solutions. Future
research on algorithmic recruitment discrimination could explore
quantitative analysis or experimental methods across different
countries and cultures. Additionally, future studies could examine
the mechanics of algorithmic recruitment and the technical rules
that impact the hiring process. It would be interesting to analyze",4.910335064,0,The context discusses discrimination theory and algorithmic bias in recruitment but does not define or mention the term 'agent discrimination'.,1,The generated answer is faithful because it correctly states that the provided context does not define or discuss ‚Äúagent discrimination.‚Äù,0,"The generated answer incorrectly states that the document does not define 'agent discrimination', while the ground truth provides a specific definition.",,
"According to the document, what are some characteristics used in discrimination theory?","Race, ethnicity, color, and gender.","According to the document, here are some characteristics used in discrimination theory:

*   **Race**
*   **Ethnicity**
*   **Color**
*   **Gender**
*   **Age**

Additionally, the document outlines four broad theoretical groups for understanding discrimination:

1.  **Competitive Market Theory:** Attributes discrimination primarily to personal prejudice.
2.  **Monopoly Model of Discrimination:** Discrimination due to monopolistic power.
3.  **Statistical Theory of Discrimination:** Based on inadequate information and biased outcomes.
4.  **Antecedent Market Discrimination Hypothesis**","Discrimination theory. Discrimination in the labor market is
deÔ¨Åned by the ILO‚Äôs Convention 111, which encompasses any
unfavorable treatment based on race, ethnicity, color, and gender
that undermines employment equality (Ruwanpura, 2008).
Economist Samuelson (1952) offers a similar deÔ¨Ånition, indicat-
ing that discrimination involves differential treatment based on
personal characteristics, such as ethnic origin, gender, skin color,
and age.
Various perspectives on the causes and manifestations of
discrimination can be broadly categorized into four theoretical Various perspectives on the causes and manifestations of
discrimination can be broadly categorized into four theoretical
groups. TheÔ¨Årst is the competitive market theory, which explains
discriminatory practices within an equilibrium of perfect
competition (Lundberg and Startz, 1983). This view attributes
discrimination primarily to personal prejudice. The second is the
monopoly model of discrimination, which posits that mono-
polistic power leads to discriminatory behavior (Cain,1986). The
third is the statistical theory of discrimination, which suggests
that nonobjective variables, such as inadequate information, that nonobjective variables, such as inadequate information,
contribute to biased outcomes (Dickinson and Oaxaca, 2009).
Lastly, we have the antecedent market discrimination hypothesis
as the fourth category.
Statistical discrimination theory. Statistical discrimination refers
to prejudice from assessment criteria that generalize group
characteristics to individuals (Tilcsik, 2021). It arises due to
limitations in employers‚Äôresearch techniques or the cost con-
straint of obtaining information in the asymmetry between
employers and job seekers. Even without monopolistic power, discrimination (Favaretto et al., 2019; Kordzadeh & 
Ghasemaghaei, 2022). The social component often 
originates from societal and economic structural biases, 
which can foster the differential treatment and 
marginalization of certain groups. On the other hand, the 
technological element emanates from the perpetuated 
discriminatory behaviors of algorithmic systems. 
Algorithmic feedback loops: Feedback loops play a 
significant role in algorithmic discrimination in the 
context of continuously updated ML models. These loops 
arise when the outcomes of algorithmic decisions provide models frequently aid human decisions, researchers and 
practitioners often employ the te rm ‚Äúalgorithmic 
discrimination‚Äù to refer to system outputs that 
disproportionately benefit or disadvantage specific 
groups, even when no justification for the disparate 
treatment exists from a ground -truth perspective 
(Kordzadeh & Ghasemaghaei, 2022).1  
Algorithmic discrimination can originate from various 
sources. First, it may stem from intentional or 
unintentional social biases encoded within the training 
data (Friedman & Nissenbaum, 1996; Romei & Ruggieri, 
2013; Kleinberg et al., 2018). For example, if a training unequally and discrimination based on legally protected char-
acteristics, such as race and gender (Jackson, 2021). When
assessments consistently overestimate or underestimate a parti-
cular group‚Äôs scores, they produce ‚Äúpredictive bias‚Äù (Raghavan
et al.,2020
). Unfortunately, these discriminatory results are often
overlooked or disregarded due to the misconception that AI
processes are inherently‚Äúobjective‚Äù and ‚Äúneutral.‚Äù
REVIEW ARTICLE HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS | https://doi.org/10.1057/s41599-023-02079-x",11.2181356,1,"The context directly answers the question by stating that discrimination involves differential treatment based on characteristics like ""race, ethnicity, color, and gender"" [cite: 1938] and ""ethnic origin, gender, skin color, and age""[cite: 1939].",1,"All claims in the generated answer are directly supported by the provided context. The context lists characteristics such as ""race, ethnicity, color, and gender"" [1938] and ""age"" [1939], and also outlines the four theoretical groups mentioned.",1,"The generated answer and the ground truth list the same characteristics, making them semantically identical.",,
What is the generic C R ISP-D M process model useful for?,"Planning, documentation and communication.","According to the text, the generic CRISP-DM process model is useful for:

*   **Planning:** It provides a framework for planning data mining projects.
*   **Communication:** It facilitates communication within and outside the project team.
*   **Documentation:** It‚Äôs helpful for documenting the data mining process.
*   **Developing specialized models:** It serves as a foundation for creating more detailed process models.","both the structure and the flexibility necessary to suit the needs of both groups.
The generic C R ISP-D M  process m odel is useful for planning, com m unication w ithin and outside the project team , and
docum entation. The generic check-lists are helpful even for experienced people. The generic process m odel provides an
excellent foundation for developing a specialized process m odel w hich prescribes the steps to be taken in detail and
w hich gives practical advice for all these steps.
1 Introduction
D ata m ining is a creative process w hich requires a num ber of different skills and know ledge. 15. Mai 2025
Structuring an AI project: CRISP-DM 
6
1. Business Understanding2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment
Data 
Cross Industry Standard Process for Data Mining process m odels m ust be flexible and living as w ell.
6 C onclusions and Future W ork
W e can conclude that C R ISP-D M  w orks. The generic process m odel is useful for planning,
docum entation and com m unication. It is fairly easy to w rite specialized process m odels based on
generic check lists. Finding the right level of detail is still difficult. B ut the process is living and
therefore all the docum ents m ust be living docum ents, too.
The claim s of the C R ISP-D M  projects are not easy to evaluate, especially in term s of speed and for carrying out data m ining projects. The process m odel is independent of both the industry sector and the technology
used. In this paper w e argue in favor of a standard process m odel for data m ining and report som e experiences w ith the
C R ISP-D M  process m odel in practice.
W e applied and tested the C R ISP-D M  m ethodology in a response m odeling application project. The final goal of the
project w as to specify a process w hich can be reliably and efficiently repeated by different people and adapted to m ining tasks, suggest appropriate data transform ations and data m ining techniques, and provide
m eans for evaluating the effectiveness of the results and docum enting the experience.
The C R ISP-D M  (C R oss Industry Standard Process for D ata M ining) project1 addressed parts of
these problem s by defining a process m odel w hich provides a fram ew ork for carrying out data
                                                          
1 The C R ISP-D M  process m odel is being developed by a consortium  of leading data m ining users and suppliers: D aim lerC hrysler project w as to specify a process w hich can be reliably and efficiently repeated by different people and adapted to
different situations. The initial projects w ere perform ed by experienced data m ining people; future projects are to be
perform ed by people w ith low er technical skills and w ith very little tim e to experim ent w ith different approaches. It
turned out, that the C R ISP-D M  m ethodology w ith its distinction of generic and specialized process m odels provides
both the structure and the flexibility necessary to suit the needs of both groups.",8.73361969,1,"The context directly answers the question, stating that the generic CRISP-DM process model is useful for ""planning, com munication w ithin and outside the project team, and docum entation""[cite: 1960].",1,"All claims in the generated answer are directly supported by the provided context, which states that the generic CRISP-DM process model is useful for ""planning, com munication w ithin and outside the project team, and docum entation"" [1960].",1,The generated answer is semantically identical to the ground truth.,,
"According to the document, what can AI-based recruitment reduce?",Costs.,"According to the document, AI-based recruitment can reduce:

*   **Costs** (as suggested by Hmoud and Laszlo, Johansson and Herranen, Raveendra et al., Black and van Esch, and Allal-Ch√©rif et al.)
*   **Time** (as suggested by Upadhyay and Khandelwal and Johansson and Herranen)
*   **Transactional workload** (as proposed by Upadhyay and Khandelwal and Johansson and Herranen)","REVIEW ARTICLE
Ethics and discrimination in artiÔ¨Åcial intelligence-
enabled recruitment practices
Zhisheng Chen 1‚úâ
This study aims to address the research gap on algorithmic discrimination caused by AI-
enabled recruitment and explore technical and managerial solutions. The primary research
approach used is a literature review. TheÔ¨Åndings suggest that AI-enabled recruitment has
the potential to enhance recruitment quality, increase efÔ¨Åciency, and reduce transactional
work. However, algorithmic bias results in discriminatory hiring practices based on gender, studies point out that AI-supported recruitment has
beneÔ¨Åts. Beattie et al. (2012), Newell (2015), Raub (2018),
Miasato and Silva (2019), Beneduce (2020), and Johnson
et al. (2020) state that it can reduce costs; Hmoud and
Laszlo (2019), Johansson and Herranen (2019), Raveendra
et al. (2020), Black and van Esch (2020), and Allal-Ch√©rif
et al. ( 2021) suggest it saves time; Upadhyay and
Khandelwal (2018) and Johansson and Herranen (2019)
present it reducing transactional workload.
2. The second theme is the causes of algorithmic discrimina-
tion. McFarland and McFarland (2015), Mayson (2018), algorithmic hiring. This study contends that resolving algorithmic
discrimination in recruitment requires technical solutions and the
implementation of internal ethical governance and external
regulations.
The subsequent study is structured intoÔ¨Åve parts. The Ô¨Årst
section provides the theoretical background for this research. The
following section outlines the research methodology employed in
the literature review and identiÔ¨Åes four key themes. The third
section delves into a detailed discussion of these four themes:
applications and beneÔ¨Åts of AI-based recruitment, factors con- recruiters, thus changing the traditional practices of the recruit-
ment industry (Upadhyay and Khandelwal,2018). Most profes-
sionals believe that AI is bene Ô¨Åcial to recruiters in terms of
reducing routine and administrative tasks (Johansson and
Herranen, 2019). Recruiters will hand over time-consuming
administrative tasks like recruiting, screening, and interviewing to
AI, allowing more scope for recruiters to concentrate on strategic
affairs (Upadhyay and Khandelwal,2018
).
Theme II. Why is there algorithmic recruitment
discrimination
Algorithms are not inherently discriminatory, and engineers applications and beneÔ¨Åts of AI-based recruitment, factors con-
tributing to algorithmic recruitment discrimination, types of
discrimination in algorithmic recruitment, and measures to
mitigate algorithmic hiring discrimination. The fourth section
involves conducting a survey among respondents and analyzing
the primary data collected to support our study. TheÔ¨Ånal section
concludes by suggesting future directions for research.
Theory background
Discrimination theory. Discrimination in the labor market is
deÔ¨Åned by the ILO‚Äôs Convention 111, which encompasses any Silva (2019), and Beneduce (2020), Johnson et al. (2020).
Claim that AI-supported recruitment can reduce
costs
Hmoud and Laszlo (2019), Johansson and Herranen (2019),
Raveendra et al. (2020), Black and van Esch (2020), and Allal-
Ch√©rif et al. (2021)
Suggests that AI support can save time
Upadhyay and Khandelwal (2018), Johansson and Herranen
(2019)
Propose that AI support can reduce transactional
workload
2. Causes of algorithmic
discrimination
McFarland and McFarland (2015), Mayson (2018), Raso et al.
(2018), Raub (2018), Raghavan et al. (2020), Njoto (2020),
Zixun (2020), and Jackson (2021)",9.915781498,1,"The context provides a clear, bulleted list of benefits from AI-supported recruitment, citing studies that claim it can ""reduce costs"" [cite: 1983], ""save time"" [cite: 1984], and reduce ""transactional workload""[cite: 1985]. The question asks for one benefit, and the context provides three.",1,"All claims in the generated answer are directly supported by the provided context, which cites various studies indicating that AI-supported recruitment can reduce costs [1997], save time [1999], and reduce transactional workload [1979].",1,The generated answer and the ground truth are semantically identical.,,
"According to the document, what is the aim of the C R ISP-D M process model?","To make large data mining projects less costly, more reliable, more repeatable, more manageable, and faster.","According to the document, the aim of the CRISP-DM process model is to:

*   Specify a process which can be reliably and efficiently repeated by different people and adapted to different situations.
*   Suggest appropriate data transformations and data mining techniques.
*   Provide means for evaluating the effectiveness of the results and documenting the experience.","15. Mai 2025
Structuring an AI project: CRISP-DM 
6
1. Business Understanding2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment
Data 
Cross Industry Standard Process for Data Mining for carrying out data m ining projects. The process m odel is independent of both the industry sector and the technology
used. In this paper w e argue in favor of a standard process m odel for data m ining and report som e experiences w ith the
C R ISP-D M  process m odel in practice.
W e applied and tested the C R ISP-D M  m ethodology in a response m odeling application project. The final goal of the
project w as to specify a process w hich can be reliably and efficiently repeated by different people and adapted to m ining tasks, suggest appropriate data transform ations and data m ining techniques, and provide
m eans for evaluating the effectiveness of the results and docum enting the experience.
The C R ISP-D M  (C R oss Industry Standard Process for D ata M ining) project1 addressed parts of
these problem s by defining a process m odel w hich provides a fram ew ork for carrying out data
                                                          
1 The C R ISP-D M  process m odel is being developed by a consortium  of leading data m ining users and suppliers: D aim lerC hrysler project w as to specify a process w hich can be reliably and efficiently repeated by different people and adapted to
different situations. The initial projects w ere perform ed by experienced data m ining people; future projects are to be
perform ed by people w ith low er technical skills and w ith very little tim e to experim ent w ith different approaches. It
turned out, that the C R ISP-D M  m ethodology w ith its distinction of generic and specialized process m odels provides
both the structure and the flexibility necessary to suit the needs of both groups. 15. Mai 2025
Overview CRISP-DM
9 developed during these initial projects. These tem plates proved to be quite helpful especially for
people w ho are not proficient w ith our particular data m ining tool.
5 L essons learned
In this section, w e try to sum m arize som e of the experiences w e m ade in both applying the
generic C R ISP-D M  process m odel and in developing a specialized process m odel.
W e expected the generic process m odel to be useful for planning and docum entation, and this
turned out to be the case. H ow ever, the use of the m odel for com m unication both w ithin and",7.892440081,1,"The context directly states that a goal of the project was ""to specify a process which can be reliably and efficiently repeated by different people and adapted to different situations"" [cite: 2007] and to provide a ""framework for carrying out data mining tasks""[cite: 2008].",1,"All claims in the generated answer are directly verifiable from the provided context, which states that the goal is to ""specify a process which can be reliably and efficiently repeated"" [2001] and that it provides a framework for carrying out data mining tasks [2008].",0,"The generated answer provides a different, less comprehensive aim ('to specify a process which can be reliably and efficiently repeated'). The ground truth gives the full, multi-faceted aim of making projects 'less costly, more reliable, more repeatable, more manageable, and faster'.",,
,,,,,,,,,,,,
,,,,,,,,,,,,
,,,,,,,,,,,,
,,,,,,,,,,,,
,,,,,,,,,,,,
