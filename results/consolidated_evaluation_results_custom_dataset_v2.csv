question,ground_truth_answer,generated_answer,retrieved_context,response_time_seconds,correctness_score,correctness_reasoning,faithfulness_score,faithfulness_reasoning,relevance_score,relevance_reasoning
"In the paper about the Centaur foundation model, what happens to the model's internal representations after being fine-tuned on the Psych-101 dataset?",The model's internal representations become more aligned with human neural activity.,The provided text doesn't contain information about the Centaur foundation model or what happens to its internal representations after being fine-tuned on the Psych-101 dataset. It discusses a different machine learning model and a general approach to understanding how such models work.,"die das beeinflussen und
was hier Venkatesh und Kollegen 
gemacht haben,
die haben acht verschiedene 
Modelle
aus ganz unterschiedlichen
Disziplinen zusammengenommen und
haben jahrelang rumgewerkelt, um 
zu schauen,
was sind eigentlich die latent 
ähnlichen Faktoren,
was können wir irgendwie 
zusammenfassen und
was sind Faktoren,
die möglichst orthogonal einzeln 
gesehen
unterschiedlich sind und
viel Erklärungsgehalt dafür 
haben
in der Vorhersage,
ob ein Mensch die Technologie 
nutzen wird oder nicht.
Und das haben Sie das Modell, 
was entwickelt haben
letztlich auf ganz viele 
empirische Daten
gelegt und gezeigt,
dass dieses Modell um die 70 % 
der Variation darin,
ob Leute mit Technologie 
interagieren,
diese wirklich nutzen und 
akzeptieren, erklären kann.
Als Spoiler schon mal 70 % der
Variation zu erklären ist 
massiv,
insbesondere in solchen 
soziotechnischen Systemen,
wo wie immer der Mensch die 
Schwachstelle ist.
Womit haben Sie angefangen? Sie 
haben gesagt.
Und dieses Modell ist
vor allen Dingen aus der 
Perspektive
geschaffen worden damals.
Wie kriegen wir eigentlich Leute 
in Unternehmen dazu,
die bereitgestellte Technologie 
zu nutzen?
Es gibt mittlerweile auch zwei
Erweiterungen von diesem Modell Sie sind ein Machine Learning 
Modell.
Kommen wir jetzt zur heutigen 
Vorlesung.
Immer mit diesem Gedanken im 
Kopf.
Wir haben Inputdaten, wir haben
ein Modell und dieses Modell
macht auf den Inputdaten 
letztlich uns eine Vorhersage,
die möglichst präzise ist für 
Daten,
die Sie noch nicht gesehen 
haben.
Fangen wir jetzt wirklich an,
in diesem Teil eins rein zu 
gehen, um zu verstehen,
was können diese Modelle
eigentlich liefern aus einer 
ökonomischen,
betriebswirtschaftlichen, 
gesellschaftlichen Perspektive?
Wir werden jetzt in den ersten
Vorlesungen und es wird so
bis zur fünften Vorlesung gehen.
Da werden wir langsam anfangen,
auch in den zweiten Teil 
überzugehen.
Aber zunächst mal interessiert 
uns gar nicht,
wie wir auf dieses Modell 
kommen,
was dieses Modell genau ist.
Wir werden erstmal annehmen,
da ist irgendein Modell,
das fällt sozusagen vom Himmel.
Und was macht dieses Modell mit 
uns?
Was macht dieses Modell mit 
Organisationen?
Was macht dieses Modell mit 
Personen?
Was macht dieses Modell mit der 
Gesellschaft?
Und um so ein bisschen
eine Hands on Vorstellung zu 
haben,
was Machine Learning Modelle 
machen,
habe ich hier mal ein Beispiel 
mitgebracht,
wo wir jetzt als Gruppe Machine 
Learning Modell spielen. eher das Modell nehmen, was 
einfacher ist.
Der Gedanke, der dahinter 
steckt,
ist, dass wir vermeiden wollen,
dass die zufälligen Schwankungen 
in den
Daten mit höherer 
Modellkomplexität
in dem Modell erkannt werden als 
wichtige Muster.
Time ist jetzt auch ein bisschen 
drauf gucken,
dass ich meinen Time Management 
richtig betreibe,
weil wie Sie vielleicht gemerkt 
haben,
habe ich die Tendenz, viel zu 
reden.
Kommen Sie gerne nach der 
Vorlesung,
dann können wir darüber 
sprechen.
Wenn wir das verallgemeinern und 
jetzt nicht nur
über unser EiscremeBeispiel 
nachdenken,
sondern ganz, ganz, ganz High 
Level aus einer fast schon.
Und Uwe Walz würde sich freuen,
wenn diese Formel hier angezeigt 
wird.
Wahrscheinlich aus einer 
mikroökonomischen
Perspektive kann man
natürlich fragen Warum brauchen 
wir Vorhersagen?
Und aus einer ökonomischen
Sicht Wenn ich bestimmte 
Entscheidungsprobleme,
Nutzenmaximierungsprobleme,
Gewinnmaximierungsprobleme 
aufschreibe, dann ist immer so
ein bisschen in
fast allen Optimierungsproblemen 
uncertainty mit drin.
Bestimmte Sachen weiß ich 
einfach nicht.
Es kommt so ein bisschen darauf 
an,
was in der Zukunft passieren 
wird.
Wenn ich heute investiere,
wenn ich eigentlich mein",24.06436753,0,"The generated answer is a refusal to answer, stating the information is not in the text. The ground truth provides a specific, factual answer. They are contradictory.",1,"The generated answer is a refusal to answer, and the reasons it gives for refusing are all supported by the context. The context does not mention the 'Centaur foundation model' or 'Psych-101 dataset', and it does discuss other models and general ML concepts.",0,"The context discusses machine learning models from a general, economic perspective and does not contain any information about the 'Centaur foundation model' or the 'Psych-101 dataset'."
"In the study on capturing human cognition, how does the Centaur model's performance compare to existing cognitive models?",Centaur captures the behaviour of held-out participants better than existing cognitive models.,"Laut dem Text erreicht das Centaur-Modell eine Erklärungskraft von rund 70% der Variation, wenn es um die Vorhersage geht, ob Menschen Technologie nutzen oder nicht. Dies ist eine signifikante Leistung, insbesondere in soziotechnischen Systemen, in denen der Mensch die Schwachstelle darstellt. Der Text erwähnt jedoch nicht, wie sich diese Leistung im Vergleich zu anderen kognitiven Modellen, wie sie in der Studie zur Erfassung menschlicher Kognition beschrieben sind, verhält.","die das beeinflussen und
was hier Venkatesh und Kollegen 
gemacht haben,
die haben acht verschiedene 
Modelle
aus ganz unterschiedlichen
Disziplinen zusammengenommen und
haben jahrelang rumgewerkelt, um 
zu schauen,
was sind eigentlich die latent 
ähnlichen Faktoren,
was können wir irgendwie 
zusammenfassen und
was sind Faktoren,
die möglichst orthogonal einzeln 
gesehen
unterschiedlich sind und
viel Erklärungsgehalt dafür 
haben
in der Vorhersage,
ob ein Mensch die Technologie 
nutzen wird oder nicht.
Und das haben Sie das Modell, 
was entwickelt haben
letztlich auf ganz viele 
empirische Daten
gelegt und gezeigt,
dass dieses Modell um die 70 % 
der Variation darin,
ob Leute mit Technologie 
interagieren,
diese wirklich nutzen und 
akzeptieren, erklären kann.
Als Spoiler schon mal 70 % der
Variation zu erklären ist 
massiv,
insbesondere in solchen 
soziotechnischen Systemen,
wo wie immer der Mensch die 
Schwachstelle ist.
Womit haben Sie angefangen? Sie 
haben gesagt.
Und dieses Modell ist
vor allen Dingen aus der 
Perspektive
geschaffen worden damals.
Wie kriegen wir eigentlich Leute 
in Unternehmen dazu,
die bereitgestellte Technologie 
zu nutzen?
Es gibt mittlerweile auch zwei
Erweiterungen von diesem Modell Aber den umgekehrten Effekt.
Wir haben die Behavioral,
diese kognitive Komponente 
davon,
die sich eigentlich in unserem 
Kopf geschaffen wird,
wo wir diese Intention to use 
entwickeln,
die wiederum von diesen drei 
Faktoren in diesem Modell
hier ganz grob auf einem sehr 
hohen Level.
Den Zusammenhang erklärt wird.
Und diese Beziehungen hängen
wiederum von den Moderatoren ab.
Ja, ja, erklären, warum das was 
Negatives ist.
Muss ich sie an das Papier 
verweisen, dass keine Ahnung,
wann ich das letzte Mal gelesen 
habe,
steht da bestimmt drin. Kann ich 
ihnen hochladen?
Bzw. Das ist glaube ich sogar 
Open Source.
Das hat mittlerweile glaube ich 
70.000
Situationen oder so,
also das ist wirklich eines der 
fundamentalen Modelle,
wo wir immer noch versuchen zu 
verstehen,
was beeinflusst eigentlich die 
Nutzung von wie gesagt,
Technologie breiter gefasst, 
aber für uns ist relevante.
Mit dem Schwerpunkt unseres 
Kurses sprechen wir natürlich
über die sogenannte Mensch 
Maschine Kollaboration,
was letztlich ist die Nutzung 
und
Akzeptanz von der KI 
Technologie.
Wir versuchen uns in der 
Wirtschaftsinformatik
gerade so ein bisschen wieder 
auf das Neue,
auf die neue Kuh, die durchs
Dorf getrieben wird, zu 
konzentrieren. Feedback Loops in Machine Learning 
 
811 
3.2 Previous Empirical Studies 
We buil t our simulations on two secondary datasets, 
collected by several authors of this paper as part of 
different empirical studies. Study A was an incentivized 
field study conducted over three years from 2016 to 
2019. Study A measured participant s’ behavior in the 
investment game  defined above  in their  role as 
borrowers. The data from Study A allow ed us to 
develop an ML model predicting borrowers’ repayment 
decision and serves as the foundation for simulating 
borrower behavior. Study B, conducted in December 
2020, was an incentivized online experiment where 
participants engaged in the outlined investment game in 
the role of investors. In this experiment, investors could 
access an ML model predicting borrowers ’ repayment 
likelihood. Notably, this model, along with the 
borrowers with whom investors from Study B 
interacted, originated from Study A data. The data from 
Study B provide d the basis for simulating investor 
decisions. We present the exact instructions given in 
these studies in Appendix B.1. 
Study A: At the onset of each semester, first -semester 
economics students from a large German university were",12.56632924,0,The generated answer makes a completely different claim (70% explanatory power for technology use) than the ground truth (outperforming existing cognitive models in capturing participant behavior). The two statements are not semantically related.,0,The generated answer is not faithful. It incorrectly attributes the finding that a model can explain '70% of the variation' in technology acceptance to the 'Centaur-Modell'. The context states this finding is about a model from 'Venkatesh and colleagues'.,0,"The context is entirely irrelevant. It discusses a model for technology acceptance and an investment game study, with no mention of the 'Centaur model' or its performance compared to other cognitive models."
"According to the paper on the Centaur foundation model, what is it designed to predict and simulate regarding human cognition?",It can predict and simulate human behaviour in any experiment expressible in natural language.,"Gemäß der Arbeit über das Centaur-Fundamentmodell soll das Modell die Nutzung und Akzeptanz von Technologie durch Menschen vorhersagen und simulieren. Genauer gesagt, es versucht, die Faktoren zu erklären, die beeinflussen, ob eine Person eine Technologie tatsächlich nutzt und akzeptiert. Es konzentriert sich auf die kognitive Komponente – die ""Intention to use"" – und wie diese von drei Hauptfaktoren beeinflusst wird.
","Sie sind ein Machine Learning 
Modell.
Kommen wir jetzt zur heutigen 
Vorlesung.
Immer mit diesem Gedanken im 
Kopf.
Wir haben Inputdaten, wir haben
ein Modell und dieses Modell
macht auf den Inputdaten 
letztlich uns eine Vorhersage,
die möglichst präzise ist für 
Daten,
die Sie noch nicht gesehen 
haben.
Fangen wir jetzt wirklich an,
in diesem Teil eins rein zu 
gehen, um zu verstehen,
was können diese Modelle
eigentlich liefern aus einer 
ökonomischen,
betriebswirtschaftlichen, 
gesellschaftlichen Perspektive?
Wir werden jetzt in den ersten
Vorlesungen und es wird so
bis zur fünften Vorlesung gehen.
Da werden wir langsam anfangen,
auch in den zweiten Teil 
überzugehen.
Aber zunächst mal interessiert 
uns gar nicht,
wie wir auf dieses Modell 
kommen,
was dieses Modell genau ist.
Wir werden erstmal annehmen,
da ist irgendein Modell,
das fällt sozusagen vom Himmel.
Und was macht dieses Modell mit 
uns?
Was macht dieses Modell mit 
Organisationen?
Was macht dieses Modell mit 
Personen?
Was macht dieses Modell mit der 
Gesellschaft?
Und um so ein bisschen
eine Hands on Vorstellung zu 
haben,
was Machine Learning Modelle 
machen,
habe ich hier mal ein Beispiel 
mitgebracht,
wo wir jetzt als Gruppe Machine 
Learning Modell spielen. die das beeinflussen und
was hier Venkatesh und Kollegen 
gemacht haben,
die haben acht verschiedene 
Modelle
aus ganz unterschiedlichen
Disziplinen zusammengenommen und
haben jahrelang rumgewerkelt, um 
zu schauen,
was sind eigentlich die latent 
ähnlichen Faktoren,
was können wir irgendwie 
zusammenfassen und
was sind Faktoren,
die möglichst orthogonal einzeln 
gesehen
unterschiedlich sind und
viel Erklärungsgehalt dafür 
haben
in der Vorhersage,
ob ein Mensch die Technologie 
nutzen wird oder nicht.
Und das haben Sie das Modell, 
was entwickelt haben
letztlich auf ganz viele 
empirische Daten
gelegt und gezeigt,
dass dieses Modell um die 70 % 
der Variation darin,
ob Leute mit Technologie 
interagieren,
diese wirklich nutzen und 
akzeptieren, erklären kann.
Als Spoiler schon mal 70 % der
Variation zu erklären ist 
massiv,
insbesondere in solchen 
soziotechnischen Systemen,
wo wie immer der Mensch die 
Schwachstelle ist.
Womit haben Sie angefangen? Sie 
haben gesagt.
Und dieses Modell ist
vor allen Dingen aus der 
Perspektive
geschaffen worden damals.
Wie kriegen wir eigentlich Leute 
in Unternehmen dazu,
die bereitgestellte Technologie 
zu nutzen?
Es gibt mittlerweile auch zwei
Erweiterungen von diesem Modell Aber den umgekehrten Effekt.
Wir haben die Behavioral,
diese kognitive Komponente 
davon,
die sich eigentlich in unserem 
Kopf geschaffen wird,
wo wir diese Intention to use 
entwickeln,
die wiederum von diesen drei 
Faktoren in diesem Modell
hier ganz grob auf einem sehr 
hohen Level.
Den Zusammenhang erklärt wird.
Und diese Beziehungen hängen
wiederum von den Moderatoren ab.
Ja, ja, erklären, warum das was 
Negatives ist.
Muss ich sie an das Papier 
verweisen, dass keine Ahnung,
wann ich das letzte Mal gelesen 
habe,
steht da bestimmt drin. Kann ich 
ihnen hochladen?
Bzw. Das ist glaube ich sogar 
Open Source.
Das hat mittlerweile glaube ich 
70.000
Situationen oder so,
also das ist wirklich eines der 
fundamentalen Modelle,
wo wir immer noch versuchen zu 
verstehen,
was beeinflusst eigentlich die 
Nutzung von wie gesagt,
Technologie breiter gefasst, 
aber für uns ist relevante.
Mit dem Schwerpunkt unseres 
Kurses sprechen wir natürlich
über die sogenannte Mensch 
Maschine Kollaboration,
was letztlich ist die Nutzung 
und
Akzeptanz von der KI 
Technologie.
Wir versuchen uns in der 
Wirtschaftsinformatik
gerade so ein bisschen wieder 
auf das Neue,
auf die neue Kuh, die durchs
Dorf getrieben wird, zu 
konzentrieren.",10.98655295,0.2,"The generated answer is partially correct but significantly narrows the scope. The ground truth states the model can handle *any* experiment in natural language, a very broad capability. The generation limits this to only predicting the 'use and acceptance of technology', which is factually incorrect and misses the core capability of the model.",0,"The generated answer is unfaithful. While the description of the model's function (predicting technology use, focusing on 'Intention to use') is supported by the context, the context attributes these characteristics to a model by 'Venkatesh und Kollegen', not the 'Centaur-Fundamentmodell' as claimed in the answer.",0,"The context describes a model for predicting technology acceptance, explaining about 70% of the variation in user interaction. It does not mention the 'Centaur foundation model' or its specific design to predict and simulate human cognition."
"For the Centaur model, what is the name and scale of the dataset used for fine-tuning to capture human cognition?","Psych-101, which covers trial-by-trial data from over 60,000 participants in 160 experiments.","Das Datenset, das für das Fein-Tuning des Centaur-Modells zur Erfassung menschlicher Kognition verwendet wurde, hatte den Namen ""XML"".","die das beeinflussen und
was hier Venkatesh und Kollegen 
gemacht haben,
die haben acht verschiedene 
Modelle
aus ganz unterschiedlichen
Disziplinen zusammengenommen und
haben jahrelang rumgewerkelt, um 
zu schauen,
was sind eigentlich die latent 
ähnlichen Faktoren,
was können wir irgendwie 
zusammenfassen und
was sind Faktoren,
die möglichst orthogonal einzeln 
gesehen
unterschiedlich sind und
viel Erklärungsgehalt dafür 
haben
in der Vorhersage,
ob ein Mensch die Technologie 
nutzen wird oder nicht.
Und das haben Sie das Modell, 
was entwickelt haben
letztlich auf ganz viele 
empirische Daten
gelegt und gezeigt,
dass dieses Modell um die 70 % 
der Variation darin,
ob Leute mit Technologie 
interagieren,
diese wirklich nutzen und 
akzeptieren, erklären kann.
Als Spoiler schon mal 70 % der
Variation zu erklären ist 
massiv,
insbesondere in solchen 
soziotechnischen Systemen,
wo wie immer der Mensch die 
Schwachstelle ist.
Womit haben Sie angefangen? Sie 
haben gesagt.
Und dieses Modell ist
vor allen Dingen aus der 
Perspektive
geschaffen worden damals.
Wie kriegen wir eigentlich Leute 
in Unternehmen dazu,
die bereitgestellte Technologie 
zu nutzen?
Es gibt mittlerweile auch zwei
Erweiterungen von diesem Modell dieser Gleichung hier 
ausdrücken.
Wir haben drei verschiedene 
Komponenten.
Wir haben hier dieses Hütchen,
wir haben das fix und wir haben 
hier dieses Y Hütchen.
Meine erste Frage an Sie Was war 
das? F Hütchen.
Yes, genau richtig.
Wir haben hier das erlernte 
Machine Learning Modell,
was die Muster, die wir in 
historischen
Daten durch Algorithmen erkannt 
haben, abspeichert.
Hier in diesem F. Steckt unser 
gesamtes Wissen drin,
was wir irgendwie extrahieren
und wie genau wir das 
extrahieren.
Das wird der zweite Teil unserer 
Vorlesung sein.
Wichtig hierbei Hütchen ist 
immer dafür ein Indikator,
dass wir von einer Approximation 
sprechen.
Das ist ein Modell.
Das ist nicht der wahre 
unterliegende Prozess,
der die Daten generiert.
Das ist nicht die Landschaft von 
Frankfurt sozusagen,
sondern es ist die Landkarte.
Es ist ein explizit abstrakteres 
Modell,
eine Darstellung der Realität.
Und da können eben Fehler drin 
sein.
Es ist ganz wichtig, sich
immer wieder vor Augen zu 
halten.
Dann haben wir die zweite 
Komponente.
Das war das XML. Was ist das?.X. 
Jemand eine Idee?
Jetzt dahinten? Genau das sind 
die Daten,
die wir in diese Maschine 
reintun.
Wir haben zum Beispiel, wenn Sie 
überlegen,
Sie interagieren mit Chat GPT 10. Juli 2025
A mathematical model of a brain cell: perceptron
10
#𝑦!=𝑓%""𝑤""⋅𝑥""+𝑏
Weighted linear combination of inputsOutput
Non-linearization(activation function) Intercept
Representation   +Evaluation+Optimization",7.655549288,0,"The generated answer states the dataset is named 'XML', while the ground truth states it is 'Psych-101'. The answers are factually contradictory.",0,"The generated answer is not faithful. It incorrectly claims the dataset used for the 'Centaur-Modell' was named 'XML'. The context mentions 'XML' only as a generic variable placeholder for data ('X') in a mathematical formula, not as the name of a specific dataset. Furthermore, the context does not mention the 'Centaur' model at all.",0,The context explains the general components of a machine learning model using the notation ð‘¦Ì‚=ð‘“Ì‚(X). It does not contain any information about the 'Centaur model' or a fine-tuning dataset named 'Psych-101'.
In the paper 'A foundation model to predict and capture human cognition' what is the name of the computational model introduced?,Centaur.,"Das in der Arbeit 'A foundation model to predict and capture human cognition' eingeführte Rechenmodell heißt ""System eins"".","Sie sind ein Machine Learning 
Modell.
Kommen wir jetzt zur heutigen 
Vorlesung.
Immer mit diesem Gedanken im 
Kopf.
Wir haben Inputdaten, wir haben
ein Modell und dieses Modell
macht auf den Inputdaten 
letztlich uns eine Vorhersage,
die möglichst präzise ist für 
Daten,
die Sie noch nicht gesehen 
haben.
Fangen wir jetzt wirklich an,
in diesem Teil eins rein zu 
gehen, um zu verstehen,
was können diese Modelle
eigentlich liefern aus einer 
ökonomischen,
betriebswirtschaftlichen, 
gesellschaftlichen Perspektive?
Wir werden jetzt in den ersten
Vorlesungen und es wird so
bis zur fünften Vorlesung gehen.
Da werden wir langsam anfangen,
auch in den zweiten Teil 
überzugehen.
Aber zunächst mal interessiert 
uns gar nicht,
wie wir auf dieses Modell 
kommen,
was dieses Modell genau ist.
Wir werden erstmal annehmen,
da ist irgendein Modell,
das fällt sozusagen vom Himmel.
Und was macht dieses Modell mit 
uns?
Was macht dieses Modell mit 
Organisationen?
Was macht dieses Modell mit 
Personen?
Was macht dieses Modell mit der 
Gesellschaft?
Und um so ein bisschen
eine Hands on Vorstellung zu 
haben,
was Machine Learning Modelle 
machen,
habe ich hier mal ein Beispiel 
mitgebracht,
wo wir jetzt als Gruppe Machine 
Learning Modell spielen. die das beeinflussen und
was hier Venkatesh und Kollegen 
gemacht haben,
die haben acht verschiedene 
Modelle
aus ganz unterschiedlichen
Disziplinen zusammengenommen und
haben jahrelang rumgewerkelt, um 
zu schauen,
was sind eigentlich die latent 
ähnlichen Faktoren,
was können wir irgendwie 
zusammenfassen und
was sind Faktoren,
die möglichst orthogonal einzeln 
gesehen
unterschiedlich sind und
viel Erklärungsgehalt dafür 
haben
in der Vorhersage,
ob ein Mensch die Technologie 
nutzen wird oder nicht.
Und das haben Sie das Modell, 
was entwickelt haben
letztlich auf ganz viele 
empirische Daten
gelegt und gezeigt,
dass dieses Modell um die 70 % 
der Variation darin,
ob Leute mit Technologie 
interagieren,
diese wirklich nutzen und 
akzeptieren, erklären kann.
Als Spoiler schon mal 70 % der
Variation zu erklären ist 
massiv,
insbesondere in solchen 
soziotechnischen Systemen,
wo wie immer der Mensch die 
Schwachstelle ist.
Womit haben Sie angefangen? Sie 
haben gesagt.
Und dieses Modell ist
vor allen Dingen aus der 
Perspektive
geschaffen worden damals.
Wie kriegen wir eigentlich Leute 
in Unternehmen dazu,
die bereitgestellte Technologie 
zu nutzen?
Es gibt mittlerweile auch zwei
Erweiterungen von diesem Modell Und diese Systeme haben ein
Zusammenspiel dann was bestimmt,
ob ich eigentlich das System 
nutze.
Das war eines der fundamentalen 
Ergebnisse,
die Sie hier gefunden haben in 
der Studie.
Und dann Sie haben gesagt okay, 
wenn ich weiß,
dass wir die Menschen in
ihrer Kognition überzeugen 
müssen,
dass sie das System nutzen 
sollten und akzeptieren
sollten entweder über System
eins oder über System zwei 
Aktivierungen,
dann lass uns doch mal drüber 
nachdenken,
welche Faktoren denn hier eine 
besondere Rolle spielen.
Und da haben Sie insgesamt in
diesem Modell vier verschiedene 
Faktoren identifiziert.
Einer der Faktoren nennen Sie 
die Performance Expectancy.
Das können Sie sich vorstellen.
Sie haben ein System vor sich 
und ob
Sie eine Bereitschaft 
grundsätzlich Formen
in ihrer Kognition des System zu 
benutzen,
hängt damit zusammen, ob sie 
glauben,
dass dieses System Ihnen hilft,
bestimmte Ziele zu erreichen.
Wenn Sie sich die verschiedenen 
GPTsysteme,
die aktuell verfügbar sind,
auch in den öffentlichen 
Versionen,
dann sind da ganz viele 
verschiedene.
Dann gibt es aktuell vier 
Punkte, wo ich glaube,
das ist generell ZugReifbar 
mittlerweile.
Dann haben wir drei,
wir haben 4.1 4:05 usw.
Wenn ich die Entscheidung 
treffe,",6.453553915,0,"The generated answer claims the model is called 'System eins', while the ground truth states it is 'Centaur'. The answers are factually contradictory.",0,"The generated answer is not faithful. The context mentions 'System eins' in the context of psychological activation ('System eins oder Ã¼ber System zwei Aktivierungen'), not as the name of a computational model. The answer misinterprets this phrase.",0,"The context discusses a model for technology acceptance that identifies factors influencing user adoption, mentioning 'System eins' and 'System zwei' activations. It does not mention the paper 'A foundation model to predict and capture human cognition' or the computational model named 'Centaur'."
The paper 'Algorithmic Bias?' concludes that optimizing for what factor can lead to apparently discriminatory outcomes in ad delivery?,An algorithm that simply optimizes for cost-effectiveness.,"Laut dem Text führt die Optimierung für den Faktor ""Geschlecht"" zu scheinbar diskriminierenden Ergebnissen bei der Werbeauslieferung. Unternehmen zeigen Männern Anzeigen für Stammberufe und Frauen für Kosmetikprodukte, basierend auf marktwirtschaftlichen Überlegungen.","können,
dass Algorithmen den ein
bestimmtes Scoring an den Tag 
legen,
dass von dem Preis ihrer 
Aufmerksamkeit die
Kosten und die möglichen 
Benefits
in diesen Algorithmen mit 
gelernt wurden.
Zu einem gewissen Grad, was dazu 
führt,
dass es für die Unternehmen 
profitabler ist,
in einer automatisierten Art und 
Weise,
Männern anzeigen, Werbeanzeigen 
für Stammberufe zu zeigen
und Frauen Anzeigen für 
bestimmte
Kosmetikprodukte anzuzeigen,
einfach aus einer 
marktwirtschaftlichen 
Perspektive.
Aus einer ökonomischen 
Perspektive,
was die Unternehmen an Einkünfte 
erzeugen können,
was innerhalb dieser 
algorithmischen,
automatisierten Struktur 
stattfinden kann.
Auch das Papier werde ich Ihnen
hochladen auf Olat für 
diejenigen,
die sich dafür interessieren.
Die einfachste oder die 
intuitivste Art und Weise,
über diese Diskriminierung 
nachzudenken, ist,
dass wir selbst bei einem guten 
Algorithmus in
diese Subteile unserer Daten 
schauen müssen.
Wir können nicht immer nur das 
Aggregat beachten,
sondern wir müssen für bestimmte 
Subgruppen die
häufigen Fällen auch über das 
Gesetz Minoritäten,
die über Gesetze geschützt sind.
Bestimmte geschützte 
Eigenschaften von Personen 
müssen
in solchen Machine Learning significant consequences, such as in healthcare, loan 
approval, hiring, or criminal justice systems. 
Mitigating algorithmic discrimination : The 
expansive literature on algorithmic discrimination 
proposes various methods to identify and alleviate 
such biases. According to d ’Alessandro et al. (2017), 
we can divide these mitigation strategies into three 
categories: pre -processing, in -processing, and post -
processing. Pre -processing strategies strive to 
eliminate disparities inherent in the dataset. Methods 
such as those proposed by Kamiran and Calders (2012) 
and Zafar et al. (2017) employ data pre -processing 
techniques like feature massaging and reweighting to 
balance the dataset based on social group 
characteristics. In -processing strategies involve 
conventional learning algorit hms during model 
training. Researchers often use techniques like naive 
Bayes and decision tr ees for debiasing (Calders & 
Verwer, 2010; Zhang et al., 2018). Additional research 
suggests placing constraints on the classification 
model to mandate the satisfaction of a proxy 
(Woodworth et al., 2017). Lastly, post -processing 
strategies aim to adjust the output to counter biases. 
For example, Corbett -Davies et al. (2017) that nonobjective variables, such as inadequate information,
contribute to biased outcomes (Dickinson and Oaxaca, 2009).
Lastly, we have the antecedent market discrimination hypothesis
as the fourth category.
Statistical discrimination theory. Statistical discrimination refers
to prejudice from assessment criteria that generalize group
characteristics to individuals (Tilcsik, 2021). It arises due to
limitations in employers’research techniques or the cost con-
straint of obtaining information in the asymmetry between
employers and job seekers. Even without monopolistic power,
statistical discrimination can occur in the labor market due to
information-gathering methods. Employers are primarily inter-
ested in assessing candidates ’ competitiveness when making
recruitment decisions. However, obtaining this information
directly is challenging, so employers rely on various indirect
techniques.
Discrimination carries both individual and societal economic
costs. The social cost arises from the decrease in overall economic
output caused by discrimination. However, this is still deemed
efﬁcient under imperfect information and aligns with the
employer’s proﬁt maximization goal. Therefore, it is likely that",8.367995501,0,"The generated answer claims the optimization factor is 'gender', while the ground truth states it is 'cost-effectiveness'. These are fundamentally different causal explanations for the discriminatory outcome and are therefore contradictory.",0,"The generated answer is not faithful. It claims that the optimization factor leading to discriminatory outcomes is 'Geschlecht' (gender). The context states that it is more 'profitabler' (profitable) from a 'marktwirtschaftlichen Perspektive' (market-economic perspective) to show different ads to men and women. This implies the optimization is for profit or cost-effectiveness, which then results in differentiation by gender, but the context does not state that the optimization is *for* the factor of gender itself.",1,"The context is highly relevant. It directly states that from a 'marktwirtschaftlichen Perspektive' (market/economic perspective), which is equivalent to cost-effectiveness, it is more profitable for companies to show men ads for STEM jobs and women ads for cosmetic products, thus leading to discriminatory outcomes."
"In the context of the STEM career ad study, what was the difference in click behavior between men and women who were shown the ad?","Among those who saw the ad, women were more likely to click on it than men.","Die bereitgestellten Informationen geben keinen Hinweis auf einen Unterschied im Klickverhalten zwischen Männern und Frauen, die eine Anzeige für STEM-Berufe sahen. Der Text konzentriert sich auf andere Aspekte, wie historische Daten, die zu systematischen Verzerrungen in der Bewertung von Bewerbungen führten, und die Problematik der Verzerrungen in Trainingsdaten für KI-Systeme.","Frauen,
wie hoch ist denn für Männer?
Wurde dann gesehen,
dass sie für Frauen systematisch
bei gleichen Qualifikationen
systematisch schlechter war.
Woher kann das kommen,
dass das System das trotzdem 
erkannt hat oder
diesen Bias reproduziert hat,
der in den historischen Daten 
vorgelegen hat?
In der Vergangenheit waren viel 
mehr Männer
an den großen Universitäten,
haben dann mehr technische 
Berufe gehabt oder
technische Studiengänge sind 
dann
eher in den technischen Berufen,
so dass der Anteil der Frauen
in den Daten einfach viel 
geringer war,
was das System interpretiert hat 
als naja,
Frauen sollte ich nicht 
anstellen.
Ich wollte noch sagen, dass 
vielleicht auch andere
Ideen also nicht identifizieren 
würde.
Ich weiß es nicht.
Amazon wird wahrscheinlich nicht 
Körpergröße benutzen,
aber beschnittene Männer eher 
größer.
Und dann so welche Daten genau 
in die Richtung?
Das sind andere Korrelationen.
Ich muss nicht genau ihr 
Geschlecht
wissen oder ihre Identifikation
mit einem bestimmten Geschlecht.
Ich kann über ganz viele andere
korrelative Maße ein sehr
guter Einschätzung davon 
bekommen,
ob sie sich mit
einem bestimmten Geschlecht 
identifizieren.
Hier in diesem Fall war es 
tatsächlich die gesagt Na ja,
per Gesetz dürfen wir nicht auf 
Gender gucken.
Was also gemacht wurde,
ist man hat die Gendermerkmale,
also die selbst angegebenen 
Geschlecht.
Geschlechtsidentifikation hat 
man rausgenommen.
Es war also nicht Teil des 
Systems.
Trotzdem in diesem Testbereich,
wenn wir in dem Crisp an 
Evaluation denken,
bevor das System wirklich live 
gegangen
ist und massiv eben angefangen 
hat,
die neue Einstellungskriterien 
zu beeinflussen,
haben bestimmte Tests gezeigt.
Naja, obwohl ich nicht angegeben 
habe,
ob diese Person, obwohl das 
Modell nicht in der Lage war,
auf Informationen über die
Geschlechtsidentifikation diese 
Person zuzugreifen,
hat das System systematisch
bei Frauen eine geringere 
Wahrscheinlichkeit ausgespuckt.
Woher kann das kommen? Was 
denken Sie?
Ich habe nicht dem Modell Zugang 
zu dem
eigentlichen 
Genderidentification gegeben
und trotzdem in Tests.
Wenn ich dann gesagt habe, naja,
wie hoch ist denn die 
Vorhersagegenauigkeit für 
Frauen,
wie hoch ist denn für Männer?
Wurde dann gesehen,
dass sie für Frauen systematisch
bei gleichen Qualifikationen
systematisch schlechter war.
Woher kann das kommen,
dass das System das trotzdem 
erkannt hat oder
diesen Bias reproduziert hat, Das hat Google jetzt anscheinend 
durch Filter so gemacht,
dass wenn man Krankenpfleger 
eingibt,
dass sowohl Männer und Frauen 
gezeigt werden.
Aber bis vor zwei Jahren war
es immer noch ein sehr gutes 
Beispiel.
Wenn ich Sie frage, googeln Sie 
mal bitte nach Images.
Dann war Krankenpfleger zu 99 %
weiblich und Arzt zu 99 % 
männlich,
obwohl diese Bilder natürlich 
von beiden
eigentlich schon vorhanden sein 
sollen.
Das heißt, wir haben hier
irgendwelche gewachsenen 
technischen Grundlagen,
Datenbanken, die das einfach 
noch nicht abbilden können.
Having said that, die 
Unternehmen sind
sehr sensibilisiert durch diese 
ganzen PR Probleme,
die sie damit erlitten haben und 
haben angefangen,
diese Daten zu bereinigen.
Aber das erfordert eben massiv 
viel Investitionen
in Datenbereinigung,
wo wir wieder in dem 
Kriegsmodell,
bei dem Data Preparation sind.
Sie müssen sich klar sein Wie 
sind
Ihre Strukturen der Daten 
eigentlich aufgebaut?
Soweit ich weiß es auch manchmal
das Labeling von Menschen 
gemacht.
Richtig? Genau. Es könnte so 
sein,
dass wir haben eine Gruppe von 
Menschen,
die nicht politisch korrekt 
denken.
Und dann würden sie es bewusst 
falsch.
Richtig. Auch ein massives 
Problem.
Wir haben auf der einen Seite",9.80636549,0,"The generated answer is a refusal to answer, stating there is no information in the text. The ground truth provides a specific, factual answer about click behavior. The answers are contradictory.",1,"The generated answer is faithful. It correctly states that the retrieved context does not contain information about the click behavior of men and women. It also accurately summarizes the actual content of the context, which discusses historical data bias and biased AI recruiting tools.",0,"The context is irrelevant. It discusses an AI system that, due to historical data bias, systematically produced lower probability scores for women even when the 'gender' feature was removed. It does not mention a study on STEM career ads or any difference in click behavior between men and women."
"In the empirical study of gender-based discrimination in STEM ad display, what reason is given for why fewer women saw the advertisement?","Younger women are a prized demographic and are more expensive to show ads to, so a cost-optimizing algorithm shows the ad to them less often.","Die empirische Studie nennt keinen Grund, warum weniger Frauen die Anzeige sahen. Sie beschreibt, wie das System trotz des Ausschlusses von Geschlechtsidentifikationsmerkmalen systematisch bei Frauen eine geringere Wahrscheinlichkeit für Vorhersagen von Kreditwürdigkeit ausspuckte.","und das implizit lernen.
Und das ist sehr, sehr, sehr 
versteckt ist,
wo eigentlich jetzt eine 
Diskriminierung herkommt.
Wenn wir es aber drin lassen,
gibt es bestimmte Methoden, das 
direkt abzulesen.
Aber die Frage was will man denn 
da,
um das zu prüfen?
Alle anderen Faktoren, die
dieses Modell reingehen, 
funktionieren,
weil sonst könnte man ja die
Aussage eigentlich treffen 
Genau,
Sie würden sie würden die 
trainierte Maschine nehmen,
würden Vorhersagen machen für 
alle
Frauen im Raum, für alle Männer 
im Raum,
für alle nonbinäre Gender im
Raum und würden das dann im 
Aggregat hierbei.
Deswegen reden wir über dieses 
Group Fairness Vergleich.
Hierbei. Jetzt haben wir die 
Equal Opportunity.
Schauen Sie sich an, wir haben 
hier die
Wahrscheinlichkeit, dass 
vorhergesagt wird,
jemand ist kreditwürdig,
obwohl diese Person eigentlich 
nicht kreditwürdig ist.
Vorhersage ist eins True Outcome
ist null für alle Personen im 
Raum,
die das weibliche Geschlecht
haben und dass diese Fehlerrate,
weil wir sprechen ja hier von 
der
Vorhersage eins und ist 
eigentlich null.
Das heißt, wir machen eine 
falsche Vorhersage,
dass dieser Fehler,
dieser false positive. Ich sage, 
es ist positiv.
Eigentlich ist es negativ, gesagt Na ja,
per Gesetz dürfen wir nicht auf 
Gender gucken.
Was also gemacht wurde,
ist man hat die Gendermerkmale,
also die selbst angegebenen 
Geschlecht.
Geschlechtsidentifikation hat 
man rausgenommen.
Es war also nicht Teil des 
Systems.
Trotzdem in diesem Testbereich,
wenn wir in dem Crisp an 
Evaluation denken,
bevor das System wirklich live 
gegangen
ist und massiv eben angefangen 
hat,
die neue Einstellungskriterien 
zu beeinflussen,
haben bestimmte Tests gezeigt.
Naja, obwohl ich nicht angegeben 
habe,
ob diese Person, obwohl das 
Modell nicht in der Lage war,
auf Informationen über die
Geschlechtsidentifikation diese 
Person zuzugreifen,
hat das System systematisch
bei Frauen eine geringere 
Wahrscheinlichkeit ausgespuckt.
Woher kann das kommen? Was 
denken Sie?
Ich habe nicht dem Modell Zugang 
zu dem
eigentlichen 
Genderidentification gegeben
und trotzdem in Tests.
Wenn ich dann gesagt habe, naja,
wie hoch ist denn die 
Vorhersagegenauigkeit für 
Frauen,
wie hoch ist denn für Männer?
Wurde dann gesehen,
dass sie für Frauen systematisch
bei gleichen Qualifikationen
systematisch schlechter war.
Woher kann das kommen,
dass das System das trotzdem 
erkannt hat oder
diesen Bias reproduziert hat, 0% in Iterations 1 (left panel) to 22% in Iteration 100 
(right panel) if there is no human discrimination (z-axis). 
However, this growth is significantly curtailed, reaching 
merely 1.2%, 6.9%, 14.3% under very high, high, and 
medium human discrimination, respectively. 
Conversely, human discrimination against women does 
not alter the share of positive predictions for male 
borrowers (see Figure A7 in the Appendix), regardless of 
the initial label imbalance. For example, at maximum 
label imbalance, the positive predictions  for men 
minimally fluctuate, moving from 34.4% to 36.1% 
without human discrimination and to 33.8% with very 
high human discrimination (36.3% and 34.2% for high 
and medium levels of human discrimination, 
respectively). Our regression analyses (see Table A2 in 
the Appendix) statistically corroborate these findings. 
Regression estimates in Column (1) suggest that for an 
initially unbiased model under high and very high human 
discrimination, the gender gap widens by about 0.07 
percentage points per iteration, or 7 percentage points 
across all 100 iterations.",9.12384057,0,"The generated answer is a refusal to answer, stating no reason is given. The ground truth provides a specific, detailed reason. The answers are contradictory.",1,"The generated answer is faithful. It correctly states that the retrieved context does not give a reason why fewer women saw a specific ad. It accurately describes a different example that is present in the context, regarding a system showing lower probability for women in creditworthiness predictions even after gender features were removed.",0,The context is entirely irrelevant. It discusses fairness metrics like 'Equal Opportunity' in the context of creditworthiness predictions and how a model might have different error rates for different genders. It does not mention a study on STEM ad displays or provide a reason why fewer women saw a particular advertisement.
"Regarding the display of STEM career ads, what was the empirical result of the ad's delivery in the 'Algorithmic Bias?' paper?",Fewer women saw the ad than men.,"According to the text, the empirical results of advertising delivery in the work ‘Algorithmic Bias’ were not explicitly detailed. The text focuses on the broader discussion of algorithmic bias and mitigation strategies, particularly regarding pre-, in-, and post-processing techniques.","that nonobjective variables, such as inadequate information,
contribute to biased outcomes (Dickinson and Oaxaca, 2009).
Lastly, we have the antecedent market discrimination hypothesis
as the fourth category.
Statistical discrimination theory. Statistical discrimination refers
to prejudice from assessment criteria that generalize group
characteristics to individuals (Tilcsik, 2021). It arises due to
limitations in employers’research techniques or the cost con-
straint of obtaining information in the asymmetry between
employers and job seekers. Even without monopolistic power,
statistical discrimination can occur in the labor market due to
information-gathering methods. Employers are primarily inter-
ested in assessing candidates ’ competitiveness when making
recruitment decisions. However, obtaining this information
directly is challenging, so employers rely on various indirect
techniques.
Discrimination carries both individual and societal economic
costs. The social cost arises from the decrease in overall economic
output caused by discrimination. However, this is still deemed
efﬁcient under imperfect information and aligns with the
employer’s proﬁt maximization goal. Therefore, it is likely that 15. Mai 2025
Algorithmic bias
Algorithmic bias: outputs of an algorithm benefit or disadvantage certain individuals or groupsmore than others without a justified reasonfor such unequal impacts •Ethical concern is the replication and reinforcement of social biasesthat exist in society•Algorithmic bias is a socio-technical constructthat involves technology and human actors•Social aspect: biases that have long existed in society•Technical facet: the manifestation of social biases in models’ outcomes
14 significant consequences, such as in healthcare, loan 
approval, hiring, or criminal justice systems. 
Mitigating algorithmic discrimination : The 
expansive literature on algorithmic discrimination 
proposes various methods to identify and alleviate 
such biases. According to d ’Alessandro et al. (2017), 
we can divide these mitigation strategies into three 
categories: pre -processing, in -processing, and post -
processing. Pre -processing strategies strive to 
eliminate disparities inherent in the dataset. Methods 
such as those proposed by Kamiran and Calders (2012) 
and Zafar et al. (2017) employ data pre -processing 
techniques like feature massaging and reweighting to 
balance the dataset based on social group 
characteristics. In -processing strategies involve 
conventional learning algorit hms during model 
training. Researchers often use techniques like naive 
Bayes and decision tr ees for debiasing (Calders & 
Verwer, 2010; Zhang et al., 2018). Additional research 
suggests placing constraints on the classification 
model to mandate the satisfaction of a proxy 
(Woodworth et al., 2017). Lastly, post -processing 
strategies aim to adjust the output to counter biases. 
For example, Corbett -Davies et al. (2017)",6.994228125,0,"The generated answer is a refusal to answer, stating the results were not detailed. The ground truth provides the specific empirical result. The answers are contradictory.",1,"The generated answer is faithful. It correctly states that the context does not detail the empirical results of the ad delivery. It also accurately summarizes the actual content of the retrieved context, which focuses on general theories of algorithmic bias and mitigation strategies.",0.2,"The context discusses the general concepts of statistical discrimination and mitigation strategies for algorithmic bias. However, it does not provide any specific empirical results from the 'Algorithmic Bias?' paper regarding the delivery of STEM career ads. The relevance is very low as it only touches on the broad topic."
"In the study on gender-based discrimination in STEM career ads, what was the explicit intention for the ad's delivery?",The ad was explicitly intended to be gender-neutral in its delivery.,"Die Studie untersuchte, ob Algorithmen bei der Anzeige von Stellenanzeigen für STEM-Berufe (Wissenschaft, Technologie, Ingenieurwesen, Mathematik) geschlechtsspezifische Diskriminierung zeigten. Die explizite Absicht der Auslieferung der Anzeigen war, die Darstellung von Karrieremöglichkeiten für Frauen und Männern zu untersuchen und zu sehen, ob das System systematisch Frauen benachteiligte, selbst wenn sie ähnliche Qualifikationen hatten.","maintained ten years. After applying an initial screening related
to titles, keywords, or abstracts, the literature was selected based
on its relevance to the research topic.
The obtained literature was studied in depth to reveal the
surfaced themes. Several systematic research themes were iden-
tiﬁed, including AI-based recruitment applications and beneﬁts,
causes of algorithmic discrimination, which algorithmic recruit-
ment discrimination exists, and algorithmic recruitment dis-
crimination resolution.
The process applied for the reviews depicted in Fig.1. After
excluding duplicates and less relevant and outdated literature,
only 45 articles could be used as references for this study (referred
to Table1). The literature review shows that most of the research
on algorithmic hiring discrimination has occurred in recent years.
The research trend indicates that algorithmic hiring discrimina-
tion will be a hot research topic in the coming period.
1. The ﬁrst theme is the application of various aspects of
recruitment based on artiﬁcial intelligence support and its
beneﬁts. Bogen and Rieke (2018), Ahmed (2018), Hmoud
and Laszlo (2019), Albert (2019), van Esch et al. (2019),
Köchling et al. ( 2022), and Chen ( 2023) consider the gesagt Na ja,
per Gesetz dürfen wir nicht auf 
Gender gucken.
Was also gemacht wurde,
ist man hat die Gendermerkmale,
also die selbst angegebenen 
Geschlecht.
Geschlechtsidentifikation hat 
man rausgenommen.
Es war also nicht Teil des 
Systems.
Trotzdem in diesem Testbereich,
wenn wir in dem Crisp an 
Evaluation denken,
bevor das System wirklich live 
gegangen
ist und massiv eben angefangen 
hat,
die neue Einstellungskriterien 
zu beeinflussen,
haben bestimmte Tests gezeigt.
Naja, obwohl ich nicht angegeben 
habe,
ob diese Person, obwohl das 
Modell nicht in der Lage war,
auf Informationen über die
Geschlechtsidentifikation diese 
Person zuzugreifen,
hat das System systematisch
bei Frauen eine geringere 
Wahrscheinlichkeit ausgespuckt.
Woher kann das kommen? Was 
denken Sie?
Ich habe nicht dem Modell Zugang 
zu dem
eigentlichen 
Genderidentification gegeben
und trotzdem in Tests.
Wenn ich dann gesagt habe, naja,
wie hoch ist denn die 
Vorhersagegenauigkeit für 
Frauen,
wie hoch ist denn für Männer?
Wurde dann gesehen,
dass sie für Frauen systematisch
bei gleichen Qualifikationen
systematisch schlechter war.
Woher kann das kommen,
dass das System das trotzdem 
erkannt hat oder
diesen Bias reproduziert hat, Journal of the Association for Information Systems 
 
828 
Köchling, A., & Wehner, M. C. (2020). Discriminated 
by an algorithm: a systematic review of 
discrimination and fairness by algorithmic 
decision-making in the context of HR 
recruitment and HR development. Business 
Research, 13(3), 795-848.  
Kusner, M. J., & Loftus, J. R. (2020). The long road to 
fairer algorithms. Nature, 578(7793), 34-36. 
Lahey, J. N. (2008). Age, women, and hiring an 
experimental study. Journal of Human 
Resources, 43(1), 30-56.  
Lakkaraju, H., Kleinberg, J., Leskovec, J., Ludwig, J., 
& Mullainathan, S. (2017). The selective labels 
problem: Evaluating algorithmic predictions in 
the presence of unobservables. Proceedings of 
the ACM SIGKDD International Conference on 
Knowledge Discovery and Data Mining  (pp. 
275-284).  
Lakkaraju, H., & Rudin, C. (2017). Learning cost -
effective and interpretable treatment regimes. 
Proceedings of the 20th International 
Conference on Artificial Intelligence and 
Statistics (pp. 166-175).  
Lambrecht, A., & Tucker, C. (2019). Algorithmic 
bias? an empirical study of apparent gender -
based discrimination in the display of stem 
career ads. Management Science, 65(7), 2966-
2981.",11.78093243,0.3,"The generated answer is not semantically consistent with the ground truth. The ground truth states the *intention* was for the ad to be gender-neutral. The generation describes the *goal of the study*, which was to investigate if discrimination was occurring. These are different concepts; the study's goal was to test if the neutral intention was met in practice.",1,The generated answer is faithful. The context cites a paper on 'gender-based discrimination in the display of stem career ads' and describes a test where the system's output for women was found to be 'systematisch schlechter' even with the same qualifications . The generated answer accurately synthesizes this information to describe the intention of the study.,1,The context is highly relevant. It describes a study where gender characteristics were explicitly removed from the system ('man hat die Gendermerkmale ... rausgenommen') by law ('per Gesetz dÃ¼rfen wir nicht auf Gender gucken'). This directly supports the idea that the explicit intention was for the process to be gender-neutral.
The findings of the 'Feeback Loops in Machine Learing' paper underscore the complex nature of algorithmic discrimination as what kind of phenomenon?,A sociotechnological phenomenon.,"Die Ergebnisse des Papiers 'Feedback Loops in Machine Learning' betonen die komplexe Natur der algorithmischen Diskriminierung als ein Phänomen, das durch die Interaktion zwischen ML-Systemen und menschlichen Benutzern in Umgebungen entsteht, in denen kontinuierlich aktualisierte ML-Modelle erforderlich sind. Es zeigt sich, dass Menschen die Lernfähigkeiten von ML-Systemen untergraben und diese dazu bringen können, diskriminierendes Verhalten zu verstärken oder zu übernehmen.","Feedback Loops in Machine Learning 
 
807 
2.1 Algorithmic Discrimination 
Algorithmic discrimination: Discrimination involves 
statements or actions that unjustifiably disadvantage 
members of particular social groups. These actions 
typically stem from conscious or subconscious attitudes, 
prejudices, or emotional associations tied to 
characteristics such as  gender, age, disability, race, 
language, religion, or sexual identity (Scherr, 2008). In 
today’s era, where algorithmic systems based on ML 
models frequently aid human decisions, researchers and 
practitioners often employ the te rm “algorithmic 
discrimination” to refer to system outputs that 
disproportionately benefit or disadvantage specific 
groups, even when no justification for the disparate 
treatment exists from a ground -truth perspective 
(Kordzadeh & Ghasemaghaei, 2022).1  
Algorithmic discrimination can originate from various 
sources. First, it may stem from intentional or 
unintentional social biases encoded within the training 
data (Friedman & Nissenbaum, 1996; Romei & Ruggieri, 
2013; Kleinberg et al., 2018). For example, if a training 
dataset holds more positively labeled examples for men, 
the ML model may predict positive labels less accurately Feedback Loops in Machine Learning 
 
815 
 
Note: Panel (i) illustrates outcomes where the initial label imbalance for the minority class was at the maximum, whereas Panel (ii) corresponds 
to conditions with no initial label imbalance 
Figure 4. Progression of the Mean Share of Positive Predictions and False-Negative Error Rates  
across Iterations, Differentiated by Gender over Time 
4.1 Continuous Updating and 
Algorithmic Discrimination 
Figure 4 illustrates the temporal evolution of mean 
shares of positive predictions and false-negative errors 
in the absence of human discrimination . We present 
separate results for female  (dashed lines)  and male 
borrowers (solid lines). Panel (i ) outlines simulation 
results for our treatment condition with maxim um 
initial training data label imbalance —where there are  
no repayment examples. Panel (ii) presents results for 
our control condition without initial label imbalance. 
Our findings indicate that the continuous updating of 
machine learning (ML) models can help reduce 
algorithmic discrimination over time, as measured by 
statistical parity. In situations where there was a 
substantial initial label imbalance leading to discrimination. We highlight that continuous updating, 
absent enduring human discrimination, may stimulate  
self-correcting mechanisms. Theoretically, our findings 
underscore the sociotechnological nature of algorithmic 
discrimination. We extend the existing literature by 
revealing how algorithmic discrimination can diminish 
or emerge due to the interaction bet ween ML systems 
and human users in environments where continuous ly 
updating ML models is essential. We f ound evidence 
that humans in the loop can undermine the powerful 
learning capabilities of ML systems, inadvertently 
teaching the machines to maintain or even adopt 
discriminatory behaviors over time. Our insights 
provide a novel, dynamic perspective on algorithmic 
discrimination, enhancing the comprehension of its 
origins and moderating factors and highlighting the 
potency of continuous model updating to mitigate it. 
Our findings also speak to broader discussions on ways 
to address model drift challenges (see, e.g., Mallick et 
al., 2022). In our context, unjustified algorithmic 
discrimination can be thought of as an outdated input -
output relationship that the model learned from training 
data, i.e., as resulting from a concept drift. On the other",11.47098446,1,"The generated answer is semantically consistent with the ground truth. It correctly identifies algorithmic discrimination as a sociotechnological phenomenon and adds accurate, directly related details about the interaction between ML systems and human users.",1,The entire generated answer is directly supported by the provided context. The context explicitly states that 'our findings underscore the sociotechnological nature of algorithmic discrimination' [cite: 245] [cite_start]and that discrimination can emerge 'due to the interaction between ML systems and human users' [cite: 246] [cite_start]where 'humans in the loop can undermine the powerful learning capabilities of ML systems'[cite: 247].,1,"The context directly answers the question. It explicitly states, 'Theoretically, our findings underscore the sociotechnological nature of algorithmic discrimination.'"
What type of setting was used in the simulations of the 'Feedback Loops in Machine Learning' paper to examine the ML model's evolution?,"A setting that mirrors sequential interactions, such as loan approval decisions.","Im Paper 'Feedback Loops in Machine Learning' wurde eine Umgebung mit einem Investmentspiel verwendet, in der Teilnehmer als Kreditnehmer und Investoren agierten. Diese Umgebung diente dazu, die Entwicklung von ML-Modellen unter Berücksichtigung von Drift und Feedback-Schleifen zu untersuchen.","Feedback Loops in Machine Learning 
 
805 
generate predictions (Parisi et al., 2019). However, in 
dynamic, nonstationary environments, the underlying 
data-generating process that ML models aim to 
approximate can change over time. This phenomenon, 
referred to as drift (Lu et al., 2018), can lead to  
progressively poorer predictions. The decrease in 
prediction performance can originate from changes in 
the underlying relationship between the input features 
and the target variable —concept drift (Widmer & 
Kubat, 1996)—or changes in the distributions of t he 
input features or the target variable—data drift (Mallick 
et al., 2022). As a consequence, to maintain or even 
improve prediction accuracy over time, it is imperative 
to continuously update ML models on recent data that 
reflect new patterns in the data -generating process 
(Gama et al., 2014). 
The efficacy of continuous updating inherently links to 
the quality and structure of the collected data. Ideally, 
updating processes should empower models to learn 
from their past mistakes —that is, identify cases for 
which they generate inaccurate predictions. However, 
ML models that support or automate human decisions 
typically do more than merely provide neutral Feedback Loops in Machine Learning 
 
811 
3.2 Previous Empirical Studies 
We buil t our simulations on two secondary datasets, 
collected by several authors of this paper as part of 
different empirical studies. Study A was an incentivized 
field study conducted over three years from 2016 to 
2019. Study A measured participant s’ behavior in the 
investment game  defined above  in their  role as 
borrowers. The data from Study A allow ed us to 
develop an ML model predicting borrowers’ repayment 
decision and serves as the foundation for simulating 
borrower behavior. Study B, conducted in December 
2020, was an incentivized online experiment where 
participants engaged in the outlined investment game in 
the role of investors. In this experiment, investors could 
access an ML model predicting borrowers ’ repayment 
likelihood. Notably, this model, along with the 
borrowers with whom investors from Study B 
interacted, originated from Study A data. The data from 
Study B provide d the basis for simulating investor 
decisions. We present the exact instructions given in 
these studies in Appendix B.1. 
Study A: At the onset of each semester, first -semester 
economics students from a large German university were Feedback Loops in Machine Learning 
 
859 
Appendix C: Technical Details on Simulation 
C.1 Details on the Repayment-Predicting ML Model in Simulations 
To gain insights into the determinants of the predictions of the ML model that aims to forecast whether borrowers will 
make a repayment, we use the popular SHAP (Shapley additive explanations) explainability method (Lundberg & Lee, 
2017). Notably, we show results for the models ’ behaviors before any updating takes place. SHAP is inspired by 
cooperative game theory explaining individual predictions by assuming that each feature value of the instance is a 
player in a game where the prediction is the payout. Estimated SHAP values describe the average marginal contribution 
of a feature value across all possible feature coalitions of a given instance. By averaging the SHAP values across all 
possible values a feature can take on, we obtain ed a reliable measure of this feature’s importance for the prediction 
task. In the following, we show SHAP values for initially biased and unbiased ML models. Each figure contains 
information on the overall importance of each feature for the prediction (higher position in the vertical ranking) and",8.691168547,1,"The generated answer is semantically consistent with the ground truth. The ground truth gives a concise description of the setting, and the generation provides a more detailed but entirely accurate and consistent description of that same setting, including the roles of participants as borrowers and investors.",1,"The generated answer is faithful. [cite_start]The context states that the simulations were built on two secondary datasets from empirical studies[cite: 259]. [cite_start]Study A involved an 'investment game' with participants as 'borrowers' [cite: 260][cite_start], and Study B involved the same 'investment game' with participants as 'investors'[cite: 262]. This setting mirrors sequential interactions like loan approvals.",1,The context directly answers the question by describing the setting used for the simulations. It mentions that the simulations were built on two secondary datasets from empirical studies (Study A and Study B) that both used an 'investment game' where participants acted as borrowers and investors.
What is the key finding regarding the continuous updating of ML models?,Continuous updating can help mitigate algorithmic discrimination and enhance economic efficiency over time.,That’s correct. The study shows that humans can undermine the learning capabilities of ML systems and cause them to adopt or reinforce discriminatory behaviors.,"discrimination. We highlight that continuous updating, 
absent enduring human discrimination, may stimulate  
self-correcting mechanisms. Theoretically, our findings 
underscore the sociotechnological nature of algorithmic 
discrimination. We extend the existing literature by 
revealing how algorithmic discrimination can diminish 
or emerge due to the interaction bet ween ML systems 
and human users in environments where continuous ly 
updating ML models is essential. We f ound evidence 
that humans in the loop can undermine the powerful 
learning capabilities of ML systems, inadvertently 
teaching the machines to maintain or even adopt 
discriminatory behaviors over time. Our insights 
provide a novel, dynamic perspective on algorithmic 
discrimination, enhancing the comprehension of its 
origins and moderating factors and highlighting the 
potency of continuous model updating to mitigate it. 
Our findings also speak to broader discussions on ways 
to address model drift challenges (see, e.g., Mallick et 
al., 2022). In our context, unjustified algorithmic 
discrimination can be thought of as an outdated input -
output relationship that the model learned from training 
data, i.e., as resulting from a concept drift. On the other imbalance combined with high or very high levels of 
human discrimination (see Columns 4 and 5).  
In sum, these results emphasize that the capacity of 
continuous ML model updating to mitigate algorithmic 
discrimination critically relies on the absence of 
discriminatory behavior by human decision makers. If 
such behaviors persist —potentially giving rise to the 
initial label imbalance in the training data—continuous 
updating has a minimal effect on improving the ML 
model’s behavior toward the discriminated group. Our 
findings even suggest that human discrimination can 
cause ML models, originally trained on balanced data and 
displaying no algorithmic discrimination, to adopt 
increasingly discriminatory behaviors, as measured by 
statistical parity. In the context of our loan approval 
example, the results reveal that the efficacy of 
continuously updated ML models notably declines if a 
loan officer persistently discriminates against female 
applicants, regardless of the creditworthiness assessment 
generated by the ML model. Consequently, the ML 
model’s prediction may persistently demonstrate gender 
disparity across two key dimensions: the ML model ’s 
propensity to deem female applicants as creditworthy and discrimination, as human discrimination hinders the self-
correcting capacities of ML models. Therefore, in 
conjunction with these regulations, we advocate 
measures aimed at identifying and mitigating 
(subconscious) discriminatory practices by 
organizational decision makers. These measures could 
serve as essential complementary elements to ensure that 
continuously updated ML models demonstrate desirable 
behaviors when organizations implement regulatory 
requirements that involve humans in the decision loop. 
5.4 Limitations and Future Research  
Like any study, this study also has limitations—which, 
we believe , provide valuable directions for future 
research to enhance our understanding of how 
algorithmic discrimination evolves in environments 
where ML models undergo continuous updates. One",6.703697205,1,"The generated answer is semantically consistent with the ground truth. The ground truth states that continuous updating can help mitigate algorithmic discrimination. The generated answer states that humans can undermine this process, which is a key part of the same finding, making them consistent.",0.5,"The first part of the generated answer, stating that 'continuous updating can help mitigate algorithmic discrimination,' is faithful and directly supported by the context[cite: 274]. However, the second part of the answer, which claims humans can cause systems to 'adopt or reinforce discriminatory behaviors,' contradicts the first part and is an incomplete representation of the context, which presents this as a potential negative outcome that continuous updating helps to mitigate.",1,"The context is highly relevant as it directly discusses the effects of continuous model updating. It states that continuous updating 'may stimulate self-correcting mechanisms' and can mitigate algorithmic discrimination, but also warns that this capacity 'critically relies on the absence of discriminatory behavior by human decision makers.'"
How do ML models endogenously shape their future training data?,"By influencing human decisions, which then generate new data points (or a lack thereof) for future model training.","Basierend auf dem bereitgestellten Text beeinflussen ML-Modelle ihre zukünftigen Trainingsdaten durch einen Prozess, der als „selektive Kennzeichnung“ (selective labeling) bezeichnet wird. Hier die wichtigsten Punkte:

*   **Endogene Datengestaltung:** ML-Modelle beeinflussen die Zusammensetzung der Daten, die für ihre kontinuierliche Aktualisierung zur Verfügung stehen, selbst.
*   **Vorhersagen beeinflussen neue Daten:** Die Vorhersagen, die das Modell trifft, führen dazu, dass neue Daten erstellt werden, die für das Modell als Trainingsdaten verwendet werden.
*   **Selektive Kennzeichnung:** Diese endogene Datengestaltung kann die Vorhersagen des Modells entweder aufrechterhalten oder sogar verschärfen, wenn die Vorhersagen des Modells diskriminierend sind.

Zusammenfassend lässt sich sagen, dass ML-Modelle nicht nur aus Daten lernen, sondern auch aktiv die Art der Daten beeinflussen, die für ihre Weiterentwicklung verwendet werden, was zu einer Art Feedback-Schleife führen kann.","a data -generating process distinct from subsequent 
simulation iterations, then the ML model’s bias against 
women essentially emerges from a concept dri ft 
(Widmer & Kubat, 1996). This means the initial ML 
model approximates a once-accurate but now outdated 
data-generating process. The observed feedback loop, 
where the ML model progressively becomes less 
biased, then demonstrates its ability to overcome 
concept drifts when updated with new training data it 
influences. Conversely, persistent human 
discrimination shifts the training data ’s gender 
composition, increasingly diverging from the borrower 
pool over iterations. However, the core relationship 
between borrower attributes and their repayment 
propensity remains unchanged. Thus, ongoing human 
discrimination aligns with a n ongoing  data drift 
(Mallick et al. , 2022), as the incoming data ’s 
composition on which the model predicts, deviates 
from its training data. With biased decision-making by 
humans in the loop  undermining the discriminating 
ML model ’s capacity to self -correct, i.e., overcome 
concept drift through continuous updating, one may 
interpret our finding s as evidence for an adverse 
interaction between a data and a concept drift that availability of this data point for future model updates and potentially affecting the model ’s 
performance. This paper delves into the relationship between the continuous updating of ML models 
and algorithmic discrimination in environments where predictions endogenously influence the 
creation of new training data. Using comprehensive simulations based on secondary empirical data, 
we examine the dynamic evolution of an ML model ’s fairness and economic consequences in a 
setting that mirrors sequential interactions, such as loan approval decisions. Our findings indicate 
that continuous updating can help mitigat e algorithmic discrimination and enhance economic 
efficiency over time. Importantly, we provide evidence that human decision makers in the loop who 
possess the authority to override ML predictions may impede the self -correction of discriminatory 
models and even induce initially unbiased models to become discriminatory with time. These 
findings underscore the complex sociotechnological nature of algori thmic discrimination and 
highlight the role that humans play in addressing it when ML models undergo continuous updating. endogenous composition of future training data, a 
problem referred to as selective labeling (Lakkaraju et 
al., 2017; Little & Rubin, 2019), can maintain or even 
exacerbate inaccurate or discriminatory predictions. 
In this paper, we explore the dynamic interplay 
between the continuous updating of ML models and 
algorithmic discrimination when ML predictions 
endogenously shape the composition of additional data 
available for model updating. In particular, our work 
focuses on the role of ongoing discrimination by 
human decision  makers who have the final say in an 
ML-supported decision-making task. A steady stream 
of previous work has examined how algorithmic 
discrimination can reproduce and perpetuate 
discriminatory patterns ingrained in societal structures 
(Lambrecht & Tucker, 2019; Morse et al., 202 2; 
Teodurescu et al., 2021). Some studies have developed 
theoretical arguments concerning the emergence of 
feedback loops when ML models continually learn 
from the discriminatory outcomes they help ed to 
generate (see, for example, Cowgill & Tucker, 2019; 
Ensign et al., 2017; Silva & Kenney, 2019). However, 
as Kordzadeh and Ghasemaghaei (2022) observed in 
their literature review, systematic empirical",17.72973466,1,"The generated answer is semantically consistent with the ground truth. It correctly identifies that models shape their own training data by influencing human decisions, which is the core concept.",1,The generated answer is faithful to the retrieved context. [cite_start]The context explains that ML predictions 'endogenously shape the composition of additional data available for model updating' [cite: 307] [cite_start]and that this process is referred to as 'selective labeling'[cite: 306].,1,"The context directly answers the question. It explicitly states that 'ML predictions endogenously shape the composition of additional data available for model updating,' a problem referred to as 'selective labeling.' It further explains that this feedback loop occurs when model predictions influence human decisions, which in turn generate the new data used for model updates."
What effect can human decision-makers have on the self-correction of discriminatory models when they are kept in the loop?,Human decision-makers in the loop may impede the self-correction of discriminatory models and can even cause initially unbiased models to become discriminatory over time.,"Laut dem Text haben menschliche Entscheidungsträger negative Auswirkungen auf die Selbstkorrektur diskriminierender Modelle, wenn sie in den Prozess einbezogen werden. Konkret heißt es:

*   **Menschliche Diskriminierung behindert die Selbstkorrektur:** Wenn menschliche Entscheidungsträger diskriminierende Praktiken anwenden, kann dies die Fähigkeit der ML-Modelle, sich selbst zu korrigieren, beeinträchtigen.
*   **Notwendigkeit ergänzender Maßnahmen:** Um sicherzustellen, dass kontinuierlich aktualisierte ML-Modelle wünschenswerte Verhaltensweisen zeigen, sind Maßnahmen zur Identifizierung und Minderung (unbewusster) diskriminierender Praktiken von Entscheidungsträgern erforderlich.

Zusammenfassend lässt sich sagen, dass menschliche Einflüsse die Fähigkeit der Modelle, sich selbst zu korrigieren, untergraben und ergänzende Maßnahmen zur Kontrolle menschlicher Diskriminierung erforderlich machen.","Journal of the Association for Information Systems 
 
824 
Indeed, self-correcting mechanisms may require time 
to take effect, during which disadvantaged social 
groups may continue to endure discriminatory 
practices. Rather, we perceive our findings as a 
testament to the substantial learning capabilities of 
modern ML models undergoing continuous updating. 
We argue that these capabilities can complement other 
interventions aimed at addressing algorithmic 
discrimination, such as the proper preprocessing of 
training data. This approach is particularly effective 
when organizations take measures to ensure that their 
employees do not engage in (subconscious) 
discriminatory practices during ML -supported 
decision-making processes. However, overreliance on 
the self -correcting aspects of continuous updating 
processes could cause significant damage to both an 
organization’s economic performance and reputation if 
ML systems are deployed hastily without rigorous ly 
testing for and addressing algorithmic discrimination. of inadvertently perpetuating or igniting algorithmic 
discrimination if these individuals engage in 
discriminatory practices. In this context, efforts aimed at 
identifying and mitigating (subconscious) discriminatory 
practices of organizational decision  makers, such as 
awareness training, become an indispensable 
complementary element to ensure that continuously 
updated ML models exhibit desirable behaviors. 
2 Theoretical and Conceptual 
Background 
In this section, we first provide the conceptual 
underpinnings of algorithmic discrimination. 
Subsequently, we discuss the literature gaps our work 
aims to address. discrimination, as human discrimination hinders the self-
correcting capacities of ML models. Therefore, in 
conjunction with these regulations, we advocate 
measures aimed at identifying and mitigating 
(subconscious) discriminatory practices by 
organizational decision makers. These measures could 
serve as essential complementary elements to ensure that 
continuously updated ML models demonstrate desirable 
behaviors when organizations implement regulatory 
requirements that involve humans in the decision loop. 
5.4 Limitations and Future Research  
Like any study, this study also has limitations—which, 
we believe , provide valuable directions for future 
research to enhance our understanding of how 
algorithmic discrimination evolves in environments 
where ML models undergo continuous updates. One",16.93880868,1,The generated answer is semantically consistent with the ground truth. Both state that human decision-makers can hinder the self-correction of discriminatory models and cause unbiased models to become biased.,1,The generated answer is faithful. [cite_start]The context explicitly states that 'human decision makers in the loop who possess the authority to override ML predictions may impede the self-correction of discriminatory models and even induce initially unbiased models to become discriminatory with time'[cite: 304].,1,The context directly answers the question by stating that 'human discrimination hinders the self-correcting capacities of ML models.' It further explains that 'efforts aimed at identifying and mitigating (subconscious) discriminatory practices of organizational decision makers' are an 'indispensable complementary element' to ensure models exhibit desirable behaviors.
What is a key challenge with opaque algorithmic designs in recruitment?,"They hinder the detection and correction of biases, making it difficult for HR teams to ensure equitable hiring.","Basierend auf dem Text ist eine zentrale Herausforderung, die mit undurchsichtigen Algorithmen im Einstellungsprozess verbunden ist, dass man sich nur auf einen einzelnen Vorhersagetest konzentriert und die Technologie nicht in die anderen Prozesse integriert. Dies führt dazu, dass man nur auf eine einzelne Vorhersage schaut, anstatt den gesamten Workflow zu berücksichtigen und zu analysieren, welche Veränderungen notwendig sind, um die Technologie wirklich nutzbar zu machen.","Wenn es um die Implementierung 
eines KI Projektes geht.
Und das Wichtige, was ich immer
wieder hervorheben möchte, ist,
dass wir grundsätzlich damit 
anfangen sollten,
uns das Business Problem klar zu 
machen.
Uns geht es erstmal nicht darum,
Algorithmen zu entwickeln, die
schneller sind als vorherige 
Algorithmen,
die irgendwie eine ganz marginal
höhere Prediction probability
haben als vorherige Technologie.
Nein, wir wollen immer direkt 
anfangen mit
Was ist eigentlich unser 
Problem,
was wir lösen können?
Denn häufig wird sich
rausstellen Wir brauchen gar 
keinen Machine Learning.
Wir brauchen gar keine KI 
Systeme.
Es gibt andere Lösungen,
die wir anwenden können.
Eines der grundlegenden 
Probleme,
die im Moment so ein bisschen 
vor allen Dingen in
der Consultancy Industrie sich 
herausstellen,
ist, dass viele sich hinstellen 
und sagen,
KI kann ihnen sehr viel lösen.
Aber in häufigen Fällen gibt
es auch andere Technologien, 
andere Tools,
die eingesetzt werden können,
um bestimmte Business Probleme 
zu lösen.
Aber dafür müssen wir erstmal
ein Verständnis davon haben,
was das eigentlich ist.
Und wenn wir herausgefunden 
haben,
was wir eigentlich lösen wollen,
was eben dieses bestimmte 
Prediction Problem ist, meines Workflows an 
Veränderungen,
damit diese Technologie wirklich 
nutzbar ist?
Brauche ich ein bestimmtes User 
Interface?
Muss ich meine Leute in
einer gewissen Art und Weise 
schulen?
Muss ich den Ablauf der Prozesse 
verändern?
Muss ich beispielsweise, wenn 
ich
bessere Vorhersagen machen kann,
ob ein Mitarbeiter tatsächlich 
in die engere
Auswahl kommen soll oder ein 
Bewerber
in die engere Auswahl kommen 
soll oder nicht?
Hat das natürlich Implikationen,
wenn das alles durch Machine 
Learning sehr gut
automatisiert ablaufen kann.
Wie viele Bewerber ich 
eigentlich händeln kann?
Könnte zur Folge haben,
dass ich innerhalb meines 
Prozesses viel
mehr Ressourcen auf die
Bewerbung der offenen Stelle 
läge,
dass sich andere Quellen der 
Bewerbung,
andere Plattformen nutze,
damit Leute über diese Stelle 
informiert
werden und sich bewerben.
Denn die Prediction Technology 
ist so
genau und so gut, so schnell,
dass ich viel mehr handeln kann 
mit einer höheren
Wahrscheinlichkeit
wider den besseren Bewerber oder 
den besten Bewerber.
Finde aus einer größeren Menge 
von möglichen Bewerbern.
Ich denke also wieder mit Was 
sollte sich innerhalb
meines Prozesses
innerhalb dieses Workflows auch 
verändern?
Integriert mehr Integration? Learning.
Ich habe wirklich nur diesen 
einen Vorhersagetest und den
ersetze ich und ansonsten lasse 
ich
alles genauso wie es ist.
Ich habe also keine
starke Integration der 
Technologie
in meine anderen Prozesse 
hinein,
denn ich gucke immer
nur auf diesen einen bestimmten 
Task,
auf diese eine bestimmte 
Vorhersage, die gemacht wird.
Und wenn wir einen Schritt 
weiter gehen,
dann haben wir die nächste 
Stufe,
die wir innerhalb der 
Organisation die
Applikation oder 
Anwendungslösung nennen.
Bei so einer Lösung haben
wir jetzt nicht einfach nur eine 
einzige Vorhersage,
die durch ein Modell übernommen 
wird,
die es vorher schon gab,
sondern wir haben ein System,
was mehrere häufig von diesen
Points Solutions zusammen nutzt 
Zusammenführt,
was mehr in meine Prozesse 
integriert wird.
Ich denke also auf einer 
größeren
Bandbreite mit Was passiert 
denn,
wenn ich anfange, eine bestimmte 
Vorhersage durch
Machine Learning Applikationen 
besser zu machen?
Was brauche ich noch innerhalb
meines Workflows an 
Veränderungen,
damit diese Technologie wirklich 
nutzbar ist?
Brauche ich ein bestimmtes User 
Interface?
Muss ich meine Leute in
einer gewissen Art und Weise 
schulen?
Muss ich den Ablauf der Prozesse 
verändern?",11.22366548,1,"The generated answer is semantically consistent with the ground truth. The ground truth identifies a key challenge as the difficulty in detecting and correcting biases due to opaque designs. The generation describes a related challenge: the tendency to focus on a single predictive test without integrating it into the broader workflow, which also leads to unresolved issues.",0,"The generated answer is not faithful. It claims the challenge is focusing only on a single prediction test and not integrating the technology. The provided context does not mention opaque algorithms or the challenges associated with them. [cite_start]Instead, it discusses the importance of integrating a prediction technology into the entire workflow[cite: 342, 348].",0.3,"The context discusses a challenge in implementing AI, which is the tendency to focus on a single prediction task ('diesen einen bestimmten Task') without considering the necessary changes to the entire workflow. While this is a valid challenge, it does not directly address the problem of 'opaque' designs hindering the detection and correction of biases. The connection is weak."
"According to some studies cited, what are two benefits of AI-supported recruitment?",It can reduce costs and save time.,"Laut der Studie werden durch KI-gestütztes Recruiting zwei Vorteile genannt:

*   Verbesserte Qualität der Rekrutierung
*   Kostensenkung","REVIEW ARTICLE
Ethics and discrimination in artiﬁcial intelligence-
enabled recruitment practices
Zhisheng Chen 1✉
This study aims to address the research gap on algorithmic discrimination caused by AI-
enabled recruitment and explore technical and managerial solutions. The primary research
approach used is a literature review. Theﬁndings suggest that AI-enabled recruitment has
the potential to enhance recruitment quality, increase efﬁciency, and reduce transactional
work. However, algorithmic bias results in discriminatory hiring practices based on gender,
race, color, and personality traits. The study indicates that algorithmic bias stems from
limited raw data sets and biased algorithm designers. To mitigate this issue, it is recom-
mended to implement technical measures, such as unbiased dataset frameworks and
improved algorithmic transparency, as well as management measures like internal corporate
ethical governance and external oversight. Employing Grounded Theory, the study conducted
survey analysis to collectﬁrsthand data on respondents’ experiences and perceptions of AI-
driven recruitment applications and discrimination.
Introduction
T employment opportunities and the potential for discrimination
without accountability. To harness the beneﬁts of AI in recruiting,
organizations should exercise careful selection of their programs,
promote the adoption of accountable algorithms, and advocate
for improvements in racial and gender diversity within high-tech
companies.
The general construct of this study is,ﬁrst, an extension of
statistical discrimination theory in the context of the algorithmic
economy; second, a synthesis of the current literature on the
beneﬁts of algorithmic hiring, the roots and classi ﬁcation of
algorithmic discrimination; and third, initiatives to eliminate the
existence of algorithmic hiring discrimination; fourth, based on
the Grounded Theory, we conduct surveys with respondents and
analyze primary data to support the study.
The contributions of this study are as follows:
First, discuss job market discrimination theories in the digital
age context. When considering statistical discrimination theories,
we should consider the current circumstances. It is necessary to
apply these discrimination theories to evaluate the issues that
arise from the use of technology in the digital age, particularly that impact the hiring process. It would be interesting to analyze
the psychological effects of applying this algorithmic recruitment
technique on various populations (gender, age, education level)
from an organizational behavior perspective. While recent studies
have primarily discussed discrimination theory in the traditional
economy’s hiring market, future theoretical research should
consider how advanced technology affects equity in hiring within
the digital economy.
Conclusion
The study concludes that the fo urth industrial revolution
introduced technological innovations signiﬁcantly affecting the
recruitment industry. It extends the analysis of statistical dis-
crimination theory in the digital age and adopts a literature
review approach to explore four themes related to AI-based
recruitment. The study argues that algorithmic bias remains an
issue while AI recruitment tools offer beneﬁts such as improved
recruitment quality, cost reduction, and increased ef ﬁciency.
Recruitment algorithms ’bias is evident in gender, race, color,
and personality. The primary source of algorithmic bias lies in
partial historical data. The personal preferences of algorithm
engineers also contribute to algorithmic bias. Technical mea-",6.077848434,0.8,"The generated answer is mostly consistent with the ground truth. The ground truth states the benefits are reducing costs and saving time. The generation states the benefits are 'improved recruitment quality' and 'cost reduction'. 'Increased efficiency' (mentioned in the source) is a close synonym for saving time, and 'improved quality' is another benefit mentioned in the source. So, it captures the core ideas.",0.5,"The generated answer claims two benefits: improved recruitment quality and cost reduction. [cite_start]The context supports both of these claims[cite: 368]. [cite_start]However, it also mentions a third benefit, 'increased efï¬ciency'[cite: 368], which the generated answer omits. The answer is therefore only partially faithful as it presents an incomplete list of benefits mentioned in the source.",1,"The context directly answers the question. It states that 'AI recruitment tools offer beneï¬ts such as improved recruitment quality, cost reduction, and increased ef ï¬ciency.'"
What are two recommended categories of measures to mitigate algorithmic bias in recruitment?,Technical measures (like unbiased dataset frameworks and improved transparency) and management measures (like internal ethical governance and external oversight).,"Laut dem Text werden folgende zwei Kategorien von Maßnahmen empfohlen, um algorithmische Verzerrungen im Recruiting zu mindern:

1.  **Pre-Processing-Strategien:** Diese Strategien zielen darauf ab, Ungleichheiten in den Daten selbst zu beseitigen. Beispiele sind Feature-Massage und Re-Weighting.
2.  **Post-Processing-Strategien:** Diese Strategien zielen darauf ab, die Ausgabe des Algorithmus anzupassen, um Verzerrungen zu korrigieren.","technical and managerial aspects to tackle discrimination in
algorithmic hiring. This study contends that resolving algorithmic
discrimination in recruitment requires technical solutions and the
implementation of internal ethical governance and external
regulations.
The subsequent study is structured intoﬁve parts. The ﬁrst
section provides the theoretical background for this research. The
following section outlines the research methodology employed in
the literature review and identiﬁes four key themes. The third
section delves into a detailed discussion of these four themes:
applications and beneﬁts of AI-based recruitment, factors con-
tributing to algorithmic recruitment discrimination, types of
discrimination in algorithmic recruitment, and measures to
mitigate algorithmic hiring discrimination. The fourth section
involves conducting a survey among respondents and analyzing
the primary data collected to support our study. Theﬁnal section
concludes by suggesting future directions for research.
Theory background
Discrimination theory. Discrimination in the labor market is
deﬁned by the ILO’s Convention 111, which encompasses any
unfavorable treatment based on race, ethnicity, color, and gender significant consequences, such as in healthcare, loan 
approval, hiring, or criminal justice systems. 
Mitigating algorithmic discrimination : The 
expansive literature on algorithmic discrimination 
proposes various methods to identify and alleviate 
such biases. According to d ’Alessandro et al. (2017), 
we can divide these mitigation strategies into three 
categories: pre -processing, in -processing, and post -
processing. Pre -processing strategies strive to 
eliminate disparities inherent in the dataset. Methods 
such as those proposed by Kamiran and Calders (2012) 
and Zafar et al. (2017) employ data pre -processing 
techniques like feature massaging and reweighting to 
balance the dataset based on social group 
characteristics. In -processing strategies involve 
conventional learning algorit hms during model 
training. Researchers often use techniques like naive 
Bayes and decision tr ees for debiasing (Calders & 
Verwer, 2010; Zhang et al., 2018). Additional research 
suggests placing constraints on the classification 
model to mandate the satisfaction of a proxy 
(Woodworth et al., 2017). Lastly, post -processing 
strategies aim to adjust the output to counter biases. 
For example, Corbett -Davies et al. (2017) discrimination
Algorithms are not inherently discriminatory, and engineers
rarely intentionally introduce bias into algorithms. However, bias
can still arise in algorithmic recruitment. This issue is closely
linked to the fundamental technology behind AI and ML. The ML
process can be simpliﬁed into several stages, each involving three
key components contributing to algorithmic bias: dataset con-
struction, the engineer’s target formulation, and feature selection
(36KE, 2020). When the dataset lacks diverse representation from
different companies, bias may be introduced during the devel-
opment of algorithmic rules by engineers and when annotators
handle unstructured data (Zixun,2020).
Datasets: bias soil. Datasets serve as the foundation of machine
learning (ML). If an algorithm’s data collection lacks quantity and
quality, it will fail to represent reality objectively, leading to
inevitable bias in algorithmic decisions. Researchers commonly
use a 95% conﬁdence level, which provides 95% certainty but still
leaves a one in twenty chance of bias (Raub,2018). Nearly every
ML algorithm relies on biased databases.
One issue arises when datasets are skewed towards accessible",11.18796587,1,The generated answer is semantically consistent with the ground truth. Both identify two categories of measures: technical ones (like unbiased frameworks and transparency) and management/governance ones (like ethical governance and oversight).,0,"The generated answer is not faithful. It lists 'Pre-Processing-Strategien' and 'Post-Processing-Strategien' as the two recommended categories. [cite_start]While the context does mention these two strategies [cite: 382, 388][cite_start], it also explicitly mentions a third category, 'in-processing'[cite: 381], which is omitted from the generated answer. The answer is therefore an incomplete and inaccurate representation of the context.",1,"The context directly answers the question. It first states that resolving the issue requires 'technical solutions and the implementation of internal ethical governance and external regulations.' It then also mentions a three-category division of mitigation strategies: 'pre-processing, in-processing, and post-processing.'"
"Besides gender and race, what other characteristic is mentioned as a basis for discriminatory hiring practices by AI?",Personality traits.,Laut dem Text wird neben Geschlecht und Nationalität auch die Persönlichkeit und der IQ als Grundlage für diskriminierungsbedingte Einstellungspraktiken durch KI genannt.,"of inadvertently perpetuating or igniting algorithmic 
discrimination if these individuals engage in 
discriminatory practices. In this context, efforts aimed at 
identifying and mitigating (subconscious) discriminatory 
practices of organizational decision  makers, such as 
awareness training, become an indispensable 
complementary element to ensure that continuously 
updated ML models exhibit desirable behaviors. 
2 Theoretical and Conceptual 
Background 
In this section, we first provide the conceptual 
underpinnings of algorithmic discrimination. 
Subsequently, we discuss the literature gaps our work 
aims to address. REVIEW ARTICLE
Ethics and discrimination in artiﬁcial intelligence-
enabled recruitment practices
Zhisheng Chen 1✉
This study aims to address the research gap on algorithmic discrimination caused by AI-
enabled recruitment and explore technical and managerial solutions. The primary research
approach used is a literature review. Theﬁndings suggest that AI-enabled recruitment has
the potential to enhance recruitment quality, increase efﬁciency, and reduce transactional
work. However, algorithmic bias results in discriminatory hiring practices based on gender,
race, color, and personality traits. The study indicates that algorithmic bias stems from
limited raw data sets and biased algorithm designers. To mitigate this issue, it is recom-
mended to implement technical measures, such as unbiased dataset frameworks and
improved algorithmic transparency, as well as management measures like internal corporate
ethical governance and external oversight. Employing Grounded Theory, the study conducted
survey analysis to collectﬁrsthand data on respondents’ experiences and perceptions of AI-
driven recruitment applications and discrimination.
Introduction
T Thirdly, concerns are raised regarding potential hiring
discrimination perpetrated by machines. This can arise from AI
tools, such as partial source data, or users unfamiliar with user
interfaces and operations.
Fourthly, intrinsic factors like personality and IQ, as well as
extrinsic factors like gender and nationality, have been observed
to inﬂuence the accurate identi ﬁcation and judgment of AI
systems concerning hiring discrimination.
Fifthly, respondents offer recommendations for combating
discrimination by machines, including technical and non-
technical approaches.
Recommendations for future studies
This study conducted a literature review to analyze algorithmic
recruitment discrimination’s causes, types, and solutions. Future
research on algorithmic recruitment discrimination could explore
quantitative analysis or experimental methods across different
countries and cultures. Additionally, future studies could examine
the mechanics of algorithmic recruitment and the technical rules
that impact the hiring process. It would be interesting to analyze
the psychological effects of applying this algorithmic recruitment
technique on various populations (gender, age, education level)",6.243913651,1,"The generated answer is semantically consistent with the ground truth. The ground truth identifies 'Personality traits' as another basis for discrimination, and the generation correctly states 'personality and IQ'.",1,"The generated answer is faithful. [cite_start]The context explicitly states that 'algorithmic bias results in discriminatory hiring practices based on gender, race, color, and personality traits'[cite: 402]. [cite_start]It also mentions 'intrinsic factors like personality and IQ' [cite: 408] as influencing AI systems concerning hiring discrimination.",1,"The context directly answers the question by stating that 'algorithmic bias results in discriminatory hiring practices based on gender, race, color, and personality traits.'"
"According to the study of the paper 'Ethics and discrimination in artificial intelligence-enabled recruitment practices', what are two primary sources from which algorithmic bias stems?",Algorithmic bias stems from limited raw data sets and biased algorithm designers.,"Basierend auf der Studie „Ethik und Diskriminierung in KI-gestützten Recruiting-Praktiken“ resultiert algorithmische Verzerrung aus zwei Hauptquellen:

1.  **Begrenzte Rohdatensätze:** Die Algorithmen werden mit begrenzten Datensätzen trainiert, was zu Verzerrungen führen kann.
2.  **Voreingenommene Algorithmusdesigner:** Die Verzerrungen entstehen auch durch die voreingenommenen Designer der Algorithmen.","REVIEW ARTICLE
Ethics and discrimination in artiﬁcial intelligence-
enabled recruitment practices
Zhisheng Chen 1✉
This study aims to address the research gap on algorithmic discrimination caused by AI-
enabled recruitment and explore technical and managerial solutions. The primary research
approach used is a literature review. Theﬁndings suggest that AI-enabled recruitment has
the potential to enhance recruitment quality, increase efﬁciency, and reduce transactional
work. However, algorithmic bias results in discriminatory hiring practices based on gender,
race, color, and personality traits. The study indicates that algorithmic bias stems from
limited raw data sets and biased algorithm designers. To mitigate this issue, it is recom-
mended to implement technical measures, such as unbiased dataset frameworks and
improved algorithmic transparency, as well as management measures like internal corporate
ethical governance and external oversight. Employing Grounded Theory, the study conducted
survey analysis to collectﬁrsthand data on respondents’ experiences and perceptions of AI-
driven recruitment applications and discrimination.
Introduction
T technical and managerial aspects to tackle discrimination in
algorithmic hiring. This study contends that resolving algorithmic
discrimination in recruitment requires technical solutions and the
implementation of internal ethical governance and external
regulations.
The subsequent study is structured intoﬁve parts. The ﬁrst
section provides the theoretical background for this research. The
following section outlines the research methodology employed in
the literature review and identiﬁes four key themes. The third
section delves into a detailed discussion of these four themes:
applications and beneﬁts of AI-based recruitment, factors con-
tributing to algorithmic recruitment discrimination, types of
discrimination in algorithmic recruitment, and measures to
mitigate algorithmic hiring discrimination. The fourth section
involves conducting a survey among respondents and analyzing
the primary data collected to support our study. Theﬁnal section
concludes by suggesting future directions for research.
Theory background
Discrimination theory. Discrimination in the labor market is
deﬁned by the ILO’s Convention 111, which encompasses any
unfavorable treatment based on race, ethnicity, color, and gender Thirdly, concerns are raised regarding potential hiring
discrimination perpetrated by machines. This can arise from AI
tools, such as partial source data, or users unfamiliar with user
interfaces and operations.
Fourthly, intrinsic factors like personality and IQ, as well as
extrinsic factors like gender and nationality, have been observed
to inﬂuence the accurate identi ﬁcation and judgment of AI
systems concerning hiring discrimination.
Fifthly, respondents offer recommendations for combating
discrimination by machines, including technical and non-
technical approaches.
Recommendations for future studies
This study conducted a literature review to analyze algorithmic
recruitment discrimination’s causes, types, and solutions. Future
research on algorithmic recruitment discrimination could explore
quantitative analysis or experimental methods across different
countries and cultures. Additionally, future studies could examine
the mechanics of algorithmic recruitment and the technical rules
that impact the hiring process. It would be interesting to analyze
the psychological effects of applying this algorithmic recruitment
technique on various populations (gender, age, education level)",11.80279231,1,The generated answer is semantically consistent with the ground truth. Both state that the two primary sources of bias are limited/biased raw data and biased algorithm designers.,1,The generated answer is faithful. [cite_start]The context explicitly states that 'The study indicates that algorithmic bias stems from limited raw data sets and biased algorithm designers.' [cite: 417],1,The context directly answers the question. It explicitly states: 'The study indicates that algorithmic bias stems from limited raw data sets and biased algorithm designers.'
What does the CRISP-DM User Guide provide that the Reference Model does not?,"The User Guide gives more detailed tips and hints for each phase and task on how to do a data mining project, whereas the Reference Model describes what to do.","The text doesn't provide any information about a ""CRISP-DM User Guide"" or what it offers that the reference model doesn't. It only describes the CRISP-DM reference model itself.","15. Mai 2025
Overview CRISP-DM
9 in einer bestimmten Domäne,
in einem bestimmten Bereich 
angewendet werden kann,
sondern eben in verschiedenen 
Sektoren.
Es wird überall gebraucht.
Also General Purpose und
vorher war mal und ich finde den 
Namen furchtbar.
Aber um sie nicht zu verwirren,
habe ich eine andere als die 
herkömmliche Abkürzung,
die Sie in vielen ökonomischen
Büchern noch finden, nämlich 
GPT.
Das ist General Purpose.
Technologie hat natürlich Open 
AI
uns alle so ein bisschen 
versaut.
Dieses Wort zu benutzen,
insbesondere wenn man irgendwie 
an der
Schnittstelle zu Machine 
Learning arbeitet,
weil alle direkt an das 
Sprachmodell denken.
Deswegen hier diese furchtbare
Abkürzung General purpose
Tonnen general purpose 
technology.
Diese Technologien haben
die gesamte Zivilisation der
Menschheit schon immer massiv 
verändert.
Nicht nur, weil sie auf der 
einen Seite weit
eingesetzt worden sind und
auf der anderen Seite eben über
die Zeit immer besser genutzt 
wurden,
erkannt wurde, wo wir sie noch 
einsetzen
kann Economies of Scale 
eingesetzt haben.
Viele Leute nutzen es wird immer 
knapper.
Sondern auch, weil diese 
Innovationen,
diese Kerninnovationen,
letztlich zu weiteren
komplementären Innovationen 
geführt haben. Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können.",6.231246948,0,"The generated answer is a refusal to answer, stating the text doesn't provide the information. The ground truth provides a specific, factual answer. The answers are contradictory.",0,"The generated answer is not faithful. The retrieved context does not contain any information about a 'CRISP-DM User Guide' or compare it to a 'reference model'. [cite_start]The context only mentions the acronym GPT in the context of 'General Purpose Technologie'[cite: 437, 438].",0,The context is entirely irrelevant. It discusses General Purpose Technology (GPT) and the general scope of a Machine Learning course. It contains no information about the CRISP-DM User Guide or how it differs from the Reference Model.
Which task is mentioned as often being the lengthiest in the Data Preparation phase?,The 'Clean data' task.,"Basierend auf dem Text wird die Aufgabe, welche Informationen als ""gut"" für einen Bewerbungsprozess gelten, am häufigsten als zeitaufwendig genannt. Der Text betont, dass Data Scientists Experten innerhalb der Organisation konsultieren müssen, um herauszufinden, welche Daten tatsächlich relevant sind und wie sie bewertet werden.","Dann haben wir die Abteilungen,
die dann auch wieder ihre 
einzelnen Datenpools hat,
darüber,
wie gut die Leute eigentlich 
arbeiten
und das zusammen zu bringen, zu 
sehen,
wie sich eine bestimmte
Person von der ersten 
Kontaktaufnahme,
darüber, welche Informationen, 
wie
sie überhaupt diesen Funnel 
gekommen ist,
hin zum Bewerbungsgespräch, hin 
zu Evaluation,
wie sich das alles verbinden 
lässt,
kostet unfassbar viel Zeit und 
die meisten
Unternehmen haben teilweise 
nicht mal die Möglichkeit,
bestimmte Sachen zu verbinden,
weil wir wieder über Datenschutz 
etc.
sprechen. Und das müssen sie 
alles,
so gut es geht, schon von 
vornherein mitdenken.
Aber angenommen, wir sind an dem 
Punkt,
dass das alles jetzt 
funktionieren würde,
kommt der nächste riesen 
aufwändige Schritt
in dem technischen Prozess jetzt 
schon und wir
treten das weiterhin wie eine
Blackbox und
Blackbox wird nachher noch mal 
ein anderes Thema sein.
Aber aktuell sagen wir,
wir nehmen an, diese ganzen 
Prozesse,
diese ganzen Methoden, das 
Training von Daten,
das würden wir alles schon 
wissen.
Beziehungsweise es würde uns
aktuell noch nicht 
interessieren.
Da kommen wir zu dem zweiten 
Teil der Vorlesung.
Aber ein Riesenteil.
Bevor wir überhaupt an Modelle Trainieren
selber gar nicht lange und
wir können sehr viele Kniffe 
benutzen,
wie wir dieses diesen
Trainingsprozess in einer 
gewissen Art
und Weise automatisieren können,
indem wir zum Beispiel
die Modellstruktur, die 
Modellauswahl,
sogar die Auswahl der relevanten
Inputinformationen durch 
bestimmte sogenannte
Cross Validation Verfahren durch
die Daten selber identifizieren 
lassen.
Ich hasse diesen Satz,
aber hier passiert dann sehr 
häufig dieses Let
the data speak so wenig anhaben 
wie möglich machen.
Wir versuchen einfach, das beste 
Modell zu finden.
Und auch das sei wieder betont, 
ist fundamental.
Uns geht es darum, ein Modell zu 
finden,
was nicht unsere historischen
Daten so gut es geht erklärt,
sondern sobald das Modell da 
ist,
möchten wir ein Modell haben,
was es uns ermöglicht,
Vorhersagen für die Zukunft zu 
machen,
also Vorhersagen für Beispiele,
Observationen, die das Modell 
noch nicht gesehen hat.
Denken Sie an das 
EiscremeBeispiel zurück.
Es ging nicht darum, perfekt zu 
erklären,
wie sich in der
Vergangenheit unsere 
Eisverkäufer abhängig
von bestimmten 
Wetterinformationen dargestellt 
haben,
sondern es ging darum Ich habe 
einen bestimmte
Logik identifiziert aus den 
historischen Daten. Modells durchgedacht werden.
Denn sobald ich es implementiert 
haben
und am Ende feststellen ja,
ich habe eigentlich irgendwas 
gemessen,
was gar nicht so wichtig für die 
Organisation ist,
dann können sie sehr, sehr viel 
Geld
in den Sand gesetzt haben.
Sobald Sie dieses 
Businessverständnis
identifiziert haben, geht es 
daran?
Ja, ich möchte eine Vorhersage 
machen.
Das Allererste, was ich brauche, 
ist erstmal gute Daten.
Wie kann ich dieses Modell 
eigentlich entwickeln?
Was für Informationen brauche 
ich?
Da müssen Sie als der Data 
Scientist, der Data Engineer,
wie auch immer Sie sich 
schimpfen
wollen in ein paar Jahren,
müssen dann zu den Experten 
gehen innerhalb der
Organisation und eigentlich mal 
nachfragen.
Hey Herr Manager, um
bei diesem Beispiel zu bleiben 
Was
sind eigentlich gute 
Informationen,
auf die ihr achtet in so einem 
Bewerbungsprozess?
Um zu identifizieren oder selber 
einzuschätzen?
Wird das ein guter oder ein 
schlechter
Mitarbeiter für diese bestimmte 
Stelle sein.
Sie müssen also identifizieren 
welche
Daten welche Variablen sind 
eigentlich da?
Müssen Sie vielleicht neue 
Informationen erheben?
Sind bestimmte Informationen gar 
nicht zugänglich?
Und das Letzte kann tatsächlich",8.504841805,0.8,"The generated answer is semantically consistent with the ground truth. The ground truth identifies the 'Clean data' task. The generation describes the task of identifying what information is 'good' for a hiring process as being very time-consuming, which is a core component of the data cleaning and preparation phase.",0,"The generated answer is not faithful. It claims the lengthiest task is defining what information is 'good' for an application process. The context does not state this. [cite_start]It mentions that data scientists need to ask experts what they consider 'gute Informationen'[cite: 461], but it does not state that this specific task is the most time-consuming.",0.8,"The context is relevant. While it doesn't explicitly name the 'Clean data' task, it describes the process of identifying and integrating the right data as a 'riesen aufwÃ¤ndige Schritt' (huge, complex step) that 'kostet unfassbar viel Zeit' (costs an incredible amount of time). This process is a core component of data preparation and cleaning."
What is the stated aim of the CRISP-DM process model?,"To make large data mining projects less costly, more reliable, more repeatable, more manageable, and faster.","Das Ziel des CRISP-DM Prozessmodells ist es, Vorhersageprobleme durch den Einsatz von Modellen zu lösen. Es geht darum, aus den vorhandenen Daten die relevantesten Features zu identifizieren und eine möglichst genaue Vorhersage über das gewünschte Ergebnis (Outcome/Label) zu erstellen.","15. Mai 2025
Structuring an AI project: CRISP-DM 
6
1. Business Understanding2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment
Data 
Cross Industry Standard Process for Data Mining bekommen,
was diese Daten alles bedeuten.
Sie haben bei mir in der im 
Seminar
gesessen letztes Semester diese 
Daten,
die Sie da erhalten haben, von 
der Firma.
Totales Chaos.
Muss man sich erstmal reindenken 
und
das braucht massiv viel Zeit.
Wenn wir aber dann die Daten 
sauber gemacht haben,
dann geht es endlich an den,
den sag ich mal aus meiner
Sicht coolsten Teil dieses 
Prozesses, wo wir versuchen,
das anfänglich definierte 
Vorhersageproblem
durch Modelle zu lösen.
Hier passiert jetzt in
Anführungsstrichen eigentlich 
die Magic,
Hier haben wir unsere 
Algorithmen,
hier haben wir unsere 
verschiedenen Modelle,
die wir alle ausprobieren,
um zu sehen,
wie können wir denn
eigentlich aus den Daten, die 
wir haben,
unsere Features,
eine möglichst genaue Vorhersage 
über
diesen Teil der Daten,
unser Outcome, unser Label?
Was nutzen wir da?
Welche Modellarchitektur,
um möglichst out of sample gute 
Vorhersagen zu machen?
Wir trainieren dieses Modell und 
in
den meisten Fällen dauert es 
Trainieren
selber gar nicht lange und
wir können sehr viele Kniffe 
benutzen,
wie wir dieses diesen
Trainingsprozess in einer 
gewissen Art
und Weise automatisieren können,
indem wir zum Beispiel
die Modellstruktur, die 
Modellauswahl, 15. Mai 2025
Overview CRISP-DM
9",6.93716383,0,"The generated answer describes the aim of the modeling phase (solving a prediction problem), not the aim of the entire CRISP-DM process model. The ground truth provides the correct, broader aim of making projects more manageable, reliable, and faster. The answers are not semantically consistent.",1,"The generated answer is faithful. [cite_start]The context states that the goal of the 'Modeling' phase is to 'versuchen, das anfÃ¤nglich definierte Vorhersageproblem durch Modelle zu lÃ¶sen' [cite: 469] [cite_start]and to find the 'mÃ¶glichst genaue Vorhersage'[cite: 470].",0.3,"The context is only partially relevant. It describes the goal of the 'Modeling' phase of the CRISP-DM process, which is 'das anfÃ¤nglich definierte Vorhersageproblem durch Modelle zu lÃ¶sen' (to solve the initially defined prediction problem using models). It does not, however, state the overall aim of the entire CRISP-DM process model itself."
What does CRISP-DM stand for?,Cross Industry Standard Process for Data Mining.,CRISP-DM steht für Cross Industry Standard Process for Data Mining.,"15. Mai 2025
Structuring an AI project: CRISP-DM 
6
1. Business Understanding2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment
Data 
Cross Industry Standard Process for Data Mining Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. 15. Mai 2025
Overview CRISP-DM
9",3.318456888,1,The generated answer is semantically consistent with the ground truth. Both correctly identify what CRISP-DM stands for.,1,The generated answer is faithful. [cite_start]The retrieved context explicitly states that CRISP-DM stands for 'Cross Industry Standard Process for Data Mining'[cite: 473].,1,The context directly answers the question. An image within the context explicitly contains the text 'Cross Industry Standard Process for Data Mining' associated with the acronym CRISP-DM.
What are the six phases of the CRISP-DM process model?,"The six phases are Business Understanding, Data Understanding, Data Preparation, Modeling, Evaluation, and Deployment.","Die sechs Phasen des CRISP-DM Prozessmodells sind:

1.  Business Understanding
2.  Data Understanding
3.  Data Preparation
4.  Modeling
5.  Evaluation
6.  Deployment","bekommen,
was diese Daten alles bedeuten.
Sie haben bei mir in der im 
Seminar
gesessen letztes Semester diese 
Daten,
die Sie da erhalten haben, von 
der Firma.
Totales Chaos.
Muss man sich erstmal reindenken 
und
das braucht massiv viel Zeit.
Wenn wir aber dann die Daten 
sauber gemacht haben,
dann geht es endlich an den,
den sag ich mal aus meiner
Sicht coolsten Teil dieses 
Prozesses, wo wir versuchen,
das anfänglich definierte 
Vorhersageproblem
durch Modelle zu lösen.
Hier passiert jetzt in
Anführungsstrichen eigentlich 
die Magic,
Hier haben wir unsere 
Algorithmen,
hier haben wir unsere 
verschiedenen Modelle,
die wir alle ausprobieren,
um zu sehen,
wie können wir denn
eigentlich aus den Daten, die 
wir haben,
unsere Features,
eine möglichst genaue Vorhersage 
über
diesen Teil der Daten,
unser Outcome, unser Label?
Was nutzen wir da?
Welche Modellarchitektur,
um möglichst out of sample gute 
Vorhersagen zu machen?
Wir trainieren dieses Modell und 
in
den meisten Fällen dauert es 
Trainieren
selber gar nicht lange und
wir können sehr viele Kniffe 
benutzen,
wie wir dieses diesen
Trainingsprozess in einer 
gewissen Art
und Weise automatisieren können,
indem wir zum Beispiel
die Modellstruktur, die 
Modellauswahl, 15. Mai 2025
Overview CRISP-DM
9 15. Mai 2025
Structuring an AI project: CRISP-DM 
6
1. Business Understanding2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment
Data 
Cross Industry Standard Process for Data Mining",5.917240143,1,The generated answer is semantically consistent with the ground truth. Both correctly list the six phases of the CRISP-DM process model.,1,"The generated answer is faithful. The retrieved context lists the six phases in a diagram: '1. Business Understanding', '2. Data Understanding', '3. Data Preparation', '4. Modeling', '5. Evaluation', '6. [cite_start]Deployment'[cite: 485].",1,"The context directly answers the question. An image within the context clearly lists the six phases: '1. Business Understanding', '2. Data Understanding', '3. Data Preparation', '4. Modeling', '5. Evaluation', and '6. Deployment'."
What three characteristics define a General Purpose Technology (GPT)?,"They are pervasive, improve over time, and lead to complementary innovation.","Basierend auf dem Text definieren drei Merkmale eine General Purpose Technology (GPT):

1.  **Anwendbarkeit in verschiedenen Sektoren:** Eine GPT kann in vielen verschiedenen Bereichen eingesetzt werden.
2.  **Veränderung durch Nutzung:** Diese Technologien haben die gesamte Zivilisation der Menschheit massiv verändert, sowohl durch breite Anwendung als auch durch kontinuierliche Verbesserung und Anpassung.
3.  **Beeinflussung durch soziale Faktoren:** Die Akzeptanz und Nutzung einer GPT wird durch die Wahrnehmung des Umfelds und die soziale Einflussnahme beeinflusst.","in einer bestimmten Domäne,
in einem bestimmten Bereich 
angewendet werden kann,
sondern eben in verschiedenen 
Sektoren.
Es wird überall gebraucht.
Also General Purpose und
vorher war mal und ich finde den 
Namen furchtbar.
Aber um sie nicht zu verwirren,
habe ich eine andere als die 
herkömmliche Abkürzung,
die Sie in vielen ökonomischen
Büchern noch finden, nämlich 
GPT.
Das ist General Purpose.
Technologie hat natürlich Open 
AI
uns alle so ein bisschen 
versaut.
Dieses Wort zu benutzen,
insbesondere wenn man irgendwie 
an der
Schnittstelle zu Machine 
Learning arbeitet,
weil alle direkt an das 
Sprachmodell denken.
Deswegen hier diese furchtbare
Abkürzung General purpose
Tonnen general purpose 
technology.
Diese Technologien haben
die gesamte Zivilisation der
Menschheit schon immer massiv 
verändert.
Nicht nur, weil sie auf der 
einen Seite weit
eingesetzt worden sind und
auf der anderen Seite eben über
die Zeit immer besser genutzt 
wurden,
erkannt wurde, wo wir sie noch 
einsetzen
kann Economies of Scale 
eingesetzt haben.
Viele Leute nutzen es wird immer 
knapper.
Sondern auch, weil diese 
Innovationen,
diese Kerninnovationen,
letztlich zu weiteren
komplementären Innovationen 
geführt haben. Studierende machen sich mit der Funktionsweise von generativen KI-Modellen wie GPT vertraut. Sie lernen, diese durch gezieltes Prompting für Managemententscheidungen einzusetzen und kritisch zu bewerten, insbesondere unter wirtschaftlichen und ethischen Gesichtspunkten. Adoption,
die Acceptance dieser 
Technologie
nach oben gegangen machen.
Diese beiden Faktoren sind für 
Sie erstmal meine Idee,
meine Vorstellung davon, die ich 
in meinem Kopf forme.
Kann mir das System wirklich 
helfen,
ein bestimmtes Ziel zu 
erreichen?
0.2 Wie schwierig ist es denn 
für mich?
Wie viel Effort muss ich 
aufwenden,
um das System vernünftig zu 
nutzen?
Und der dritte fundamentale 
Faktor,
der auf diese behavior 
Intention.
Ich habe gerade 
fälschlicherweise viel gesagt,
weil ich hier viel gezählt habe,
aber der dritte große Faktor,
der auf diese behavioral 
Intention einzahlt,
ist das Umfeld.
Wenn Sie alle Chatgbt nutzen,
dann sehe ich das als Signal,
dass ich es auf jeden Fall mal 
ausprobieren sollte.
Wenn Sie alle sagen Chat GPT ist 
der größte Quatsch,
werde ich weniger bereit sein 
als Einzelperson,
die das System noch nicht 
benutzt hat,
dieses System zu akzeptieren und 
tatsächlich zu nutzen.
Das hier sind interne Faktoren, 
sozusagen.
Und hier haben wir mit dieser 
Social Influence
eben die Wahrnehmung über das 
Umfeld,
wie das Umfeld diese Technologie 
wahrnimmt,
was für Attitude das Umfeld 
darüber hat,
ob es vielleicht auch sogar eine
Art soziale Norm geworden ist,
ein bestimmtes System zu nutzen",10.93296218,1,The generated answer is semantically consistent with the ground truth. Both identify the three key characteristics of a General Purpose Technology.,0.5,"The generated answer claims three characteristics: applicability in various sectors, change through use/improvement, and influence by social factors. [cite_start]The context supports the first two points, stating it can be 'angewendet werden kann, sondern eben in verschiedenen Sektoren' [cite: 488] [cite_start]and that they have 'massiv verÃ¤ndert' civilization through widespread use and improvement over time[cite: 493]. [cite_start]However, the third point, 'Beeinflussung durch soziale Faktoren' (influence by social factors), while supported by context mentioning 'Social Influence'[cite: 503], is specifically about technology *acceptance*, not a defining characteristic of a GPT itself according to the provided text.",1,"The context is highly relevant. It describes General Purpose Technologies (GPTs) as being applicable 'in verschiedenen Sektoren' (pervasive), that they are 'Ã¼ber die Zeit immer besser genutzt wurden' (improve over time), and that these 'Kerninnovationen, letztlich zu weiteren komplementÃ¤ren Innovationen gefÃ¼hrt haben' (core innovations ultimately led to further complementary innovations)."
"In the paper 'THE PRODUCTIVITY J-CURVE: HOW INTANGIBLES COMPLEMENT GENERAL PURPOSE TECHNOLOGIES', by how much higher was the adjusted measure of Total Factor Productivity (TFP) compared to official measures at the end of 2017?",The adjusted TFP was 15.9% higher than official measures at the end of 2017.,The text doesn't provide information about the adjusted Total Factor Productivity (TFP) measurement at the end of 2017 or how it compares to official measurements.,"8. Mai 2025
Brynjolfsson et al. (2025): productivity results
27
Substantial increase in worker productivity 3. Juli 2025
What then?
Consider technical performance metric that is independent of threshold
• Solution: Receiver Operating Characteristic
• Simulate thresholds from 0 to 1 and calculate TPR and FPR for every threshold value
• Plot every (TPR, FPR) tuple with TPR being on the y-axis and FPR on the x-axis
18 gehabt habe,
bringt GPT dann irgendwas noch?
Weil hier die Leute im roten die 
haben es
immer direkt von Anfang an 
gehabt und die im Grünen,
die haben es dann erst ab Monat 
fünf und
sechs nach einer gewissen 
Einarbeitungszeit gehabt.
Und wir sehen, selbst nach einer
gewissen Einarbeitungszeit wird 
dann
auf einmal diese 
Produktivitätssteigerung
höher im Vergleich zu den 
Personen im Unternehmen.
Die blaue Linie, die nie
exist dazu bekommen haben, 
danach ja.
Aber am besten ist es gewesen,
wenn die Leute von Anfang
an eben diese Technologie 
Zugriff hatten.
Wichtig hier sei darauf 
hingedeutet.
Erste Studien zeigen Das ist 
auch bei Experten.
Das sind alles Leute,
die neu angestellt wurden.
Da sehen wir diese massiven 
Produktivitätssteigerung.
Aber erste Studien zeigen,
dass das wohl nicht nur für 
Offices gilt,
sondern in Tasks wie Software 
Development
anscheinend insbesondere auch 
für Experten gilt,
so dass wir hier wieder so ein 
bisschen
Evidenz dafür bekommen,
dass diese Technologie eventuell 
diese Schere
in der Produktivität von 
Experten,
Leuten mit viel Humankapital
und mit geringem Humankapital 
verändert.
Letzter Punkt Auch die Kunden 
sind happy geworden.
Wir haben höhere Net Promoter 
Scores.",6.483602285,0,"The generated answer is a refusal to answer, stating the text doesn't provide the information. The ground truth provides a specific, factual answer. The answers are contradictory.",0,"The generated answer is not faithful. The retrieved context does not contain any information about the Total Factor Productivity (TFP) or compare an adjusted measure to official measures. [cite_start]The context discusses worker productivity increases after the introduction of GPT in a company[cite: 508, 512].",0,"The context is irrelevant. It shows graphs illustrating productivity gains for employees using a GPT-like tool over several months but contains no information about Total Factor Productivity (TFP), specific measurements from the end of 2017, or a comparison to official measures."
What did Robert Solow's productivity paradox state?,That one 'can see in the computer age everywhere but in the productivity statistics',"The text doesn't mention Robert Solow or his productivity paradox. It describes a ""J-Curve"" pattern of productivity changes, which is a different concept. 

Here's a summary of the J-Curve pattern described in the text:

*   **Initial Dip:** Productivity initially falls or stalls due to heavy up-front investment in things like data, skills, and process redesign.
*   **Rebound:** Productivity then accelerates in the long run as these complementary investments pay off. This is driven by learning effects, scale economies, and network externalities.

Do you want me to explain the J-Curve pattern in more detail, or perhaps discuss Robert Solow's productivity paradox separately?","Produktivität massiv ansteigt.
0.1. 0.2. Wir sehen das.
Hier haben Sie drei Gruppen.
Die Gruppe, die neu angestellt 
wurde,
das ist die, die Monate,
wie lange die Person schon dort 
arbeitet.
Wir sehen hier den roten 
Graphen, der uns zeigt.
Die Personen, die von 
vornherein,
sobald sie anfangen, mit PT 
gearbeitet haben.
Ja, wir sehen hier,
dass die Produktivität sofort 
massiv nach oben geht.
Wir haben diejenigen hier, die 
Blauen,
die niemals Access bekommen 
haben zu der Technologie.
Auch bei denen sehen wir 
natürlich über die Zeit.
Wenn sie länger in der Firma 
waren,
haben sie die Prozesse 
kennengelernt und
wurden immer ein bisschen 
produktiver.
Das heißt, wir haben hier 
sozusagen eine Kontrollgruppe.
Und dann haben Sie in dem in der 
Studie sogar
noch eine weitere Gruppe von 
Leuten,
die Sie dann nach 5 bis 6 
Monaten,
also in dem Monat fünf und sechs 
seit der Anstellung
haben sie den dann Zugriff auf 
GPT gegeben,
um herauszufinden.
Naja, inwiefern?
Wenn ich schon anfange Training 
gehabt habe,
bringt GPT dann irgendwas noch?
Weil hier die Leute im roten die 
haben es
immer direkt von Anfang an 
gehabt und die im Grünen,
die haben es dann erst ab Monat 
fünf und
sechs nach einer gewissen 
Einarbeitungszeit gehabt. Produktivitätsveränderungen 
negativ sein kann.
Das ist so dieser untere 
Halbkreis von dem J.
Und das kann verschiedene Gründe 
haben.
Unter anderem eben, dass diese
Technologien noch nicht 
ausreichend in den
Organisationen mit
komplementären Investitionen 
integriert worden sind.
Und dann sind wir noch 
technischer
geworden aus einer 
mikroökonomischen Perspektive.
Wir haben kurz über die Trust 
Game Struktur gesprochen,
wo es darum geht.
Ich mache Entscheidungen, 
ökonomisch
relevante Entscheidungen unter 
Unsicherheit.
Und in diesen Szenarien kann 
Machine Learning uns helfen.
Wenn Sie sich wieder vorstellen,
Sie sind hier der Investor.
Sie haben 10 Millionen € zur 
Verfügung,
Sie entweder in ein Startup 
investieren
können oder eben auch nicht.
Wenn Sie nicht investieren, 
haben Sie
10 Millionen Cash und das 
Startup hat nichts.
Wenn Sie es investieren,
dann kann das Startup entweder 
sich anstrengen,
viel arbeiten, kann diese Summe,
die Sie investieren,
verdreifachen und gibt Ihnen die 
Hälfte zurück.
Oder aber das Startup strengt
sich ein bisschen an und läuft 
weg.
Dann haben wir gesagt Wenn wir 
uns
das als 
Nutzenmaximierungsstrategie
aufschreiben aus dieser 
mikroökonomischen,
schrägstrich spieltheoretischen 8. Mai 2025
Expect a J-Curve
J-Curve: two-phase productivity pattern that emerges when a GePuTdiffuses•Short-run dipas measured productivity falls or stalls•Heavy up-front investmentin data, skills, process redesign, and complementary tech•Intangible assets (software, know-how) rise, but are poorly captured in standard measures•Resources diverted from current production to capability-building (output forgone)•Long-run rebound as productivity accelerates once complements are in place•Learning effects, scale economies, and network externalities kick in•Complementary investments start paying off measurably8",12.83277655,0,"The generated answer is a refusal to answer, stating the text doesn't mention the topic. The ground truth provides the specific definition of the paradox. The answers are contradictory.",0,"The generated answer is not faithful. The retrieved context does not mention Robert Solow or his productivity paradox. [cite_start]Instead, it describes a 'J-Curve' pattern of productivity, which involves an initial dip followed by a rebound[cite: 565].",0.1,"The context is irrelevant to the specific question asked. It describes the 'J-Curve' pattern of productivity, where there is a short-run dip followed by a long-run rebound. It makes no mention of Robert Solow or his productivity paradox."
What are some examples of complementary investments required by General Purpose Technologies (GPTs) like AI?,"Business process redesign, co-invention of new products and business models, and investments in human capital.","Basierend auf dem Text sind hier einige Beispiele für ergänzende Investitionen, die bei General Purpose Technologies (GPTs) wie KI erforderlich sind:

*   **Sensoren und vernetzte Geräte:** Um KI-Agenten effektiv nutzen zu können, werden Sensoren und vernetzte Geräte benötigt, um Daten zu sammeln.
*   **Datenpipelines und ML-Ops:** Neue Prozesse und Infrastrukturen, wie Datenpipelines und ML-Ops, sind notwendig, um die KI-Technologie zu nutzen und zu verwalten.
*   **KI-first Prozesse:** Die Organisation muss sich anpassen und neue Prozesse entwickeln, die auf KI-Technologien basieren.
*   **Synthetic Data:** Künstlich erzeugte Daten, um die KI-Modelle zu trainieren, wenn reale Daten knapp sind.

Der Text betont, dass es sich um eine Anpassung der Organisation handelt, um den vollen Wert der GPTs zu erschließen.","Datenbank schaffen.
Ich muss ganz viele intangible 
Assets Know how kreieren,
um dann letztlich auch wieder 
weitere Innovationen.
Wir reden über General Purpose 
Technologien,
komplementäre Investitionen 
anzuregen.
Und das führt natürlich dazu, 
dass viele Ressourcen,
die eigentlich vielleicht auf 
der Produktivität
per se gelegen haben,
abgezogen werden und in
diese Produktivitätssteigerung 
investiert werden.
Und damit haben wir immer so ein 
bisschen.
Wir brauchen erstmal viel Zeit
und sollten nicht zu ungeduldig 
sein,
bis wir die Effekte dieser
neuen Technologie wirklich 
sehen.
Ich habe ihn letztes
Mal schon gesagt der große 
Missglauben
bei vielen Unternehmen ist 
weiterhin Ich nehme ei,
schmeiß es ins Unternehmen und 
es bringt sofort was.
Ne KI muss integriert sein.
Wir müssen die Prozesse da herum 
bauen,
Genauso wie wir die Fabriken
mit der Einführung der 
Elektrizität
im Vergleich zur Steam Engine 
umbauen mussten,
müssen wir unsere Organisationen 
adaptieren.
Und das führt dazu, dass wir 
eben am
Anfang diese Zeit brauchen,
um aus dieser Krise 
rauszukommen.
Und wir sehen die ersten 
Anzeichen,
dass wir jetzt möglicherweise
über KI Agenten nachdenken, da 
rauskommen.
Bei Software Development sind 8. Mai 2025
AI as General-Purpose technologyWhat is a General-Purpose Technology (GePuT)?•Pervasive: can be applied across sectorsof the economy. •Rapidly improving & cheaper over time: learning-by-doing, scale economies, Moore-like curves•Complements: sparks waves of follow-on innovations, new business models, organizational redesign.•Previous examples: Steam engine, Electricity, Digital ComputingAI be seen as a GePuTas well –why?•Core function gets dramatically cheaper: prediction making•Ubiquitous use-cases across every industry.•For the first time: continuous learning of the technology itself with cross industry spillovers•Catalyst for complements:•New inputs: sensors, connected devices, synthetic data•New “orgware”: data pipelines, ML-ops, AI-first processes•…
7
Managerial perspective: invest in complementary technologies, andadjust organization to unlock its full value. in einer bestimmten Domäne,
in einem bestimmten Bereich 
angewendet werden kann,
sondern eben in verschiedenen 
Sektoren.
Es wird überall gebraucht.
Also General Purpose und
vorher war mal und ich finde den 
Namen furchtbar.
Aber um sie nicht zu verwirren,
habe ich eine andere als die 
herkömmliche Abkürzung,
die Sie in vielen ökonomischen
Büchern noch finden, nämlich 
GPT.
Das ist General Purpose.
Technologie hat natürlich Open 
AI
uns alle so ein bisschen 
versaut.
Dieses Wort zu benutzen,
insbesondere wenn man irgendwie 
an der
Schnittstelle zu Machine 
Learning arbeitet,
weil alle direkt an das 
Sprachmodell denken.
Deswegen hier diese furchtbare
Abkürzung General purpose
Tonnen general purpose 
technology.
Diese Technologien haben
die gesamte Zivilisation der
Menschheit schon immer massiv 
verändert.
Nicht nur, weil sie auf der 
einen Seite weit
eingesetzt worden sind und
auf der anderen Seite eben über
die Zeit immer besser genutzt 
wurden,
erkannt wurde, wo wir sie noch 
einsetzen
kann Economies of Scale 
eingesetzt haben.
Viele Leute nutzen es wird immer 
knapper.
Sondern auch, weil diese 
Innovationen,
diese Kerninnovationen,
letztlich zu weiteren
komplementären Innovationen 
geführt haben.",16.72192359,1,"The generated answer is semantically consistent with the ground truth. It provides several correct examples of complementary investments, such as new data pipelines, AI-first processes, and sensors, which align with the categories mentioned in the ground truth (process redesign, new business models, human capital).",1,"The generated answer is faithful. [cite_start]The context explicitly lists catalysts for complements to AI as a GePuT, including 'New inputs: sensors, connected devices, synthetic data' and 'New â€œorgwareâ€: data pipelines, ML-ops, AI-first processes'[cite: 551]. [cite_start]It also mentions the need to 'unsere Organisationen adaptieren' (adapt our organizations)[cite: 547].",1,"The context directly answers the question. Under the heading 'AI as General-Purpose technology', it provides a bullet point 'Catalyst for complements' which lists examples such as 'New inputs: sensors, connected devices, synthetic data' and 'New â€œorgwareâ€: data pipelines, ML-ops, AI-first processes'."
"According to the text, what is the 'Productivity J-Curve' phenomenon?","It is a phenomenon where, as firms adopt a new General Purpose Technology (GPT), total factor productivity (TFP) growth is initially underestimated because resources are spent on unmeasured intangible capital. Later, measured productivity growth overestimates true productivity as the benefits from those intangibles are realized.","Laut dem Text ist das Phänomen der ""Productivity J-Curve"" wie folgt:

Es handelt sich um ein Produktivitätsmuster, das bei der Einführung neuer Technologien, insbesondere von ""General Purpose Technologies"" wie GPT, auftritt. Zuerst kommt es zu einem kurzfristigen Produktivitätstief, weil es massive Investitionen in die Nutzung und Anpassung der Technologie gibt. Diese Investitionen umfassen Schulungen, Infrastrukturaufbau und die Entwicklung von ""intangible assets"" (Know-how). Erst danach, wenn die ergänzenden Investitionen Früchte tragen und ""Learning Effects"", ""Scale Economies"" und ""Network Externalities"" einsetzen, beginnt die Produktivität wieder zu steigen und beschleunigt sich. Es ist also ein Phasenmuster: erstmal ein Rückgang, dann ein steiler Anstieg.","8. Mai 2025
Expect a J-Curve
J-Curve: two-phase productivity pattern that emerges when a GePuTdiffuses•Short-run dipas measured productivity falls or stalls•Heavy up-front investmentin data, skills, process redesign, and complementary tech•Intangible assets (software, know-how) rise, but are poorly captured in standard measures•Resources diverted from current production to capability-building (output forgone)•Long-run rebound as productivity accelerates once complements are in place•Learning effects, scale economies, and network externalities kick in•Complementary investments start paying off measurably8 der Produktivität, dann sehen 
wir,
dass am Anfang bei vielen 
Technologien eigentlich
und das ist ein Average
erstmal die Produktivität runter 
geht.
Wir sind sozusagen an der 
unteren dieser Kurve,
diesem unteren Halbkreis von dem 
J.
Und erst danach geht es 
eigentlich nach oben.
Wir haben eine massiven 
Produktivität.
Das ist wie gesagt der die
Veränderung wir sehen hier ist 
erstmal runtergeht,
dann geht steil nach oben und 
das ist ein Phänomen,
was wir diese Kurve nennen.
Und das sehen wir immer wieder 
mit
verschiedenen General purpose 
technology.
Und das hat ganz einfache 
Gründe, nämlich,
dass am Anfang,
wenn wir in diese Technologien 
investieren,
wie in GPT investiert wird,
haben wir erstmal riesige 
anfängliche Investitionen,
die sich nicht sofort auszahlen.
Wir haben massive Investitionen,
beispielsweise darin,
dass Leute die Technologie 
richtig nutzen können.
Ich muss Schulungen machen,
ich muss die Infrastruktur 
schaffen,
ich muss die Anbindung an meine 
Datenbank schaffen.
Ich muss ganz viele intangible 
Assets Know how kreieren,
um dann letztlich auch wieder 
weitere Innovationen.
Wir reden über General Purpose 
Technologien,
komplementäre Investitionen 
anzuregen.
Und das führt natürlich dazu, um für abgewandelte Gewichte in 
den Turbinen,
die größer gemacht wurden, zu 
korrigieren.
Und diese Systeme haben dazu 
geführt,
dass sie bei bestimmten 
Informationssignalen,
die eingegangen sind,
einfach korrigieren wollte und 
die Nase nach
unten gemacht hat von dem 
Flieger in der Luft,
was dann dazu geführt hat.
Natürlich, wenn der Pilot das
nicht mehr korrigieren kann und
die Nase einfach nach unten 
gedrückt wird,
egal was der Pilot macht, 
automatisiert,
dass die Flieger abgestürzt 
sind.
Ähnliches Beispiel auch wieder 
mit Todesfällen ist,
wenn automatisierte Autos nicht 
funktionieren.
Da sitzt zwar ein Fahrer drin,
das ist eines der der Beispiele,
wo jetzt auch ein Urteil 
gesprochen wurde.
Vor ein paar Wochen in den Waymo 
Cars in Kalifornien,
die schon von alleine fahren,
haben sie meistens trotzdem noch 
einen Human Driver.
Aber dieser Human Driver ist 
nicht in
Entscheidungsgewalt
und muss sehr schnell reagieren 
manchmal.
Also wir haben automatisierte
Prozesse und eigentlich ist
da irgendwie noch so ein Mensch 
mit drin.
Der Mensch kann aber eigentlich 
nicht mehr eingreifen
und es hat dazu geführt,
dass dieser Safety Driver,
der drin war, das war irgendwie 
eine ältere Dame,
die irgendwie übermüdet war etc.",15.42065215,1,The generated answer is semantically consistent with the ground truth. Both correctly describe the 'J-Curve' as a pattern with an initial dip in productivity (due to unmeasured investments in intangibles) followed by a later rebound as the benefits are realized.,1,The generated answer is faithful. [cite_start]The context describes the J-Curve as a 'two-phase productivity pattern' with a 'Short-run dip as measured productivity falls or stalls' due to 'Heavy up-front investment' and a 'Long-run rebound as productivity accelerates once complements are in place'[cite: 565]. This matches the description in the generated answer.,1,"The context directly and comprehensively answers the question. It defines the 'J-Curve' as a 'two-phase productivity pattern' with a 'Short-run dip' due to 'Heavy up-front investment' in things like data and skills (which are poorly captured in standard measures), followed by a 'Long-run rebound as productivity accelerates once complements are in place'."
"What societal benefit, in terms of CO2 emissions, would a 2.6% return decrease translate to based on U.S. figures from 2022?","It would result in a reduction of 624,000 metric tons of CO2 emissions.","Basierend auf dem bereitgestellten Text würde eine Reduzierung der Produktivität um 2,6 % zur Senkung der CO2-Emissionen in den USA im Jahr 2022 zu einer Reduzierung von 624.000 Tonnen CO2-Emissionen führen.","effect corresponds to annual savings in processing costs 
of approximately $340,000 and translates into an 8.7% 
increase in profits. From an industry-wide perspective, 
based on a projected $25.1 billion in online returns pro -
cessing expenses in the United States for 2023 (Zheng 
2023 ), the decrease would translate to annual cost sav -
ings of approximately $650 million. From a societal per -
spective, based on U.S. figures from 2022, the 2.6% 
return decrease would result in a reduction of 624,000 
metric tons of CO
2 
emissions (Calma 2023 ). This reduc -
tion is roughly equivalent to the annual emissions from 
the electricity consumption of 121,000 U.S. homes.
1
Second, further analyses using the CML model 
reveal that the green nudge substantially reduced 
returns for approximately 60% of customers but led to 
an increase for the remaining 40%, suggesting that 
green nudging can occasionally backfire. This backfir -
ing effect, which has also been observed in prior studies 
(e.g., Hagmann et al. 2019 , Osman 2020 ), diminishes 
the intervention’s effectiveness from both business and 
societal perspectives. An off-policy evaluation provides 
evidence that “smartly” administering a green nudge 24. April 2025
Summary and impact: what ML does
https://www.readycloud.com/info/14-facts-about-ecommerce-product-returns
up to 4.6% decrease
•Our green nudges can be easily implemented at low costin all online shops •Our ""smart"" implementation uses open-source libraries and may predict impact on individual-level profit of any nudge•Our return reduction on global scale would save…•…up to 200,000 tons of CO2 emissions •…up to 120,000 tons of waste
Annual impact for industry partner: in the six figures Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können.",9.617277622,1,"The generated answer is semantically consistent with the ground truth. Both state the correct figure of 624,000 metric tons of CO2 emissions.",1,"The generated answer is faithful. [cite_start]The context explicitly states, 'From a societal perspective, based on U.S. figures from 2022, the 2.6% return decrease would result in a reduction of 624,000 metric tons of CO2 emissions'[cite: 583].",1,"The context directly answers the question, stating 'From a societal per - spective, based on U.S. figures from 2022, the 2.6% return decrease would result in a reduction of 624,000 metric tons of CO2 emissions'."
What is the estimated annual savings in processing costs for the industry partner due to the green nudge?,"The effect corresponds to annual savings in processing costs of approximately $340,000.","Laut dem Text beträgt der geschätzte jährliche Gewinnanstieg für den Industriepartner aufgrund des ""grünen Nudges"" im sechsstelligen Bereich.","24. April 2025
Summary and impact: what ML does
https://www.readycloud.com/info/14-facts-about-ecommerce-product-returns
up to 4.6% decrease
•Our green nudges can be easily implemented at low costin all online shops •Our ""smart"" implementation uses open-source libraries and may predict impact on individual-level profit of any nudge•Our return reduction on global scale would save…•…up to 200,000 tons of CO2 emissions •…up to 120,000 tons of waste
Annual impact for industry partner: in the six figures annually. This amount is roughly equivalent to the 
annual emissions from the electricity consumption of 
121,000 U.S. homes.
3
Notably, the actual savings in 
emissions are likely to be even higher both as the vol -
ume of returns continues to grow further (Calma 2023 ) 
and because emissions through packaging and the pro -
duction process of discarded goods are not included.
From a business perspective, according to internal 
figures of our industry partner, the estimated annual 
profit increase quickly amortizes costs associated with 
the development, implementation, and maintenance of 
green nudging. In fact, the developed dual nudge 
turned out to be so successful that our industry partner 
opted to keep the green nudge running in the German 
online shop. The project’s success is affirmed by a prac -
tice executive who corroborates the effectiveness of the 
implemented dual-nudge approach by stating that
[t]he reduction in returns without a negative impact 
on revenue was huge for us. So huge, in fact, that we 
opted for keeping the experiment live and showing 
the successful treatment to all of our German online 
customers. —Practice partner executive
Apart from the immediate business benefits through Kihal et al. 2021 , Pfrang and Spreer 2022 ). This paper 
aims to contribute to this discussion by empirically 
evaluating the effectiveness of an informational inter -
vention, referred to as green nudging, in decreasing 
product returns.
In this study, we partnered with a leading European 
fashion retailer. Like many in the industry, the retailer 
grapples with the challenges and costs arising from 
online product returns. Seeking to align profitability 
with environmental responsibility, we collaborated 
with our partner to craft a strategy that not only curtails 
product returns but also, that resonates with the retai -
ler’s sustainable ethos and is economically viable. The 
jointly developed green nudge comprises two prompts: 
informing online customers about the negative envi -
ronmental impact of product returns throughout 
(shopping cart prompt) and at the conclusion of their 
online shopping journey (reminder prompt). We con -
ducted an extensive field experiment with 117,304 par -
ticipants in the retailer’s online shop to empirically 
validate the green nudge. We then apply modern 
causal machine learning (CML) methods (Athey et al. 
2019 ) to analyze treatment heterogeneities based on",7.12606883,0.9,"The generated answer is semantically consistent with the ground truth. The ground truth states the savings are '$340,000'. The generation states the savings are 'in the six figures', which is a less precise but correct and consistent statement.",0,"The generated answer is not faithful. It claims the annual profit increase is in the six figures. [cite_start]However, the context explicitly states that the 'annual savings in processing costs' are approximately $340,000 and that this translates to an '8.7% increase in profits'[cite: 582]. While $340,000 is a six-figure amount, the generation incorrectly labels it as 'profit increase' instead of 'savings in processing costs'.",0.7,"The context is relevant but not fully specific. One part of the context states, 'Annual impact for industry partner: in the six figures,' which supports the general magnitude of the answer. However, it does not provide the precise figure of '$340,000.'"
"In the 'Smart Green Nudging' paper, what was the sample size (n) of the randomized field experiment discussed?","The experiment had a sample size of 117,304 participants (n = 117,304).","Die Stichprobengröße (n) des randomisierten Feldexperiments, das im Paper diskutiert wird, ist nicht explizit angegeben.","The rest of the paper is structured as follows. Section 
2 provides the theoretical background by reviewing 
related literature. Section 3 presents the setting and 
results of our randomized field experiment. Section 4
details the configuration and results from our causal 
machine learning model, along with the evaluation of 
smart green nudging. Section 5 concludes by discuss -
ing the practical implications of our work, its limita -
tions, and potential avenues for future research.
2. Related Literature
Our work relates to three streams of literature, namely 
(i) product returns, (ii) nudging, and (iii) treatment het -
erogeneities and causal machine learning.
2.1. Product Returns
The surge in product returns and the corresponding busi -
ness and environmental repercussions have prompted 
von Zahn et al.: Product Returns, Digital Footprints, and Causal Machine Learning 
2 Marketing Science, Articles in Advance, pp. 1–16, © 2024 The Author(s) 
Downloaded from informs.org by [141.2.113.143] on 24 April 2025, at 02:36 . For personal use only, all rights reserved. significant variability in how individuals respond to 
nudging (Hummel and Maedche 2019 ), rendering the 
outcomes of green nudging unpredictable (Lehner et al. 
2016 ). Additionally, few researchers have explored the 
impact of green nudges on a large scale (see He et al. 
2023 for an exception), leaving a gap in our understand -
ing and a need to reconcile these divergent findings.
We extend prior research by conducting a large- 
scale, randomized field experiment to test the effective -
ness of green nudges in reducing product returns. Our 
green nudge effectively leverages customers’ desire to 
sustain a positive self-image through environmentally 
friendly behavior (Schubert 2017 ). It heightens aware -
ness of the negative environmental impact linked to 
returning products during both the prepurchase and 
postpurchase phases of the customer journey.
2.3. Treatment Heterogeneities and Causal 
Machine Learning
There often exists a notable heterogeneity in customer 
reactions to marketing strategies (El Kihal and Shehu 
2022 ), especially nudging techniques (Lehner et al. 
2016 , Mirsch et al. 2017 , Hummel and Maedche 2019 ). 
Accordingly, relying solely on average treatment and assess a causal machine learning model designed to identify treatment heterogeneities 
and personalize green nudging (i.e., make nudging “smart”). Our off-policy evaluation 
indicates that this personalization can approximately double the success of green nudging. 
The study demonstrates the effectiveness of both subtle marketing interventions and per -
sonalization using causal machine learning in mitigating environmentally and economi -
cally harmful product returns, thus highlighting the feasibility of employing “Better 
Marketing for a Better World” approaches in a digital setting.
History: Olivier Toubia served as the senior editor. This paper was selected as a finalist in the 2022 Gary 
L. Lilien ISMS-MSI Practice Prize Competition. 
Open Access Statement: This work is licensed under a Creative Commons Attribution-NonCommercial- 
NoDerivatives 4.0 International License. You are free to download this work and share with others, 
but cannot change in any way or use commercially without permission, and you must attribute this 
work as “Marketing Science. Copyright © 2024 The Author(s). https:/ /doi.org/10.1287/mksc.2022. 
0393, used under a Creative Commons Attribution License: https:/ /creativecommons.org/licenses/",7.05337882,0,"The generated answer is a refusal to answer, stating the sample size is not specified. The ground truth provides the exact sample size. The answers are contradictory.",0,"The generated answer is not faithful. [cite_start]The retrieved context explicitly states that the study conducted 'an extensive field experiment with 117,304 participants'[cite: 605]. The generated answer claims the sample size is not explicitly stated.",0,The context discusses the related literature and the general setup of the green nudge experiment but does not contain any information about the sample size (n) of the randomized field experiment.
What are the two types of returns mentioned in the context of online shopping?,'Real returns' (where the customer intended to keep the item) and 'opportunistic returns' (where the customer orders multiple options with the intent to return some).,"Im Kontext des Online-Shoppings werden zwei Arten von Renditen erwähnt:

1.  **Produkt-Renditen** (Product Returns)
2.  **Netto-Renditen** (Net Sales)","Kihal et al. 2021 , Pfrang and Spreer 2022 ). This paper 
aims to contribute to this discussion by empirically 
evaluating the effectiveness of an informational inter -
vention, referred to as green nudging, in decreasing 
product returns.
In this study, we partnered with a leading European 
fashion retailer. Like many in the industry, the retailer 
grapples with the challenges and costs arising from 
online product returns. Seeking to align profitability 
with environmental responsibility, we collaborated 
with our partner to craft a strategy that not only curtails 
product returns but also, that resonates with the retai -
ler’s sustainable ethos and is economically viable. The 
jointly developed green nudge comprises two prompts: 
informing online customers about the negative envi -
ronmental impact of product returns throughout 
(shopping cart prompt) and at the conclusion of their 
online shopping journey (reminder prompt). We con -
ducted an extensive field experiment with 117,304 par -
ticipants in the retailer’s online shop to empirically 
validate the green nudge. We then apply modern 
causal machine learning (CML) methods (Athey et al. 
2019 ) to analyze treatment heterogeneities based on they shop during weekends or weekdays as other online 
shopping studies have shown (Grahl et al. 2023 ).
Individuals’ digital footprints contain meaningful 
information (Berg et al. 2020 ). In our CML model, we use 
these footprints, specifically the internet provider, 
browser type, and IP geolocation, which have been 
shown to be relevant in explaining behavioral heteroge -
neities (see, e.g., CivicScience 2015 , Berg et al. 2020 , Ebert 
et al. 2021 ). We treat all three predictors from the digital 
footprint as categorical variables. To prepare them for 
our CML model, we apply one-hot encoding and feature 
selection, which we detail in Online Appendix A.5.
4.1.2. The Causal Forest. We estimate heterogeneous 
treatment effects using a causal forest (Athey et al. 2019 ). 
This method calculates conditional average treatment 
effects for various combinations of predictor values. Prac -
tically, the causal forest segments global average treat -
ment effects into local conditional averages by repeatedly 
dividing customers into subgroups and calculating the 
difference in effects between treatment and control 
groups within each subgroup. Its capability to capture 
highly nonlinear treatment heterogeneities makes it parti - cost nature, seeking simply to inform customers about 
the repercussions of their postpurchase actions. Closely 
related to our research, Ghose et al. ( 2023 ) recently 
assessed the effectiveness of pressure-oriented and self- 
assurance-oriented nudges on sales and returns, find -
ing that the latter is better suited to boosting net sales. 
Unlike our study, the nudges that they examined pro -
vide direct information about products under consider -
ation by online shoppers. To our knowledge, we are the 
first to design and test the efficacy of making the envi -
ronmental consequences of postpurchase behavior 
salient in reducing product returns through a large- 
scale field experiment.
2.2. Nudging
As a cognitive intervention, nudging aims to subtly 
alter human behavior through modifications in the 
choice architecture (Thaler and Sunstein 2009 ). Cru -
cially, nudges guide behavior without restricting 
options, substantially altering material incentives, or 
using coercion (Thaler and Sunstein 2009 , Mirsch et al. 
2017 ). They are minimally invasive interventions that 
maintain freedom of choice (Thaler and Sunstein 2003 ) 
and can enhance economic efficiency by facilitating 
superior choices with minimal expenditure.",7.085172892,0,"The generated answer identifies 'Product Returns' and 'Net Sales' as two types of returns, which is incorrect. The ground truth correctly identifies the two types of returns as 'real' and 'opportunistic'. The answers are not semantically consistent.",0,"The generated answer is not faithful. It identifies 'Product Returns' and 'Net Sales' as the two types of returns. [cite_start]The context does mention 'product returns' [cite: 625] [cite_start]and 'net sales'[cite: 640], but 'net sales' is a measure of revenue after returns, not a type of return itself.",0.1,"The context is only slightly relevant. It repeatedly mentions 'product returns' as a general concept but does not define or discuss different types of returns, such as 'real returns' or 'opportunistic returns'."
"According to the paper, by how much did the smart green nudge decrease product returns compared to having no nudge at all?",The smart green nudge resulted in a 6.7% decrease in product returns compared to no nudge at all.,"Der ""Smart Green Nudge"" reduzierte die Produkt-Renditen im Vergleich zu einer Nicht-Implementierung um 2,1%.","the potential of smart green nudging as an effective 
personalization strategy for both businesses and the 
environment.
5. Discussion and Conclusion
5.1. Contribution
Our study addresses the challenge of product returns 
by developing and empirically validating a green 
nudging intervention. Green nudging prompts shop -
pers toward more environmentally conscious and 
thoughtful behavior, effectively reducing product 
returns. Our large-scale field experiment shows that 
green nudging lowers product returns by 2.6% without 
negatively impacting sales. For our industry partner, 
the observed effect translates into an estimated annual 
reduction in processing costs of about $340,000 and an 
8.7% boost in profits. On a larger scale, estimations 
based on public data from the United States suggest 
that the achieved reduction in returns could signifi -
cantly decrease U.S. fashion industry-wide costs by 
$650 million (Zheng 2023 ) and carbon emissions by 
624,000 metric tons (Calma 2023 ). Additionally, our 
causal machine learning model identifies notable varia -
tions in consumer responses to the nudge. Subsequent 
off-policy evaluation indicates that exploiting these 
variations (i.e., nudging “smartly”) could more than vertical axis) as we vary the policy π by applying the 
intervention to different shares of the test data (on the 
horizontal axis). In essence, the curve shows the overall 
efficacy of smart green nudging as we progressively 
include the top 10%, 20%, and 30% of customers who 
the CML model predicts to achieve the largest reduc -
tions in returns. A random administration of the green 
nudge to an equally sized share (the dashed line in 
Figure 4 ) would result in a linear decrease from the 
level of the control group (no customers treated) to that 
of naive green nudging (all customers treated). The 
Figure 3. (Color online) Group Average Treatment Effects 
(ATEs) by Treatment Policy 
Notes. We depict the group average treatment effects of the dual 
nudge on returns (shipment) measured in the test data. The left bar 
presents the ATE for the group with π(x
i
) � 0 (40.7% of the test data), 
whereas the right bar presents the ATE for the group with π(x
i
) � 1 
(59.3% of the test data). The vertical lines represent the 95% confi -
dence intervals.
von Zahn et al.: Product Returns, Digital Footprints, and Causal Machine Learning 
Marketing Science, Articles in Advance, pp. 1–16, © 2024 The Author(s) 11 variation in treatment effects across different states (see 
Online Appendix A.9). However, excluding indivi -
duals from Baden-W ¨urttemberg who, on average, 
exhibit a notable adverse reaction to the green nudge 
results in a modest improvement of 0.1 percentage 
points in the effectiveness of the green nudge.
Overall, the results for smart green nudging offer an 
optimistic outlook. From a business perspective, imple -
menting smart green nudging could potentially double 
the cost savings compared with the naive strategy. 
Equally significant is the environmental benefit. 
Applied across the United States in logistics, this 
approach could double the effect on CO
2 
emissions to 
an impressive total of more than 1 million tons annu -
ally (Calma 2023 ). These dual advantages underscore 
Table 4. Summary Statistics from the Analyses of Smart Green Nudging on Test Data
Share treated, %
Returns (shipment) Returns (value) Cart conversion Sales
Mean (SE) Mean (SE) Mean (SE) Mean (SE)
No nudging 0.0 0.262 (0.005) 18.61 (0.58) 0.628 (0.006) 51.96 (0.90)
Naive green nudging 100.0 0.256 (0.005) 18.22 (0.56) 0.631 (0.005) 52.49 (0.87)
Difference from no nudging, % � 2.10 � 2.10 0.51 1.01",6.914641857,0,"The generated answer states a 2.1% decrease, while the ground truth states a 6.7% decrease. The answers are factually contradictory.",0,"The generated answer is not faithful. It claims a 2.1% decrease in product returns. [cite_start]The retrieved context, in Table 4, shows that 'Naive green nudging' resulted in returns of 0.256 compared to 'No nudging' at 0.262, with the 'Difference from no nudging' listed as -2.10%[cite: 663]. The query asks about the 'smart' green nudge, not the 'naive' one. [cite_start]The context discusses the 'smart' nudge separately, stating it could 'double the success'[cite: 620], but does not give a specific percentage for the smart nudge versus no nudge.",0.6,"The context is relevant as it provides data on the effect of the nudge. However, the table in the context shows that the 'Naive green nudging' resulted in a 2.1% decrease in returns compared to 'No nudging'. It does not contain the 6.7% figure for the 'smart green nudge' mentioned in the question."
"In the 'Smart Green Nudging' study, which variable was identified by SHAP values as the most pivotal for the prediction?",The initial cart value.,"Laut dem Text wurde der initiale Warenkorbwert durch SHAP-Werte als die variable identifiziert, die am wichtigsten für die Vorhersage war.","contribute to the predictions (Senoner et al. 2022 ). In 
our case, SHAP values indicate that the initial cart 
value is the variable most pivotal for the prediction. We 
report SHAP values from our CML model in Online 
Appendix A.10. However, it is crucial to differentiate 
between variables that predict the treatment effect and 
those that act as causal moderators. We encourage 
future research to rigorously investigate the causal role 
of variables in moderating the effectiveness of green 
nudging.
Our study also underscores the effectiveness of using 
customer carts and digital footprint data to personalize 
marketing interventions. Our analyses reveal multiple 
characteristics that induce heterogeneous treatment 
effects, including the type of internet browser, the inter -
net provider, the federal state, and the weekday.
7
For 
example, weekend shoppers are more effectively 
nudged than weekday shoppers, possibly because of 
lower stress levels, aligning with similar literature find -
ings (Grahl et al. 2023 ). Similarly, the internet browser 
and other characteristics of the digital footprint can 
hint at underlying customer traits and demographics 
(Berg et al. 2020 ). Incorporating these insights, practi - 22. Mai 2025
Shapley scores: weighted average
•Local accuracy: attributions sum (exactly) to the prediction difference•Consistency: if a model changes so that the marginal contribution of a feature value increases or stays the same (regardless of other features), the Shapley value also increases or stays the same.•Missingness: unused features get SHAP value of 0 x*=0→𝜙+•Additivity: SHAP values can be added to show the joint contribution of several features to a prediction
22
𝜙%𝑓,𝑥=	2&!⊆	)!𝑧*!𝑀−𝑧*−1!𝑀! (𝑓)𝑧*−𝑓)𝑧*\i)Shapley value for i= savings
Model f
For individual x with a specific combination of features
Weighted sum over allSubsets z’of (transformed) data point x; whereM is total number of features in full set
Difference inModel prediction
𝑃𝑟𝑒𝑑𝑖𝑐𝑡𝑖𝑜𝑛!=𝐸(-𝑓𝑋)	+	3""𝜙! purchase, ensuring an unbiased and comprehensive 
assessment of green nudging effects (e.g., encompass -
ing effects on the conversion rate).
3.2.1. Overall Effects of Green Nudging. Table 2 pre -
sents individual summary statistics for key business 
metrics from our field experiment. Specifically, we out -
line average customer responses in terms of binary return 
decisions, the value of returned products, the cart conver -
sion, and sales. We display these results separately for 
the control group (without nudging) and the two treat -
ment groups (single nudge and dual nudge). For all three 
groups, we visualize the key business metrics and confi -
dence intervals relative to the control group in Figure 2 .
Our results suggest that the dual-green-nudge inter -
vention can significantly reduce product returns with -
out harming sales. On the extensive margin, customers 
in the dual-nudge treatment are on average 2.6% less 
likely to return at least one product and thus, make a 
return shipment compared with the control group (0.24 
versus 0.26, respectively; p < 0.03, Mann–Whitney U 
test). We also observe an impact on the intensive mar -
gin. On average, customers exposed to the dual nudge",6.941674948,1,The generated answer is semantically consistent with the ground truth. Both correctly identify the 'initial cart value' as the most pivotal variable.,1,The generated answer is faithful. [cite_start]The context explicitly states that 'SHAP values indicate that the initial cart value is the variable most pivotal for the prediction'[cite: 665].,1,"The context directly answers the question. It explicitly states, 'In our case, SHAP values indicate that the initial cart value is the variable most pivotal for the prediction.'"
"In the field experiment from the 'Smart Green Nudging' paper, what was the initial aim of the academic team members regarding the prompts they were testing?",The initial aim was to isolate the effects of the cart prompt and the reminder prompt.,"According to the text, the academic team's original goal was to develop a machine learning model to identify treatment heterogeneities and personalize green nudging – essentially, to make nudging “smart.”","die das beeinflussen und
was hier Venkatesh und Kollegen 
gemacht haben,
die haben acht verschiedene 
Modelle
aus ganz unterschiedlichen
Disziplinen zusammengenommen und
haben jahrelang rumgewerkelt, um 
zu schauen,
was sind eigentlich die latent 
ähnlichen Faktoren,
was können wir irgendwie 
zusammenfassen und
was sind Faktoren,
die möglichst orthogonal einzeln 
gesehen
unterschiedlich sind und
viel Erklärungsgehalt dafür 
haben
in der Vorhersage,
ob ein Mensch die Technologie 
nutzen wird oder nicht.
Und das haben Sie das Modell, 
was entwickelt haben
letztlich auf ganz viele 
empirische Daten
gelegt und gezeigt,
dass dieses Modell um die 70 % 
der Variation darin,
ob Leute mit Technologie 
interagieren,
diese wirklich nutzen und 
akzeptieren, erklären kann.
Als Spoiler schon mal 70 % der
Variation zu erklären ist 
massiv,
insbesondere in solchen 
soziotechnischen Systemen,
wo wie immer der Mensch die 
Schwachstelle ist.
Womit haben Sie angefangen? Sie 
haben gesagt.
Und dieses Modell ist
vor allen Dingen aus der 
Perspektive
geschaffen worden damals.
Wie kriegen wir eigentlich Leute 
in Unternehmen dazu,
die bereitgestellte Technologie 
zu nutzen?
Es gibt mittlerweile auch zwei
Erweiterungen von diesem Modell and assess a causal machine learning model designed to identify treatment heterogeneities 
and personalize green nudging (i.e., make nudging “smart”). Our off-policy evaluation 
indicates that this personalization can approximately double the success of green nudging. 
The study demonstrates the effectiveness of both subtle marketing interventions and per -
sonalization using causal machine learning in mitigating environmentally and economi -
cally harmful product returns, thus highlighting the feasibility of employing “Better 
Marketing for a Better World” approaches in a digital setting.
History: Olivier Toubia served as the senior editor. This paper was selected as a finalist in the 2022 Gary 
L. Lilien ISMS-MSI Practice Prize Competition. 
Open Access Statement: This work is licensed under a Creative Commons Attribution-NonCommercial- 
NoDerivatives 4.0 International License. You are free to download this work and share with others, 
but cannot change in any way or use commercially without permission, and you must attribute this 
work as “Marketing Science. Copyright © 2024 The Author(s). https:/ /doi.org/10.1287/mksc.2022. 
0393, used under a Creative Commons Attribution License: https:/ /creativecommons.org/licenses/ von Anfang bis Ende von
einer Maschine durchgeführt 
worden ist.
Der Mensch hat daran nichts 
verändert.
hat. Weder bei Ideation nur den 
Anfang.
Befehl eingegeben.
Komme mit einer das haben sie 
glaube ich gesagt,
irgendwie Develop a new year for
innovative machine learning 
paper
that they want to publish at
this conference und the machine 
green with it.
Und das hat es anscheinend durch
den Peer Review Prozess 
geschafft.
Immer so ein bisschen Grain of 
salt sehen.
Ist natürlich auch medial 
aufgebauscht.
Wie viel wirklich dann an der
Stelle noch an Mensch 
reingeflossen ist,
kann ich Ihnen an dieser Stelle 
nicht verlässlich sagen.
Ich warte selber auf das 
Research Papier,
das das erklärt, was da wirklich 
passiert ist.
Aber das ist natürlich die 
mediale Darstellung.
Jetzt erstmal davon Companions,
das ist auch so ein Riesending.
Weiß nicht, ob du es mitgekriegt 
haben.
Mark Zuckerberg hatte auf 
irgendwo
in den USA auf einer Sitzung 
jetzt gesagt,
dass er das Problem von 
Einsamkeit lösen will,
in dem alle Menschen mit KI 
interagieren KI,
die auf Social Media trainiert 
worden ist.
Die Idee gibt es natürlich schon 
länger.
Ich glaube, diese Idee
hat ihn gewissermaßen vielleicht 
Potenzial zu helfen.",7.484349012,0,The generated answer claims the aim was to develop a machine learning model to personalize nudging. The ground truth states the initial aim was to isolate the effects of two different prompts. These are different research goals and are not semantically consistent.,1,"The generated answer is faithful. [cite_start]The context states that the study's aim is to 'assess a causal machine learning model designed to identify treatment heterogeneities and personalize green nudging (i.e., make nudging â€œsmartâ€)'[cite: 690].",0,"The context describes the overall goal of the paper, which is to 'assess a causal machine learning model designed to identify treatment heterogeneities and personalize green nudging.' It does not mention an initial aim of isolating the effects of the cart prompt and the reminder prompt specifically."
"In the 'Smart Green Nudging' paper, what were the estimated annual savings in processing costs for the industry partner as a result of the green nudging intervention?","The estimated annual savings in processing costs were approximately $340,000.",Der Branchenpartner erzielte durch den Einsatz der grünen Anreizeinsatz etwa 340.000 US-Dollar an jährlichen Kosteneinsparungen.,"the potential of smart green nudging as an effective 
personalization strategy for both businesses and the 
environment.
5. Discussion and Conclusion
5.1. Contribution
Our study addresses the challenge of product returns 
by developing and empirically validating a green 
nudging intervention. Green nudging prompts shop -
pers toward more environmentally conscious and 
thoughtful behavior, effectively reducing product 
returns. Our large-scale field experiment shows that 
green nudging lowers product returns by 2.6% without 
negatively impacting sales. For our industry partner, 
the observed effect translates into an estimated annual 
reduction in processing costs of about $340,000 and an 
8.7% boost in profits. On a larger scale, estimations 
based on public data from the United States suggest 
that the achieved reduction in returns could signifi -
cantly decrease U.S. fashion industry-wide costs by 
$650 million (Zheng 2023 ) and carbon emissions by 
624,000 metric tons (Calma 2023 ). Additionally, our 
causal machine learning model identifies notable varia -
tions in consumer responses to the nudge. Subsequent 
off-policy evaluation indicates that exploiting these 
variations (i.e., nudging “smartly”) could more than Kihal et al. 2021 , Pfrang and Spreer 2022 ). This paper 
aims to contribute to this discussion by empirically 
evaluating the effectiveness of an informational inter -
vention, referred to as green nudging, in decreasing 
product returns.
In this study, we partnered with a leading European 
fashion retailer. Like many in the industry, the retailer 
grapples with the challenges and costs arising from 
online product returns. Seeking to align profitability 
with environmental responsibility, we collaborated 
with our partner to craft a strategy that not only curtails 
product returns but also, that resonates with the retai -
ler’s sustainable ethos and is economically viable. The 
jointly developed green nudge comprises two prompts: 
informing online customers about the negative envi -
ronmental impact of product returns throughout 
(shopping cart prompt) and at the conclusion of their 
online shopping journey (reminder prompt). We con -
ducted an extensive field experiment with 117,304 par -
ticipants in the retailer’s online shop to empirically 
validate the green nudge. We then apply modern 
causal machine learning (CML) methods (Athey et al. 
2019 ) to analyze treatment heterogeneities based on 24. April 2025
Summary and impact: what ML does
https://www.readycloud.com/info/14-facts-about-ecommerce-product-returns
up to 4.6% decrease
•Our green nudges can be easily implemented at low costin all online shops •Our ""smart"" implementation uses open-source libraries and may predict impact on individual-level profit of any nudge•Our return reduction on global scale would save…•…up to 200,000 tons of CO2 emissions •…up to 120,000 tons of waste
Annual impact for industry partner: in the six figures",6.950434446,1,"The generated answer is semantically consistent with the ground truth. Both state the correct figure of approximately $340,000 in annual savings.",1,"The generated answer is faithful. [cite_start]The retrieved context states, 'For our industry partner, the observed effect translates into an estimated annual reduction in processing costs of about $340,000'[cite: 703].",1,"The context provides a direct answer to the question. It states, 'For our industry partner, the observed effect translates into an estimated annual reduction in processing costs of about $340,000'."
Where is INFORMS located?,"INFORMS is located in Maryland, USA.","INFORMS befindet sich in Maryland, USA.","Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. Informationen zur Vorlesung: Gehalten am Do. 12:00 bis 16:00; wöchentlich vom 24.04.2025 bis 24.07.2025; Ort: Hörsaalzentrum Westend - HZ 12 This article was downloaded by: [141.2.113.143] On: 24 April 2025, At: 02:36
Publisher: Institute for Operations Research and the Management Sciences (INFORMS)
INFORMS is located in Maryland, USA
Marketing Science
Publication details, including instructions for authors and subscription information:
http://pubsonline.informs.org
Smart Green Nudging: Reducing Product Returns
Through Digital Footprints and Causal Machine
Learning
Moritz von Zahn, Kevin Bauer, Cristina Mihale-Wilson, Johanna Jagow, Maximilian
Speicher, Oliver Hinz
To cite this article:
Moritz von Zahn, Kevin Bauer, Cristina Mihale-Wilson, Johanna Jagow, Maximilian Speicher, Oliver Hinz (2024)
Smart Green Nudging: Reducing Product Returns Through Digital Footprints and Causal Machine Learning.
Marketing Science
Published online in Articles in Advance 08 Aug 2024
. https://doi.org/10.1287/mksc.2022.0393
This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International
License. You are free to download this work and share with others, but cannot change in any way or use
commercially without permission, and you must attribute this work as “Marketing Science. Copyright © 2024 The",3.271111965,1,"The generated answer is semantically consistent with the ground truth. Both correctly state that INFORMS is located in Maryland, USA.",1,"The generated answer is faithful. [cite_start]The context explicitly states 'INFORMS is located in Maryland, USA'[cite: 719].",1,"The context directly answers the question, stating 'INFORMS is located in Maryland, USA.'"
What programming language will be used in the course?,Python.,In diesem Kurs wird die Programmiersprache Python verwendet.,"Ein besonderer Fokus des Kurses liegt auf praxisnahen Übungen: Mithilfe der Programmiersprache Python werden die Teilnehmer Schritt für Schritt an die Umsetzung von ML-Projekten herangeführt. Alle Programmierübungen sind so gestaltet, dass sie auch ohne Vorkenntnisse lösbar sind, und die Studierenden erhalten die notwendige Unterstützung, um die Inhalte erfolgreich umzusetzen. Ziel ist es, ein solides Verständnis für ML-Tools zu entwickeln und deren Nutzen für Managemententscheidungen zu erkennen.
Darüber hinaus wird der Kurs die aufkommende Bedeutung von generativen KI-Modellen wie GPT beleuchten. Studierende lernen, wie diese Modelle durch gezieltes Prompting eingesetzt werden können, um spezifische Managementfragen zu adressieren und Entscheidungsprozesse zu unterstützen. eigentlich 
Entscheidungsunterstützung,
wo das System uns sagt Nein,
das ist eine Möglichkeit,
wie man diesen Code weiterführt.
Auf der anderen Seite haben
wir unsere ganzen großen 
Sprachmodelle,
mit denen wir tagtäglich 
zusammenarbeiten,
wo unser Job ist, eigentlich 
nicht,
etwas an die Maschine komplett 
zu delegieren.
Ja, Sie sollten nicht eine 
Eingabe machen.
Schreib mir meine 
Bachelorarbeit, die Maschine 
macht das.
Sie nehmen die Bachelorarbeit 
und geben die ab,
sondern Sie sollten
das als 
Entscheidungsunterstützung 
ansehen,
wo Sie als der Mensch Input von 
der Maschine bekommen,
Sie diesen Input nachprüfen 
sollten
und letztlich selber die finale 
Entscheidung treffen.
Das ist vorbei.
Also verstehe ich das richtig,
dass wir im Prinzip im zweiten 
Teil des Events,
dass man eine Entscheidung 
trifft,
Also eine Entscheidung dann,
wenn das fliegende Maschinen 
scheitert.
Ich muss nur so lachen wegen 
Meter,
weil ich gerade ein
Forschungsprojekt bin mit einer 
Psychologiekollegin
und wir reden über 
Metakognition.
Und wir sagen tatsächlich,
dass Metakognition auf dem Meta 
Level fällt.
Die Entscheidung, ob ich die
Entscheidung jemand anders 
machen lasse.
Also auch wieder System eins und 
System zwei,
so ein bisschen Die gemacht hat,
das User Interface war
die reine Technologie dieser 
großen Sprachmodelle.
Die gibt es theoretisch schon 
seit 2017.
Die wurden natürlich immer 
besser.
Wir hatten am Ende die Version 
drei Punkt irgendwas,
was dann integriert wurde.
Aber es wurde integriert.
Dieses fundamentale KI Modell in
eine ausreichend kompatible und
nutzerfreundliche Umgebung,
nämlich Chat GPT, was
noch mal das Grundmodell GPT
plus weitere Systeme sind, die 
hier zusammenspielen.
Das heißt Forgeat GPT.
Gab es diese großen 
Sprachmodelle schon?
Die haben sich wie gesagt immer 
weiter verbessert.
Grundsätzlich haben
wir aber alle erst damit 
angefangen und
haben eine ganze Industrie 
eigentlich damit angefangen,
es kommerziell zu benutzen.
Ab dem Moment, wo dieses
User Interface richtig 
hinbekommen wurde
und die User des Systems 
hochgegangen ist.
Das ist eine der Kern messages
die Bereitschaft des Nutzers,
mit den Systemen zu 
interagieren.
Generell, wo wir
häufig von Adoption reden 
Technologie use.
Wenn wir ganz, ganz breit sind.
Das ist zentral dafür,
wie eine Technologie tatsächlich
letztlich Einfluss haben kann 
auf unser Sozialleben,
auf unsere ökonomischen 
Prozesse,
auf Unternehmen
und letztlich natürlich auf 
Produktivität.",4.002728701,1,The generated answer is semantically consistent with the ground truth. Both correctly identify Python as the programming language used.,1,"The generated answer is faithful. The context states, 'Mithilfe der Programmiersprache Python werden die Teilnehmer Schritt fÃ¼r Schritt an die Umsetzung von ML-Projekten herangefÃ¼hrt.' (With the help of the Python programming language, participants will be guided step-by-step through the implementation of ML projects) [cite_start][cite: 723].",1,"The context directly answers the question, stating 'Mithilfe der Programmiersprache Python werden die Teilnehmer Schritt fÃ¼r Schritt an die Umsetzung von ML-Projekten herangefÃ¼hrt' (With the help of the programming language Python, participants will be guided step-by-step through the implementation of ML projects)."
"According to the text, what are four useful applications of Large Language Models (LLMs) in everyday life?","Four useful applications of LLMs are: synthesizing information (such as summarizing and translating), acting as an argumentative sparring partner to identify weak points in arguments, brainstorming creative ideas, and assisting with code-related tasks like documentation and translation between programming languages.","Der Text nennt folgende vier nützliche Anwendungen von Large Language Models (LLMs) im Alltag:

1.  **Entscheidungsunterstützung** durch Code-Vorschläge (die Maschine sagt ""Nein, das ist eine Möglichkeit, wie man diesen Code weiterführt"").
2.  **Zusammenarbeit** mit Systemen wie ChatGPT.
3.  **Analyse von Kundendaten** (im Kontext von Managemententscheidungen).
4.  **Vorhersage von Markttrends** (ebenfalls im Kontext von Managemententscheidungen).","Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. gemacht hat,
das User Interface war
die reine Technologie dieser 
großen Sprachmodelle.
Die gibt es theoretisch schon 
seit 2017.
Die wurden natürlich immer 
besser.
Wir hatten am Ende die Version 
drei Punkt irgendwas,
was dann integriert wurde.
Aber es wurde integriert.
Dieses fundamentale KI Modell in
eine ausreichend kompatible und
nutzerfreundliche Umgebung,
nämlich Chat GPT, was
noch mal das Grundmodell GPT
plus weitere Systeme sind, die 
hier zusammenspielen.
Das heißt Forgeat GPT.
Gab es diese großen 
Sprachmodelle schon?
Die haben sich wie gesagt immer 
weiter verbessert.
Grundsätzlich haben
wir aber alle erst damit 
angefangen und
haben eine ganze Industrie 
eigentlich damit angefangen,
es kommerziell zu benutzen.
Ab dem Moment, wo dieses
User Interface richtig 
hinbekommen wurde
und die User des Systems 
hochgegangen ist.
Das ist eine der Kern messages
die Bereitschaft des Nutzers,
mit den Systemen zu 
interagieren.
Generell, wo wir
häufig von Adoption reden 
Technologie use.
Wenn wir ganz, ganz breit sind.
Das ist zentral dafür,
wie eine Technologie tatsächlich
letztlich Einfluss haben kann 
auf unser Sozialleben,
auf unsere ökonomischen 
Prozesse,
auf Unternehmen
und letztlich natürlich auf 
Produktivität. Die System eins Muster.
Eine sehr schöne Interpretation
dieser grundlegenden Idee,
dass wir unterschiedliche
Lösungsstrategien gesucht und 
gefunden haben.
Durch unser Lernen, durch unsere 
Erfahrungen,
die wir im Leben individuell 
gemacht haben.
Beispiele von Mensch Maschine 
Interaktion im Alltag.
Das hier ist insbesondere
für Softwareentwicklung 
natürlich hochgradig 
interessant.
Ich fange an, Code zu schreiben.
Wenn Sie mit Charlotte,
die in der Übung die
Notebook Files schreiben und das 
mit
einem Pro Account auf Google 
Collab machen.
Dann fangen sie an, was zu 
schreiben und plötzlich
stehen die nächsten 20 Zeilen 
Code schon da,
weil die Maschine antizipiert,
was sie eigentlich schreiben 
wollen und
Sie klicken nur noch Enter und
der ganze Code ist plötzlich 
schon da.
Diese Suggestions Johns 
eigentlich.
Wenn wir uns hier wieder
auf diese zwei verschiedenen 
sehr
dichotomen Möglichkeiten der
Zusammenarbeit konzentrieren,
haben wir über diese
Code Recommendations
eigentlich 
Entscheidungsunterstützung,
wo das System uns sagt Nein,
das ist eine Möglichkeit,
wie man diesen Code weiterführt.
Auf der anderen Seite haben
wir unsere ganzen großen 
Sprachmodelle,
mit denen wir tagtäglich 
zusammenarbeiten,",11.54506063,0.8,"The generated answer is semantically consistent with the ground truth. The ground truth lists four specific applications. The generation lists four related applications ('decision support', 'collaboration', 'customer data analysis', 'market trend prediction') that capture the same spirit and cover the same domains (information synthesis, brainstorming, coding).",0.5,"The generated answer lists four applications. [cite_start]Three of them are supported by the context: 'EntscheidungsunterstÃ¼tzung' (decision support) through code suggestions [cite: 762][cite_start], collaboration with large language models like ChatGPT [cite: 763][cite_start], and analysis of customer data / prediction of market trends[cite: 744]. However, the fourth claim, that LLMs act as an 'argumentative sparring partner', is not mentioned in the retrieved context.",0.8,"The context is relevant. It mentions several applications of large language models, including 'EntscheidungsunterstÃ¼tzung' (decision support) through code suggestions, collaboration with models like ChatGPT, and using ML for analyzing customer data and predicting market trends, which aligns with the applications of synthesizing information, brainstorming, and coding assistance."
For what types of tasks are basic chat models the most suitable choice?,Basic chat models are most suitable for low-stake tasks where a fast response is required.,"Basierend auf dem Text sind grundlegende Chat-Modelle am besten geeignet, wenn Nutzer ihre Entscheidungen anhand von Informationen unterstützen lassen wollen. Konkret können sie genutzt werden, um:

*   **Informationen zu gewichten:** Nutzer können die Vorschläge des Systems bewerten und entscheiden, ob sie für ihre Entscheidungsfindung relevant sind.
*   **Bei der Ideenfindung zu helfen:** Nutzer können Fragen stellen wie ""Wo kann ich einen guten Urlaub machen?"" und die Vorschläge des Systems nutzen, um Ideen zu sammeln.

Es ist wichtig zu beachten, dass grundlegende Chat-Modelle noch nicht in der Lage sind, komplexe Aufgaben wie das Buchen eines Urlaubs durchzuführen (wie ""Klick macht das alles"").","die Entscheidungsgewalt haben,
der Mensch in diesem Loop
würde nie auf die Maschine 
hören.
Alle möglichen Effizienzgewinne, 
die wir hätten,
werden gar nicht realisiert.
Es kommt immer auf die Nutzung 
anderer
will ich sie heute 
sensibilisieren.
Und da gibt es eine 
Riesenliteratur zu
ganz viel aktive Forschung,
wie wir eigentlich erreichen 
können,
dass Menschen vernünftig mit
diesen Maschinen interagieren.
Richtig hinterfragen,
welche Informationen sie wie 
gewichten sollen.
Und wenn Sie jetzt mal an Chat 
GPT
denken und andere große 
Sprachmodelle,
wo Sie der Nutzer sind Sie 
machen Eingaben,
Sie kriegen Vorschläge an 
Ausgaben.
Wir sind noch nicht bei KI 
Agenten,
wo ich sage ich möchte einen 
Urlaub gebucht haben.
Klick macht das alles, sondern 
diese Systeme.
Sie können hingehen und fragen 
wo
kann ich guten Urlaub machen?
Dieses und jenes sind meine 
Präferenzen.
Eine solche und solche Art von 
Urlaub möchte ich machen.
Und dann kriegen Sie einen 
Vorschlag von diesem System.
Ihre Rolle dabei ist dann 
letztlich zu entscheiden
Ist diese Information gut oder 
schlecht?
Ist es eine Information,
die Sie nutzen sollten in
Ihrer Entscheidungsfindung oder 
nicht?
Und da sehen wir mehr und mehr,
dass ich eben diese Die System eins Muster.
Eine sehr schöne Interpretation
dieser grundlegenden Idee,
dass wir unterschiedliche
Lösungsstrategien gesucht und 
gefunden haben.
Durch unser Lernen, durch unsere 
Erfahrungen,
die wir im Leben individuell 
gemacht haben.
Beispiele von Mensch Maschine 
Interaktion im Alltag.
Das hier ist insbesondere
für Softwareentwicklung 
natürlich hochgradig 
interessant.
Ich fange an, Code zu schreiben.
Wenn Sie mit Charlotte,
die in der Übung die
Notebook Files schreiben und das 
mit
einem Pro Account auf Google 
Collab machen.
Dann fangen sie an, was zu 
schreiben und plötzlich
stehen die nächsten 20 Zeilen 
Code schon da,
weil die Maschine antizipiert,
was sie eigentlich schreiben 
wollen und
Sie klicken nur noch Enter und
der ganze Code ist plötzlich 
schon da.
Diese Suggestions Johns 
eigentlich.
Wenn wir uns hier wieder
auf diese zwei verschiedenen 
sehr
dichotomen Möglichkeiten der
Zusammenarbeit konzentrieren,
haben wir über diese
Code Recommendations
eigentlich 
Entscheidungsunterstützung,
wo das System uns sagt Nein,
das ist eine Möglichkeit,
wie man diesen Code weiterführt.
Auf der anderen Seite haben
wir unsere ganzen großen 
Sprachmodelle,
mit denen wir tagtäglich 
zusammenarbeiten, Dann werden wir anfangen,
über Daten und Datenaufbereitung 
zu sprechen.
Dann werden wir verschiedene 
Modelle durchgehen
und dann sprechen wir über die 
Evaluation dieser Modelle.
Das Deployment per se.
Wir werden Ihnen da gerne
Ressourcen Online Ressourcen zur 
Verfügung stellen.
Das würde den Rahmen dieses 
Kurses bei weitem sprengen.
Und für einen Einführungskurs 
müsste ich
da deutlich mehr 
Programmierkenntnisse 
voraussetzen.
Deswegen werden wir an der 
Stelle
eben entsprechend einen Cut 
machen.
Gibt es an dieser Stelle Fragen?
Hier haben Sie noch mal ein 
Overview.
Dieses Paper, wo die ganze Idee 
vorgestellt wurde,
das werden wir in auf alle zur
Verfügung stellen für 
diejenigen,
die es durchlesen möchten.
Hier stehen noch mal so ein paar 
Subziele aufgelistet,
worüber ich aber mit Ihnen noch 
mal,
Wenn wir über die 
Projektstruktur und die
Ziele von Machine Learning 
Modellen
jetzt nachdenken möchte und
sie für sensibilisieren möchte.
Ist die Idee, dass wir Machine 
Learning immer als
eine Business Solution sehen 
möchten,
wie aber unterschiedliche
Arten von diesen Lösungen haben?
Wir haben unterschiedliche 
Ausmaße der Integration
unserer Machine Learning Systeme
innerhalb unserer Organisation,",13.81993341,1,The generated answer is semantically consistent with the ground truth. It correctly identifies that basic chat models are best for decision support in low-stakes situations where users need quick suggestions to inform their own choices.,1,"The generated answer is faithful. [cite_start]The context describes a user interacting with a large language model to get suggestions, for example, for a vacation ('wo kann ich guten Urlaub machen?')[cite: 771]. [cite_start]The user's role is then to decide if the information is good or bad for their decision-making[cite: 773, 774]. This aligns with the generated answer's claim that such models are suitable for supporting user decisions.",0.9,"The context strongly supports the answer. It explains that current systems like ChatGPT are used for decision support, where the user asks for suggestions (e.g., 'wo kann ich guten Urlaub machen?') and then decides if the information is good or bad. This aligns perfectly with low-stake tasks where a fast response is needed to aid a decision."
"According to the document, what is the population of Munich?",1578567,Das Dokument erwähnt keine Bevölkerungszahl von München.,"gibt aber 10 % der Kunden der 
Population für diese Bank,
wo die diese 
Kreditwürdigkeitsmaschine 
genutzt wird.
10 % von Personen,
die erst in den letzten Jahren
nach Deutschland emigriert sind.
Für diese Personen liegen häufig
keine großen Datenmengen vor.
Für diese Personen kann ein 
Mislabeling in den
Daten stattgefunden haben und
für diese Personen haben wir 
eine Vorhersagegenauigkeit.
Accuracy von 50 % bei
zwei möglichen OutComes 
Kreditwürdig oder nicht?
Das ist nicht besser,
als wenn ich mich hinstelle und 
eine Münze
werfe und trotzdem im Aggregat,
weil der Anteil dieser Personen 
in
der Population relativ kleiner 
ist als der,
würde in der Messung auf dem
ganz hohen Level eigentlich 
rauskommen.
Tolle Maschine, super 90 % plus 
Vorhersagegenauigkeit.
Das heißt, worüber Sie immer 
nachdenken
müssen ist gibt es
bestimmte protected Features per
Gesetz oder auch was Sie für 
ethisch richtig halten,
wo Sie sich dann anschauen,
Haben wir hier eigentlich
Vorhersagegenauigkeit in
technische Performance der 
Maschine,
die für diese beiden Subgruppen 
vergleichbar sind.
Und grundsätzlich ist dieses 
Fehlverhalten von Maschinen,
wenn systematisch basierend auf
bestimmten soziodemographischen 
Faktoren,
die wir rechtlich oder decisions. We present the exact instructions given in 
these studies in Appendix B.1. 
Study A: At the onset of each semester, first -semester 
economics students from a large German university were 
recruited to participate in an ongoing field study. The study 
was conducted by a subset of this paper ’s authors and 
aimed to examine correlations between academic 
performance, personal characteristics, and behavioral 
measurements, including outcomes of sequential social 
dilemmas such as the investment game. The study, 
accessible via a link sent to students ’ email addresses, 
comprised a comprehensive survey on personal 
demographics, socioeconomic background, cognitive 
abilities, personality traits, and, crucially for our 
simulations, a sequential social dilemma game 
incorporating our previously described investment game (a 
detailed description of this game can be found in Appendix 
B.1). Participants’ decisions were incentivized, allowing 
for the measurement of revealed preferences, an approach 
superior to simple self -reported measures due to its 
potential to reduce presentation and demand effects 
(Camerer and Hogarth, 1999). The incentives involved 
earning real money based on the game outcomes with other mathematics from the University of Bonn in 1995 and received his PhD in economics at Tilburg University in 1999. 
Before joining Goethe University Frankfurt, he was employed at the Institute for Empirical Research in Economics at 
the University of Zurich from 2000 to 2008. His primary area of research is behavioral and organizational economics, 
with a particular interest in the theoretical and exper imental analysis of social interaction, human -bounded rational 
decision-making, and the psychology of incentives.  Michael Kosfeld is the director of the Frankfurt Laboratory for 
Experimental Economic Research (FLEX) and the Center for Leadership and Behavior in Organizations (CLBO).  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Copyright © 2024 by the Association for Information Systems. Permission to make digital or hard copies of all or part 
of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for 
profit or commercial advantage and that copies bear this notice and full citation on the first page. Copyright for 
components of this work owned by others than the Association for Information Systems must be honored. Abstracting",4.297011614,0,"The generated answer is a refusal to answer, stating the document does not mention the population. The ground truth provides the specific population figure. The answers are contradictory.",0,"The generated answer is not faithful. The retrieved context does not mention the population of Munich. [cite_start]The context mentions a 'large German university' [cite: 797] [cite_start]and the University of Bonn[cite: 801], but no population figures are provided.",0,The context is completely irrelevant. It discusses issues of algorithmic bias in creditworthiness prediction for immigrant populations and provides details of an unrelated field study with economics students. It contains no information about the population of Munich.
How many parameters did GPT-2 have?,1.5B parameters.,"GPT-2 hatte 1,5 Milliarden Parameter.","17. Juli 2025
Evolution of OpenAI’s GPT modelsGPT:117M parameters (Radford et al., 2018)•Transformer decoder with 12 layers•Trained on BooksCorpus: over 7000 unique books (4.6GB text)GPT-2:1.5B parameters (Radford et al., 2019)•Same architecture as GPT but more flexible•Also: trained on much more data: 40 GB of internet text dataGPT-3:175B parameters (Brown et al., 2020)•Over 600GB of text dataGPT-4:1.76T parameters (undisclosed)•Mixture of Expert: different expert models with >200B parameter each•10 trillion words ~ 40 Billion pages (exact size unknown)
35 um bestimmte Datensätze zu 
erzeugen.
Deswegen bin ich auch sehr.
Diese dieser Model Breakdown,
von dem ich gesprochen habe,
der tritt vor allem dann auf, 
wenn ich
einfach nur den Output nehme,
da das nicht checke und nicht 
auf eine bestimmte Art
und Weise nochmal bearbeite,
vorbereite und das dann
einfach RAW in mein Modell rein 
tue.
Denn wenn die Modelle schlechter 
die großen unternehmen.
Was man machen kann ist 
Modeldestillation beispielsweise
GPT benutze ich lasse GPT ein 
von mir geprägtes und
designtes Datensatz bauen und 
dann
trainiere ich ein kleineres 
Modell auf dem Wissen.
Dann kann ich einen Teil des 
Wissens aus dem großen
Modell in das kleine Modell 
einführen.
Das heißt, wenn OpenAI unsere 
Daten
sammelt und sein Modell 
verbessert,
kann DeepSec letztlich Teile 
dieses
Wissens extrahieren und in
seine kleinere Modelle 
reinpacken.
Fragen? Ja. Man, dass mehrere
Personen gleichzeitig falsche 
Informationen.
Ja. Total. Es gibt.
Es gibt die ersten Anzeichen 
dafür, dass on scale.
LM Highjacking betrieben wird.
Das heißt, die ganzen Webscraper 
gehen auf.
Ist alles automatisiert.
Also da ist kein Mitarbeiter von 
OpenAI,
der auf eine Website geht,
das kopiert und den Datensatz 
packt,
sondern da sind Maschinen, also die wie eintauchen.
Da gibt es einen massiven 
Anstieg in den
Bachelorarbeiten oder 
Masterarbeiten auf Englisch,
dass dieses Wort genutzt wird 
mit dem Einführen von GPT.
Jetzt sehen wir wieder, dass ein 
bisschen zurückgeht,
weil Leute angefangen haben zu 
verstehen,
dass Delf ein sehr starkes 
Signal dafür ist,
dass etwas von GPT geschrieben 
worden ist.
Wenn ich also eine Maschine 
gebaut habe,
die Predigt, dann haben sie GPT 
benutzt oder nicht?
Und diese Maschine möglichst auf 
Delph geachtet hat
und das super richtig war,
ja, dann
funktioniert die Maschine heute 
nicht mehr so gut,
weil sie ihr Verhalten verändert 
haben.
Und diese Probleme nennen
wir grundsätzlich Drift Probleme
und davon haben wir zwei Typen.
Der eine Typ ist, dass sich die 
Verteilung in
den Daten ändert und der andere 
ist,
dass ich fundamental in dem 
Verhalten etwas ändert.
Hier an dem Beispiel von 
Marketing,
von Sales auf der einen Seite 
den sogenannten Data Drift.
Wir haben eine einen Shift
in der Verteilung der Typen der 
Observation,
die wir haben in der 
Vergangenheit.
Wenn Sie hier auf der Achse,
die den zeitlichen Verlauf sehen 
auf der Y Achse,
haben wir die Anzahl oder die 
Menge des Sales,
und sie haben rote und blaue 
Typen.",4.039583921,1,The generated answer is semantically consistent with the ground truth. Both correctly state that GPT-2 had 1.5 billion parameters.,1,"The generated answer is faithful. [cite_start]The provided context explicitly states in a diagram title, 'GPT-2: 1.5B parameters'[cite: 806].",1,The context directly answers the question. A slide titled 'Evolution of OpenAIâ€™s GPT models' clearly lists 'GPT-2: 1.5B parameters'.
What is the intuition behind how an 'attention head' works in a language model?,"An attention head represents a word as a weighted combination of itself and all the words that came before it. The weights in this combination are based on the similarity between the words, which helps the model understand the context of the sentence.","Basierend auf dem bereitgestellten Text kann ich keine direkte Erklärung für die Intuition hinter der Funktionsweise einer ""Attention Head"" in einem Sprachmodell geben. Der Text erwähnt ""Attention Heads"" nur im Zusammenhang mit der Nutzung von Technologie und der Interaktion zwischen Mensch und Maschine.

Allerdings kann ich aus dem Kontext ableiten, dass die ""Attention Heads"" eine zentrale Rolle bei der Verarbeitung von Informationen spielen, insbesondere im Zusammenhang mit der Bewertung von Informationen als ""gut"" oder ""schlecht"" und der Gewichtung von Informationen bei der Entscheidungsfindung.

Hier ist eine Interpretation, die auf dem Kontext basiert:

Die Intuition hinter einer ""Attention Head"" ist, dass sie es dem Modell ermöglicht, sich auf die relevantesten Teile der Eingabe zu konzentrieren, um die Bedeutung der Informationen zu verstehen.  Es ist wie ein Filter, der hilft, die wichtigsten Aspekte zu identifizieren, anstatt die gesamte Eingabe gleich zu behandeln.  Dies ist besonders wichtig bei Aufgaben, die subjektive Beurteilungen erfordern, wie z.B. die Bewertung von Urlaubsvorschlägen oder die Gewichtung von Informationen bei der Entscheidungsfindung.

**Wichtig:** Der Text liefert keine detaillierte technische Erklärung der Funktionsweise von Attention Heads. Er konzentriert sich auf die Anwendung dieser Technologie im Kontext der Mensch-Maschine-Kollaboration.
","Aber den umgekehrten Effekt.
Wir haben die Behavioral,
diese kognitive Komponente 
davon,
die sich eigentlich in unserem 
Kopf geschaffen wird,
wo wir diese Intention to use 
entwickeln,
die wiederum von diesen drei 
Faktoren in diesem Modell
hier ganz grob auf einem sehr 
hohen Level.
Den Zusammenhang erklärt wird.
Und diese Beziehungen hängen
wiederum von den Moderatoren ab.
Ja, ja, erklären, warum das was 
Negatives ist.
Muss ich sie an das Papier 
verweisen, dass keine Ahnung,
wann ich das letzte Mal gelesen 
habe,
steht da bestimmt drin. Kann ich 
ihnen hochladen?
Bzw. Das ist glaube ich sogar 
Open Source.
Das hat mittlerweile glaube ich 
70.000
Situationen oder so,
also das ist wirklich eines der 
fundamentalen Modelle,
wo wir immer noch versuchen zu 
verstehen,
was beeinflusst eigentlich die 
Nutzung von wie gesagt,
Technologie breiter gefasst, 
aber für uns ist relevante.
Mit dem Schwerpunkt unseres 
Kurses sprechen wir natürlich
über die sogenannte Mensch 
Maschine Kollaboration,
was letztlich ist die Nutzung 
und
Akzeptanz von der KI 
Technologie.
Wir versuchen uns in der 
Wirtschaftsinformatik
gerade so ein bisschen wieder 
auf das Neue,
auf die neue Kuh, die durchs
Dorf getrieben wird, zu 
konzentrieren. die Entscheidungsgewalt haben,
der Mensch in diesem Loop
würde nie auf die Maschine 
hören.
Alle möglichen Effizienzgewinne, 
die wir hätten,
werden gar nicht realisiert.
Es kommt immer auf die Nutzung 
anderer
will ich sie heute 
sensibilisieren.
Und da gibt es eine 
Riesenliteratur zu
ganz viel aktive Forschung,
wie wir eigentlich erreichen 
können,
dass Menschen vernünftig mit
diesen Maschinen interagieren.
Richtig hinterfragen,
welche Informationen sie wie 
gewichten sollen.
Und wenn Sie jetzt mal an Chat 
GPT
denken und andere große 
Sprachmodelle,
wo Sie der Nutzer sind Sie 
machen Eingaben,
Sie kriegen Vorschläge an 
Ausgaben.
Wir sind noch nicht bei KI 
Agenten,
wo ich sage ich möchte einen 
Urlaub gebucht haben.
Klick macht das alles, sondern 
diese Systeme.
Sie können hingehen und fragen 
wo
kann ich guten Urlaub machen?
Dieses und jenes sind meine 
Präferenzen.
Eine solche und solche Art von 
Urlaub möchte ich machen.
Und dann kriegen Sie einen 
Vorschlag von diesem System.
Ihre Rolle dabei ist dann 
letztlich zu entscheiden
Ist diese Information gut oder 
schlecht?
Ist es eine Information,
die Sie nutzen sollten in
Ihrer Entscheidungsfindung oder 
nicht?
Und da sehen wir mehr und mehr,
dass ich eben diese zumindest durch eine bestimmte
Methode mir ein bisschen 
erklären kann.
Woher eigentlich diese 
Vorhersage stammt.
Sie sehen auch hier diese Task 
factors.
Die Natur des Tasks ist das,
worüber ich gerade gesprochen 
habe.
Spielt hochgradig eine Rolle,
wo wir tendenziell sehen,
dass Task, die wir als sehr 
subjektiv wahrnehmen,
wie Film Recommendations,
Wenn Menschen sich gegenseitig 
Witze erzählen sollen,
Einschätzungen davon,
ob ein bestimmter Urlaubsort 
interessant ist oder nicht,
diese ganzen sehr
subjektiv wahrgenommenen 
Aufgaben präferieren
wir eher von Menschen,
Hilfe anzunehmen,
dass von Menschen lösen zu 
lassen als von Maschinen.
Wohingegen für komplexe
objektive Tasks wie Berechnungen 
von Aktienkursen,
Einschätzungen von 
CompanyDefaults etc.
Da tendieren Menschen von dem,
was die Forschung aktuell zeigt 
und es
ist wie gesagt ein sehr aktives 
Feld dazu,
eher Hilfe von Maschinen 
anzunehmen.
Gibt es irgendwelche Fragen 
soweit?
So, jetzt kommen wir zu den zwei 
Modes of Collaboration.
Auch wieder sehr dichotom 
gedacht als über
Kategorien haben wir zwei und es 
gibt eine Strömung,
die mittlerweile so ein bisschen 
sagt Naja,
eigentlich haben wir drei 
Kategorien.
Hier streiten wir uns aber nicht 
drüber,",22.83436966,0,"The generated answer is a refusal to answer, stating it cannot provide an explanation. The ground truth provides a clear and concise explanation of how an attention head works. The answers are contradictory.",0,"The generated answer is not faithful. It claims the intuition is that an attention head represents a word as a weighted combination of itself and preceding words. The provided context does not explain what an 'attention head' is or how it works. [cite_start]It discusses human-machine collaboration and how users should 'hinterfragen, welche Informationen sie wie gewichten sollen' (question how they should weight which information)[cite: 842], but this is about human cognition, not the technical function of an attention head.",0.2,"The context is tangentially related as it discusses human-AI collaboration and how humans should evaluate information from models like ChatGPT. However, it does not provide a technical explanation of how an 'attention head' works. The reasoning is based on a high-level interpretation rather than a direct explanation from the text."
What is Word2Vec and what is its function?,Word2Vec is a simple neural network that is used to generate word embeddings from a text corpus.,"Basierend auf dem bereitgestellten Kontext ist Word2Vec ein neuronales Netzwerk, das verwendet wird, um Wort-Embeddings zu generieren. Hier ist eine Zusammenfassung seiner Funktion:

*   **Idee:** Word2Vec basiert auf der Idee, dass Wörter, die in ähnlichen Kontexten verwendet werden, ähnliche numerische Darstellungen (Embeddings) haben sollten. Es versucht, Wörter anhand ihres umgebenden Kontexts vorherzusagen.
*   **Gelerntes Gewichte als Embeddings:** Die Gewichte, die das neuronale Netzwerk während des Trainings lernt, werden als Wort-Embeddings verwendet.
*   **Fixe Dictionary von Vektoren:** Es erzeugt ein festes Wörterbuch von Vektoren, das für die weitere Verwendung verfügbar ist.
*   **Verschiedene Trainingsmethoden:** Es gibt zwei Hauptmethoden zum Trainieren von Word2Vec:
    *   **Continuous Bag of Words (CBOW):** Vorhersage des Wortes anhand seiner umgebenden Wörter.
    *   **Skip-gram:** Vorhersage der umgebenden Wörter anhand des Wortes selbst (die Umkehrung von CBOW).

Der Kontext erwähnt auch, dass Word2Vec in der Praxis viel größere Embeddings (über 100 Dimensionen) verwendet und auf großen Datensätzen wie Wikipedia trainiert wird. Es verwendet Techniken wie Negative Sampling, um das Training zu beschleunigen.","17. Juli 2025
Learning word embeddings with Word2VecWord2Vec: simple neural networkto generate word embeddings given a text corpus•Idea: predict words from their surrounding context•Learned weights are embeddings•Through optimization: words in similar context have similar embeddings•Gives us a fixed dictionary of vectors for words we can utilizeIntuitive example: assume we have a text corpus with two sentences
15
Training dataPizza is awesomePizza is greatPizzaisgreatawesome
PizzaisgreatawesomeInput layerEmbeddings layer Output layer 17. Juli 2025
Word2VecIn practice:•Word2Vec has much larger embeddings layer (>100 dimensions)•Trained on large data set, e.g.entire, Wikipedia•Alternative prediction goal is skipgram•Predict surrounding words from word itself (the other way round for CBOW)Training embeddings requires high computational power•Typically, more than 100 dimensionalembedding•Size of dictionary is in the million•w2v speeds up training by negative sampling
18 17. Juli 2025
Word2Vec example (continuous bag of words version)
16
Training dataPizzaisawesomePizza is greatPizzaisgreatawesome
PizzaisgreatawesomeInput layerEmbeddings layerOutput layer
1001
Words àOne-hot Vector One-hot VectoràWords0100
Training dataPizza is awesomePizzaisgreatPizzaisgreatawesome
PizzaisgreatawesomeInput layerEmbeddings layerOutput layer
1010
Words àOne-hot Vector One-hot VectoràWords0100",21.79010797,1,The generated answer is semantically consistent with the ground truth. Both correctly identify Word2Vec as a neural network used to generate word embeddings from a text corpus.,1,"The generated answer is faithful. [cite_start]The context states that Word2Vec is a 'simple neural network to generate word embeddings' [cite: 863][cite_start], that the 'Idea' is to 'predict words from their surrounding context' [cite: 863][cite_start], that 'Learned weights are embeddings' [cite: 863][cite_start], and it mentions the two training methods 'CBOW' [cite: 861] [cite_start]and 'skipgram'[cite: 864].",1,"The context directly answers the question. It describes Word2Vec as a 'simple neural network to generate word embeddings given a text corpus' and explains that its idea is to 'predict words from their surrounding context,' with the learned weights becoming the embeddings."
What is one potential problem with representing words as indexed tokens?,Lacking interpretability of distance.,"Laut dem Kontext ist ein potenzielles Problem bei der Darstellung von Wörtern als indizierte Token das „Lacking interpretability of distance“ – also das Fehlen der Möglichkeit, Distanzen zu interpretieren. Die Idee ist, One-Hot-Encoding zu verwenden, um Distanzen gleich zu machen.","17. Juli 2025
TokenizationMost simple view: words are discrete and independent tokens•Represent words as indexed tokens
What is a potential problem here?•Lacking interpretability of distance •Idea: Employ one-hot-encoding so that distances are all the same
10
WordIndex tokenHello 0… …King 145Queen156… …
WordIndex tokenOne-hot vectorHello 0 [1,0,…,0,0,…,0]… … …King 145 [0,0,…,1,0,…,0]Queen156 [0,0,…,0,1,…,0]… … … eine Prediction zu machen, sind 
massiv gering.
Ja, das ist fast ignorierbar.
Außer wenn wir natürlich 
wirklich
über große Sprachmodelle reden,
wo Milliarden von Menschen jeden
Tag riesige Texte da 
reinknallen.
Aber die marginale Beitrag,
dass sie eine Vorhersage machen 
oder
auch die marginale Beitrag von 
einer weiteren Callum,
einem weiteren Wort in
dem Datensatz, ist vollkommen 
ignorierbar.
Das ist wieder die Masse, die es 
letztlich macht.
Ja, und in dem Fall von Demogons 
Razor
sprechen wir nicht davon,
einen Parameter mehr,
sondern tausende von Parametern 
mehr.
Deswegen ist es für unsere
PC's und auch für die 
Entscheidung,
welche Modelle Unternehmen 
einsetzen,
ob sie bei tabularen Daten immer 
an der Stelle gesagt,
ob ich jetzt einen Random Forest 
einsetze
mit 10.000 Bäumen oder ich
nehme einen ein neuronales 
Netzwerk mit 20 Layern.
Der Verbrauch der Energie ist 
für zumindest Predictions
über Kreditwürdigkeit 
ignorierbar unterschiedlich.
Ich kann Sie an entsprechende 
Quellen verlinken.
Dann frage ich mich, wenn ich 
das.
Wenn ich dieses Argument 
beziehe,
auf das Training des Modells,
dann kann ich ja noch nicht 
werten.
Bevor ich es trainiere, kann ich 
nicht vorhersehen,
ob die zusätzlichen Parameter 
wie ein 17. Juli 2025
Encoding language for a neural network
8
Neural networks cannot interpret words:•Neural networks require numerical inputs•We need to transform words into “numbers” and vice versa
“I like ___”𝑓""𝑤⋅𝑥 “pizza”
“I like ___”𝑓""𝑤⋅𝑥 “pizza”𝑥 𝑦
Consider the sentence “I like pizza”",8.620388031,1,The generated answer is semantically consistent with the ground truth. Both identify the lack of distance interpretability as a key problem.,1,"The generated answer is faithful. [cite_start]The context slide asks 'What is a potential problem here?' after showing words represented as indexed tokens, and the next bullet point answers: 'Lacking interpretability of distance'[cite: 866].",1,"The context directly addresses the question. A slide is titled 'Represent words as indexed tokens' and then asks 'What is a potential problem here?', immediately followed by the answer 'Lacking interpretability of distance'."
"According to the gradient descent, what two steps are taken to decrease a model's error during training?","To decrease the error, the model's weights (w) are changed in the direction of the negative slope, and the size of this change is scaled by the learning rate (η).","Laut dem Text werden bei Gradient Descent die folgenden zwei Schritte unternommen, um den Fehler eines Modells während des Trainings zu verringern:

1.  Compute gradients: ,ℒ,-, ,ℒ,.(through back-propagation algorithm)
2.  Update weights and biases: 𝑤=𝑤−𝜂⋅,ℒ,-, 𝑏=𝑏−𝜂⋅,ℒ,.","3. Juli 2025
Adaptive Boosting (AdaBoost)
12
Training Procedure:
1. All observations in the dataset are initially given equal weights
2. Fit weak to the data and calculate errors for each observation in training set
3. Train next model on (re)weighted training set where previously wrongly predicted observations 
have a higher weight
4. Repeat procedure until convergence is achieved of restrictions are met
Prediction of new instances based on weighted majority vote of ensemble (weights 
according to individual model accuracy) 
Source 10. Juli 2025
Gradient descent: the optimization algorithm
27
We solve the following problem during training
Complexity of problem requires a step-wise solving using gradient descent:1.Initialize 𝑤,𝑏randomly2.Loop until convergence of loss1.Compute gradients: ,ℒ,-, ,ℒ,.(through back-propagation algorithm)2.Update weights and biases: 𝑤=𝑤−𝜂⋅,ℒ,-, 𝑏=𝑏−𝜂⋅,ℒ,.3.Compute new loss: ℒA𝑦𝑤,𝑏,𝑦3.Return weights
argminY,Z	ℒ/𝑦𝑥|𝑤,𝑏,𝑦 Quellen verlinken.
Dann frage ich mich, wenn ich 
das.
Wenn ich dieses Argument 
beziehe,
auf das Training des Modells,
dann kann ich ja noch nicht 
werten.
Bevor ich es trainiere, kann ich 
nicht vorhersehen,
ob die zusätzlichen Parameter 
wie ein
besseres Modell gehen oder 
nicht.
Wir trainieren uns, um 
rauszufinden.
Das sind jetzt schon sehr 
detaillierte Fragen.
Wir haben unterschiedliche 
Parameter,
wir haben Parameter, wir haben 
Hyperparameter.
Und die Hyperparameter, die 
werden tatsächlich in
dem Trainingsprozess data driven 
bestimmt die Parameter,
da haben Sie bestimmte 
Freiheitsgrade,
die zu setzen. Zum Beispiel?
Sie können auch entscheiden,
welche Features Sie reinnehmen 
wollen.
Sie können den Datensatz 
halbieren,
wenn Sie lustig sind und
dann sagen Ich versuche es jetzt 
hiermit.
Grundsätzlich habe ich auch 
Kontrolle darüber,
wie lange ich trainiere, wie 
viele
Iterationen eines 
Trainingsprozess ich habe.
Bei neuronalen Netzen 
beispielsweise
kann ich ganz klar festlegen Ich
trainiere nur 100 Runden.
Das heißt nicht, dass das das 
beste Modell ist.
Ich kann eintragen,
dass das Modell so lange 
trainieren soll, bis die,
bis die der Marginal die
marginale Verbesserung des 
Modells gen null geht.",10.78351927,1,The generated answer is semantically consistent with the ground truth. Both correctly describe the two steps of gradient descent: changing weights in the direction of the negative slope and scaling the change by the learning rate.,1,"The generated answer is faithful. [cite_start]The context shows a diagram for gradient descent that includes the step 'Update weights and biases: ð‘¤=ð‘¤âˆ’ðœ‚â‹…,â„’,-, ð‘=ð‘âˆ’ðœ‚â‹…,â„’,.'[cite: 876]. This formula shows that the weights (w) are updated in the direction of the negative gradient (slope) scaled by the learning rate (Î·).",1,"The context provides a slide titled 'Gradient descent: the optimization algorithm' which explicitly lists the update rule for the weights as 'ð‘¤=ð‘¤âˆ’ðœ‚â‹…(âˆ‚â„’/âˆ‚w)'. This shows that weights (w) are changed in the direction of the negative gradient (slope), scaled by the learning rate (Î·), which directly answers the question."
"According to the text, what are hyperparameters and what is their primary function in machine learning?","Hyperparameters are variables that determine the structure of a model and its learning process. Their primary function is to regularize the model, which helps to control for overfitting and underfitting. For example, in a neural network, hyperparameters include the number of layers and neurons.","Laut dem Text sind Hyperparameter Variablen, die die Struktur des Modells und den Lernprozess bestimmen. Sie ermöglichen es, das Modell zu regularisieren und Über- oder Unteranpassung zu vermeiden. Verschiedene Modelle und Lernalgorithmen haben unterschiedliche Hyperparameter.","Studierende werden mit den wichtigsten Fragestellungen rund um den Einsatz von Machine Learning (ML) in Managemententscheidungen vertraut gemacht. Sie erwerben grundlegende theoretische Kompetenzen im Bereich ML und verstehen, wie diese Technologien betriebliche Prozesse und strategische Entscheidungen beeinflussen können.
Studierende erlernen den Umgang mit grundlegenden Methoden und Werkzeugen des maschinellen Lernens, einschließlich Datenaufbereitung, Modelltraining und -bewertung. Sie entwickeln die Fähigkeit, wirtschaftliche Fragestellungen in ML-Probleme zu übersetzen und datenbasierte Lösungen analytisch sowie strukturiert zu erarbeiten.
Im Rahmen der Veranstaltung werden zahlreiche Praxisbeispiele und Fallstudien aus verschiedenen Industrien behandelt, die die Anwendung von ML und generativer KI im geschäftlichen Kontext beleuchten. Insbesondere in den angebotenen Übungen und praktischen Programmieraufgaben lernen Studierende, das erlangte Wissen anzuwenden, auch ohne vorherige Programmiererfahrung. Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. 3. Juli 2025
Hyperparameters
The number of trees (parameters) and other choices on the model 
architecture (e.g., tree depth) are hyperparameters 
Hyperparameters are variables that 
• determine the structure of the model and the learning process
• allow us to regularize our model and shape over- and underfitting outcomes 
• different models and learning algorithms have different hyperparameters
• For example: neural networks’ hyperparameters include
• # layers
• # neurons per layer
• activation functions
By tuning hyperparameters, we can find a “good model complexity”, but 
of course the question is how we do that given the first rule of testing?
24",8.109428883,1,The generated answer is semantically consistent with the ground truth. Both correctly define hyperparameters as variables that determine a model's structure and learning process and are used for regularization.,1,The generated answer is faithful. [cite_start]The context defines hyperparameters as variables that 'determine the structure of the model and the learning process' [cite: 899] [cite_start]and 'allow us to regularize our model and shape over- and underfitting outcomes'[cite: 899].,1,The context directly answers the question. It defines Hyperparameters as variables that 'determine the structure of the model and the learning process' and 'allow us to regularize our model and shape over- and underfitting outcomes'.
What are the cores advantages of ensemble methods?,"Improved accuracy, Reduction of overfitting and Handling High Dimensionality.","Die Hauptvorteile von Ensemble-Methoden sind:

*   **Verbesserte Genauigkeit:** Ensemble-Methoden führen zu einer Vorhersagegenauigkeit, die von keinem einzelnen Modell erreicht werden könnte.
*   **Reduziertes Risiko von Überanpassung:** Da sie mehrere Lernende verwenden, sind Ensemble-Methoden robuster und weniger anfällig für Überanpassung.
*   **Effektive Behandlung von hoher Dimensionalität:** Ensemble-Methoden können große Datenmengen mit hochdimensionalen Räumen effektiv verarbeiten.","3. Juli 2025
Ensemble methods
Ensemble methods rely on different models that are simultaneously applied to the same problem
Predictions are aggregated producing the final prediction
• Hard vote: majority of individual votes
• Soft vote: average individual predicted probabilities and one final vote
• Meta model: train machine learning model to aggregate prediction (stacking)
Models‘ errors should be as uncorrelated as possible so that they cancel out through aggregation
6
Model 1
Model 2
Model 3
Model N-1
Model N
…
Aggregator Overall 
prediction 3. Juli 2025
(Dis)advantages of ensembles
Core advantages of ensemble methods include:
1. Improved Accuracy: Ensemble methods result in a prediction accuracy that is better than
any individual model could achieve
2. Reduction of Overfitting: Because they use multiple learners, ensemble methods tend to
be more robust and less prone to overfitting, i.e., typically generalize rather well
3. Handling High Dimensionality: Ensemble methods can effectively handle large amounts
of data with high-dimensional spaces.
Core disadvantages of ensemble methods include:
1. Increased Complexity: Can be computationally expensive and require significant 
resources to train because they involve training multiple models instead of a single one.
2. Interpretability: Ensemble models are difficult to interpret compared to individual models. 
3. Risk of Overfitting with Noise: Although ensemble methods are generally more robust to 
overfitting, they can still overfit if the data is noisy. 
14 10. Juli 2025
Last time: ensemble methods
•Different models that are simultaneously applied to the same problem•However: only ”one layer” of models, i.e., no (comprehensive) stacking•Today: layers if modelsfeedingintoeachother•Idea(smallexample):
2
Model 1Model 2Model 3
Model N-1Model N… AggregatorOverall prediction
Model 1, Layer 1Model 2, Layer 1Model 1, Layer 2Model 2, Layer 2Final model(Aggregator)Overall prediction",11.09639049,1,"The generated answer is semantically consistent with the ground truth. Both correctly identify improved accuracy, reduction of overfitting, and handling high dimensionality as the core advantages.",1,"The generated answer is faithful. [cite_start]The context lists 'Improved Accuracy', 'Reduction of Overfitting', and 'Handling High Dimensionality' as 'Core advantages of ensemble methods'[cite: 904, 905].",1,"The context directly answers the question. A slide titled '(Dis)advantages of ensembles' lists 'Improved Accuracy,' 'Reduction of Overfitting,' and 'Handling High Dimensionality' as core advantages."
What are some core disadvantages of decision trees?,"Overfitting, instability, and optimization difficulty.","Basierend auf dem bereitgestellten Text lassen sich folgende Kernnachteile von Entscheidungsbäumen identifizieren:

*   **Überanpassung (Overfitting):** Der Text erwähnt, dass Machine Learning Modelle, einschließlich Entscheidungsbäume, “bessere oder schlechtere Performance aufweisen” und dass man “die einzige Performance, die wir sehen, auf historischen Daten” beobachten muss. Dies deutet darauf hin, dass Entscheidungsbäume anfällig für Überanpassung sein können, wenn sie zu komplex werden und sich an den Trainingsdaten zu stark anpassen, anstatt allgemeine Muster zu lernen.

*   **Instabilität:** Entscheidungsbäume können aufgrund ihrer rekursiven Natur instabil sein. Kleine Änderungen in den Trainingsdaten können zu großen Veränderungen in der Struktur des Baumes und somit zu unterschiedlichen Vorhersagen führen.

*   **Schwierigkeiten bei der Handhabung von kontinuierlichen Variablen:** Obwohl Entscheidungsbäume mit kontinuierlichen Variablen arbeiten können, ist dies oft weniger effizient als bei anderen Algorithmen. Die Aufteilung der Daten anhand von Schwellenwerten kann zu Informationsverlust führen.

Zusammenfassend lässt sich sagen, dass Entscheidungsbäume anfällig für Überanpassung, instabil und möglicherweise weniger geeignet sind, um komplexe Beziehungen zwischen Variablen zu modellieren.","Ende die verarbeitete 
Information,
die Prediction von der KI
und die eigentliche Information 
von dem Task.
Was Sie hier machen, ist dann 
selber,
als Mensch die finale 
Entscheidung zu treffen.
Und in diesem Kontext gibt es 
zwei
Arten von sogenannter Autorität 
von Entscheidungsgewalt.
Für diejenigen, die den
Kurs von Ferdinand von Siemens 
zu Decision,
Making and Markets und 
OrganIzations besucht haben,
haben das vielleicht schon mal 
gehört.
Die Idee von realer und formaler 
Autorität,
Wer hat davon schon gehört?
Die Idee von formaler Autorität 
ist.
Das ist etwas, wo ich laut 
Verträgen
auf jeden Fall final
für die Entscheidung 
verantwortlich bin.
Ich drücke am Ende als Mensch 
den Knopf.
Das ist hier der Fall.
Was aber sein kann,
ist Und jetzt sind wir bei 
realer Autorität.
Stellen Sie sich vor, Sie müssen 
den Knopf drücken.
Aber die Maschine sagt Ihnen ja.
Drückt den Knopf oder nicht?
Und Sie folgen immer der 
Maschine.
Sie überlegen gar nicht mehr 
selber,
sondern mehr oder weniger 
automatisch.
Folgen Sie immer zu 100 %,
was die Maschine sagt.
Dann sind Sie zwar immer noch 
die Person,
die formal die Autorität hat,
auf den Knopf zu drücken,
aber die reale Autorität,
weil sie immer der Maschine 
folgen, betriebswirtschaftlich
ökonomische Entscheidungen zu 
treffen.
Wer sieht das nicht?
Noch mal, was ich letztes Mal 
gesagt habe Wenn Sie
was nicht verstehen, ist es 
nicht Ihre Schuld.
Dann habe ich es einfach 
schlecht erklärt.
Deswegen immer raus damit.
Dann gehe ich davon aus, dass 
jeder verstanden hat.
Aber eine andere Frage haben
wir ja theoretisch auch
noch andere 
Entscheidungsmöglichkeiten,
Parametern, die dieselbe 
Qualität liefern.
Vollkommen richtig. Da wäre 
jetzt die Frage,
ob es eine 
Entscheidungsmöglichkeit,
die zwei Parameter verwendet,
besser als eine auf einem 
Papier.
Das ist sehr, sehr gute Frage.
Da gibt es verschiedene Theorien 
zu.
Grundsätzlich, wie wir sehen 
werden,
für den technischen Teil der 
Vorlesung.
Wir können für das gleiche
Problem verschiedene Regeln 
identifizieren.
Verschiedene Machine Learning 
Modelle trainieren.
Diese Machine Learning Modelle 
können bessere oder
schlechtere Performance 
aufweisen.
Wenn sie aber genau die gleiche 
Performance aufweisen,
dann haben wir natürlich in 
einer gewissen Art und
Weise die Wahl, immer darauf 
achtend,
dass die einzige Performance, 
die wir sehen,
aktuell immer Performance auf 
historischen Daten ist.
Das heißt, wir müssen auf der Informationen
verarbeiten und wie welche
Probleme hier eine Rolle spielen 
könnten in Bezug auf
die richtige Gewichtung Ihrer 
eigenen Expertise
und der von der Maschine,
welche Signal Sie bekommen.
Das ist das, womit wir uns heute 
befassen.
Ja. Und wenn es
jetzt um sowas geht wie 
Stellenbesetzung
in der Personalabteilung,
ist das ja verständlich.
Ja, was ist mit Sektoren,
in denen man sich so schnell,
in denen so schnell
Entscheidungen getroffen werden 
müssen,
dass das überhaupt möglich ist?
Sprechen wir auch drüber.
Es gibt nämlich zwei Arten
von Mensch Maschine 
Kollaboration.
Wenn man so grob einteilt auf 
der einen Seite die
Idee von 
Entscheidungsunterstützung und 
auf
der anderen Seite die Idee von
Entscheidungsautomatisierung.
Aber auch bei der 
Entscheidungsautomatisierung.
Das Konzept von Human in the 
Loop ist,
dass der Mensch entscheidet 
Welche Entscheidungen
lagere ich denn überhaupt an die 
Maschine aus?
Das heißt, hier geht es dann 
eben um diesen
Unterschied von Humans in
the loop dahingehend Sie 
entscheiden,
Ich transferiere 
Entscheidungsgewalt in diesen
automatisierten Fällen oder Sie 
behalten immer
die Entscheidungsgewalt,
müssen sich aber entscheiden Wie
viel Gewicht geben Sie 
eigentlich?",22.14843559,0.9,"The generated answer is semantically consistent with the ground truth. The ground truth lists 'Overfitting, instability, and optimization difficulty'. The generation lists 'Overfitting', 'instability', and 'difficulties in handling continuous variables'. The third point is slightly different but related to optimization difficulty, making the answers highly consistent.",0,"The generated answer is not faithful. It lists overfitting, instability, and optimization difficulty as disadvantages. The retrieved context does not mention decision trees or their disadvantages. [cite_start]The context discusses the concept of 'formaler AutoritÃ¤t' (formal authority) versus 'realer AutoritÃ¤t' (real authority) in human-AI decision making [cite: 918, 921] [cite_start]and mentions that different ML models can have better or worse performance on historical data[cite: 931, 932], but it does not list specific disadvantages of decision trees.",0.4,"The context is partially relevant. It mentions that different machine learning models can have 'bessere oder schlechtere Performance' (better or worse performance), which hints at the problem of overfitting. It also discusses the need to make choices between different models, which relates to optimization difficulty. However, it doesn't explicitly name overfitting, instability, or optimization difficulty as disadvantages of decision trees specifically."
"According to the document, what is the formula for Balanced Accuracy (Bal. Acc.)?",Bal. Acc. = (Sensitivity + Specificity) / 2,"Laut dem Text lautet die Formel für Balanced Accuracy (Bal. Acc.):

Bal. Acc. = (Accuracy + Specificity) / 2
","26. Juni 2025
Technical performance on unseen data (2/2)
Accuracy can be misleading, esp. in case of imbalanced samples, hence, we may also want to consider
Combining these measures results in other important measures:
𝑺𝒆𝒏𝒔𝒊𝒕𝒊𝒗𝒊𝒕𝒚=𝑻𝑷𝑻𝑷+𝑭𝑵𝑷𝒓𝒆𝒄𝒊𝒔𝒊𝒐𝒏=𝑻𝑷𝑻𝑷+𝑭𝑷
𝑩𝒂𝒍.	𝑨𝒄𝒄.=𝑺𝒆𝒏𝒔𝒊𝒕𝒊𝒗𝒊𝒕𝒚+𝑺𝒑𝒆𝒄𝒊𝒇𝒊𝒄𝒊𝒕𝒚𝟐 𝑭𝟏=𝟐∗𝑺𝒆𝒏𝒔𝒊𝒕𝒊𝒗𝒊𝒕𝒚∗𝑷𝒓𝒆𝒄𝒊𝒔𝒊𝒐𝒏𝑺𝒆𝒏𝒔𝒊𝒕𝒊𝒗𝒊𝒕𝒚+𝑷𝒓𝒆𝒄𝒊𝒔𝒊𝒐𝒏
Tree A prediction$𝑦!	 True outcome(𝑦) Tree Bprediction$𝑦""	1 1 11 1 11 0 01 1 01 0 00 1 00 1 00 0 00 0 00 0 0
Confusion matrix
𝑺𝒑𝒆𝒄𝒊𝒇𝒊𝒄𝒊𝒕𝒚=𝑻𝑵𝑻𝑵+𝑭𝑷
What is the Bal. Acc. And F1for the two models?
𝑦=1𝑦=0$𝑦=13 2$𝑦=02 3
𝑦=1𝑦=0$𝑦=12 0$𝑦=03 5
Tree A Tree B 15. Mai 2025
Different types of solutions
10
Balanced Scorecard§Überarbeitung der Inhalte§Wiedereinführung der BSC zum kontinuierlichem Controlling
ISO-Zertifizierung§Interne Audits im HWS und FSS§ISO INTEGRA 1x1§Verpflichtende Besprechung von Prozessen auf Ressort-/ Stabstreffen
Point solutions•Definition:A solution that addresses a single, specific problem or need.•Scope:Narrow and focused.•Integration:Typically standalone; not integrated with other systems.•Use case: Quick wins, easy to implement, often first step in solving a broader challenge. •Example:Fraud detection model (Anomaly detection)Application solutions•Definition:A complete software or tool that solves a broader problem•Scope: Medium; focused on a domain or function•Integration: May integrate with other applications or systems.•Use case: Useful when a domain-specific tool is needed •Example: Customer support app (Classification + UI + reporting) accuracy and establishing itself as a reliable tool (Chen,2022). It can collect and evaluate large
amounts of data that may exceed human analytical capacities, enabling AI to provide decision
recommendations (Shaw, 2019).
Modern technologies, including artiﬁcial intelligence solutions, have revolutionized work and
contributed to developing human resources management (HRM) for improved outcomes
(Hmoud and Laszlo,2019). One signiﬁcant area where their impact is felt is in the recruitment
process, where AI implementation can potentially provide a competitive advantage by enabling a
better understanding of talent compared to competitors, thereby enhancing the company’s
competitiveness (Johansson and Herranen,2019).
AI receives commands and data input through algorithms. While AI developers believe their
algorithmic procedures simplify hiring and mitigate bias, Miasato and Silva (2019) argue that
https://doi.org/10.1057/s41599-023-02079-x OPEN
1 College of Economics and Management, Nanjing University of Aeronautics and Astronautics, Nanjing, China.✉email: njuczs@nuaa.edu.cn
HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS|          (2023) 10:567 | https://doi.org/10.1057/s41599-023-02079-x 1
1234567890():,;",6.487388611,0,"The generated answer provides an incorrect formula, stating Bal. Acc. = (Accuracy + Specificity) / 2. The ground truth provides the correct formula: Bal. Acc. = (Sensitivity + Specificity) / 2. The answers are factually contradictory.",1,The generated answer is faithful. The context states that 'Bal. Acc. [cite_start]= (Sensitivity + Specificity) / 2'[cite: 942].,1,The context provides a direct and explicit answer to the question. A slide shows the formula for Balanced Accuracy as 'Bal. Acc. = (Sensitivity + Specificity) / 2'.
"According to the text, what is information gain?",Information gain is the improvement in an evaluation measure (such as the reduction in entropy) that is achieved by splitting the data at a parent node (level t) into its child nodes (level t+1).,"Laut dem Text ist Informationsgewinn durch die Nutzung von Suggestionen (Empfehlungen) durch eine Maschine gegeben, wenn die Person ""ganz sicher"" ist, dass sie das nicht wollen. Die Maschine kann dann automatisch Vorschläge machen, und die Person entscheidet, ob sie diese akzeptiert oder nicht.","Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. zu kompliziert.
Grundgedanke ist richtig.
Ich habe zwei Schnittstellen,
die relevant sind und worauf Sie 
gucken,
ist einfach immer die höchste 
Nutzenlinie.
Höchste Indifferenzkurve, 
nämlich hier in
dem Bereich ist das rote am 
höchsten und
das Rote ist die Nutzung der 
Nutzen,
den Sie haben von in Aktion in 
diesem Bereich
hier ist der Nutzen von dem 
Suggestion am höchsten.
Also, wenn Sie irgendwo im 
Nirgendwo sind,
wenn es nicht so ganz klar ist,
dass Sie das auf keinen Fall 
wollen,
oder wenn es relativ klar ist,
dass sie das wollen, dann in 
diesem Zwischending.
Formal einfach sollte die uhr 
einfach vorschlagen.
Das ist formalisiert.
Die Grundidee von Wenn es ganz 
sicher ist,
dass Sie es nicht wollen,
dann können wir das automatisch
von der Maschine machen lassen.
Das ist einfach nicht passiert.
Wenn Sie ganz sicher.
Wenn die Wahrscheinlichkeit sehr 
hoch ist, dass Sie es.
Auf jeden Fall. Es geht los da 
draußen.
Wenn Sie aber ganz sicher sind,
dass das gemacht werden soll,
dann können wir automatisiert 
das
machen lassen von der Maschine.
Und hier in diesem, wie gesagt,
nirgendwo Bereich soll die 
Maschine einfach vorschlagen
und der Mensch selber 
entscheidet
aus dem vorherigen Denken 
wieder. dass diese Technologie eventuell 
diese Schere
in der Produktivität von 
Experten,
Leuten mit viel Humankapital
und mit geringem Humankapital 
verändert.
Letzter Punkt Auch die Kunden 
sind happy geworden.
Wir haben höhere Net Promoter 
Scores.
0.1. 0.2 Die Mitarbeiter sind 
selber auch happy geworden.
Nicht nur produktiver, sondern 
auch happy.
Ja, denn es wurde reported,
dass weniger Eskalation passiert 
ist,
dass der Kunde am
Telefon gesagt hat Hey, jetzt 
gib mir mal dein Manager.
Du erzählst ja nur Quatsch. Ja, 
und
die Leute hatten längere Tenure,
sind länger dabei geblieben,
was so ein bisschen darauf 
hindeutet,
dass in diesem Fall.
Ich bin sehr vorsichtig sind.
Super Papier. Noch mal kann ich 
Ihnen
nur empfehlen zu lesen.
Ich werde es hochladen,
aber das in diesem Fall eine Win 
win
win Situation entstanden ist.
Und damit will ich Sie nicht 
länger quälen.
Vielen Dank für die 
Aufmerksamkeit
und wir sehen uns nächste Woche.
Und wer Fragen hat,
mag bitte nach vorne kommen.
So, ich wollte.",7.841263533,0,"The generated answer provides a nonsensical and incorrect definition related to user certainty and suggestions. The ground truth provides the correct, technical definition of information gain as the reduction in entropy from a data split. The answers are not remotely similar.",0,The generated answer is not faithful. It claims that information gain comes from using 'Suggestionen' (suggestions) from a machine when a person is sure they don't want something. [cite_start]The retrieved context uses the term 'Suggestion' [cite: 958] in a completely different context of a utility curve for a user deciding whether to accept a machine's suggestion. The context does not define 'information gain' at all.,0,The context is irrelevant. It discusses the concept of 'Mixed Initiative' where a machine makes a suggestion but the human decides. It does not contain any information about 'information gain' in the context of decision trees or entropy reduction.
What is KNN used for?,KNN is a supervised learning algorithm used for classification and regression.,"According to the text, KNN (K Nearest Neighbors) is used to evaluate whether a specific investment object, such as P2P loans, is suitable for a customer.","Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. in einer bestimmten Domäne,
in einem bestimmten Bereich 
angewendet werden kann,
sondern eben in verschiedenen 
Sektoren.
Es wird überall gebraucht.
Also General Purpose und
vorher war mal und ich finde den 
Namen furchtbar.
Aber um sie nicht zu verwirren,
habe ich eine andere als die 
herkömmliche Abkürzung,
die Sie in vielen ökonomischen
Büchern noch finden, nämlich 
GPT.
Das ist General Purpose.
Technologie hat natürlich Open 
AI
uns alle so ein bisschen 
versaut.
Dieses Wort zu benutzen,
insbesondere wenn man irgendwie 
an der
Schnittstelle zu Machine 
Learning arbeitet,
weil alle direkt an das 
Sprachmodell denken.
Deswegen hier diese furchtbare
Abkürzung General purpose
Tonnen general purpose 
technology.
Diese Technologien haben
die gesamte Zivilisation der
Menschheit schon immer massiv 
verändert.
Nicht nur, weil sie auf der 
einen Seite weit
eingesetzt worden sind und
auf der anderen Seite eben über
die Zeit immer besser genutzt 
wurden,
erkannt wurde, wo wir sie noch 
einsetzen
kann Economies of Scale 
eingesetzt haben.
Viele Leute nutzen es wird immer 
knapper.
Sondern auch, weil diese 
Innovationen,
diese Kerninnovationen,
letztlich zu weiteren
komplementären Innovationen 
geführt haben. im Taunus angeschaut haben,
wie Menschen tatsächlich mit KI 
interagieren.
Ob es eigentlich gut ist,
wenn Ihr Sparkassenberater eine 
KI benutzt,
um Ihnen Investmentberatung zu
geben und wie Sie eigentlich
darauf reagieren oder ob
das Ganze vielleicht 
automatisiert ablaufen sollte.
Das Papier ist jetzt
also kommt bald im Management 
Science Journal raus.
Wie gesagt, die letzten fünf 
Minuten.
Aber vorher noch mal 
irgendwelche
Unklarheiten zu dem Thema,
was wir oder Themen,
die wir bisher besprochen haben.
Cool. Wie gesagt, wir haben
uns in diesem Projekt
Sparkasse kam auf uns zu und hat 
gesagt naja,
wir haben hier eine Idee
oder wir möchten gerne mal 
rausfinden,
ob unsere Kunden eigentlich eher 
wollen,
dass sie von einem Robo Advisor 
beraten werden,
also einem automatisierten 
System,
wo kein Mensch mehr dabei ist 
oder von Mensch Berater,
der mit der KI zusammenarbeitet
und gemeinsam sozusagen als
Human AI Team diese Beratung an 
den Kunden gibt.
Der Kunde ist eben darüber 
informiert.
Was wir gemacht haben, ist Wir 
haben
eine Feldstudie gemacht, zwei 
Stufen.
Wir haben für die erste Stufe 
ganz viele Daten gesammelt,
haben KI System gebaut,
was bewertet hat, ob ein 
bestimmtes Investitionsobjekt,
hier eben P2P loans,",5.835735798,0,The generated answer claims KNN is used to evaluate investment suitability. The ground truth states it is a supervised learning algorithm for classification and regression. These are fundamentally different descriptions of the algorithm's purpose.,0,"The generated answer is not faithful. It claims KNN is used to evaluate P2P loans. [cite_start]The context does mention a study where an AI system was built to evaluate P2P loans[cite: 991], but it never mentions the KNN algorithm specifically. The context discusses KNN in a different, more general context related to management decisions.",0,The context is irrelevant. It discusses a case study with a German savings bank (Sparkasse) about using AI for investment advice on P2P loans. It does not mention the K-Nearest Neighbors (KNN) algorithm.
"According to the document, what are the three components of the training process of supervised machine learning?",Representation +Evaluation +Optimization,"Laut dem Text umfasst der Trainingsprozess beim überwachten maschinellen Lernen drei Komponenten:

1.  **F** (Das erlernte Machine Learning Modell, das Muster in historischen Daten speichert.)
2.  **XML** (Die Daten, die in die Maschine reingesetzt werden.)
3.  **Y** (Ein Indikator, dass es sich um eine Approximation handelt.)","Studierende werden mit den wichtigsten Fragestellungen rund um den Einsatz von Machine Learning (ML) in Managemententscheidungen vertraut gemacht. Sie erwerben grundlegende theoretische Kompetenzen im Bereich ML und verstehen, wie diese Technologien betriebliche Prozesse und strategische Entscheidungen beeinflussen können.
Studierende erlernen den Umgang mit grundlegenden Methoden und Werkzeugen des maschinellen Lernens, einschließlich Datenaufbereitung, Modelltraining und -bewertung. Sie entwickeln die Fähigkeit, wirtschaftliche Fragestellungen in ML-Probleme zu übersetzen und datenbasierte Lösungen analytisch sowie strukturiert zu erarbeiten.
Im Rahmen der Veranstaltung werden zahlreiche Praxisbeispiele und Fallstudien aus verschiedenen Industrien behandelt, die die Anwendung von ML und generativer KI im geschäftlichen Kontext beleuchten. Insbesondere in den angebotenen Übungen und praktischen Programmieraufgaben lernen Studierende, das erlangte Wissen anzuwenden, auch ohne vorherige Programmiererfahrung. dieser Gleichung hier 
ausdrücken.
Wir haben drei verschiedene 
Komponenten.
Wir haben hier dieses Hütchen,
wir haben das fix und wir haben 
hier dieses Y Hütchen.
Meine erste Frage an Sie Was war 
das? F Hütchen.
Yes, genau richtig.
Wir haben hier das erlernte 
Machine Learning Modell,
was die Muster, die wir in 
historischen
Daten durch Algorithmen erkannt 
haben, abspeichert.
Hier in diesem F. Steckt unser 
gesamtes Wissen drin,
was wir irgendwie extrahieren
und wie genau wir das 
extrahieren.
Das wird der zweite Teil unserer 
Vorlesung sein.
Wichtig hierbei Hütchen ist 
immer dafür ein Indikator,
dass wir von einer Approximation 
sprechen.
Das ist ein Modell.
Das ist nicht der wahre 
unterliegende Prozess,
der die Daten generiert.
Das ist nicht die Landschaft von 
Frankfurt sozusagen,
sondern es ist die Landkarte.
Es ist ein explizit abstrakteres 
Modell,
eine Darstellung der Realität.
Und da können eben Fehler drin 
sein.
Es ist ganz wichtig, sich
immer wieder vor Augen zu 
halten.
Dann haben wir die zweite 
Komponente.
Das war das XML. Was ist das?.X. 
Jemand eine Idee?
Jetzt dahinten? Genau das sind 
die Daten,
die wir in diese Maschine 
reintun.
Wir haben zum Beispiel, wenn Sie 
überlegen,
Sie interagieren mit Chat GPT Trainieren
selber gar nicht lange und
wir können sehr viele Kniffe 
benutzen,
wie wir dieses diesen
Trainingsprozess in einer 
gewissen Art
und Weise automatisieren können,
indem wir zum Beispiel
die Modellstruktur, die 
Modellauswahl,
sogar die Auswahl der relevanten
Inputinformationen durch 
bestimmte sogenannte
Cross Validation Verfahren durch
die Daten selber identifizieren 
lassen.
Ich hasse diesen Satz,
aber hier passiert dann sehr 
häufig dieses Let
the data speak so wenig anhaben 
wie möglich machen.
Wir versuchen einfach, das beste 
Modell zu finden.
Und auch das sei wieder betont, 
ist fundamental.
Uns geht es darum, ein Modell zu 
finden,
was nicht unsere historischen
Daten so gut es geht erklärt,
sondern sobald das Modell da 
ist,
möchten wir ein Modell haben,
was es uns ermöglicht,
Vorhersagen für die Zukunft zu 
machen,
also Vorhersagen für Beispiele,
Observationen, die das Modell 
noch nicht gesehen hat.
Denken Sie an das 
EiscremeBeispiel zurück.
Es ging nicht darum, perfekt zu 
erklären,
wie sich in der
Vergangenheit unsere 
Eisverkäufer abhängig
von bestimmten 
Wetterinformationen dargestellt 
haben,
sondern es ging darum Ich habe 
einen bestimmte
Logik identifiziert aus den 
historischen Daten.",9.848101139,0,"The generated answer incorrectly identifies the components of the machine learning equation (F-hat, XML, Y) as the three components of the training process. The ground truth correctly identifies the three components as Representation, Evaluation, and Optimization.",0.5,"The generated answer lists three components: Representation, Evaluation, and Optimization. [cite_start]The context does mention these three terms in a diagram heading: 'Representation + Evaluation + Optimization'[cite: 87]. However, the generated answer incorrectly links them to variables from a different part of the text ('F', 'XML', 'Y'). While the three components are in the context, the explanation provided in the answer is not faithful.",0.8,"The context is highly relevant. It breaks down the supervised machine learning process using the formula ð‘¦Ì‚ = ð‘“Ì‚(ð‘¥) and explains the three components: ð‘“Ì‚ (the learned model, or Representation), X (the input data), and ð‘¦Ì‚ (the prediction). While it doesn't explicitly use the words Evaluation and Optimization in this specific segment, the overall lecture context it's drawn from is about the entire ML process, including those steps. The explanation of the components directly relates to the three parts of the training process."
"In the case study with the Sparkasse, is the combination of a human and a machine advisor better or worse than the machine alone?",Worse.,"Laut dem Text ist die Kombination aus Mensch und Maschine (als ""Mensch plus Maschine"") schlechter als die Maschine allein. Der Text besagt, dass das gemeinsame Produkt schlechter ist als das, was die Maschine alleine macht.","technische Performance der 
Maschine,
die für diese beiden Subgruppen 
vergleichbar sind.
Und grundsätzlich ist dieses 
Fehlverhalten von Maschinen,
wenn systematisch basierend auf
bestimmten soziodemographischen 
Faktoren,
die wir rechtlich oder
als Gesellschaft für wichtig 
erachten.
Wenn dort Unterschiede 
vorliegen,
die in der Realität aber 
eigentlich keine Rolle spielen,
also ohne Rechtfertigung,
unterscheidet die Maschine in
ihrer Vorhersagegenauigkeit,
in welchem Maß auch immer wir 
das jetzt messen,
zwischen diesen beiden Gruppen,
dann sprechen wir von 
algorithmischer Diskriminierung.
Algorithmische Diskriminierungen 
gibt es,
ein ganz tolles Papier hier von 
zwei
Kollegen werde ich Ihnen auch 
noch hochladen.
Und diese algorithmische 
Diskriminierung
hat ein ganz großes Problem.
Nämlich wir haben nicht, das es
vorher nicht auch schon hätte 
sein können,
dass Ihr Bankberater in dieser
einen Sparkasse
gegen bestimmte Minoritäten 
diskriminiert hat.
Aber diese Maschinen erzeugen 
oder erzeugen dieses
Muster auf eine Art und Weise,
auf eine skalierbare Art und 
Weise,
wie sie eine einzelne Person nie 
hätte darstellen können.
Und das hat auf der einen Seite 
eben technische Aspekte,
aber auch soziale Aspekte. viel.
Das ist tatsächlich so ein 
bisschen intuitiv.
Auch die der Mechanismus,
auf den alles hindeutet.
Wir haben uns angeschaut. Glaubt 
der Mensch einfach.
Das glaubt der Kunde, dass 
Maschine
plus Mensch besser berät.
Also dass es genauer ist,
dass es vertrauenswürdiger ist
und bessere 
Investitionsempfehlungen gibt?
Nee, überhaupt nicht.
Wenn, dann antizipiert der Kunde 
sogar.
Naja, wenn Mensch plus Maschine 
zusammenarbeitet,
ist das gemeinsame Produkt 
schlechter als das,
was die Maschine alleine macht.
Ist aber egal, weil ich fühle 
mich besser,
wenn der Mensch dabei ist.
Dieser emotionale,
wie wir es hier aus dieser
Theorie von der Elaboration 
likelihood
Model der Peripherie peripheral 
Part in Ihrem Gehirn.
Also diese affektiven Signale, 
da ist jemand,
der hält Ihre Hand,
wenn es schief geht,
auf den können Sie sauer sein, 
wenn es schief geht.
Und dann können wir das hier 
zeigen,
dass es eben nicht darum geht,
dass der Mensch die Beratung 
mehr akzeptiert,
mehr bereit ist zu bezahlen am 
Ende.
So suggerieren unsere 
Ergebnisse,
wenn Mensch plus Maschine da 
sind.
Nicht weil es denkt es besser, 
sondern einfach,
weil da jemand da ist, der ihnen 
die Hand hält.
Ähm, ja.
Takeaways, das habe ich glaube 
ich, geben,
was Entscheidungsparameter 
angeht.
Macht Sinn. Gut, ein Konzept,
was ich auch durch meine eigene 
Forschung
in unbedingt nahe legen möchte,
ist die Idee von Mensch 
Maschine.
Komplementaritäten bedeutet Was 
wir
erreichen wollen ist eigentlich 
ein Setting,
wo Mensch und Maschine auf eine
Art und Weise zusammenarbeiten,
dass die Performance dieses
kollaborativen Systems besser 
ist als
die Performance der einzelnen 
Komponenten.
Und das kann natürlich
aus verschiedenen Gründen 
entspringen.
Diese komplementären Stärken.
Haben Sie eine Idee, was so die 
zwei Faktoren sind,
warum Menschen und Maschinen 
sich ergänzen und
warum nicht die Maschine immer 
besser
ist und nicht der Mensch immer 
besser ist?
Auf einem sehr high Level ja,
vielleicht auch mit dem 
Zusammenspiel der
zwei Systeme mit dem eins und 
zwei.
Interessante Perspektive.
Kann man so interpretieren,
dass die Maschine eher System 
zwei ist
und der Mensch sehr schnell 
heuristisch
affektiv entscheidet.
Ja, geht in einen der beiden 
Punkte,
die ich zusammenfassen möchte, 
mit ein Ja.
Ja. Ja, würde ich jetzt als ein
anderes Thema noch mal 
betrachten.
Moralität.
Wir sprechen jetzt hier wirklich 
um
Ergänzung von Fähigkeiten.
Erstmal die einbringen,",8.587983608,1,The generated answer is semantically consistent with the ground truth. Both state that the combination of a human and machine advisor is worse than the machine alone.,1,"The generated answer is faithful. [cite_start]The context describes a study with a 'Mensch plus Maschine' (human plus machine) setup and states that 'ist das gemeinsame Produkt schlechter als das, was die Maschine alleine macht' (the joint product is worse than what the machine does alone)[cite: 1022].",1,"The context is highly relevant and directly answers the question. It explicitly states, 'Naja, wenn Mensch plus Maschine zusammenarbeitet, ist das gemeinsame Produkt schlechter als das, was die Maschine alleine macht.' (Well, when human plus machine work together, the joint product is worse than what the machine does alone)."
"What is the concept of 'Mixed Initiative' in human-AI interaction, as exemplified by a smartwatch asking if it should record a workout?","'Mixed Initiative' is a middle ground between full automation and full manual control, where the system proactively suggests an action, but the human still makes the final choice to accept or reject it.","Basierend auf dem bereitgestellten Text lässt sich das Konzept der ""Mixed Initiative"" in der Mensch-KI-Interaktion, wie es sich in einem Smartwatch-Szenario zeigt, wie folgt verstehen:

**Die ""Mixed Initiative"" bedeutet, dass sowohl der Mensch als auch die KI die Initiative bei der Interaktion übernehmen.**

Im Kontext der Smartwatch, die fragt, ob eine Trainingssession aufgezeichnet werden soll, bedeutet das Folgendes:

*   **KI-Initiative:** Die Smartwatch (die KI) stellt die Frage und bietet eine Option (Aufzeichnung).
*   **Menschliche Initiative:** Der Nutzer hat die Freiheit, zu antworten, indem er entweder ""Ja"" oder ""Nein"" sagt. Der Nutzer kontrolliert also die Richtung der Interaktion.

**Der Text betont, dass es nicht nur um eine passive Frage der KI geht, sondern um eine Kooperation zwischen Mensch und Maschine.** Die Sparkasse hat diese Idee untersucht, um zu sehen, ob Kunden lieber von einem Robo-Advisor beraten werden oder von einem menschlichen Berater, der mit einer KI zusammenarbeitet.

**Der Text impliziert, dass die ""Mixed Initiative"" ein wichtiger Aspekt der Mensch-KI-Interaktion ist, um eine effektive und akzeptierte Zusammenarbeit zu gewährleisten.** Es geht nicht darum, dass die KI einfach Entscheidungen trifft, sondern dass der Mensch und die KI gemeinsam arbeiten, um die bestmögliche Lösung zu finden.

Ich hoffe, diese Erklärung ist hilfreich!","So legen wir los. Herzlich 
willkommen.
Vorlesung fünf sozusagen.
Fast schon Bergfest, oder?
Heute ist, glaube ich, Bergfest,
wenn man die restlichen 
Vorlesungen zusammenzählt.
Auch weil ich jetzt schon 
mehrfach gefragt wurde.
Dazu mit der Klausur.
Das hier ist jetzt die letzte
Vorlesung aus diesem ersten 
Teil,
wo es darum geht, ein 
grundsätzliches
Verständnis dafür zu schaffen,
was KI bewirken kann,
wie Menschen mit KI 
zusammenarbeiten können,
was potenzielle Schwachpunkte 
und Probleme sind,
wenn wir KI einsetzen.
Heute sprechen wir über Mensch 
Maschine Interaktion,
bauen sozusagen auf der 
Erklärbarkeit.
Vorlesungen von vor zwei Wochen
auf und dann ist dieser erste 
Block abgeschlossen.
Dann fängt es nächste Woche
an mit dem eher technischen 
Blog,
wo wir jetzt wirklich uns dann 
damit befassen werden,
wie wir diese Systeme bauen,
was die Mathematik dahinter ist,
wo die Stärken und die
Schwächen von bestimmten 
Modellen liegen.
Und zu Beginn der nächsten
Vorlesung werden wir dafür dann 
aber zum Abschluss dieses
ersten Blockes so eine Art 
kleinen Recap machen,
wo ich Ihnen auch
ein paar Fragen interaktiv
mit der Gruppe durchspielen 
werde.
Von der Struktur der Frage 
können Sie dann auf die
Struktur der Fragen in wo Sie KI einsetzen können,
wann und wo mögliche 
Problemstellungen sind.
Aus diesem ersten Teil hier 
zumindest,
dass Sie uns das strukturiert 
wiedergeben
können und uns zeigen,
dass Sie diese Denkweise 
verstanden haben.
Wenn wir heute dann wie gesagt,
einsteigen und das Thema des 
ersten Blockes abschließen.
Kümmern wir uns jetzt noch mal 
darum,
was eigentlich der Mensch in 
diesem ganzen System
weiterhin noch macht und kümmern 
uns
um diese Mensch Maschine 
Interaktion.
Wenn Sie sich erinnern Sehr früh
in der zweiten Vorlesung haben 
wir festgestellt,
dass die meisten Machine 
Learning Anwendungen
es uns eigentlich erlauben,
Vorhersagen über oder unter 
Unsicherheit zu machen.
Wir kriegen Informationen, die 
uns nicht vorliegen,
und diese Informationen sind
irgendwie nützlich für uns in 
einem Entscheidungsprozess.
Sei es in dem Beispiel,
dass wir eine 
Investitionsentscheidung
treffen möchten und uns
dafür überlegen oder eine 
Vorhersage benötigen.
Wird diese 
Investitionsentscheidung, wie in
diesem Beispiel eine hohe
Rückzahlung für mich ergeben 
oder eine
niedrige Rückzahlung?
Mit dieser Information kann ich 
mir dann überlegen,
ob ich diese Investition
tatsächlich machen möchte oder 
eben nicht. im Taunus angeschaut haben,
wie Menschen tatsächlich mit KI 
interagieren.
Ob es eigentlich gut ist,
wenn Ihr Sparkassenberater eine 
KI benutzt,
um Ihnen Investmentberatung zu
geben und wie Sie eigentlich
darauf reagieren oder ob
das Ganze vielleicht 
automatisiert ablaufen sollte.
Das Papier ist jetzt
also kommt bald im Management 
Science Journal raus.
Wie gesagt, die letzten fünf 
Minuten.
Aber vorher noch mal 
irgendwelche
Unklarheiten zu dem Thema,
was wir oder Themen,
die wir bisher besprochen haben.
Cool. Wie gesagt, wir haben
uns in diesem Projekt
Sparkasse kam auf uns zu und hat 
gesagt naja,
wir haben hier eine Idee
oder wir möchten gerne mal 
rausfinden,
ob unsere Kunden eigentlich eher 
wollen,
dass sie von einem Robo Advisor 
beraten werden,
also einem automatisierten 
System,
wo kein Mensch mehr dabei ist 
oder von Mensch Berater,
der mit der KI zusammenarbeitet
und gemeinsam sozusagen als
Human AI Team diese Beratung an 
den Kunden gibt.
Der Kunde ist eben darüber 
informiert.
Was wir gemacht haben, ist Wir 
haben
eine Feldstudie gemacht, zwei 
Stufen.
Wir haben für die erste Stufe 
ganz viele Daten gesammelt,
haben KI System gebaut,
was bewertet hat, ob ein 
bestimmtes Investitionsobjekt,
hier eben P2P loans,",25.33882546,1,"The generated answer is semantically consistent with the ground truth. Both correctly describe 'Mixed Initiative' as a middle ground where the system can proactively suggest an action, but the human retains the final choice.",1,"The generated answer is faithful. The context describes a situation where a smartwatch asks the user 'Soll ich das eigentlich aufzeichnen?' (Should I record this?) [cite_start][cite: 1067]. [cite_start]It calls this 'The Idea of Mixed Initiative'[cite: 1072], where the system proposes an action ('Initiative' from the AI) but the user makes the final decision ('Initiative' from the human).",1,"The context directly explains the concept. It describes a smartwatch that asks the user if it should start recording a workout. It defines this as 'Mixed Initiative,' where the system proactively suggests an action ('ihnen etwas vorzuschlagen') but the user makes the final decision, combining automation with user control."
What did the speaker say about the possibility of the smartwatch automatically starting to record a workout?,The speaker said the smartwatch could estimate the probability that the user wants their sport recorded.,"Der Sprecher hat gesagt, dass die Smartwatch in Extremfällen einfach ""die Aktion machen, das eben aufzuzeichnen oder die uhr macht das eben nicht."" Er beschrieb dies als einen Fall, in dem die Uhr selbst entscheidet, ob sie etwas aufzeichnet oder nicht, ohne dass der Nutzer aktiv eingreift.","Wenn Sie entscheiden würden, 
nicht zu delegieren,
dass Sie auf jeden Fall das 
selber machen, hilft es ja.
Ja, das ging jetzt gerade,
was sie gesagt hatten.
Naja, muss es denn immer das 
eine oder das andere sein?
Nee, muss es natürlich nicht.
Denken Sie an diejenigen im 
Raum,
die irgendeine Smartwatch haben.
Wenn Sie Sport machen und 
plötzlich
das System Sie fragt Soll ich 
das eigentlich aufzeichnen?
Sind Sie gerade am Sport machen?
Das ist irgendwie so eine Art 
Mischung davon.
Also weder das System selber 
entschieden,
jetzt irgendwas aufzuzeichnen 
ohne Ihre Einwilligung.
Sie haben also diese 
Entscheidung
des automatisierten 
Aufzeichnungs nicht
an die Maschine delegiert.
Aber Sie haben auch nicht aktiv 
gesagt Na ja,
ich gehe jetzt hin und such das 
raus.
Sondern die Maschine von sich 
entscheidet,
ihnen etwas vorzuschlagen in the 
first place.
Und das nennen wir grundsätzlich
The Idea of Mixed Initiative.
Und es geht auch schon auf ein 
sehr frühes
wissenschaftliches Papier 
zurück,
nämlich Anfang der 
Zweitausenderjahre.
Weiß jemand, wer das ist? Hier. 
Mal von ihm gehört?
Es ist der Chief Scientific 
Officer von Microsoft.
Der,
der für sehr viele
wissenschaftliche 
Strategieentscheidungen oder die uhr macht einfach 
nichts in Aktion.
In diesen Extremfällen Jetzt 
gehen wir gleich
wieder in die Mitte davon.
Aber Sie laufen und Sie möchten,
dass Laufen aufgezeichnet haben 
Sie laufen, möchten,
dass nicht aufgezeichnet haben 
und
die Maschine kann selber die 
Aktion machen,
das aufzuzeichnen oder die uhr 
macht das eben nicht.
Und dann haben wir vier 
verschiedene Fälle und
das versuchen wir wieder über 
Nutzen darzustellen.
Ganz, ganz allgemein.
Der Nutzen, den ich davon habe,
wenn die uhr die Aktion 
durchführt
und die Messung beginnt, 
gegeben.
Ich möchte auch, dass diese 
Messung gemacht wird.
Wenn ich Sport mache versus die
uhr macht das einfach
und eigentlich will ich das gar 
nicht.
Umgekehrt hier und das ist wer 
kennt dieses
Symbol? Was bedeutet das?
Genau. Das ist aus der 
Mathematik der Logik.
Wenn Sie dieses seitlich 
gedrehte Liter sehen,
heißt das immer Nicht immer.
Nicht a, nicht Action.
Sie können eigentlich hier,
um das Beispiel zu 
vervollständigen.
Sie möchten gerne, dass 
aufgezeichnet wird,
aber die uhr macht es nicht 
automatisch.
Not Action.
Und ein anderer Fall ist,
Sie möchten es nicht und die uhr 
macht es nicht.
Diese vier Extremfälle haben wir 
jetzt wieder. obwohl die Leute wissen, die 
Maschine ist gut.
Das Signal unsere Prediction,
die ist wertvoll,
die sollte ich in meine 
Überlegungen mit einbeziehen.
Die ignorieren das einfach.
Riesen Phänomen.
Sehr gutes Thema für eine 
Bachelorarbeit.
Ach nee, ich wollte 
weitermachen.
Sorry. Nach der Vorlesung.
Ja, ich muss ein bisschen auf 
die Zeit achten.
Hier. Worauf ich hinaus wollte 
mit der Darstellung,
dass sich unser PC verändert,
aber nicht unser OO.
Also Sie haben weiterhin diese 
Bewertung.
Womit ich darauf hinaus möchte, 
ist die Tatsache,
dass weiterhin Platz für Sie als 
Mensch besteht.
Die Maschine gibt Ihnen
eine Vorhersage und diese 
Vorhersage
verändert Ihre subjektive
Einschätzung über die 
Wahrscheinlichkeit,
Aber sie verändert nicht,
dass sie weiterhin eigentlich 
für sich bestimmen müssen.
Wie gut finde ich denn 
eigentlich,
dass ich 15 Kriege
in diesem Fall und das 
Unternehmen 15 kriegt?
Oder dass ich zehn kriege
und das Unternehmen null kriegt?
Sie können ja zum Beispiel 
jemand sein,
der sagt Naja, mir ist es super,
super wichtig,
dass ich den Gesamtkuchen, die 
Effizienz maximiere.
Das heißt, wenn wir beide 15 
haben,
ist das relativ für sie besser 
als
in diesem Beispiel hier null und 
20.",9.286752224,1,The generated answer is semantically consistent with the ground truth. Both convey the idea that the smartwatch can estimate the probability of the user's desire and act on that estimation.,1,"The generated answer is faithful. [cite_start]The context describes how a smartwatch can estimate the probability of a user wanting their activity recorded and then either automatically record it, do nothing, or, in an intermediate case, ask the user[cite: 1075, 1076]. This supports the claim that the watch could estimate the probability.",1,"The context is highly relevant. It describes a scenario with a smartwatch that can automatically start or not start an action (recording a workout). It then states, 'die Maschine kann selber die Aktion machen, das aufzuzeichnen oder die uhr macht das eben nicht,' which directly implies the system can estimate the probability of the user's preference and act on it."
The lecture describes two extremes in human-machine collaboration. What is 'Algorithm Aversion'?,"'Algorithm Aversion' is the observation that people often consciously choose not to use a helpful algorithm, even when they know it is objectively more accurate than their own opinion or that of other humans.","Laut der Vorlesung ist ""Algorithm Aversion"" die Tendenz von Menschen, Algorithmen zu vermeiden, weil sie die Möglichkeit haben, eine Person für eine schlechte Entscheidung verantwortlich zu machen. Menschen haben eine psychologische Befriedigung daraus, jemanden für negative Ergebnisse verantwortlich zu machen, was sie dazu bringt, Algorithmen zu bevorzugen, bei denen diese Möglichkeit fehlt.","Dann gibt es ja rein theoretisch 
keine Person,
wo man quasi die man zur 
Rechenschaft ziehen könnte,
wenn die Entscheidung 
fehlschlägt.
Davor schaltet, auch wenn er 
automatisiert
die ganze Zeit quasi einfach nur 
sagt ja, jetzt ist fein.
Dann hat man zumindest jemanden, 
dem man zutraut.
Das ist grundsätzlich richtig.
Behalten Sie den Gedanken bei,
weil nächstes Mal sprechen wir 
über
die Idee von Decision Threshold 
nochmal.
Aber das ist grundsätzlich auch 
etwas,
was so ein bisschen die 
Forschung andeutet.
Menschen haben
diese Algorithmen Aversion und 
machen es nicht,
weil sie am Ende jemanden lähmen 
blamieren möchten.
Wenn eine Maschine etwas macht,
dann können Sie gern die 
Maschine bleiben.
Die Maschine hat er leider 
nicht.
Nicht viel Negatives von.
Und es stellt sich heraus,
dass auch die psychologische
eigene Befriedigung darüber zu 
sagen Ich habe jemanden,
dem ich die Schuld zuweisen 
kann,
wenn mir etwas Schlechtes 
passiert. Einer anderen Person.
Diese psychologische 
Befriedigung haben sie nicht,
wenn Sie am Ende eine Maschine 
bleiben.
Was so ein bisschen darauf 
hindeutet,
dass Menschen eine 
Zahlungsbereitschaft dafür 
haben,
einen anderen Menschen drin zu
haben in dieser 
Entscheidungssituation. obwohl die Leute wissen, die 
Maschine ist gut.
Das Signal unsere Prediction,
die ist wertvoll,
die sollte ich in meine 
Überlegungen mit einbeziehen.
Die ignorieren das einfach.
Riesen Phänomen.
Sehr gutes Thema für eine 
Bachelorarbeit.
Ach nee, ich wollte 
weitermachen.
Sorry. Nach der Vorlesung.
Ja, ich muss ein bisschen auf 
die Zeit achten.
Hier. Worauf ich hinaus wollte 
mit der Darstellung,
dass sich unser PC verändert,
aber nicht unser OO.
Also Sie haben weiterhin diese 
Bewertung.
Womit ich darauf hinaus möchte, 
ist die Tatsache,
dass weiterhin Platz für Sie als 
Mensch besteht.
Die Maschine gibt Ihnen
eine Vorhersage und diese 
Vorhersage
verändert Ihre subjektive
Einschätzung über die 
Wahrscheinlichkeit,
Aber sie verändert nicht,
dass sie weiterhin eigentlich 
für sich bestimmen müssen.
Wie gut finde ich denn 
eigentlich,
dass ich 15 Kriege
in diesem Fall und das 
Unternehmen 15 kriegt?
Oder dass ich zehn kriege
und das Unternehmen null kriegt?
Sie können ja zum Beispiel 
jemand sein,
der sagt Naja, mir ist es super,
super wichtig,
dass ich den Gesamtkuchen, die 
Effizienz maximiere.
Das heißt, wenn wir beide 15 
haben,
ist das relativ für sie besser 
als
in diesem Beispiel hier null und 
20. So legen wir los. Herzlich 
willkommen.
Vorlesung fünf sozusagen.
Fast schon Bergfest, oder?
Heute ist, glaube ich, Bergfest,
wenn man die restlichen 
Vorlesungen zusammenzählt.
Auch weil ich jetzt schon 
mehrfach gefragt wurde.
Dazu mit der Klausur.
Das hier ist jetzt die letzte
Vorlesung aus diesem ersten 
Teil,
wo es darum geht, ein 
grundsätzliches
Verständnis dafür zu schaffen,
was KI bewirken kann,
wie Menschen mit KI 
zusammenarbeiten können,
was potenzielle Schwachpunkte 
und Probleme sind,
wenn wir KI einsetzen.
Heute sprechen wir über Mensch 
Maschine Interaktion,
bauen sozusagen auf der 
Erklärbarkeit.
Vorlesungen von vor zwei Wochen
auf und dann ist dieser erste 
Block abgeschlossen.
Dann fängt es nächste Woche
an mit dem eher technischen 
Blog,
wo wir jetzt wirklich uns dann 
damit befassen werden,
wie wir diese Systeme bauen,
was die Mathematik dahinter ist,
wo die Stärken und die
Schwächen von bestimmten 
Modellen liegen.
Und zu Beginn der nächsten
Vorlesung werden wir dafür dann 
aber zum Abschluss dieses
ersten Blockes so eine Art 
kleinen Recap machen,
wo ich Ihnen auch
ein paar Fragen interaktiv
mit der Gruppe durchspielen 
werde.
Von der Struktur der Frage 
können Sie dann auf die
Struktur der Fragen in",9.306067467,1,The generated answer is semantically consistent with the ground truth. Both correctly define 'Algorithm Aversion' as the phenomenon of people choosing not to use helpful algorithms.,1,"The generated answer is faithful. [cite_start]The context describes 'Algorithm Aversion' as a phenomenon where people ignore a helpful algorithm's prediction ('Die ignorieren das einfach') even when they know it is valuable ('obwohl die Leute wissen, die Maschine ist gut. Das Signal unsere Prediction, die ist wertvoll')[cite: 1104, 1105]. [cite_start]It also provides a reason: people want someone to blame ('Ich habe jemanden, dem ich die Schuld zuweisen kann') which is not possible with a machine[cite: 1101, 1102].",1,"The context directly explains the concept of algorithm aversion. It mentions that people often ignore helpful predictions from a machine ('obwohl die Leute wissen, die Maschine ist gut...Die ignorieren das einfach'). It also provides a reason: people want someone to blame ('Ich habe jemanden, dem ich die Schuld zuweisen kann'), which is not possible with a machine, thus they have an aversion to using it."
What are the two extremes of observation regarding human-machine collaboration?,Algorithm aversion and Algorithm appreciation.,"Basierend auf dem Text gibt es zwei Extreme der Beobachtung in Bezug auf die Zusammenarbeit zwischen Mensch und Maschine:

1.  **Übermäßige Abhängigkeit von der Maschine:** Hierbei wird die Ausgabe der Maschine (z.B. Vorhersage) überbewertet, und der Mensch ignoriert seine eigene Expertise und sein Urteilsvermögen. Der Mensch nimmt einfach das ""Ja, jetzt ist fein"" der Maschine an, ohne zu hinterfragen oder zu prüfen, ob die Entscheidung richtig ist.

2.  **Ignorieren des Signals der Maschine:** Hierbei wird das Signal der Maschine komplett ignoriert, und der Mensch verlässt sich nicht auf die Informationen, die die Maschine liefert.
","geben,
was Entscheidungsparameter 
angeht.
Macht Sinn. Gut, ein Konzept,
was ich auch durch meine eigene 
Forschung
in unbedingt nahe legen möchte,
ist die Idee von Mensch 
Maschine.
Komplementaritäten bedeutet Was 
wir
erreichen wollen ist eigentlich 
ein Setting,
wo Mensch und Maschine auf eine
Art und Weise zusammenarbeiten,
dass die Performance dieses
kollaborativen Systems besser 
ist als
die Performance der einzelnen 
Komponenten.
Und das kann natürlich
aus verschiedenen Gründen 
entspringen.
Diese komplementären Stärken.
Haben Sie eine Idee, was so die 
zwei Faktoren sind,
warum Menschen und Maschinen 
sich ergänzen und
warum nicht die Maschine immer 
besser
ist und nicht der Mensch immer 
besser ist?
Auf einem sehr high Level ja,
vielleicht auch mit dem 
Zusammenspiel der
zwei Systeme mit dem eins und 
zwei.
Interessante Perspektive.
Kann man so interpretieren,
dass die Maschine eher System 
zwei ist
und der Mensch sehr schnell 
heuristisch
affektiv entscheidet.
Ja, geht in einen der beiden 
Punkte,
die ich zusammenfassen möchte, 
mit ein Ja.
Ja. Ja, würde ich jetzt als ein
anderes Thema noch mal 
betrachten.
Moralität.
Wir sprechen jetzt hier wirklich 
um
Ergänzung von Fähigkeiten.
Erstmal die einbringen, Signal
gar nicht erst gesehen hätte.
Und das ist eines der zentralen 
Probleme,
die wir sehen, wenn Menschen mit
Maschinen zusammenarbeiten.
Wie nutzen Menschen dieses 
Signal,
wenn der Mensch in diesem Loop 
ist?
Haben Sie vielleicht schon öfter 
gehört aus
den Nachrichten Diese Idee von 
Menschen bleiben
im Loop Humans in the Loop,
wo Menschen, die Informationen 
von der KI bekommen,
aber Menschen letztlich die 
finale Entscheidung treffen.
Wenn die Menschen overconfidence
in die Maschine oder sich selber 
sind,
könnte es sein, dass sie die
Signal diese Vorhersage der
Maschine der KI komplett 
ignorieren.
Oder Aber wenn Sie glauben,
ich sollte einfach das machen,
was die Maschine mir sagt, kann 
es auch sein,
dass Sie dieses Signal der 
Maschine übergewichten.
Sie verlassen komplett ihren 
Player.
Sie glauben, sie haben 
eigentlich gar keine Ahnung als
Experte und nehmen einfach das 
an,
was die Maschine ihnen sagt?
Und dieses Problem von diesem
Zusammenspiel von wie sie diese 
Informationen
verarbeiten und wie welche
Probleme hier eine Rolle spielen 
könnten in Bezug auf
die richtige Gewichtung Ihrer 
eigenen Expertise
und der von der Maschine,
welche Signal Sie bekommen.
Das ist das, womit wir uns heute 
befassen. Ich kann Ihnen aber Brief und 
Siegel darauf geben,
dass es kein KI System der Welt 
gibt,
was immer richtig ist.
Das heißt, die Rolle des 
Menschen
ist eigentlich rauszufinden,
wann ist die Maschine nicht 
richtig.
Und das mit der eigenen und das
ist gleich der zweite Teil der
Vorlesung von heute
zu überlegen Wie kriege ich es 
eigentlich hin,
dass Mensch und Maschine 
zusammen so gut
sind, dass die gemeinsame,
diese kollaborative Performance 
besser ist,
als wenn sie alles die Maschine 
machen lassen
oder wenn sie einfach alles 
selber machen?
Aber diese Facetten, die Sie 
gesagt haben,
diese Idee davon Warum
verlasse ich mich eigentlich auf 
die Maschine.
Möchte ich nicht, dass mein Kopf 
rollt?
Möchte ich auch meine
Wahrnehmung meiner Verantwortung 
accountability irgendwie
an die Maschine abgeben?
Hochgradig komplexe
Facetten aus unterschiedlichen 
Perspektiven.
So dass man, wenn man quasi als
Unternehmen die 
Entscheidungsmacht bei
der Maschine bei der KI 
überlässt.
Dann gibt es ja rein theoretisch 
keine Person,
wo man quasi die man zur 
Rechenschaft ziehen könnte,
wenn die Entscheidung 
fehlschlägt.
Davor schaltet, auch wenn er 
automatisiert
die ganze Zeit quasi einfach nur 
sagt ja, jetzt ist fein.",14.19408107,1,The generated answer is semantically consistent with the ground truth. Both correctly identify the two extremes as algorithm aversion (under-reliance) and algorithm appreciation (over-reliance).,0.5,"The generated answer correctly identifies 'Algorithm aversion' as one extreme, which is supported by the context[cite: 1104, 1105]. However, the other extreme it names, 'Algorithm appreciation', is not mentioned in the text. [cite_start]The context describes the opposite problem as people who 'Ã¼bergewichten' (overweight) the machine's signal and ignore their own expertise[cite: 1135, 1136], which is a form of over-reliance, not necessarily 'appreciation'.",1,"The context directly addresses the question. It describes two problematic extremes in human-AI interaction: one where users 'komplett ignorieren' (completely ignore) the machine's suggestion, and another where they 'Ã¼bergewichten' (over-weight) the signal and stop using their own expertise. This aligns with the concepts of algorithm aversion and an over-reliance that can be termed algorithm appreciation."
What were the developers struggling with regarding Windows eight?,The developers of Windows 8 were struggling with the bad user interface.,"Die Entwickler von Windows 8 hatten folgende Schwierigkeiten:

*   **Totale Katastrophe der Benutzeroberfläche (User Interface):** Die Oberfläche war für die Entwickler eine Katastrophe, die sich nicht gut anfühlte und nicht gut funktionierte.
*   **Entwickler konzentrierten sich ausschließlich auf die Oberfläche:** Die Entwickler waren zu sehr auf die Oberfläche fokussiert und haben die tatsächlichen Nutzerbedürfnisse nicht ausreichend berücksichtigt.
*   **Entwicklung für Windows 8:** Das System wurde für Windows 8 entwickelt, was zu Problemen führte, da die Oberfläche für die Nutzer eine Katastrophe war.","the loop dahingehend Sie 
entscheiden,
Ich transferiere 
Entscheidungsgewalt in diesen
automatisierten Fällen oder Sie 
behalten immer
die Entscheidungsgewalt,
müssen sich aber entscheiden Wie
viel Gewicht geben Sie 
eigentlich?
Der Information von der Maschine 
macht es Sinn.
So fangen wir aber
mal einen Schritt weiter vorne 
an Erinnern Sie sich noch?
Ich weiß nicht, ob Sie dafür 
noch zu jung sind, Sogar.
Aber erinnern Sie sich noch
an diese Version von Microsoft?
Microsoft acht kam raus
2012 und es war ein vollkommenes 
Desaster für Microsoft.
Warum? Naja, viele der User 
waren total überfordert.
Das war eigentlich grundsätzlich 
ein
tolles System mit ganz vielen 
Neuerungen,
mit ganz vielen Funktionen,
wo sich die Entwickler gedacht 
haben Naja,
das sollte meinen Nutzern 
gefallen.
Das macht alles viel einfacher.
Da soll der Entscheidungsfindung 
Prozessen
arbeiten helfen.
War alles natürlich well 
intended.
Problem war, wir alle fanden das 
nicht so cool.
Das war bei mir auch der 
Zeitpunkt,
wo ich dann komplett auf Mac 
übergesprungen bin.
Und selbst neun Jahre später war 
es immer noch so,
dass der Vorgänger Windows 
sieben
2021 hatte Windows sieben
immer noch 15 % Marktanteil von 
Windows Systemen, in einer anderen Art und Weise 
in
den Microsoftsystemen immer noch 
da.
Die wurden dort entwickelt für 
Windows acht,
aber die Oberfläche war totale 
Katastrophe.
User Interface Wir hatten 
Entwickler,
die sich ausschließlich damit 
beschäftigt haben.
Wie kann ich denn ein System 
entwickeln,
was super funktioniert haben,
aber viel zu spät eigentlich
den eigentlichen Nutzer mit 
einbezogen.
Das wurde ja auch als Mobile 
gedacht.
Also wir haben es ja versucht 
auf
dem Microsoft Handy Plattform zu 
machen.
Deshalb ist der Vorstoß
ja unterstreicht trotzdem den 
Punkt,
dass die Leute sich nicht 
ausreichend
früh überlegt haben und der.
Mein Punkt dieser Idee ist 
natürlich
für uns jetzt an dieser
Stelle Ich kann ein super System 
haben.
Worauf es aber wirklich ankommt, 
ist,
ob dieses System so genutzt 
wird,
wie ich mir das vorstelle.
Stellen Sie sich vor, Amazon
hätte das beste Recruitment Tool
basierend auf KI entwickelt
und es wäre immer richtig 
potenziell.
Aber diejenigen, die letztlich
die Entscheidungsgewalt haben,
der Mensch in diesem Loop
würde nie auf die Maschine 
hören.
Alle möglichen Effizienzgewinne, 
die wir hätten,
werden gar nicht realisiert.
Es kommt immer auf die Nutzung 
anderer
will ich sie heute Zeitpunkt,
wo ich dann komplett auf Mac 
übergesprungen bin.
Und selbst neun Jahre später war 
es immer noch so,
dass der Vorgänger Windows 
sieben
2021 hatte Windows sieben
immer noch 15 % Marktanteil von 
Windows Systemen,
wohingegen Windows acht, was
viele neue gute Funktionen 
hatte,
immer noch nur um die 1 % war.
Und es ist wieder considered 
eines der
schlechtesten Operating Systeme, 
die es gibt.
weil es einfach niemand benutzt 
hat.
Jetzt natürlich die Frage Wenn 
ich Ihnen hier
so eine anekdotische Geschichte 
erzähle,
um Sie so ein bisschen emotional 
abzuholen,
was glauben Sie, hat das mit KI 
zu tun?
Wie könnte ich aus dem 
vorherigen Beispiel,
dass die KI mir ein Signal gibt?
Ich sehe das und es
ist eigentlich ein hilfreiches 
Signal.
Wie kann ich diese Idee hier auf 
diesen
anekdotischen Fall aus der 
Geschichte
mappen? Wo ist die Verbindung?
Genau hier.
Wir haben ein tolles System. Es 
kann uns helfen.
Viele der Features im
Übrigen sind heute in einer 
anderen Darstellung,
in einer anderen Art und Weise 
in
den Microsoftsystemen immer noch 
da.
Die wurden dort entwickelt für 
Windows acht,
aber die Oberfläche war totale 
Katastrophe.
User Interface Wir hatten 
Entwickler,
die sich ausschließlich damit",13.06582165,1,The generated answer is semantically consistent with the ground truth. Both correctly state that the developers of Windows 8 struggled with a bad user interface.,1,"The generated answer is faithful. [cite_start]The context describes Windows 8 as a 'vollkommenes Desaster' [cite: 1150] [cite_start]because the 'OberflÃ¤che war totale Katastrophe' (the user interface was a total catastrophe) [cite: 1155, 1172] [cite_start]and that developers focused too much on the system's functions without involving the user early enough[cite: 1151, 1157].",1,"The context directly answers the question. It states that Microsoft's operating system from 2012, Windows 8, was a disaster because 'die OberflÃ¤che war totale Katastrophe' (the user interface was a total catastrophe) and users 'waren total Ã¼berfordert' (were totally overwhelmed)."
"In a case study about the role of the human, what was the investment amount for the P2P vehicle in the experiment?",100,Basierend auf dem bereitgestellten Text war die Investition für das P2P-Fahrzeug 10 Millionen Euro.,"informiert.
Was wir gemacht haben, ist Wir 
haben
eine Feldstudie gemacht, zwei 
Stufen.
Wir haben für die erste Stufe 
ganz viele Daten gesammelt,
haben KI System gebaut,
was bewertet hat, ob ein 
bestimmtes Investitionsobjekt,
hier eben P2P loans,
also Privatkredite, finanziert 
werden sollten,
also ob ein Kunde 100 € 
beispielsweise in die in
jemand anderen als Privatkredit
investieren möchte mit einem 
festgeschriebenen Zins.
Und dieses KI System war darauf 
ausgelegt vorherzusagen,
ob dieser Privatkredit dann
tatsächlich zurückgezahlt wird 
oder nicht,
ob ein Ausfall dieses Kredits 
auftreten wird oder nicht.
Das System war eigentlich auch 
ziemlich gut.
Es hat irgendwie so 74 % 
Accuracy gehabt.
Was für so soziales
Verhalten oder menschliches 
Verhalten vorherzusagen,
schon immer ganz gut ist.
Dann sind wir in die Sparkasse 
rein und haben mit
27 Bankern haben
wir hingesetzt und gesagt Hier 
sind
verschiedene von diesen 
Privatkrediten.
Gebt doch mal bitte deine eigene 
unabhängige Meinung an,
ob dieser Kredit und ich gebe 
dir ein
paar Informationen zu dem 
Privatkredit,
ob der zurückgezahlt wird oder 
nicht.
Würdest du das deinem Kunden?
Du als Mensch ohne KI Hilfe?
Würdest du dem Kunden empfehlen Feedback Loops in Machine Learning 
 
811 
3.2 Previous Empirical Studies 
We buil t our simulations on two secondary datasets, 
collected by several authors of this paper as part of 
different empirical studies. Study A was an incentivized 
field study conducted over three years from 2016 to 
2019. Study A measured participant s’ behavior in the 
investment game  defined above  in their  role as 
borrowers. The data from Study A allow ed us to 
develop an ML model predicting borrowers’ repayment 
decision and serves as the foundation for simulating 
borrower behavior. Study B, conducted in December 
2020, was an incentivized online experiment where 
participants engaged in the outlined investment game in 
the role of investors. In this experiment, investors could 
access an ML model predicting borrowers ’ repayment 
likelihood. Notably, this model, along with the 
borrowers with whom investors from Study B 
interacted, originated from Study A data. The data from 
Study B provide d the basis for simulating investor 
decisions. We present the exact instructions given in 
these studies in Appendix B.1. 
Study A: At the onset of each semester, first -semester 
economics students from a large German university were für wie wahrscheinlich halte ich 
das denn,
dass die das Startup zurückzahlt 
oder nicht,
kann ich theoretisch und
Michael und Ferdinand wären 
stolz.
Das sind meine beiden 
Doktorväter.
Deswegen sage ich es.
Kann ich diese Gleichung hier 
aufschreiben?
Ich kann sagen naja, ich 
investiere,
wenn mein erwarteter Nutzen Und 
ich bin jetzt ganz
allgemein mit Utility wenn die 
der Nutzen davon.
Wenn ich mit einer 
Wahrscheinlichkeit p,
dass zurückgezahlt wird ich bei
15 15 lande dieser Nutzen plus 
der erwartete Nutzen.
Naja, wenn es doch schiefgeht 
und ich bei null und
20 lande gewichtet mit der 
Wahrscheinlichkeit,
wenn das größer oder gleich
ist als naja, mein Nutzen davon,
wenn ich auf jeden Fall 10 
Millionen für mich habe und
das Startup null hat investiere,
wenn der erwartete
Nutzen von hier größer
ist als der sichere Nutzen von 
hier.
Wer sieht das nicht?
Dann habe ich wieder einen 
schlechten Job gemacht.
Klasse. Das ist großartig.
So was kann Machine Learning 
deliverern,
wenn ich mathematisch darüber 
nachdenke.
Naja, Machine Learning ändert 
letztlich eine
Sache an dieser Gleichung.
Hier nämlich,
Und ich habe hier eine falsche 
Zahl eingetragen.
Das ändere ich ab nach der 
Vorlesung.
Vorher haben wir die Gleichung,",7.116198778,0,"The generated answer states the investment amount was 10 million euros, while the ground truth states it was 100â‚¬. The answers are factually contradictory.",0,"The generated answer is not faithful. It claims the investment amount was 10 million Euro. [cite_start]The retrieved context explicitly states that the P2P loans in the experiment were for '100 â‚¬'[cite: 1175]. [cite_start]The 10 million Euro figure comes from a different, hypothetical example about investing in a startup[cite: 1193].",0.1,"The context is irrelevant to the question asked. The context describes an experiment involving P2P loans where the investment amount was 100â‚¬. The question, however, refers to a different part of the text describing a conceptual 'Trust Game' structure with a startup, where the investment amount is 10 million â‚¬."
"According to the document, what did Eric Horvitz advocate in his 1999 paper?",Elegant coupling of automation with direct manipulation by user.,"Laut dem Dokument hat Eric Horvitz den Vorschlag gemacht, dass man über Systeme nachdenken sollte, die automatisiert bestimmte Dinge abnehmen und dann autonom agieren, und er schlug vor, dass man die Entscheidung, ob man in einem ""Automation oder Delegation"" Setting ist, auch an die Maschine abgeben sollte. Er plädierte für ein ""Modelldenken"", das an Universitäten vermittelt werden sollte.","wissenschaftliches Papier 
zurück,
nämlich Anfang der 
Zweitausenderjahre.
Weiß jemand, wer das ist? Hier. 
Mal von ihm gehört?
Es ist der Chief Scientific 
Officer von Microsoft.
Der,
der für sehr viele
wissenschaftliche 
Strategieentscheidungen
letztlich verantwortlich ist.
Da. Der hat nämlich damals genau 
das gesagt,
diese ganze Diskussion zwischen 
entweder
automatisieren oder wir bleiben
im Decision Support.
Das sollten wir gar nicht so
als entweder oder betrachten,
sondern wir sollten es aus einer 
Perspektive betrachten,
dass wir vielleicht Systeme 
haben,
die uns Automatisiert von selbst 
bestimmte
Dinge abnehmen und dann autonom 
agieren.
Und für andere Dinge sollten Sie 
uns vielleicht fragen.
Das heißt, wir geben eigentlich 
die Entscheidung,
ob wir im Automation oder 
Delegation,
im Automation oder Augmentation 
Setting sind,
auch an die Maschine ab.
Und er hat dann sehr intuitives,
sehr intuitiven, konzeptionellen 
Vorschlag gemacht,
wie wir darüber nachdenken 
können.
Das ist jetzt auch wieder das 
Modelldenken,
was ich glaube sehr wichtig ist 
an Universitäten.
Gelernt werden sollte,
dass sie ein grundlegendes 
Schubladendenken haben,
wie sie über solche Probleme 
nachdenken können,
ohne dass wir jetzt keine betriebswirtschaftlich
ökonomische Entscheidungen zu 
treffen.
Wer sieht das nicht?
Noch mal, was ich letztes Mal 
gesagt habe Wenn Sie
was nicht verstehen, ist es 
nicht Ihre Schuld.
Dann habe ich es einfach 
schlecht erklärt.
Deswegen immer raus damit.
Dann gehe ich davon aus, dass 
jeder verstanden hat.
Aber eine andere Frage haben
wir ja theoretisch auch
noch andere 
Entscheidungsmöglichkeiten,
Parametern, die dieselbe 
Qualität liefern.
Vollkommen richtig. Da wäre 
jetzt die Frage,
ob es eine 
Entscheidungsmöglichkeit,
die zwei Parameter verwendet,
besser als eine auf einem 
Papier.
Das ist sehr, sehr gute Frage.
Da gibt es verschiedene Theorien 
zu.
Grundsätzlich, wie wir sehen 
werden,
für den technischen Teil der 
Vorlesung.
Wir können für das gleiche
Problem verschiedene Regeln 
identifizieren.
Verschiedene Machine Learning 
Modelle trainieren.
Diese Machine Learning Modelle 
können bessere oder
schlechtere Performance 
aufweisen.
Wenn sie aber genau die gleiche 
Performance aufweisen,
dann haben wir natürlich in 
einer gewissen Art und
Weise die Wahl, immer darauf 
achtend,
dass die einzige Performance, 
die wir sehen,
aktuell immer Performance auf 
historischen Daten ist.
Das heißt, wir müssen auf der ein Beispiel,
wo sie nur verlieren können,
weil sie werden keine Regel 
finden.
Und ich habe es durchexerziert,
wo Sie etwas finden,
was alle Observationen erklären 
kann.
Was ist die Idee? Naja, das sind 
historische Daten.
Es wurde vollkommen richtig 
gesagt.
Das ist eine gute Regel, Nämlich 
in vier von fünf.
In fünf von sechs Fällen haben 
wir eigentlich.
Mit Milt und No haben wir eine 
sehr gute Prediction.
Aber manchmal eben auch nicht.
Was bedeutet das für uns?
Es gibt in Daten ganz wichtig,
immer daran zu denken bestimmte 
zufällige Fluktuation.
Es kann zum Beispiel sein,
dass sich hier, wo wir 
festgestellt haben,
unsere Regel wäre falsch bei Hot 
und no.
Vielleicht habe ich an dem Tag 
einfach
zu wenig, zu zu viel.
So habe ich es formuliert,
zu viel angehabt und mir kam es 
wärmer vor, als es war.
Eigentlich war die Temperatur 
mild
und es war nicht windig
und dann wäre es wieder richtig 
gewesen.
Aber meine eigene zufällige 
Wahrnehmung
an diesem Tag führt dazu,
dass ich Daten falsch 
aufgeschrieben habe.
Daten per se sind immer neu.
Sie ist immer sehr viel.
Verschiedene Faktoren, die dazu 
führen können,
dass Daten zum Beispiel
nicht perfekt aufgeschrieben 
werden,
dass Daten subjektiv gemessen 
werden.",10.29387522,1,"The generated answer is semantically consistent with the ground truth. Both capture the core idea proposed by Horvitz: a blended or coupled approach between automation and direct user control, rather than a strict binary choice.",1,"The generated answer is faithful. The context states that Eric Horvitz in the early 2000s suggested that 'wir sollten es aus einer Perspektive betrachten, dass wir vielleicht Systeme haben, die uns Automatisiert von selbst bestimmte Dinge abnehmen und dann autonom agieren. Und fÃ¼r andere Dinge sollten Sie uns vielleicht fragen.' (we should view it from a perspective that we might have systems that automatically take over certain things and act autonomously. And for other things, they should perhaps ask us.) [cite_start][cite: 1202, 1203]. This aligns with the idea of coupling automation with user manipulation.",0.8,"The context is highly relevant. It attributes the idea of mixed initiative to the Chief Scientific Officer of Microsoft, who in the early 2000s argued against a simple either/or view of automation vs. decision support. He suggested systems that can 'Automatisiert von selbst bestimmte Dinge abnehmen und dann autonom agieren' (automatically take over certain things and then act autonomously) while asking the user for input on other things. This aligns well with the idea of 'elegant coupling of automation with direct manipulation'."
What is augmentation in the context of human-AI collaboration?,AI serves as a decision support tool; human always makes final decision.,"Basierend auf dem bereitgestellten Text ist Augmentation im Kontext der Mensch-KI-Zusammenarbeit die Idee, dass Mensch und Maschine auf eine Weise zusammenarbeiten, in der die Leistung des kollaborativen Systems besser ist als die Leistung der einzelnen Komponenten. Es geht darum, die Stärken des Menschen (wie schnelles, affektives Entscheiden) mit den Fähigkeiten der Maschine zu kombinieren, um ein optimales Ergebnis zu erzielen.","Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. Informationen
verarbeiten und wie welche
Probleme hier eine Rolle spielen 
könnten in Bezug auf
die richtige Gewichtung Ihrer 
eigenen Expertise
und der von der Maschine,
welche Signal Sie bekommen.
Das ist das, womit wir uns heute 
befassen.
Ja. Und wenn es
jetzt um sowas geht wie 
Stellenbesetzung
in der Personalabteilung,
ist das ja verständlich.
Ja, was ist mit Sektoren,
in denen man sich so schnell,
in denen so schnell
Entscheidungen getroffen werden 
müssen,
dass das überhaupt möglich ist?
Sprechen wir auch drüber.
Es gibt nämlich zwei Arten
von Mensch Maschine 
Kollaboration.
Wenn man so grob einteilt auf 
der einen Seite die
Idee von 
Entscheidungsunterstützung und 
auf
der anderen Seite die Idee von
Entscheidungsautomatisierung.
Aber auch bei der 
Entscheidungsautomatisierung.
Das Konzept von Human in the 
Loop ist,
dass der Mensch entscheidet 
Welche Entscheidungen
lagere ich denn überhaupt an die 
Maschine aus?
Das heißt, hier geht es dann 
eben um diesen
Unterschied von Humans in
the loop dahingehend Sie 
entscheiden,
Ich transferiere 
Entscheidungsgewalt in diesen
automatisierten Fällen oder Sie 
behalten immer
die Entscheidungsgewalt,
müssen sich aber entscheiden Wie
viel Gewicht geben Sie 
eigentlich? geben,
was Entscheidungsparameter 
angeht.
Macht Sinn. Gut, ein Konzept,
was ich auch durch meine eigene 
Forschung
in unbedingt nahe legen möchte,
ist die Idee von Mensch 
Maschine.
Komplementaritäten bedeutet Was 
wir
erreichen wollen ist eigentlich 
ein Setting,
wo Mensch und Maschine auf eine
Art und Weise zusammenarbeiten,
dass die Performance dieses
kollaborativen Systems besser 
ist als
die Performance der einzelnen 
Komponenten.
Und das kann natürlich
aus verschiedenen Gründen 
entspringen.
Diese komplementären Stärken.
Haben Sie eine Idee, was so die 
zwei Faktoren sind,
warum Menschen und Maschinen 
sich ergänzen und
warum nicht die Maschine immer 
besser
ist und nicht der Mensch immer 
besser ist?
Auf einem sehr high Level ja,
vielleicht auch mit dem 
Zusammenspiel der
zwei Systeme mit dem eins und 
zwei.
Interessante Perspektive.
Kann man so interpretieren,
dass die Maschine eher System 
zwei ist
und der Mensch sehr schnell 
heuristisch
affektiv entscheidet.
Ja, geht in einen der beiden 
Punkte,
die ich zusammenfassen möchte, 
mit ein Ja.
Ja. Ja, würde ich jetzt als ein
anderes Thema noch mal 
betrachten.
Moralität.
Wir sprechen jetzt hier wirklich 
um
Ergänzung von Fähigkeiten.
Erstmal die einbringen,",9.848335266,1,"The generated answer is semantically consistent with the ground truth. Both correctly define augmentation as a scenario where AI serves as a decision support tool, but the human makes the final decision.",1,"The generated answer is faithful. [cite_start]The context describes 'EntscheidungsunterstÃ¼tzung' (decision support) as one of two modes of human-machine collaboration[cite: 1236], where the human makes the final decision. [cite_start]The concept of 'KomplementaritÃ¤ten' is also introduced, aiming for a collaborative system that is better than its individual components[cite: 1240].",1,"The context directly answers the question. It describes two types of human-machine collaboration: 'EntscheidungsunterstÃ¼tzung' (decision support), where the human makes the final decision, and 'Entscheidungsautomatisierung' (decision automation). Augmentation is presented as another term for decision support."
What is the mean of the prediction change when considering coalitions of features?,Δ=−0.1,"Der Mittelwert der Vorhersageänderung, wenn Koalitionen von Merkmalen berücksichtigt werden, beträgt Δ=−0.1.","Also Daten sammeln über die 
letzten
Jahre deskriptive Analysen 
machen,
verstehen, was eigentlich im 
Unternehmen vor sich geht.
Aber darauf aufbauend gehen wir 
jetzt weg,
nämlich hin zu diesen 
prädiktiven Analysen,
wo wir Vorhersagen in die 
Zukunft heraus machen.
0.1 Oder Vorhersagen über Dinge,
die wir einfach nicht wissen 
aktuell.
Erinnern Sie sich mal dran Es 
geht nicht nur
rein um Zukunft.
Ja, das ist immer so ein 
bisschen vereinfacht gesagt.
Aber es geht auch darum, Sachen 
vorherzusagen,
wo ich noch nicht diese 
Information habe,
auch wenn sie theoretisch 
existiert.
Denken Sie daran, wenn Sie zum 
Arzt
gehen und der Arzt eine 
Vorhersage
über Ihre Krankheit macht,
haben Sie die Grippe oder nicht?
Haben Sie oder nicht?
In dem Moment, wo Sie zum Arzt 
gehen,
haben Sie kopiert oder nicht,
aber Sie haben die Informationen 
einfach
noch nicht im Vergleich.
Wenn wir über Aktienmärkte 
sprechen,
wenn ich den Aktienpreis morgen 
wissen möchte,
realisiert sich der Aktienpreis
morgen natürlich heute nicht 
mehr.
Und das können wir wieder 
runterbrechen
in drei verschiedene Bereiche,
wo uns diese prädiktiven 
Analysen helfen können.
Wenn Sie sich erinnern an die 
Case Study,
die wir zum Abschluss der 22. Mai 2025
Marginal contributions across coalitionsIdea:•Remove feature across all possible coalitions and compute changes in predictions•Compute a feature’s importance by marginalizing over all its contributionsSimplified example for “savings”:
21
Coalition of 3 features
Δ=−0.07
Coalitions of 2 features
Δ=−0.3
Δ=−0.02
Coalition of 1 feature
Δ=−0.01
Mean: Δ=−0.1
What is the prediction of no feature is present? availability of this data point for future model updates and potentially affecting the model ’s 
performance. This paper delves into the relationship between the continuous updating of ML models 
and algorithmic discrimination in environments where predictions endogenously influence the 
creation of new training data. Using comprehensive simulations based on secondary empirical data, 
we examine the dynamic evolution of an ML model ’s fairness and economic consequences in a 
setting that mirrors sequential interactions, such as loan approval decisions. Our findings indicate 
that continuous updating can help mitigat e algorithmic discrimination and enhance economic 
efficiency over time. Importantly, we provide evidence that human decision makers in the loop who 
possess the authority to override ML predictions may impede the self -correction of discriminatory 
models and even induce initially unbiased models to become discriminatory with time. These 
findings underscore the complex sociotechnological nature of algori thmic discrimination and 
highlight the role that humans play in addressing it when ML models undergo continuous updating.",6.098098278,1,The generated answer is semantically consistent with the ground truth. Both correctly state the mean of the prediction change is -0.1.,1,"The generated answer is faithful. The context shows a diagram with a simplified example for the feature 'savings', illustrating how the change in prediction (Î”) is calculated for different coalitions of features. [cite_start]The final line of the example explicitly states 'Mean: Î”=âˆ’0.1'[cite: 1257].",1,"The context directly answers the question. An image in the context shows a simplified example of calculating a feature's importance by looking at the change (Î”) in prediction across different feature coalitions. At the end of the example, it explicitly states 'Mean: Î”=âˆ’0.1'."
"According to the document, what is interpretability?",The ability to explain or provide the meaning in understandable terms to humans.,"Das Dokument enthält keine direkte Definition von ""Interpretierbarkeit"". Allerdings wird der Begriff in Bezug auf die Interaktion zwischen Mensch und Maschine und die Bewertung von Nutzen (Expected Utility) erwähnt. Es geht darum, wie die Vorhersagen einer Maschine (die ""Uhr"") die subjektive Einschätzung und die Bewertung von Wahrscheinlichkeiten eines Individuums beeinflussen. Die Fähigkeit, diese Interaktion zu verstehen und zu steuern, ist ein zentrales Thema.","obwohl die Leute wissen, die 
Maschine ist gut.
Das Signal unsere Prediction,
die ist wertvoll,
die sollte ich in meine 
Überlegungen mit einbeziehen.
Die ignorieren das einfach.
Riesen Phänomen.
Sehr gutes Thema für eine 
Bachelorarbeit.
Ach nee, ich wollte 
weitermachen.
Sorry. Nach der Vorlesung.
Ja, ich muss ein bisschen auf 
die Zeit achten.
Hier. Worauf ich hinaus wollte 
mit der Darstellung,
dass sich unser PC verändert,
aber nicht unser OO.
Also Sie haben weiterhin diese 
Bewertung.
Womit ich darauf hinaus möchte, 
ist die Tatsache,
dass weiterhin Platz für Sie als 
Mensch besteht.
Die Maschine gibt Ihnen
eine Vorhersage und diese 
Vorhersage
verändert Ihre subjektive
Einschätzung über die 
Wahrscheinlichkeit,
Aber sie verändert nicht,
dass sie weiterhin eigentlich 
für sich bestimmen müssen.
Wie gut finde ich denn 
eigentlich,
dass ich 15 Kriege
in diesem Fall und das 
Unternehmen 15 kriegt?
Oder dass ich zehn kriege
und das Unternehmen null kriegt?
Sie können ja zum Beispiel 
jemand sein,
der sagt Naja, mir ist es super,
super wichtig,
dass ich den Gesamtkuchen, die 
Effizienz maximiere.
Das heißt, wenn wir beide 15 
haben,
ist das relativ für sie besser 
als
in diesem Beispiel hier null und 
20. macht
die uhr die Aktion nicht.
Ich möchte eigentlich, dass es 
aufgenommen wird,
aber die uhr nimmt es nicht auf.
Und ich habe einen Nutzen,
wenn die uhr es aufnimmt und ich 
es
tatsächlich machen möchte und
jetzt von mir simplifiziert.
Für Sie kann ich natürlich hier 
einfach
diese Punkte verbinden und sagen 
naja, der Nutzen,
den ich habe von der Aktion ah,
wenn ich es nicht möchte und der 
Nutzen von der Funktion,
von der Aktion ah, wenn ich es 
eigentlich möchte,
hängt irgendwie zusammen mit der 
Wahrscheinlichkeit.
Das hier ist mein ExPected 
Utility davon.
Und genau das gleiche kann ich 
machen hier für wenn ich
etwas eigentlich nicht möchte 
meine in Aktion.
Die uhr macht etwas
nicht und ich möchte das auch 
nicht und
die uhr macht etwas nicht.
Und ich möchte das eigentlich,
wenn ich einfach diese beiden 
Endpunkte auf den
Extremen der 
Wahrscheinlichkeitsverteilung
miteinander verbinde.
Hier für Sie einfach mit einer 
linearen Funktion,
wie sie alle Mikroökonomie bei 
Uwe Walz
oder Matthias Blonski, je 
nachdem.
Dann kriege ich hier so zwei 
Funktionen,
die haben einen Schnittpunkt.
Und jetzt Mikro eins Was haben 
wir in dem Schnittpunkt?
Wir haben irgendwie eine linke 
Seite vom Schnittpunkt. implications and potential remedies. The 
British Journal of Radiology, 96(1150), Article 
20220878. 
Schelter, S., & Stoyanovich, J. (2020). Taming 
technical bias in machine learning pipelines. 
Bulletin of the Technical Committee on Data 
Engineering, 43(4), 39-50.  
Scherr, A. (2008). Diskriminierung: eine eigenständige 
Kategorie für die soziologische Analyse der (Re-) 
Produktion sozialer Ungleichheiten in der 
Einwanderungsgesellschaft? In K.-S. Rehberg 
(Ed.), Die Natur der Gesellschaft: Verhandlungen 
des 33. Kongresses der Deutschen Gesellschaft 
für Soziologie in Kassel 2006. (Vol. 1, pp. 2007-
2017). Campus.  
Schmid, T. (2021). Batch-like online learning for more 
robust hybrid artificial intelligence : 
Deconstruction as a machine learning process . 
Proceedings of the AAAI Spring Symposium: 
Combining Machine Learning with Knowledge 
Engineering.  
Shaikh, M., & Vaast, E. (2022). Algorithmic 
Interactions in Open Source Work. Information 
Systems Research, 34(2), 744-765. 
Shrestha, Y. R., Ben-Menahem, S. M., & Von Krogh, 
G. (2019). Organizational decision -making 
structures in the age of artificial intelligence. 
California Management Review, 61(4), 66-83.  
Shrestha, Y. R., & Yang, Y. (2019). Fairness in",9.947234631,1,The generated answer is semantically consistent with the ground truth. Both correctly define interpretability as the ability to explain something in understandable terms to a human.,0,The generated answer is not faithful. It provides a definition of interpretability that is not present in the retrieved context. [cite_start]The context discusses how a machine's prediction can change a human's subjective probability assessment ('verÃ¤ndert Ihre subjektive EinschÃ¤tzung Ã¼ber die Wahrscheinlichkeit') [cite: 1271] but does not define the term 'interpretability'.,0.2,"The context discusses the general concept of interpretability in the context of human-machine interaction, explaining how a machine's prediction can alter a human's subjective probability assessment. However, it does not provide a formal definition of interpretability as 'the ability to explain or provide the meaning in understandable terms to humans.'"
What does the EU AI Act Art 86 demand?,Right to Explanation of Individual Decision-Making.,"Artikel 86 der EU AI-Verordnung verlangt, dass jede Person, die von einer Entscheidung betroffen ist, die von einem Betreiber aufgrund der Ausgabe eines Hochrisiko-KI-Systems (aufgeführt in Anhang III) getroffen wurde und die Rechtsfolgen hat oder diese Person in einer Weise erheblich beeinflusst, die sie als nachteilig für ihre Gesundheit, Sicherheit oder Grundrechte ansieht, das Recht hat, vom Betreiber klare und aussagekräftige Erklärungen über die Rolle des KI-Systems im Entscheidungsprozess und die Hauptmerkmale der getroffenen Entscheidung zu erhalten.","22. Mai 2025
EU AI act
10 ethics, and responsibility in AI (Zuiderveen Borgesius,2020). The
Organization for Economic Cooperation and Development
(OECD) has provided recommendations on AI, while the
European Commission has drafted proposals regarding
the inﬂuence of algorithmic systems on human rights. In 2019,
the European Commission established a high-level expert group
on AI, which proposed ethical guidelines and self-regulatory
measures regarding AI and ethics.
Public organizations have played a role in establishing
mechanisms to safeguard algorithmic fairness. The Algorithm
Justice League (AJL) has outlined vital behaviors companies
should follow in a signable agreement. Holding accountable those
who design and deploy algorithms improves existing algorithms
in practice (36KE,2020). After evaluating IBM’s algorithm, AJL
provided feedback, and IBM responded promptly, stating that
they would address the identi ﬁed issue. As a result, IBM
signiﬁcantly improved the accuracy of its algorithm in minority
facial identiﬁcation.
Data protection and non-discrimination laws safeguard against
discriminatory practices in algorithmic decision-making. In the
EU region, Article 14 of the European Convention on Human 22. Mai 2025
Regulatory problem!
General Data Protection Regulation (GDPR) in the EU demands “transparent [data] processing” and a “right to explanation” EU AI Act Art 86: Right to Explanation of Individual Decision-Making“Any affected person subject to a decision which is taken by the deployer on the basis of the output from a high-risk AI system listed in Annex III, […] produces legal effects or similarly significantly affects that person in a way that they consider to have an adverse impact on their health, safety or fundamental rights shall have the right to obtain from the deployer clear and meaningful explanations of the role of the AI systemin the decision-making procedure and the main elements of the decision taken.”
9",10.74445105,1,The generated answer is semantically consistent with the ground truth. Both correctly state that Article 86 of the EU AI Act demands a 'Right to Explanation of Individual Decision-Making'.,1,The generated answer is faithful. [cite_start]The context explicitly states in the title of a slide: 'EU AI Act Art 86: Right to Explanation of Individual Decision-Making'[cite: 1305].,1,"The context directly answers the question. A slide titled 'EU AI act' contains Article 86, which is explicitly named 'Right to Explanation of Individual Decision-Making'."
What is a 'selective labels problem'?,It occurs when a machine learning model's prediction influences decisions that prevent the collection of data needed to evaluate the model's accuracy.,"According to the text, the ""selective labels problem"" arises when a system (like a machine learning model) tries to create its own labels. Here’s a breakdown of how it’s described:

*   **Self-Supervised Learning:** The system “sucht sich das als Label aus” – it essentially chooses its own labels based on the other words in the data.
*   **Error Accumulation:** If the system makes errors in its initial predictions and creates “noisy” labels, these errors can accumulate over time. This creates a “Compounding Effekt,” where the machine learns and reinforces those initial mistakes.

In essence, the problem is that the system’s self-generated labels aren’t necessarily accurate, and this inaccuracy can lead to a snowball effect of further errors.","die nicht zugedeckt sind aus dem 
Satz
und ich habe mir das als Label 
auserkoren.
Und ich versuche selber 
vorherzusagen,
basierend alle anderen Wörter,
was eigentlich das zugedeckte 
Wort ist.
Das nennt man self supervised 
learning.
Wann immer ich kein eigenes 
direktes Label habe,
bin ich eigentlich in
einem Bereich von sogenannten 
Supervised Learning
und supervised geht so
ein bisschen zwischen 
Supervising and sbeweis,
Supervisory Labels haben und 
dann zu beweisen,
dass sie keine haben und nur 
Strukturen erkennen möchten.
Und self supervised ist dann 
sozusagen die Mitte,
wo das System selber sagt
Ich suche mir das als Label aus 
und nehme alles andere,
um das Ausgesuchte 
vorherzusagen.
Geht in die Richtung.
Per se ist es natürlich 
problematisch,
weil wir, wenn die Maschinen 
Fehler machen,
in dem Labeling verfahren
und in diesem selbst zu 
beweisen,
die Fehler relativ gering,
weil es eben was technisches 
ist.
Wenn ich aber selber eine 
Vorhersage mache,
wie ich etwas labeln möchte und 
da Fehler drin sind,
dann lernt die Maschine,
die trainiert wird, letztlich 
neue
Fehler und dann akkumulieren
sich diese Fehler und wir reden
von einem Compounding Effekt.
Das heißt so mehr noisy
einfügen und da kann man drüber ** p < 0.05, *** p < 0.01 denote statistical significance levels. 
The Role of Ongoing Human Discrimination: Figures 
Plots for Male Borrowers 
 
Note: We illustrate how the mean share of positive predictions for male borrowers in Iterations 1 and 100 depends on the initial label imbalance 
in the training data and the degree of human discrimination by the investor. A comparison of panels for Iterations 1 and 100 for the two measures 
of algorithmic discrimination provides insights into their conditional development across iterations. Abbreviations: Share pos. predictions =  
share of positive predictions; Init. lab. imb. = initial label imbalance; Human discr. = human discrimination. 
Figure A7. Development of the Mean Share of Positive Predictions by Initial Label Imbalance  
and Degree of Human Discrimination case the borrower is male. A comparison of panels for Iterations 1 and 100 for the two measures of algorithmic discrimination provides insights 
into their conditional development across iterations. Abbreviations: Outcome under perf. inf. = outcome under perfect information; Init. lab. imb. 
= initial label imbalance; Human discr. = human discrimination. 
Figure A9. Development of the Mean Share of Game Outcomes by Initial Label Imbalance  
and Degree of Human Discrimination",13.35245395,1,The generated answer is semantically consistent with the ground truth. Both correctly describe the selective labels problem as occurring when a model's own predictions influence decisions that then prevent the collection of accurate ground truth data for evaluation.,0,"The generated answer is not faithful. It describes a 'selective labels problem' where a model's prediction influences decisions that prevent data collection. [cite_start]The retrieved context describes a different concept called 'self supervised learning', where a system creates its own labels from the data, which can lead to a 'Compounding Effekt' of errors if the initial self-generated labels are noisy[cite: 1311, 1313, 1315]. The context does not mention preventing data collection.",0.8,"The context is highly relevant. It explains 'self supervised learning' where a model creates its own labels from the data. It then describes the problem that if the machine makes errors in this self-labeling, these errors accumulate ('akkumulieren sich diese Fehler') in a 'Compounding Effekt'. This aligns with the definition of the selective labels problem, where the model's own actions (predictions/labeling) prevent the collection of accurate ground truth data."
"According to the text, what is one way to control for gender when analyzing a dataset?","By running the dataset through without including gender, but then rerunning it while including gender to compare performance.","Basierend auf dem bereitgestellten Kontext gibt es mehrere Möglichkeiten, um Gender-bedingte Verzerrungen bei der Analyse eines Datensatzes zu kontrollieren:

1.  **Auslassung von Gender-Informationen (wie im Amazon-Beispiel):** Das System hat Gender-Informationen (Geschlechtsidentifikation) aus dem Datensatz entfernt, obwohl sie vorhanden waren. Dies ermöglichte es der Maschine, Vorhersagen basierend auf allen anderen Merkmalen zu treffen, ohne von Gender beeinflusst zu werden.

2.  **Systematische Tests mit Vergleich von Genauigkeit:** Es wurde empfohlen, die Vorhersagegenauigkeit für Männer und Frauen bei gleichen Qualifikationen systematisch zu testen. Dies ermöglichte es, festzustellen, ob Frauen systematisch schlechtere Ergebnisse erzielten.

3.  **Berücksichtigung von unrepräsentativen oder unausgewogenen Daten:** Der Datensatz kann unrepräsentativ sein, was bedeutet, dass bestimmte Gruppen (z.B. Frauen) unterrepräsentiert sind. Dies kann zu Fehlvorhersagen führen.

4.  **Berücksichtigung technischer Einschränkungen und Praktiken:** Bias kann auch durch technische Einschränkungen oder Fehler bei der Entwicklung und dem Training des Modells entstehen.

Es ist wichtig zu beachten, dass das Auslassen von Gender-Informationen ein strategischer Ansatz ist, um implizite Diskriminierung zu vermeiden, die durch die Fähigkeit der Maschine, Korrelationen zwischen Gender und anderen Merkmalen zu lernen, entstehen könnte.","Datensatz,
in dem man alles angibt,
außer das Geschlecht und lässt 
das durchlaufen.
Aber hierbei würden sie Gender 
mit rein nehmen.
Also in einem ersten Schritt,
um das zu kontrollieren.
Genau in diesem Beispiel von dem 
Amazon,
das haben Sie schon richtig 
erfasst,
war es so die haben Gender 
rausgelassen,
hatten aber eine Spalte im 
Datensatz,
wo Gender noch drin war,
haben die Maschine dann
basierend auf allen Features 
außer Gender die
Vorhersage machen lassen und 
konnten dann natürlich
innerhalb ihrer Daten trotzdem 
vergleichen.
Wie ist die Performance dort in 
den Einträgen,
wo wir Männer,
Frauen nonbinär hatten und haben 
das dann verglichen?
Praktisch ja.
Aber es gibt viele Argumente 
dafür,
dass wir diese Features, die 
protected sind,
dass wir eigentlich größere 
Probleme erzeugen,
wenn wir sie den Maschinen nicht 
zur Verfügung stellen,
weil diese Maschinen so mächtig 
sind,
Korrelationen herauszufinden,
die letztlich ablesen lassen,
ob es welches Geschlecht es ist 
und das implizit lernen.
Und das ist sehr, sehr, sehr 
versteckt ist,
wo eigentlich jetzt eine 
Diskriminierung herkommt.
Wenn wir es aber drin lassen,
gibt es bestimmte Methoden, das 
direkt abzulesen.
Aber die Frage was will man denn 
da, data (Friedman & Nissenbaum, 1996; Romei & Ruggieri, 
2013; Kleinberg et al., 2018). For example, if a training 
dataset holds more positively labeled examples for men, 
the ML model may predict positive labels less accurately 
for women. Second, it can be created by unrepresentative, 
or imbalanced data (Barocas & Selbst, 2016; Mehrabi et 
al., 2021). When the dataset underrepresents certain 
groups, such as women, the ML model can make more 
errors when predicting for this group. Imbalances occur 
when labels skew significantly within specific subgroups. 
Third, technical constraints or malpractices during model 
development and training may yield discriminatory 
outputs (Friedman & Nissenbaum, 1996; Williams et al., 
2018). Biases may emerge during data integration due to 
inconsistent data formats or when the integration of 
personal information like ethnicity is mishandled (Schelter 
& Stoyanovich, 2020; Williams et al., 2018). It is critical 
to appreciate the sociotechnological nature of algorithmic 
discrimination (Favaretto et al., 2019; Kordzadeh & 
Ghasemaghaei, 2022). The social component often 
originates from societal and economic structural biases, 
which can foster the differential treatment and gesagt Na ja,
per Gesetz dürfen wir nicht auf 
Gender gucken.
Was also gemacht wurde,
ist man hat die Gendermerkmale,
also die selbst angegebenen 
Geschlecht.
Geschlechtsidentifikation hat 
man rausgenommen.
Es war also nicht Teil des 
Systems.
Trotzdem in diesem Testbereich,
wenn wir in dem Crisp an 
Evaluation denken,
bevor das System wirklich live 
gegangen
ist und massiv eben angefangen 
hat,
die neue Einstellungskriterien 
zu beeinflussen,
haben bestimmte Tests gezeigt.
Naja, obwohl ich nicht angegeben 
habe,
ob diese Person, obwohl das 
Modell nicht in der Lage war,
auf Informationen über die
Geschlechtsidentifikation diese 
Person zuzugreifen,
hat das System systematisch
bei Frauen eine geringere 
Wahrscheinlichkeit ausgespuckt.
Woher kann das kommen? Was 
denken Sie?
Ich habe nicht dem Modell Zugang 
zu dem
eigentlichen 
Genderidentification gegeben
und trotzdem in Tests.
Wenn ich dann gesagt habe, naja,
wie hoch ist denn die 
Vorhersagegenauigkeit für 
Frauen,
wie hoch ist denn für Männer?
Wurde dann gesehen,
dass sie für Frauen systematisch
bei gleichen Qualifikationen
systematisch schlechter war.
Woher kann das kommen,
dass das System das trotzdem 
erkannt hat oder
diesen Bias reproduziert hat,",26.26765275,1,"The generated answer is semantically consistent with the ground truth. Both describe a method where gender is included in the dataset for comparison purposes after an initial run where it was excluded, allowing for a performance check.",1,"The generated answer is faithful. [cite_start]The context describes an example from Amazon where 'Gender rausgelassen' (gender was left out) [cite: 1331][cite_start], but the data was still available in another column to 'vergleichen' (compare) the performance for different genders[cite: 1332]. This matches the description in the generated answer.",1,"The context directly answers the question. It describes the Amazon hiring tool case, where gender was explicitly removed as a feature, but the model still produced biased outcomes. To check this, they compared the model's performance on entries where they knew the gender ('wo wir MÃ¤nner, Frauen nonbinÃ¤r hatten und haben das dann verglichen'). This matches the method described in the answer."
"According to the text, what is one way large language models can exhibit biased tendencies?",They have been optimized to be overly agreeable and to 'say yes to everything.'.,"Laut dem Text können große Sprachmodelle voreingenommene Tendenzen zeigen, weil sie in ihren Trainingsdaten, insbesondere aus Quellen wie Wikipedia, stark linksgerichtet sind. Außerdem können die Personen, die diese Modelle entwickeln, eigene Überzeugungen haben, die sich in den Modellen widerspiegeln.
","sich nichts vormachen
und das ist eine Sache,
das würde ich jetzt per se 
erstmal nicht,
wenn wir über GPT sprechen,
wenn sie es sehen, ist nicht per 
se Bias,
Es ist ein Fehlverhalten.
Es wurde in eine bestimmte 
Richtung
gedrückt durch bestimmte 
Optimierungsverfahren,
Wenn Sie an Medien
und an politische Einstellungen 
denken.
Es gibt sehr viele Evidenzen 
dafür,
dass viele große Sprachmodelle
eher linksgerichtet sind in 
ihren Antworten.
Dass diese Modelle, wenn man zum 
Beispiel die den
Wahl O Mat mit Chat GPT macht,
dann kommt er raus,
dass Chat Gpt die Meinungen der 
Grünen,
der Linken und der SPD 
unterstützt weniger von den
rechtsgerichteten und 
rechtsradikalen Ansichten.
Was können Sie denken, woran das 
liegt?
Es liegt an den Trainingsdaten. 
Schöne Frage.
Erstmal eine Frage beantworten,
dann können Sie eine Frage 
stellen.
Wahrscheinlich, weil die 
Personen, die dahinter stehen,
die das entwickelt haben,
all diese Überzeugungen haben.
Unklar. Tatsächlich könnte ein 
Faktor sein.
Stimme ich zu.
Problem scheint eher zu sein, 
dass viel aus dem Internet.
Wikipedia ist massiv 
linksgerichtet.
Das hat er diese left leaning 
tendencies.
Auch wieder ein historisches 
Wachstum bestimmter
Tendenzen und Ansichten. eine Prediction zu machen, sind 
massiv gering.
Ja, das ist fast ignorierbar.
Außer wenn wir natürlich 
wirklich
über große Sprachmodelle reden,
wo Milliarden von Menschen jeden
Tag riesige Texte da 
reinknallen.
Aber die marginale Beitrag,
dass sie eine Vorhersage machen 
oder
auch die marginale Beitrag von 
einer weiteren Callum,
einem weiteren Wort in
dem Datensatz, ist vollkommen 
ignorierbar.
Das ist wieder die Masse, die es 
letztlich macht.
Ja, und in dem Fall von Demogons 
Razor
sprechen wir nicht davon,
einen Parameter mehr,
sondern tausende von Parametern 
mehr.
Deswegen ist es für unsere
PC's und auch für die 
Entscheidung,
welche Modelle Unternehmen 
einsetzen,
ob sie bei tabularen Daten immer 
an der Stelle gesagt,
ob ich jetzt einen Random Forest 
einsetze
mit 10.000 Bäumen oder ich
nehme einen ein neuronales 
Netzwerk mit 20 Layern.
Der Verbrauch der Energie ist 
für zumindest Predictions
über Kreditwürdigkeit 
ignorierbar unterschiedlich.
Ich kann Sie an entsprechende 
Quellen verlinken.
Dann frage ich mich, wenn ich 
das.
Wenn ich dieses Argument 
beziehe,
auf das Training des Modells,
dann kann ich ja noch nicht 
werten.
Bevor ich es trainiere, kann ich 
nicht vorhersehen,
ob die zusätzlichen Parameter 
wie ein sehr versteckt eigentlich 
bestimmte diskriminierende
Verhalten auftreten können,
weil wir einfach nicht alle 
diese Measures hier benutzen.
Grundsätzlich können wir aber
zwischen zwei verschiedenen 
Arten
dieser Measurements 
unterscheiden.
Auf der einen Seite nehmen wir 
uns
auf dem Individuen individuellen 
Level angucken.
Wenn wir uns nur in einer 
Dimension
unterscheiden und diese 
Dimension protected ist,
dann sollten unsere Vorhersagen 
möglichst ähnlich sein.
Oder wir gucken uns als Gruppen 
an,
das heißt, es kann bei uns
individuell unterschiedlich 
sein.
Wenn sich aber die 
Studierendengruppe verglichen 
mit
den Professorengruppen alles 
identisch wäre,
außer an dieser Eigenschaft,
dann würden wir im Aggregat 
zumindest erwarten,
dass sich im Durchschnitt diese
bestimmte Prediction Performance 
nicht unterscheidet.
Und umso höher ich im Aggregat 
bin,
umso tiefer versteckt kann
natürlich irgendwelche 
diskriminatorischen Muster
immer noch sein und
über spezielle Beispiele jetzt 
mal sprechen.
So müssen Sie immer über 
Diskriminierung in
Algorithmen nachdenken oder über 
Fairness.
Wir haben einen bestimmten 
Outcome,
nämlich unser Y, das unsere 
Underlying Truth,
ob jemand kreditwürdig ist oder 
nicht.",9.161952972,0,"The generated answer claims the bias comes from being 'overly agreeable', while the ground truth states the bias comes from left-leaning training data like Wikipedia. These are completely different reasons.",0,"The generated answer is not faithful. It claims models are overly agreeable and 'say yes to everything'. The retrieved context does not support this. [cite_start]Instead, it states that there is evidence that many large language models are 'eher linksgerichtet' (more left-leaning) in their answers, which is attributed to the training data, such as Wikipedia, having a 'left leaning tendencies'[cite: 1354, 1359].",1,"The context directly answers the question. It states that there is evidence that large language models are 'eher linksgerichtet' (more left-leaning) because the training data, particularly from sources like 'Wikipedia ist massiv linksgerichtet' (Wikipedia is massively left-leaning), contains these tendencies. It does not mention being overly agreeable."
What did Google do to address concerns about the representation of nurses in image search results?,Google filtered the results so that both men and women are shown when 'nurse' is entered.,"Laut dem Text hat Google Filter eingesetzt, um sicherzustellen, dass sowohl Männer als auch Frauen als Krankenschwestern in den Suchergebnissen angezeigt werden. Vor zwei Jahren war die Darstellung jedoch noch stark von weiblichen Krankenschwestern geprägt. Google hat diese Bedenken durch die Anpassung der Filter und die Bereinigung der Daten adressiert.","Das hat Google jetzt anscheinend 
durch Filter so gemacht,
dass wenn man Krankenpfleger 
eingibt,
dass sowohl Männer und Frauen 
gezeigt werden.
Aber bis vor zwei Jahren war
es immer noch ein sehr gutes 
Beispiel.
Wenn ich Sie frage, googeln Sie 
mal bitte nach Images.
Dann war Krankenpfleger zu 99 %
weiblich und Arzt zu 99 % 
männlich,
obwohl diese Bilder natürlich 
von beiden
eigentlich schon vorhanden sein 
sollen.
Das heißt, wir haben hier
irgendwelche gewachsenen 
technischen Grundlagen,
Datenbanken, die das einfach 
noch nicht abbilden können.
Having said that, die 
Unternehmen sind
sehr sensibilisiert durch diese 
ganzen PR Probleme,
die sie damit erlitten haben und 
haben angefangen,
diese Daten zu bereinigen.
Aber das erfordert eben massiv 
viel Investitionen
in Datenbereinigung,
wo wir wieder in dem 
Kriegsmodell,
bei dem Data Preparation sind.
Sie müssen sich klar sein Wie 
sind
Ihre Strukturen der Daten 
eigentlich aufgebaut?
Soweit ich weiß es auch manchmal
das Labeling von Menschen 
gemacht.
Richtig? Genau. Es könnte so 
sein,
dass wir haben eine Gruppe von 
Menschen,
die nicht politisch korrekt 
denken.
Und dann würden sie es bewusst 
falsch.
Richtig. Auch ein massives 
Problem.
Wir haben auf der einen Seite Datensatz,
in dem man alles angibt,
außer das Geschlecht und lässt 
das durchlaufen.
Aber hierbei würden sie Gender 
mit rein nehmen.
Also in einem ersten Schritt,
um das zu kontrollieren.
Genau in diesem Beispiel von dem 
Amazon,
das haben Sie schon richtig 
erfasst,
war es so die haben Gender 
rausgelassen,
hatten aber eine Spalte im 
Datensatz,
wo Gender noch drin war,
haben die Maschine dann
basierend auf allen Features 
außer Gender die
Vorhersage machen lassen und 
konnten dann natürlich
innerhalb ihrer Daten trotzdem 
vergleichen.
Wie ist die Performance dort in 
den Einträgen,
wo wir Männer,
Frauen nonbinär hatten und haben 
das dann verglichen?
Praktisch ja.
Aber es gibt viele Argumente 
dafür,
dass wir diese Features, die 
protected sind,
dass wir eigentlich größere 
Probleme erzeugen,
wenn wir sie den Maschinen nicht 
zur Verfügung stellen,
weil diese Maschinen so mächtig 
sind,
Korrelationen herauszufinden,
die letztlich ablesen lassen,
ob es welches Geschlecht es ist 
und das implizit lernen.
Und das ist sehr, sehr, sehr 
versteckt ist,
wo eigentlich jetzt eine 
Diskriminierung herkommt.
Wenn wir es aber drin lassen,
gibt es bestimmte Methoden, das 
direkt abzulesen.
Aber die Frage was will man denn 
da, new phenomenon that has become prominent over the past 10
years. In deﬁning the “algorithmic and hiring discrimination”
literature, a fairly broad approach was taken based on article
keywords rather than publication sources. Depending on the
focus, keywords related to algorithms and hiring discrimination
were included in the search string. The keyword search algorithm
for this review is as follows. (“artiﬁcial intelligence” and “hiring
discrimination”), ( “algorithms” and “recruitment discrimina-
tion”), (artiﬁcial intelligence” and “recruitment discrimination”),
and (“algorithms”and “hiring discrimination”). SCOPUS, Google
Scholar, and Web of Science are three well-known search engines
frequently used by the academic community and meet the criteria
for technology-related topics in this review. WOS is used as a
starting point for high-quality peer-reviewed scholarly articles.
The study selected these three databases, used search engines, and
maintained ten years. After applying an initial screening related
to titles, keywords, or abstracts, the literature was selected based
on its relevance to the research topic.
The obtained literature was studied in depth to reveal the",9.866739511,1,The generated answer is semantically consistent with the ground truth. Both correctly state that Google applied filters to its image search results to show both men and women for the query 'nurse'.,1,"The generated answer is faithful. [cite_start]The context states that Google used 'Filter so gemacht, dass wenn man Krankenpfleger eingibt, dass sowohl MÃ¤nner und Frauen gezeigt werden' (made filters so that when you enter nurse, both men and women are shown)[cite: 1377].",1,"The context directly answers the question. It states that Google 'hat Google jetzt anscheinend durch Filter so gemacht, dass wenn man Krankenpfleger eingibt, dass sowohl MÃ¤nner und Frauen gezeigt werden' (Google has now apparently used filters so that when you enter 'nurse', both men and women are shown)."
"According to the document, what was the reason Amazon's AI recruitment system discriminated against women?","It recognized correlations between hobbies, universities attended, and gender due to historical data showing fewer women attending certain universities and pursuing technical fields.","Laut dem Text wurde Amazons KI-Recrutierungssystem Frauen diskriminiert, weil es auf überwiegend männlichen Mitarbeitern CVs trainiert wurde.","Datensatz,
in dem man alles angibt,
außer das Geschlecht und lässt 
das durchlaufen.
Aber hierbei würden sie Gender 
mit rein nehmen.
Also in einem ersten Schritt,
um das zu kontrollieren.
Genau in diesem Beispiel von dem 
Amazon,
das haben Sie schon richtig 
erfasst,
war es so die haben Gender 
rausgelassen,
hatten aber eine Spalte im 
Datensatz,
wo Gender noch drin war,
haben die Maschine dann
basierend auf allen Features 
außer Gender die
Vorhersage machen lassen und 
konnten dann natürlich
innerhalb ihrer Daten trotzdem 
vergleichen.
Wie ist die Performance dort in 
den Einträgen,
wo wir Männer,
Frauen nonbinär hatten und haben 
das dann verglichen?
Praktisch ja.
Aber es gibt viele Argumente 
dafür,
dass wir diese Features, die 
protected sind,
dass wir eigentlich größere 
Probleme erzeugen,
wenn wir sie den Maschinen nicht 
zur Verfügung stellen,
weil diese Maschinen so mächtig 
sind,
Korrelationen herauszufinden,
die letztlich ablesen lassen,
ob es welches Geschlecht es ist 
und das implizit lernen.
Und das ist sehr, sehr, sehr 
versteckt ist,
wo eigentlich jetzt eine 
Diskriminierung herkommt.
Wenn wir es aber drin lassen,
gibt es bestimmte Methoden, das 
direkt abzulesen.
Aber die Frage was will man denn 
da, The impact of gender stereotypes on AI hiring poses genuine
risks (Beneduce,2020). In 2014, Amazon developed an ML-based
hiring tool, but it exhibited gender bias. The system did not
classify candidates neutrally for gender (Miasato and Silva,2019).
The bias stemmed from training the AI system on predominantly
male employees ’ CVs (Beneduce, 2020). Accordingly, the
recruitment algorithm perceived this biased model as indicative
of success, resulting in discrimination against female applicants
(Langenkamp et al. 2019). The algorithm even downgraded
applicants with keywords such as “female” (Faragher, 2019).
These ﬁndings compelled Amazon to withdraw the tool and
develop a new unbiased algorithm. However, this discrimination
was inadvertent, revealing theﬂaws inherent in algorithmic bias
that perpetuates existing gender inequalities and social biases
(O’neil, 2016).
Race. Microsoft’s chatbot Tay learned to produce sexist and racist
remarks on Twitter. By interacting with users on the platform,
Tay absorbed the natural form of human language, using human
tweets as its training data. Unfortunately, the innocent chatbot
quickly adopted hate speech targeting women and black indivi- REVIEW ARTICLE
Ethics and discrimination in artiﬁcial intelligence-
enabled recruitment practices
Zhisheng Chen 1✉
This study aims to address the research gap on algorithmic discrimination caused by AI-
enabled recruitment and explore technical and managerial solutions. The primary research
approach used is a literature review. Theﬁndings suggest that AI-enabled recruitment has
the potential to enhance recruitment quality, increase efﬁciency, and reduce transactional
work. However, algorithmic bias results in discriminatory hiring practices based on gender,
race, color, and personality traits. The study indicates that algorithmic bias stems from
limited raw data sets and biased algorithm designers. To mitigate this issue, it is recom-
mended to implement technical measures, such as unbiased dataset frameworks and
improved algorithmic transparency, as well as management measures like internal corporate
ethical governance and external oversight. Employing Grounded Theory, the study conducted
survey analysis to collectﬁrsthand data on respondents’ experiences and perceptions of AI-
driven recruitment applications and discrimination.
Introduction
T",6.963814735,0,"The generated answer claims the discrimination was due to recognizing correlations between hobbies and universities. The ground truth states the reason was that the AI was trained on a dataset of predominantly male employees' CVs. While these may be related, they are different levels of explanation, and the generation's claim is not what the ground truth states.",1,"The generated answer is faithful. [cite_start]The context describes an AI hiring tool from Amazon that 'exhibited gender bias' [cite: 1406] [cite_start]because it was trained on 'predominantly male employeesâ€™ CVs' [cite: 1408][cite_start], which the algorithm perceived as 'indicative of success, resulting in discrimination against female applicants'[cite: 1409].",0.8,"The context is highly relevant as it describes the Amazon AI recruitment tool case. While it does not mention hobbies or universities specifically, it does state that the bias stemmed from the AI system being trained 'on predominantly male employeesâ€™ CVs', which led the algorithm to perceive the male-dominated model as indicative of success, thereby discriminating against female applicants. This is the core reason for the discrimination."
"According to the lecture, what is the CRISP-DM model and what is its first and most important step?","The CRISP-DM (Cross-Industry Standard Process for Data Mining) is a blueprint for developing machine learning applications. Its first and most important step is Business Understanding, which involves clearly defining the business problem you are trying to solve.","Laut der Vorlesung ist das CRISP-DM-Modell ein Standardansatz für Data Mining-Projekte. Es besteht aus sechs Phasen:

1.  Business Understanding
2.  Data Understanding
3.  Data Preparation
4.  Modeling
5.  Evaluation
6.  Deployment

Der erste und wichtigste Schritt ist **Business Understanding**.","Sie sind ein Machine Learning 
Modell.
Kommen wir jetzt zur heutigen 
Vorlesung.
Immer mit diesem Gedanken im 
Kopf.
Wir haben Inputdaten, wir haben
ein Modell und dieses Modell
macht auf den Inputdaten 
letztlich uns eine Vorhersage,
die möglichst präzise ist für 
Daten,
die Sie noch nicht gesehen 
haben.
Fangen wir jetzt wirklich an,
in diesem Teil eins rein zu 
gehen, um zu verstehen,
was können diese Modelle
eigentlich liefern aus einer 
ökonomischen,
betriebswirtschaftlichen, 
gesellschaftlichen Perspektive?
Wir werden jetzt in den ersten
Vorlesungen und es wird so
bis zur fünften Vorlesung gehen.
Da werden wir langsam anfangen,
auch in den zweiten Teil 
überzugehen.
Aber zunächst mal interessiert 
uns gar nicht,
wie wir auf dieses Modell 
kommen,
was dieses Modell genau ist.
Wir werden erstmal annehmen,
da ist irgendein Modell,
das fällt sozusagen vom Himmel.
Und was macht dieses Modell mit 
uns?
Was macht dieses Modell mit 
Organisationen?
Was macht dieses Modell mit 
Personen?
Was macht dieses Modell mit der 
Gesellschaft?
Und um so ein bisschen
eine Hands on Vorstellung zu 
haben,
was Machine Learning Modelle 
machen,
habe ich hier mal ein Beispiel 
mitgebracht,
wo wir jetzt als Gruppe Machine 
Learning Modell spielen. 15. Mai 2025
Overview CRISP-DM
9 15. Mai 2025
Structuring an AI project: CRISP-DM 
6
1. Business Understanding2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment
Data 
Cross Industry Standard Process for Data Mining",9.06611681,1,The generated answer is semantically consistent with the ground truth. Both correctly identify CRISP-DM and state that its first and most important step is Business Understanding.,1,"The generated answer is faithful. [cite_start]The context explicitly states that the first step of the CRISP-DM model, a blueprint for AI projects, is 'Business Understanding' [cite: 1434][cite_start], which involves understanding the business problem to be solved[cite: 1422].",1,"The context provides a direct answer. It introduces the CRISP-DM model as a way to structure AI projects ('Struktur von solchen Projekten') and immediately details the first step, 'Business Understanding,' emphasizing the need to 'uns das Business Problem klar zu machen' (to clarify the business problem)."
The lecture describes three levels of integrating machine learning solutions into an organization. What is a 'System Solution' (the third level)?,"A 'System Solution' is the deepest level of integration, where machine learning fundamentally changes the entire organizational structure and business model, requiring a complete rethinking of processes. The example given is Amazon's 'Anticipatory Shipping' patent.","Laut der Vorlesung ist eine „Systemlösung“ (das dritte Level) eine „umfassende, integrierte Reihe von Anwendungen und Technologien, die zusammenarbeiten, um komplexe, organisation-weite Probleme zu lösen.“ Sie beinhaltet oft neue Businessmodelle und kann sogar eine Neudefinition der gesamten Organisationsstruktur erfordern.","Systemen
wissen, könnte es sein,
dass Menschen ihre Art und 
Weise,
sich zu verhalten, ändern,
um dieses das System 
auszutricksen,
indem bestimmte neue 
Fachbegriffe,
wo man denkt, das ist, wo die 
Maschine drauf anspricht.
In die Vorhersage oder in
sein Bewerbungsschreiben mit 
rein tut,
damit das System dort eben
was erkennt und eine bessere 
Vorhersage macht,
kommen wir später noch zu.
Ist das für Sie in Ordnung? 
Cool. Andere Fragen.
Dann haben wir die dritte Ebene.
Und das ist dort eigentlich,
wo alle Unternehmen gerne hin 
möchten.
Hier, das sind Quick Wins,
wo ich etwas einführen kann.
Und das ist meistens auch der 
erste Schritt.
Ich fange an, einzelne Sachen zu 
ersetzen,
einzelne Sachen besser zu 
machen.
Dann gehe ich hin und verändere 
meine Arbeitsprozesse.
Und dann haben wir aber die 
sogenannten Systemlösungen,
die dazu führen können, dass 
sich die
gesamte Organisationsstruktur 
ändern muss.
In diesen Lösungen haben wir 
neue Businessmodelle.
Wir müssen die gesamte 
Organisation neu denken.
Einführung von großen 
Sprachmodellen Kann
ich einen anderen Service 
anbieten?
Sind bestimmte Prozesse, die
vorher durchgeführt werden 
mussten,
in bestimmten Workflows komplett 
redundant geworden?
Kann ich das alles System solutions•Definition:Comprehensive, integrated set of applications and technologies that work together to address complex, organization-wide problems.•Scope:Broad; enterprise-level•Integration:Highly integrated with multiple components and data flows.•Use case:Innovation must transform or optimize an entire organization•Example:Amazon’s “Ship then Shop” (Prediction + Inventory + Logistics + …) dieser Gleichung hier 
ausdrücken.
Wir haben drei verschiedene 
Komponenten.
Wir haben hier dieses Hütchen,
wir haben das fix und wir haben 
hier dieses Y Hütchen.
Meine erste Frage an Sie Was war 
das? F Hütchen.
Yes, genau richtig.
Wir haben hier das erlernte 
Machine Learning Modell,
was die Muster, die wir in 
historischen
Daten durch Algorithmen erkannt 
haben, abspeichert.
Hier in diesem F. Steckt unser 
gesamtes Wissen drin,
was wir irgendwie extrahieren
und wie genau wir das 
extrahieren.
Das wird der zweite Teil unserer 
Vorlesung sein.
Wichtig hierbei Hütchen ist 
immer dafür ein Indikator,
dass wir von einer Approximation 
sprechen.
Das ist ein Modell.
Das ist nicht der wahre 
unterliegende Prozess,
der die Daten generiert.
Das ist nicht die Landschaft von 
Frankfurt sozusagen,
sondern es ist die Landkarte.
Es ist ein explizit abstrakteres 
Modell,
eine Darstellung der Realität.
Und da können eben Fehler drin 
sein.
Es ist ganz wichtig, sich
immer wieder vor Augen zu 
halten.
Dann haben wir die zweite 
Komponente.
Das war das XML. Was ist das?.X. 
Jemand eine Idee?
Jetzt dahinten? Genau das sind 
die Daten,
die wir in diese Maschine 
reintun.
Wir haben zum Beispiel, wenn Sie 
überlegen,
Sie interagieren mit Chat GPT",8.673750162,1,"The generated answer is semantically consistent with the ground truth. Both correctly describe a 'System Solution' as the deepest level of integration, fundamentally changing the organization and business model, and both use Amazon's anticipatory shipping as the example.",1,"The generated answer is faithful. [cite_start]The context describes the third level of integration as 'SystemlÃ¶sungen' [cite: 1441][cite_start], where the 'gesamte Organisationsstruktur Ã¤ndern muss' (the entire organizational structure must change) [cite: 1441] [cite_start]and 'neue Businessmodelle' are created[cite: 1442]. [cite_start]It gives 'Amazonâ€™s â€œShip then Shopâ€' as the example[cite: 1445].",1,The context directly answers the question. It describes the third level of integration as 'SystemlÃ¶sungen' (system solutions) where the 'gesamte Organisationsstruktur Ã¤ndern muss' (the entire organizational structure must change) and new business models are required. It then explicitly provides 'Amazonâ€™s â€œShip then Shopâ€' as the example.
"According to the text, what is one thing machine learning models currently cannot do?",Machine learning models currently cannot provide a valuation of the consequences of a particular state of the world.,"Laut dem Text können aktuelle Machine Learning-Modelle nicht:

*   **Garantieren, dass ihre Vorhersagen korrekt sind:** Die Ausgaben von Machine Learning-Modellen sind nicht zwangsläufig richtig.
*   **Sofortige, signifikante Ergebnisse von großen Technologieinvestitionen liefern:** Es kann eine Verzögerung geben, bis die Investitionen sich auszahlen, und die marginale Produktivitätsveränderung kann sogar negativ sein.
*   **Sicherstellen, dass die Daten, die das Modell kennt, vollständig sind:** Das Modell benötigt möglicherweise neue Informationen, die es noch nicht kennt.","Stelle sein.
Sie müssen also identifizieren 
welche
Daten welche Variablen sind 
eigentlich da?
Müssen Sie vielleicht neue 
Informationen erheben?
Sind bestimmte Informationen gar 
nicht zugänglich?
Und das Letzte kann tatsächlich 
und findet häufig statt,
dass man sagt Ich habe eine 
Riesenidee,
wie ich eigentlich Machine 
Learning nutzen kann.
Dazu brauche ich aber in einer 
First World ABCDE.
Und dann kommt der Betriebsrat 
und sagt ihnen Nee,
das können wir nicht machen, das 
funktioniert so nicht.
Und dann stehen sie dort und 
sagen Ja gut,
dann macht meine Modellidee,
um dieses Businessproblem zu 
lösen.
So wie ich es mir vorgestellt 
habe,
vielleicht gar keinen Sinn.
Deswegen befindet sich dann 
dieser Pfeil hier zurück.
Und Sie müssen natürlich sagen,
in der First Best World würde 
ich es gerne so haben.
Das sollte immer Ihr 
Ausgangspunkt sein.
Und dann werden Sie mit
der Realität konfrontiert und 
merken,
dass einige Sachen technisch 
einfach nicht da sind,
vielleicht noch nicht da sind.
Vielleicht bedarf es eben 
Änderungen
in der Art und Weise,
welche Informationen erheben 
werden müssen.
Es kann sein, dass Sie zu der 
Entscheidung kommen,
hier in diesem Data 
Understanding, dass Sie sagen 
Hey, Das ist unsere Prädiktion,
auf Englisch auch wieder 
indiziert durch das Hütchen.
Das Hütchen zeigt uns an dieser 
Stelle,
dass wir nicht ganz explizit 
wissen,
ob das eigentlich das reale 
Outcome ist.
Wenn Sie eine Machine Learning 
System haben,
was Ihnen basierend auf den
Soziodemografischen Faktoren 
einer Person
eine Vorhersage gibt darüber,
ob diese Person tatsächlich 
kreditwürdig ist oder nicht.
Ist dieser Output der
Maschine das Y immer eine 
Prediction,
eine Vorhersage, die nicht
notwendigerweise richtig sein 
muss.
Wir hoffen, dass sie so akkurat 
wie möglich ist.
Das ist aber nicht zwangsläufig 
gegeben.
Und wer erinnert sich an das 
Ziel von
Machine Learning aus einer 
konzeptionellen Perspektive?
Wenn wir über die overarching 
Objectives reden,
was wollen wir damit erreichen?
Wofür ist dieses ganze Modell 
gebastelt etc.
da? Die bestmöglichen 
Vorhersagen?
Genau, Und für welche Daten?
Ja, und eine Sache will ich noch 
rauskitzeln.
Was sind die Inputdaten am 
besten?
Daten, die das Modell noch nicht 
kennt? Genau das.
Es geht uns nicht darum,
dass wir ein Modell haben,
was uns optimal erklärt,
was in der Vergangenheit alles 
passiert ist.
Aber wir wollen keinen 
Vorhersagemodell
über den Stockmarket Price sind dann in eine Case Study 
gemacht,
wo ich ihnen gezeigt habe,
wie man Machine Learning 
anwenden kann.
Nicht immer nur zu negativen 
Aspekten,
aber diese Predictions,
die Machine Learning uns liefern 
kann,
wie man die auch dazu nutzen 
kann,
zum Beispiel zur Vorhersage,
welcher Kunde wie auf welches 
Messaging reagiert,
um letztlich die
Rücksenderaten von Produkten zu 
verringern.
Letzte Woche sind wir dann mehr 
ins
Detail schon reingesprungen, 
Eingesprungen,
haben uns überlegt, aus einer 
ökonomischen Perspektive,
was Prediction bedeuten könnte,
wenn wir bei General Purpose 
Technologien gesprochen.
Wir haben darüber gesprochen,
dass wir uns, wie
es bei so vielen General Purpose 
Technologien ist,
aktuell auf einen bestimmten 
Teil der Kurve,
die noch befinden,
die Kurve als die Darstellung, 
die fundamentale Idee,
dass wir nicht in große 
Technologie Investitionen habe,
dass sich die nicht sofort 
auszahlt.
Das ist immer so ein bisschen 
Verzögerung gibt,
am Anfang sogar die marginale
Produktivitätsveränderungen 
negativ sein kann.
Das ist so dieser untere 
Halbkreis von dem J.
Und das kann verschiedene Gründe 
haben.
Unter anderem eben, dass diese
Technologien noch nicht 
ausreichend in den
Organisationen mit",12.40098643,1,The generated answer is semantically consistent with the ground truth. Both correctly state that machine learning models cannot provide a valuation of the consequences of a particular outcome.,0.5,"The generated answer claims that models cannot provide a valuation of the consequences of a particular state. [cite_start]The context supports this idea by stating that the manager ('Sie als Manager') still has to decide on the consequences of an action, and the machine only provides information about probabilities ('Die Maschine per se gibt mir nur Informationen erstmal Ã¼ber die Wahrscheinlichkeit')[cite: 1735, 1741]. However, the generated answer is phrased as an absolute inability, while the context describes it as the current division of labor between human and machine.",0.2,"The context explains what machine learning models *can* do, which is to provide predictions ('eine Vorhersage gibt darÃ¼ber'). It contrasts this with the human's role, which is to assess the consequences. This implies that the model cannot provide a valuation of consequences, but it does not state it explicitly."
What are two types of bias metrics?,Individual-level metrics and group-level metrics.,"Basierend auf dem Text gibt es zwei Arten von Bias-Metriken:

1.  **Auf dem Individuenindividuellen Level**
2.  **Als Gruppen**","sehr versteckt eigentlich 
bestimmte diskriminierende
Verhalten auftreten können,
weil wir einfach nicht alle 
diese Measures hier benutzen.
Grundsätzlich können wir aber
zwischen zwei verschiedenen 
Arten
dieser Measurements 
unterscheiden.
Auf der einen Seite nehmen wir 
uns
auf dem Individuen individuellen 
Level angucken.
Wenn wir uns nur in einer 
Dimension
unterscheiden und diese 
Dimension protected ist,
dann sollten unsere Vorhersagen 
möglichst ähnlich sein.
Oder wir gucken uns als Gruppen 
an,
das heißt, es kann bei uns
individuell unterschiedlich 
sein.
Wenn sich aber die 
Studierendengruppe verglichen 
mit
den Professorengruppen alles 
identisch wäre,
außer an dieser Eigenschaft,
dann würden wir im Aggregat 
zumindest erwarten,
dass sich im Durchschnitt diese
bestimmte Prediction Performance 
nicht unterscheidet.
Und umso höher ich im Aggregat 
bin,
umso tiefer versteckt kann
natürlich irgendwelche 
diskriminatorischen Muster
immer noch sein und
über spezielle Beispiele jetzt 
mal sprechen.
So müssen Sie immer über 
Diskriminierung in
Algorithmen nachdenken oder über 
Fairness.
Wir haben einen bestimmten 
Outcome,
nämlich unser Y, das unsere 
Underlying Truth,
ob jemand kreditwürdig ist oder 
nicht. discrimination (Favaretto et al., 2019; Kordzadeh & 
Ghasemaghaei, 2022). The social component often 
originates from societal and economic structural biases, 
which can foster the differential treatment and 
marginalization of certain groups. On the other hand, the 
technological element emanates from the perpetuated 
discriminatory behaviors of algorithmic systems. 
Algorithmic feedback loops: Feedback loops play a 
significant role in algorithmic discrimination in the 
context of continuously updated ML models. These loops 
arise when the outcomes of algorithmic decisions provide 
new endogenous training data for subsequent model 
updates (Cowgill, 2018). Such loops iteratively weave 
together the social environment ’s outcomes and the 
technical performance of the algorithmic output. For 
instance, take the loan approval process depicted in 
 
1 Since the biased or disparate treatment of particular groups 
typically yields discrimination and unfairness, researchers 
often use the terms algorithmic bias, algorithmic 
Figure 1. If an ML model’s prediction of creditworthiness 
guides loan approval, this prediction will shape the data 
available for future updates. As the bank only observes data already reﬂects social prejudices, and the algorithm also
incorporates biased relationships, leading to the“bias in and bias
out” phenomenon (36KE, 2020). This phenomenon means that
discrimination and disparities exist, just like in forecasting, where
historical inequalities are projected into the future and may even
be ampliﬁed (Mayson, 2018).
A research team at Princeton University discovered that
algorithms lack access to the absolute truth. The machine corpus
contains biases that closely resemble the implicit biases observed
in the human brain. Artiﬁcial intelligence has the potential to
perpetuate existing patterns of bias and discrimination because
these systems are typically trained to replicate the outcomes
achieved by human decision-makers (Raso et al.2018). What is
worse, the perception of objectivity surrounding high-tech
systems obscures this fact.
In summary, if an algorithmic system is trained on biased and
unrepresentative data, it runs the risk of replicating that bias.
Data feature selection: designer bias. The introduction of bias is
sometimes not immediately apparent in model construction
because computer scientists are often not trained to consider",6.093388796,1,The generated answer is semantically consistent with the ground truth. Both correctly identify the two types of bias metrics as individual-level and group-level.,1,"The generated answer is faithful. [cite_start]The context clearly distinguishes between metrics on an 'Individuen individuellen Level' (individual level) and those that look at people 'als Gruppen an' (as groups)[cite: 1484, 1486].",1,The context directly answers the question. It describes two types of fairness measurements: one that looks at the 'Individuen individuellen Level' (individual level) and another that looks at 'Gruppen' (groups).
"According to the CRISP-DM framework, what is the approximate percentage of time spent on data preparation within the CRISP-DM process?",Approximately 60-80% of time.,Der Text gibt keine konkreten Zeitanteile für die einzelnen Phasen des CRISP-DM-Prozesses an.,"Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. 15. Mai 2025
Structuring an AI project: CRISP-DM 
6
1. Business Understanding2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment
Data 
Cross Industry Standard Process for Data Mining 15. Mai 2025
Overview CRISP-DM
9",5.791216135,0,"The generated answer claims 60-80% of time is spent on data preparation, but the ground truth is a refusal to answer, stating no specific time percentages are given. The answers are contradictory.",0,The generated answer is not faithful. The context does not mention the percentage of time spent on data preparation. [cite_start]It only lists 'Data Preparation' as the third phase of the CRISP-DM process[cite: 1510].,0,The context is entirely irrelevant. It discusses the phases of the CRISP-DM process model and does not contain any information about the percentage of time spent on data preparation.
What does the document state about the impact of Generative AI on employee happiness?,"The document states that employees became happier, with less escalation and longer tenure.",You are correct. The document does not contain any information about the impact of generative AI on employee satisfaction.,"Thirdly, concerns are raised regarding potential hiring
discrimination perpetrated by machines. This can arise from AI
tools, such as partial source data, or users unfamiliar with user
interfaces and operations.
Fourthly, intrinsic factors like personality and IQ, as well as
extrinsic factors like gender and nationality, have been observed
to inﬂuence the accurate identi ﬁcation and judgment of AI
systems concerning hiring discrimination.
Fifthly, respondents offer recommendations for combating
discrimination by machines, including technical and non-
technical approaches.
Recommendations for future studies
This study conducted a literature review to analyze algorithmic
recruitment discrimination’s causes, types, and solutions. Future
research on algorithmic recruitment discrimination could explore
quantitative analysis or experimental methods across different
countries and cultures. Additionally, future studies could examine
the mechanics of algorithmic recruitment and the technical rules
that impact the hiring process. It would be interesting to analyze
the psychological effects of applying this algorithmic recruitment
technique on various populations (gender, age, education level) employment opportunities and the potential for discrimination
without accountability. To harness the beneﬁts of AI in recruiting,
organizations should exercise careful selection of their programs,
promote the adoption of accountable algorithms, and advocate
for improvements in racial and gender diversity within high-tech
companies.
The general construct of this study is,ﬁrst, an extension of
statistical discrimination theory in the context of the algorithmic
economy; second, a synthesis of the current literature on the
beneﬁts of algorithmic hiring, the roots and classi ﬁcation of
algorithmic discrimination; and third, initiatives to eliminate the
existence of algorithmic hiring discrimination; fourth, based on
the Grounded Theory, we conduct surveys with respondents and
analyze primary data to support the study.
The contributions of this study are as follows:
First, discuss job market discrimination theories in the digital
age context. When considering statistical discrimination theories,
we should consider the current circumstances. It is necessary to
apply these discrimination theories to evaluate the issues that
arise from the use of technology in the digital age, particularly discrimination
Algorithms are not inherently discriminatory, and engineers
rarely intentionally introduce bias into algorithms. However, bias
can still arise in algorithmic recruitment. This issue is closely
linked to the fundamental technology behind AI and ML. The ML
process can be simpliﬁed into several stages, each involving three
key components contributing to algorithmic bias: dataset con-
struction, the engineer’s target formulation, and feature selection
(36KE, 2020). When the dataset lacks diverse representation from
different companies, bias may be introduced during the devel-
opment of algorithmic rules by engineers and when annotators
handle unstructured data (Zixun,2020).
Datasets: bias soil. Datasets serve as the foundation of machine
learning (ML). If an algorithm’s data collection lacks quantity and
quality, it will fail to represent reality objectively, leading to
inevitable bias in algorithmic decisions. Researchers commonly
use a 95% conﬁdence level, which provides 95% certainty but still
leaves a one in twenty chance of bias (Raub,2018). Nearly every
ML algorithm relies on biased databases.
One issue arises when datasets are skewed towards accessible",5.198296547,0,"The generated answer is a refusal to answer, stating the document contains no information. The ground truth provides a specific, factual answer. The answers are contradictory.",0,The generated answer is not faithful. The retrieved context does not contain any information about the impact of Generative AI on employee happiness. It discusses themes related to algorithmic discrimination in hiring.,0,"The context is entirely irrelevant. It discusses AI-based recruitment, discrimination, and the use of Grounded Theory. It contains no information about the impact of Generative AI on employee happiness."
What did Amazon patent in 2014?,A 'Chip Shop' (patent).,You are absolutely correct. The provided text is a research paper abstract and funding information related to e-commerce returns and the use of causal forests. It does not contain any information about patents filed by Amazon in 2014.,"work as “Marketing Science. Copyright © 2024 The Author(s). https:/ /doi.org/10.1287/mksc.2022. 
0393, used under a Creative Commons Attribution License: https:/ /creativecommons.org/licenses/ 
by-nc-nd/4.0/.” 
Funding: Partial financial support was received from the Leibniz Institute for Financial Research SAFE 
and the Deutsche Forschungsgemeinschaft [Grant 449023539]. 
Supplemental Material: The online appendix and data files are available at https:/ /doi.org/10.1287/mksc. 
2022.0393. 
Keywords: electronic commerce • nudging • causal forest • digital footprint • consumer returns • artificial intelligence
1. Introduction
In recent years, global e-commerce has experienced sig -
nificant and sustained growth. E-commerce presents 
numerous advantages for both customers and retailers. 
However, the lenient, and frequently free, return poli -
cies introduce drawbacks that complicate this expan -
sion. In the fashion industry, the share of purchases 
returned can reach a staggering 50% (Dzyabura et al. 
2023 ).
Product returns pose a substantial financial burden 
on retailers (Nageswaran et al. 2020 ). The costs of estab -
lishing return infrastructures (Ofek et al. 2011 ), incur -
ring transportation expenses (Zhou and Hinz 2016 ), profit or commercial advantage and that copies bear this notice and full citation on the first page. Copyright for 
components of this work owned by others than the Association for Information Systems must be honored. Abstracting 
with credit is permitted. To copy otherwise, to republish, to post on servers, or to redistribute to lists requires prior 
specific permission and/or fee. Request permission to publish from: AIS Administrative Office, P.O. Box 2712 Atlanta, 
GA, 30301-2712 Attn: Reprints, or via email from publications@aisnet.org. Stelle sein.
Sie müssen also identifizieren 
welche
Daten welche Variablen sind 
eigentlich da?
Müssen Sie vielleicht neue 
Informationen erheben?
Sind bestimmte Informationen gar 
nicht zugänglich?
Und das Letzte kann tatsächlich 
und findet häufig statt,
dass man sagt Ich habe eine 
Riesenidee,
wie ich eigentlich Machine 
Learning nutzen kann.
Dazu brauche ich aber in einer 
First World ABCDE.
Und dann kommt der Betriebsrat 
und sagt ihnen Nee,
das können wir nicht machen, das 
funktioniert so nicht.
Und dann stehen sie dort und 
sagen Ja gut,
dann macht meine Modellidee,
um dieses Businessproblem zu 
lösen.
So wie ich es mir vorgestellt 
habe,
vielleicht gar keinen Sinn.
Deswegen befindet sich dann 
dieser Pfeil hier zurück.
Und Sie müssen natürlich sagen,
in der First Best World würde 
ich es gerne so haben.
Das sollte immer Ihr 
Ausgangspunkt sein.
Und dann werden Sie mit
der Realität konfrontiert und 
merken,
dass einige Sachen technisch 
einfach nicht da sind,
vielleicht noch nicht da sind.
Vielleicht bedarf es eben 
Änderungen
in der Art und Weise,
welche Informationen erheben 
werden müssen.
Es kann sein, dass Sie zu der 
Entscheidung kommen,
hier in diesem Data 
Understanding, dass Sie sagen 
Hey,",7.03585124,0,"The generated answer is a refusal to answer, stating the document contains no information about Amazon patents. The ground truth provides a specific, factual answer. The answers are contradictory.",0,The generated answer is not faithful. The retrieved context does not contain any information about an Amazon patent from 2014. The context is a research paper about product returns.,0,The context is entirely irrelevant. It is a research paper abstract and funding information related to e-commerce returns and does not contain any information about patents filed by Amazon.
The lecture identifies two fundamental aspects that make AI different from previous General Purpose Technologies like electricity. What are they?,"First, it is a technology that can improve itself through its own use (self-learning). Second, this self-learning creates massive cross-industry spillover effects, where use in one industry can improve the system for another.","Laut der Vorlesung unterscheiden sich KI von früheren Allzwecktechnologien wie Elektrizität in zwei grundlegenden Aspekten:

1.  **Interaktion zwischen Mensch und Maschine:** KI erfordert eine aktive Interaktion und Zusammenarbeit zwischen Mensch und Maschine, während Elektrizität eine passive, unpersönliche Nutzung darstellt.
2.  **Die Frage nach ""Was ist nicht richtig"":** KI stellt die Frage, wann die Maschine nicht richtig ist, was die Rolle des Menschen bei der Entscheidungsfindung und Verantwortung hervorhebt.

Zusammenfassend geht es also um die aktive, kollaborative Beziehung zwischen Mensch und Maschine, die durch KI charakterisiert ist, im Gegensatz zur passiven Nutzung von Technologien wie Elektrizität.","So legen wir los. Herzlich 
willkommen.
Vorlesung fünf sozusagen.
Fast schon Bergfest, oder?
Heute ist, glaube ich, Bergfest,
wenn man die restlichen 
Vorlesungen zusammenzählt.
Auch weil ich jetzt schon 
mehrfach gefragt wurde.
Dazu mit der Klausur.
Das hier ist jetzt die letzte
Vorlesung aus diesem ersten 
Teil,
wo es darum geht, ein 
grundsätzliches
Verständnis dafür zu schaffen,
was KI bewirken kann,
wie Menschen mit KI 
zusammenarbeiten können,
was potenzielle Schwachpunkte 
und Probleme sind,
wenn wir KI einsetzen.
Heute sprechen wir über Mensch 
Maschine Interaktion,
bauen sozusagen auf der 
Erklärbarkeit.
Vorlesungen von vor zwei Wochen
auf und dann ist dieser erste 
Block abgeschlossen.
Dann fängt es nächste Woche
an mit dem eher technischen 
Blog,
wo wir jetzt wirklich uns dann 
damit befassen werden,
wie wir diese Systeme bauen,
was die Mathematik dahinter ist,
wo die Stärken und die
Schwächen von bestimmten 
Modellen liegen.
Und zu Beginn der nächsten
Vorlesung werden wir dafür dann 
aber zum Abschluss dieses
ersten Blockes so eine Art 
kleinen Recap machen,
wo ich Ihnen auch
ein paar Fragen interaktiv
mit der Gruppe durchspielen 
werde.
Von der Struktur der Frage 
können Sie dann auf die
Struktur der Fragen in Ich kann Ihnen aber Brief und 
Siegel darauf geben,
dass es kein KI System der Welt 
gibt,
was immer richtig ist.
Das heißt, die Rolle des 
Menschen
ist eigentlich rauszufinden,
wann ist die Maschine nicht 
richtig.
Und das mit der eigenen und das
ist gleich der zweite Teil der
Vorlesung von heute
zu überlegen Wie kriege ich es 
eigentlich hin,
dass Mensch und Maschine 
zusammen so gut
sind, dass die gemeinsame,
diese kollaborative Performance 
besser ist,
als wenn sie alles die Maschine 
machen lassen
oder wenn sie einfach alles 
selber machen?
Aber diese Facetten, die Sie 
gesagt haben,
diese Idee davon Warum
verlasse ich mich eigentlich auf 
die Maschine.
Möchte ich nicht, dass mein Kopf 
rollt?
Möchte ich auch meine
Wahrnehmung meiner Verantwortung 
accountability irgendwie
an die Maschine abgeben?
Hochgradig komplexe
Facetten aus unterschiedlichen 
Perspektiven.
So dass man, wenn man quasi als
Unternehmen die 
Entscheidungsmacht bei
der Maschine bei der KI 
überlässt.
Dann gibt es ja rein theoretisch 
keine Person,
wo man quasi die man zur 
Rechenschaft ziehen könnte,
wenn die Entscheidung 
fehlschlägt.
Davor schaltet, auch wenn er 
automatisiert
die ganze Zeit quasi einfach nur 
sagt ja, jetzt ist fein. im Taunus angeschaut haben,
wie Menschen tatsächlich mit KI 
interagieren.
Ob es eigentlich gut ist,
wenn Ihr Sparkassenberater eine 
KI benutzt,
um Ihnen Investmentberatung zu
geben und wie Sie eigentlich
darauf reagieren oder ob
das Ganze vielleicht 
automatisiert ablaufen sollte.
Das Papier ist jetzt
also kommt bald im Management 
Science Journal raus.
Wie gesagt, die letzten fünf 
Minuten.
Aber vorher noch mal 
irgendwelche
Unklarheiten zu dem Thema,
was wir oder Themen,
die wir bisher besprochen haben.
Cool. Wie gesagt, wir haben
uns in diesem Projekt
Sparkasse kam auf uns zu und hat 
gesagt naja,
wir haben hier eine Idee
oder wir möchten gerne mal 
rausfinden,
ob unsere Kunden eigentlich eher 
wollen,
dass sie von einem Robo Advisor 
beraten werden,
also einem automatisierten 
System,
wo kein Mensch mehr dabei ist 
oder von Mensch Berater,
der mit der KI zusammenarbeitet
und gemeinsam sozusagen als
Human AI Team diese Beratung an 
den Kunden gibt.
Der Kunde ist eben darüber 
informiert.
Was wir gemacht haben, ist Wir 
haben
eine Feldstudie gemacht, zwei 
Stufen.
Wir haben für die erste Stufe 
ganz viele Daten gesammelt,
haben KI System gebaut,
was bewertet hat, ob ein 
bestimmtes Investitionsobjekt,
hier eben P2P loans,",15.04333496,1,The generated answer is semantically consistent with the ground truth. Both correctly identify the two key differentiators of AI as a GPT: its ability to self-improve and the creation of cross-industry spillovers.,0,The generated answer is not faithful. It claims that AI differs from electricity because of human-machine interaction and the question of when the machine is wrong. The provided context does not compare AI to electricity or other GPTs. [cite_start]It is a recap of a lecture on human-machine interaction[cite: 1558].,0.8,"The context is highly relevant but doesn't use the exact phrasing of the answer. It discusses the unique nature of AI, highlighting the crucial role of the human in figuring out 'wann ist die Maschine nicht richtig' (when is the machine not correct) and the importance of the human-machine interaction itself. While it doesn't explicitly mention 'self-learning' or 'cross-industry spillovers', the core idea that AI's nature fundamentally changes the human-technology relationship in a way electricity did not is central to the context."
"From a purely economic perspective, what is the single most important function that machine learning technology provides?","It is a technology that massively lowers the cost of making high-quality, accurate predictions.","Aus rein wirtschaftlicher Sicht bietet Machine-Learning-Technologie die Möglichkeit, die Wahrscheinlichkeit und Präzision von Vorhersagen zu verbessern. Genauer gesagt, ermöglicht sie es, die anfängliche Einschätzung zu verfeinern, indem sie eine bessere Wahrscheinlichkeit für eine Rückzahlung (wie im Fall des Startups) liefert.
","Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. Studierende werden mit den wichtigsten Fragestellungen rund um den Einsatz von Machine Learning (ML) in Managemententscheidungen vertraut gemacht. Sie erwerben grundlegende theoretische Kompetenzen im Bereich ML und verstehen, wie diese Technologien betriebliche Prozesse und strategische Entscheidungen beeinflussen können.
Studierende erlernen den Umgang mit grundlegenden Methoden und Werkzeugen des maschinellen Lernens, einschließlich Datenaufbereitung, Modelltraining und -bewertung. Sie entwickeln die Fähigkeit, wirtschaftliche Fragestellungen in ML-Probleme zu übersetzen und datenbasierte Lösungen analytisch sowie strukturiert zu erarbeiten.
Im Rahmen der Veranstaltung werden zahlreiche Praxisbeispiele und Fallstudien aus verschiedenen Industrien behandelt, die die Anwendung von ML und generativer KI im geschäftlichen Kontext beleuchten. Insbesondere in den angebotenen Übungen und praktischen Programmieraufgaben lernen Studierende, das erlangte Wissen anzuwenden, auch ohne vorherige Programmiererfahrung. Wir haben unser gesamtes 
Investment verloren.
Und wir investieren genau dann,
wenn der Erwartungswert aus
diesen beiden möglichen Fällen,
die eintreten können, größer 
oder gleich.
Das kann man jetzt diskutieren,
ob wir hier dieses gleiche 
Zeichen dabei haben wollen,
für die Grundidee aber 
vollkommen irrelevant.
Wenn diese Aktion im
Erwartungswert einen höheren 
Nutzen für uns bringt,
als nicht zu investieren
Und die Frage war wo kommt hier 
aus
einer technischen Perspektive 
Machine Learning rein?
Was ist das Wichtige hier?
Was verändert Machine Learning 
auf der einen Seite und
was verändert Machine Learning?
Eben nicht in dieser Gleichung
aus dieser wirklich 
ökonomischen,
spieltheoretischen Perspektive. 
Wer weiß das noch?
Ja, genau.
Wir haben hier unsere eigene 
initiale Einschätzung.
Wir sehen das Startup und sagen 
Na ja,
mit einer bestimmten 
Wahrscheinlichkeit P wird sich
das Startup anstrengen und dann
kriegen wir eben diese 
Rückzahlung.
Und mit der Wahrscheinlichkeit
eins P wird das nicht passieren.
Und was Machine Learning uns 
letztlich geben kann,
ist eine bessere 
Wahrscheinlichkeit,
eine präzisere 
Wahrscheinlichkeit.
Wir haben unsere anfängliche 
Idee,
dann haben wir das Machine",8.605946064,1,The generated answer is semantically consistent with the ground truth. Both identify the most important function as massively lowering the cost of making accurate predictions.,1,"The generated answer is faithful. [cite_start]The context states that 'Machine Learning Ã¤ndert letztlich eine Sache an dieser Gleichung' (Machine learning ultimately changes one thing in this equation), which is the probability 'p'[cite: 1196, 1192]. [cite_start]It provides a 'bessere Wahrscheinlichkeit, eine prÃ¤zisere Wahrscheinlichkeit' (a better probability, a more precise probability)[cite: 1593], which massively lowers the cost of making accurate predictions.",1,"The context directly answers the question. It states that from an economic perspective, machine learning provides 'eine bessere Wahrscheinlichkeit, eine prÃ¤zisere Wahrscheinlichkeit' (a better probability, a more precise probability), which perfectly aligns with the function of lowering the cost of making accurate predictions."
"According to the text, what does the 'J-curve' represent?","The 'J-curve' represents a phenomenon where, with many technologies, productivity initially decreases before eventually increasing.","Laut dem Text repräsentiert die ""J-Kurve"" eine lineare Funktion, die durch die Verbindung der beiden Endpunkte der Extremen der Wahrscheinlichkeitsverteilung entsteht. Sie wird verwendet, um den Schnittpunkt von zwei Funktionen zu bestimmen, wobei dieser Schnittpunkt den Wert des ""Expected Utility"" darstellt.","dieser Gleichung hier 
ausdrücken.
Wir haben drei verschiedene 
Komponenten.
Wir haben hier dieses Hütchen,
wir haben das fix und wir haben 
hier dieses Y Hütchen.
Meine erste Frage an Sie Was war 
das? F Hütchen.
Yes, genau richtig.
Wir haben hier das erlernte 
Machine Learning Modell,
was die Muster, die wir in 
historischen
Daten durch Algorithmen erkannt 
haben, abspeichert.
Hier in diesem F. Steckt unser 
gesamtes Wissen drin,
was wir irgendwie extrahieren
und wie genau wir das 
extrahieren.
Das wird der zweite Teil unserer 
Vorlesung sein.
Wichtig hierbei Hütchen ist 
immer dafür ein Indikator,
dass wir von einer Approximation 
sprechen.
Das ist ein Modell.
Das ist nicht der wahre 
unterliegende Prozess,
der die Daten generiert.
Das ist nicht die Landschaft von 
Frankfurt sozusagen,
sondern es ist die Landkarte.
Es ist ein explizit abstrakteres 
Modell,
eine Darstellung der Realität.
Und da können eben Fehler drin 
sein.
Es ist ganz wichtig, sich
immer wieder vor Augen zu 
halten.
Dann haben wir die zweite 
Komponente.
Das war das XML. Was ist das?.X. 
Jemand eine Idee?
Jetzt dahinten? Genau das sind 
die Daten,
die wir in diese Maschine 
reintun.
Wir haben zum Beispiel, wenn Sie 
überlegen,
Sie interagieren mit Chat GPT werden.
Sie bewegen sich hier also auch
immer wieder in so einem Hin und 
her.
Und wenn ich dann ein Modell 
habe,
dann kommt es an die Evaluation.
Jetzt schließt sich so ein 
bisschen nämlich der Kreis,
weil ich am Anfang gesagt habe,
wie kann ich dieses Modell,
wie schätze ich den Einwand gut 
ist.
Dann habe ich, wie wir im
späteren Teil der Vorlesung 
sehen werden,
auf der einen Seite die 
technischen Maße,
die mir sagen Wie akkurat ist 
meine Vorhersage?
Wie sensitiv ist meine 
Vorhersage?
Wie spezifisch sind meine 
Vorhersagen?
Wir haben noch ein paar andere 
Messungsmöglichkeiten.
Das ist diese technische
Perspektive, die mathematische 
Perspektive.
Aber dann haben wir auch immer
noch diese Businessperspektive.
Was bringt es uns wirklich 
unterm Strich?
Was sind die Mehreinnahmen,
Was sind die weniger Ausgaben, 
die wir haben?
Wo sind diese 
Effizienzsteigerungen,
die wir erreichen möchten?
Und da müssen wir das Modell in
beiden Dimensionen vernünftig 
analysieren.
Und das geht natürlich nur,
indem ich mir vorher schon 
Gedanken darüber gemacht habe
Was ist es denn eigentlich 
objektiv,
was ich verbessern möchte?
Und wie Messer messe ich dieses 
mögliche verbessern?
Und auch hier werden Sie 
manchmal wieder macht
die uhr die Aktion nicht.
Ich möchte eigentlich, dass es 
aufgenommen wird,
aber die uhr nimmt es nicht auf.
Und ich habe einen Nutzen,
wenn die uhr es aufnimmt und ich 
es
tatsächlich machen möchte und
jetzt von mir simplifiziert.
Für Sie kann ich natürlich hier 
einfach
diese Punkte verbinden und sagen 
naja, der Nutzen,
den ich habe von der Aktion ah,
wenn ich es nicht möchte und der 
Nutzen von der Funktion,
von der Aktion ah, wenn ich es 
eigentlich möchte,
hängt irgendwie zusammen mit der 
Wahrscheinlichkeit.
Das hier ist mein ExPected 
Utility davon.
Und genau das gleiche kann ich 
machen hier für wenn ich
etwas eigentlich nicht möchte 
meine in Aktion.
Die uhr macht etwas
nicht und ich möchte das auch 
nicht und
die uhr macht etwas nicht.
Und ich möchte das eigentlich,
wenn ich einfach diese beiden 
Endpunkte auf den
Extremen der 
Wahrscheinlichkeitsverteilung
miteinander verbinde.
Hier für Sie einfach mit einer 
linearen Funktion,
wie sie alle Mikroökonomie bei 
Uwe Walz
oder Matthias Blonski, je 
nachdem.
Dann kriege ich hier so zwei 
Funktionen,
die haben einen Schnittpunkt.
Und jetzt Mikro eins Was haben 
wir in dem Schnittpunkt?
Wir haben irgendwie eine linke 
Seite vom Schnittpunkt.",8.326780319,0,The generated answer incorrectly describes the 'J-curve' as a linear function related to expected utility. The ground truth provides the correct definition related to an initial dip and subsequent rise in productivity. The answers are completely different.,0,"The generated answer is not faithful. It describes the J-curve as a linear function connecting endpoints of a probability distribution. [cite_start]The retrieved context describes the J-curve in a completely different way, as a pattern in productivity over time where 'erstmal die ProduktivitÃ¤t runter geht' (productivity first goes down) and 'danach geht es eigentlich nach oben' (afterwards it actually goes up)[cite: 1746, 1747].",0.2,The context is about using a linear function to connect endpoints on a probability distribution to find an intersection point representing expected utility. It does not mention or define the 'J-curve' related to technology adoption and productivity.
What is a potential new attack vector related to large language models?,"Systems can be hacked, leading to false or harmful code being written into company codebases.","Basierend auf dem bereitgestellten Text werden folgende potenziellen neue Angriffspfade im Zusammenhang mit Large Language Models genannt:

*   **Algorithmic Discrimination und Continuous ML Model Updating:** Die komplexe Interaktion zwischen kontinuierlichen Modellaktualisierungen und algorithmischer Diskriminierung wird als ein underexploriertes Gebiet betrachtet.
*   **Algorithmic Feedback Loops:** Iterative Updates von Systemen wie Predictive Policing-Systemen können zu verstärkter Diskriminierung gegen Minderheiten führen.
*   **Die Interaktion zwischen kontinuierlichen Modellaktualisierungen und algorithmischer Diskriminierung.**

Der Text konzentriert sich auf die potenziellen Risiken, die durch die Art und Weise entstehen, wie Large Language Models trainiert und aktualisiert werden, und nicht auf spezifische Angriffspfade.","gemacht hat,
das User Interface war
die reine Technologie dieser 
großen Sprachmodelle.
Die gibt es theoretisch schon 
seit 2017.
Die wurden natürlich immer 
besser.
Wir hatten am Ende die Version 
drei Punkt irgendwas,
was dann integriert wurde.
Aber es wurde integriert.
Dieses fundamentale KI Modell in
eine ausreichend kompatible und
nutzerfreundliche Umgebung,
nämlich Chat GPT, was
noch mal das Grundmodell GPT
plus weitere Systeme sind, die 
hier zusammenspielen.
Das heißt Forgeat GPT.
Gab es diese großen 
Sprachmodelle schon?
Die haben sich wie gesagt immer 
weiter verbessert.
Grundsätzlich haben
wir aber alle erst damit 
angefangen und
haben eine ganze Industrie 
eigentlich damit angefangen,
es kommerziell zu benutzen.
Ab dem Moment, wo dieses
User Interface richtig 
hinbekommen wurde
und die User des Systems 
hochgegangen ist.
Das ist eine der Kern messages
die Bereitschaft des Nutzers,
mit den Systemen zu 
interagieren.
Generell, wo wir
häufig von Adoption reden 
Technologie use.
Wenn wir ganz, ganz breit sind.
Das ist zentral dafür,
wie eine Technologie tatsächlich
letztlich Einfluss haben kann 
auf unser Sozialleben,
auf unsere ökonomischen 
Prozesse,
auf Unternehmen
und letztlich natürlich auf 
Produktivität. Organisation neu denken.
Einführung von großen 
Sprachmodellen Kann
ich einen anderen Service 
anbieten?
Sind bestimmte Prozesse, die
vorher durchgeführt werden 
mussten,
in bestimmten Workflows komplett 
redundant geworden?
Kann ich das alles 
automatisieren?
Müssen meine Mitarbeiter 
komplett
neue Skills an den Tag legen?
Muss ich meine Mitarbeiter 
anders aussuchen?
Muss ich meine Mitarbeiter 
anders schulen?
Indem ich ganz viele 
verschiedene
Application Solutions letztlich 
zusammenbringe?
Kann es in dem Gesamtsystem der 
Organisation zu
globalen schrägstrich 
systemischen Veränderungen 
kommen,
die alle miteinander hoch 
integriert sind,
aber eben zu einer komplett
anderen Organisation führen 
können.
Das Beispiel, das ich Ihnen 
mitgebracht
habe hier ist die Idee von 
Amazon.
Die haben es kurz schon mal 
angesprochen,
glaube ich in der letzten 
Vorlesung.
Oder war es in der Business 
School,
dass ich mich nicht mehr ganz 
sicher.
Aber Amazon hat seit 2014 ein 
Patent,
das heißt schieb den Job.
Aktuell gehen Sie auf die 
Website, sie shoppen,
dann wird es geschickt und Sie 
kriegen aktuell,
damit Sie auch schön viel auf 
Amazon einkaufen,
eine Recommendation, was Sie 
denn benötigen.
Und das ist am Ende eine Machine affecting ML systems’ functionality by explaining the 
interplay b etween continuous model updating and 
algorithmic discrimination. Despite its critical importance 
in developing countermeasures and refining policy 
recommendations, the complex interplay between 
algorithmic discrimination and continuous ML model 
updating remains an underexplored area in the literature.  
Second, our paper complements the nascent body of 
studies exploring the origins and impacts of 
algorithmic feedback loops (Burghardt & Lerman, 
2022; Cowgill, 2018). For instance, Lum and Isaac 
(2016) revealed that the iterative updates of a 
predictive poli cing system led to increased 
discrimination against minority groups. Similarly, 
Ensign et al. (2017) showed how feedback loops could",14.62140226,0,"The generated answer claims that systems can be hacked to write false code. The ground truth identifies feedback loops in predictive policing as a potential issue. These are two different, unrelated attack vectors.",0,"The generated answer is not faithful. It claims that a new attack vector is hacking systems to write false code. The retrieved context does not mention this. [cite_start]Instead, it discusses 'algorithmic feedback loops' [cite: 1649] [cite_start]and how iterative updates in systems like predictive policing can lead to increased discrimination [cite: 1650] as potential problems.",0.3,"The context is partially relevant. It discusses feedback loops in predictive policing where iterative updates lead to increased discrimination, which is a form of attack vector. It also mentions the underexplored interplay between continuous model updating and algorithmic discrimination. However, it does not mention the specific vector of hacking systems to write false code."
"According to the text, what is a problem with relying on a perfect machine learning model to predict future outcomes?","It would shift us into a situation where there appears to be no risk, but this is conceptually problematic.","Laut dem Text ist das Hauptproblem beim Vertrauen auf ein Machine-Learning-Modell zur Vorhersage zukünftiger Ergebnisse, dass der Output der Maschine *immer* eine Vorhersage ist, die nicht notwendigerweise richtig sein muss. Es ist eine Wahrscheinlichkeit, die sich ändern kann, basierend auf neuen Informationen und Mustern, die das Modell aus historischen Daten extrahiert. Es ist nicht eine garantierte ""echte"" Antwort.","Das ist unsere Prädiktion,
auf Englisch auch wieder 
indiziert durch das Hütchen.
Das Hütchen zeigt uns an dieser 
Stelle,
dass wir nicht ganz explizit 
wissen,
ob das eigentlich das reale 
Outcome ist.
Wenn Sie eine Machine Learning 
System haben,
was Ihnen basierend auf den
Soziodemografischen Faktoren 
einer Person
eine Vorhersage gibt darüber,
ob diese Person tatsächlich 
kreditwürdig ist oder nicht.
Ist dieser Output der
Maschine das Y immer eine 
Prediction,
eine Vorhersage, die nicht
notwendigerweise richtig sein 
muss.
Wir hoffen, dass sie so akkurat 
wie möglich ist.
Das ist aber nicht zwangsläufig 
gegeben.
Und wer erinnert sich an das 
Ziel von
Machine Learning aus einer 
konzeptionellen Perspektive?
Wenn wir über die overarching 
Objectives reden,
was wollen wir damit erreichen?
Wofür ist dieses ganze Modell 
gebastelt etc.
da? Die bestmöglichen 
Vorhersagen?
Genau, Und für welche Daten?
Ja, und eine Sache will ich noch 
rauskitzeln.
Was sind die Inputdaten am 
besten?
Daten, die das Modell noch nicht 
kennt? Genau das.
Es geht uns nicht darum,
dass wir ein Modell haben,
was uns optimal erklärt,
was in der Vergangenheit alles 
passiert ist.
Aber wir wollen keinen 
Vorhersagemodell
über den Stockmarket Price noch mal ganz kurz drüber.
Sobald Sie einen Task 
identifiziert haben,
wo Machine Learning bestimmte 
Vorhersagen liefern kann.
Um ihre Entscheidungen zu 
verbessern,
sollten wir nicht nur in einer
optimalen Welt diese eine 
Entscheidung,
dieser eine Vorhersage durch
Machine Learning besser machen,
sondern wir sollten auch darüber 
nachdenken,
was eigentlich benötigt wird
innerhalb meines gesamten 
Workflows wieder,
damit diese Maschine gut 
funktioniert.
Welche Daten brauche ich, welche 
Data Pipelines?
Welche Hardware? Wie verändern 
sich vielleicht
andere Teile dieses gesamten 
Workflows?
Wenn ich anfange,
eine bestimmte Vorhersage durch
Machine Learning zu ersetzen,
was meine Entscheidungen 
verändern
könnte es könnte zu mehr 
Realtime Entscheidungen kommen.
Ich könnte anfangen,
nicht mehr viel von meinen 
Ressourcen auf Lager zu haben,
weil ich bessere Vorhersagen 
darüber haben könnte,
wie viel ich eigentlich 
verkaufen möchte.
Denken Sie wieder an das 
Eiscreme EiscremeBeispiel.
Umso besser ich abschätzen kann,
was morgen eigentlich benötigt 
wird,
wie hoch die Nachfrage morgen 
sein wird,
muss ich nicht mehr auf gut 
Glück irgendwas
produzieren und habe Unter oder 
Überkapazitäten.
Und ich kann auch besser selber eins P wird das nicht passieren.
Und was Machine Learning uns 
letztlich geben kann,
ist eine bessere 
Wahrscheinlichkeit,
eine präzisere 
Wahrscheinlichkeit.
Wir haben unsere anfängliche 
Idee,
dann haben wir das Machine 
Learning Modell, was uns sagt.
Naja, ich habe andere
Informationen aus historischen 
Daten,
bestimmte Muster erkannt und 
kann eben
dem Nutzer eine bestimmte 
Wahrscheinlichkeit geben,
so dass ich nicht mehr über P 
reden muss.
Mein eigenes Bauchgefühl,
sondern eine maschinell
erzeugte mathematische 
Vorhersage.
Wie hoch ist die 
Wahrscheinlichkeit hier?
Und dann sprechen wir eben nicht 
über
diese Gleichung, wie sie hier 
jetzt steht,
sondern wir haben eben
diese sogenannte posterior 
Wahrscheinlichkeit.
Wir haben ein Signal bekommen
von unserem Machine Learning 
System
und dieses Signal führt dazu,
dass wir sagen Ja,
ich habe am Anfang gedacht,
die Wahrscheinlichkeit ist 50 
50.
Jetzt sagt die Machine mir, dass 
die Wahrscheinlichkeit,
dass eine Rückzahlung getätigt 
wird,
von dem Startup eigentlich
höher ist, eigentlich 80 % hat.
Und dementsprechend hat sich im
Erwartungswert mein Payoff 
verändert,
weil die Wahrscheinlichkeiten 
sich ändern.
Hier eben nicht mehr dieses P,
sondern wir haben jetzt hier",11.34025812,1,"The generated answer is semantically consistent with the ground truth. Both explain the problem that if a model is perfect, it removes risk, which is a conceptually problematic shift in decision-making.",1,The generated answer is faithful. [cite_start]The context describes a situation where a machine learning model provides a prediction that is '100 % korrekt'[cite: 1960]. [cite_start]It then notes that in this situation 'gibt es keine Risiko mehr' (there is no more risk) because everything can be perfectly predicted[cite: 1967]. This matches the generated answer's claim that relying on a perfect model shifts us to a situation with no risk.,1,"The context is highly relevant as it directly states, 'wenn ich aber zu 100 % weiÃŸ, was morgen passiert, ist Ã¼berhaupt noch Risiko da.' (if I know with 100% certainty what will happen tomorrow, is there any risk at all?). It further explains that in this thought experiment with a perfect machine, 'gibt es keine Risiko mehr' (there is no more risk), which is conceptually problematic."
How much have the costs for inference (using GPT or other Large Language Models) decreased in the last two years?,The costs have decreased by a factor of 34.,Die Kosten für die Inferenz (mit GPT oder anderen Large Language Models) sind seit zwei Jahren um einen Faktor von 34 gesunken.,"Sache,
die wir erstmal ausblenden.
Wir gehen davon aus,
dass die marginalen Kosten der
Produktion und die marginalen 
Kosten,
eine weitere Einheit von 
Komplexität dazuzunehmen,
de facto null sind.
Wir sprechen da dann drüber, so 
ein bisschen.
Wenn wir über GPT Systeme 
sprechen,
weil die da sehen wir natürlich 
merklich unterschiedlich,
ob ich 60 Gigabyte Text
reinknalle oder das halbe 
Internet.
Dann habe ich natürlich schon 
unterschiedliche
Kommunikationskosten.
Wobei jetzt in dem neuen Report
war zum Beispiel angezeigt,
dass die Kosten zumindest für 
die Inferenz,
also wenn Sie GPT benutzen oder
andere Large Language Models,
die Kosten sind seit zwei zwei 
Jahren Haben
die sich bei einem Faktor 34 
verringert?
Ja, das wird massiv effizienter.
Wir sehen jetzt so ein bisschen 
die
Laws of Scaling einsetzen.
Ganz kurz noch hat das Ihre 
Frage.
Das ist die beantwortet mit 
Ockhams Razor.
Wenn wir jetzt nur nach 
Temperatur entscheiden,
wäre nach diesem Gesetz kein 
Gesetz,
das vorsichtig sein. Das ist so 
eine.
Ich würde es als Daumenregel 
bezeichnen.
Deswegen hat man auch davon 
abgesehen,
dass irgendwie Rule zu nennen.
Aber grundsätzlich so ein 
bisschen aus der
Physik motiviert zu sagen naja,
ein einfacheres Modell, was mir gemacht hat,
das User Interface war
die reine Technologie dieser 
großen Sprachmodelle.
Die gibt es theoretisch schon 
seit 2017.
Die wurden natürlich immer 
besser.
Wir hatten am Ende die Version 
drei Punkt irgendwas,
was dann integriert wurde.
Aber es wurde integriert.
Dieses fundamentale KI Modell in
eine ausreichend kompatible und
nutzerfreundliche Umgebung,
nämlich Chat GPT, was
noch mal das Grundmodell GPT
plus weitere Systeme sind, die 
hier zusammenspielen.
Das heißt Forgeat GPT.
Gab es diese großen 
Sprachmodelle schon?
Die haben sich wie gesagt immer 
weiter verbessert.
Grundsätzlich haben
wir aber alle erst damit 
angefangen und
haben eine ganze Industrie 
eigentlich damit angefangen,
es kommerziell zu benutzen.
Ab dem Moment, wo dieses
User Interface richtig 
hinbekommen wurde
und die User des Systems 
hochgegangen ist.
Das ist eine der Kern messages
die Bereitschaft des Nutzers,
mit den Systemen zu 
interagieren.
Generell, wo wir
häufig von Adoption reden 
Technologie use.
Wenn wir ganz, ganz breit sind.
Das ist zentral dafür,
wie eine Technologie tatsächlich
letztlich Einfluss haben kann 
auf unser Sozialleben,
auf unsere ökonomischen 
Prozesse,
auf Unternehmen
und letztlich natürlich auf 
Produktivität. also die wie eintauchen.
Da gibt es einen massiven 
Anstieg in den
Bachelorarbeiten oder 
Masterarbeiten auf Englisch,
dass dieses Wort genutzt wird 
mit dem Einführen von GPT.
Jetzt sehen wir wieder, dass ein 
bisschen zurückgeht,
weil Leute angefangen haben zu 
verstehen,
dass Delf ein sehr starkes 
Signal dafür ist,
dass etwas von GPT geschrieben 
worden ist.
Wenn ich also eine Maschine 
gebaut habe,
die Predigt, dann haben sie GPT 
benutzt oder nicht?
Und diese Maschine möglichst auf 
Delph geachtet hat
und das super richtig war,
ja, dann
funktioniert die Maschine heute 
nicht mehr so gut,
weil sie ihr Verhalten verändert 
haben.
Und diese Probleme nennen
wir grundsätzlich Drift Probleme
und davon haben wir zwei Typen.
Der eine Typ ist, dass sich die 
Verteilung in
den Daten ändert und der andere 
ist,
dass ich fundamental in dem 
Verhalten etwas ändert.
Hier an dem Beispiel von 
Marketing,
von Sales auf der einen Seite 
den sogenannten Data Drift.
Wir haben eine einen Shift
in der Verteilung der Typen der 
Observation,
die wir haben in der 
Vergangenheit.
Wenn Sie hier auf der Achse,
die den zeitlichen Verlauf sehen 
auf der Y Achse,
haben wir die Anzahl oder die 
Menge des Sales,
und sie haben rote und blaue 
Typen.",7.014896631,1,The generated answer is semantically consistent with the ground truth. Both correctly state that costs have decreased by a factor of 34.,1,The generated answer is faithful. [cite_start]The context states that the costs for inference have 'seit zwei zwei Jahren...sich bei einem Faktor 34 verringert' (decreased by a factor of 34 in the last two years)[cite: 1681].,1,The context directly answers the question. It states that the costs for inference 'sind seit zwei zwei Jahren...bei einem Faktor 34 verringert' (have decreased by a factor of 34 in the last two years).
"What is the idea behind using simpler models, according to Ockhams Razor?",To prefer a model that needs less information to make a good prediction.,"Laut dem Kontext geht es bei der Verwendung einfacherer Modelle gemäß dem Prinzip von Ockhams Rasiermesser darum, Modelle zu bevorzugen, die weniger Informationen benötigen, um eine gute Vorhersage zu machen. Es wird argumentiert, dass die Kosten für den Energieverbrauch (oder die Komplexität) eines Modells, das mehr Daten verarbeitet, gering sind, und daher nicht berücksichtigt werden sollten. Es geht darum, die marginalen Kosten einer zusätzlichen Komplexität zu ignorieren.","Ockhams Razor aber dafür,
dass man versuchen sollte,
ein Modell so einfach wie 
möglich zu belassen.
Bedeutet in unserem Beispiel ich 
sollte ein Modell
laut diesem Ockhams Razor 
bevorzugen,
was weniger Informationen 
benötigt,
um eine gute Vorhersage zu 
machen.
Wäre das nicht auch teilweise 
ökonomischer?
In dem Modell, eine Menge 
Energie zu verbrauchen,
würden vielleicht weniger Daten
das gleiche Ergebnis bringen.
Das ist auch ein wichtiger Punkt 
grundsätzlich,
den wir aber in den Datenmengen,
über die wir alle sprechen,
wenn wir über tabulare Daten
insbesondere sprechen, 
ignorieren können,
weil die Kosten dafür so gering 
sind,
dass das keine Rolle spielt,
ob ich einen oder zwei Features 
mehr nehme.
Es gibt Unternehmen, die viel 
mehr Daten.
Das stimmt. Das ist 
grundsätzlich richtig.
Es kommt auf den 
Trainingsprozess an,
es kommt auf die Art des Modells
an für unsere Purpose is.
Aber das meine ich damit Für 
unsere Datensätze,
die wir nutzen, ist das eine 
Sache,
die wir erstmal ausblenden.
Wir gehen davon aus,
dass die marginalen Kosten der
Produktion und die marginalen 
Kosten,
eine weitere Einheit von 
Komplexität dazuzunehmen,
de facto null sind.
Wir sprechen da dann drüber, so 
ein bisschen. die das beeinflussen und
was hier Venkatesh und Kollegen 
gemacht haben,
die haben acht verschiedene 
Modelle
aus ganz unterschiedlichen
Disziplinen zusammengenommen und
haben jahrelang rumgewerkelt, um 
zu schauen,
was sind eigentlich die latent 
ähnlichen Faktoren,
was können wir irgendwie 
zusammenfassen und
was sind Faktoren,
die möglichst orthogonal einzeln 
gesehen
unterschiedlich sind und
viel Erklärungsgehalt dafür 
haben
in der Vorhersage,
ob ein Mensch die Technologie 
nutzen wird oder nicht.
Und das haben Sie das Modell, 
was entwickelt haben
letztlich auf ganz viele 
empirische Daten
gelegt und gezeigt,
dass dieses Modell um die 70 % 
der Variation darin,
ob Leute mit Technologie 
interagieren,
diese wirklich nutzen und 
akzeptieren, erklären kann.
Als Spoiler schon mal 70 % der
Variation zu erklären ist 
massiv,
insbesondere in solchen 
soziotechnischen Systemen,
wo wie immer der Mensch die 
Schwachstelle ist.
Womit haben Sie angefangen? Sie 
haben gesagt.
Und dieses Modell ist
vor allen Dingen aus der 
Perspektive
geschaffen worden damals.
Wie kriegen wir eigentlich Leute 
in Unternehmen dazu,
die bereitgestellte Technologie 
zu nutzen?
Es gibt mittlerweile auch zwei
Erweiterungen von diesem Modell Und dieses Modell ist
vor allen Dingen aus der 
Perspektive
geschaffen worden damals.
Wie kriegen wir eigentlich Leute 
in Unternehmen dazu,
die bereitgestellte Technologie 
zu nutzen?
Es gibt mittlerweile auch zwei
Erweiterungen von diesem Modell
oder auch ein paar mehr kleinere 
Erweiterungen noch,
die es dann mehr auf
die Konsumentenperspektive 
erweitert haben.
Aber das Grundmodell und das 
ist,
was ich Ihnen beibringen möchte.
Und ich dachte eigentlich,
ich könnte es relativ schnell 
machen,
aber weil es so wichtig ist,
sprechen wir doch ein paar 
Minuten drüber.
Dieses Grundmodell, das ist 
wichtig zu verstehen.
Auf der einen Seite wurde 
argumentiert,
ob meine Mitarbeiter in
meinem Unternehmen eine 
Technologie,
die ich bereitstelle,
benutzen und das gilt auch 
grundsätzlich für Kunden
mit ein paar Abwandlungen ist,
ob es sogenannte Facilitating 
conditions gibt.
Habe ich einen Hilfscenter,
habe ich in meiner Organisation 
ein einen Lehrgang,
nenne ich es jetzt einfach mal
for lack of a better world,
wo mir beigebracht wird,
wie ich mit dem System 
interagiere.
Habe ich einen IQ, habe ich 
Gruppen Arbeitsgruppen,
die sich mit dem System 
beschäftigen,
habe ich die Möglichkeit,
bestimmte Fehler von diesem 
System",11.05579996,1,"The generated answer is semantically consistent with the ground truth. Both correctly state that according to Ockham's Razor, simpler models that need less information are preferred.",1,"The generated answer is faithful. [cite_start]The context explains that Ockhams Razor argues for preferring a model that is 'so einfach wie mÃ¶glich' (as simple as possible) [cite: 1706][cite_start], meaning one that 'weniger Informationen benÃ¶tigt, um eine gute Vorhersage zu machen' (needs less information to make a good prediction)[cite: 1707].",1,"The context directly answers the question. It explains the principle of Ockhams Razor, stating one 'sollte ein Modell laut diesem Ockhams Razor bevorzugen, was weniger Informationen benÃ¶tigt, um eine gute Vorhersage zu machen' (should prefer a model according to Ockhams Razor that requires less information to make a good prediction)."
"In the paper 'The Productivity J-Curve' by Brynjolfsson et al., what does the Fortune 500 enterprise software company specialize in?",The company specializes in providing business process software for small and medium-sized U.S. businesses.,The context doesn’t provide information about the Fortune 500 company specialization discussed in the “The Productivity J-Curve” paper.,"Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. 23. Juli 2025
MachineLearning für Management Entscheidungen (MLME)Lecture11Prof. Dr. Kevin BauerLehrstuhl für Spieltheoretische und Kausale Künstliche Intelligenz 8. Mai 2025
MachineLearning für Management Entscheidungen (MLME)Lecture2Prof. Dr. Kevin BauerLehrstuhl für Spieltheoretische und Kausale Künstliche Intelligenz",5.973920822,0,"The generated answer is a refusal to answer, stating the information is not in the context. The ground truth provides a specific, factual answer. The answers are contradictory.",0,"The generated answer is not faithful. [cite_start]The retrieved context does not mention a Fortune 500 enterprise software company or what it specializes in. The context is a general course description for 'MachineLearning fÃ¼r Management Entscheidungen'[cite: 1731, 1732].",0,The context is entirely irrelevant. It describes a model explaining technology adoption and its extensions. It contains no information about a Fortune 500 company from the 'Productivity J-Curve' paper.
"According to the document, what is the economic decision rule for an investor?","'Invest'  if  p ⋅U (15,15)+ (1−p) ⋅ U(0,20) ≥U (10,0). 'Not invest' otherwise.","Laut dem Dokument gilt die folgende wirtschaftliche Entscheidungsvorschrift für einen Investor:

„Investiere“ iff 𝑝⋅𝑈15,15+1−𝑝⋅𝑈0,20≥𝑈(10,0) „Not invest“ otherwise“

Das bedeutet, der Investor soll investieren, wenn die Wahrscheinlichkeit (𝑝), dass der Kreditnehmer eine Rücküberweisung tätigt, multipliziert mit der Nutzenfunktion U15,15+1 – p*U0,20, größer oder gleich der Nutzenfunktion U(10,0) ist. Andernfalls soll er nicht investieren.","8. Mai 2025
Data driven decision-makingWhat you implicitly did (probably) are two parts:•Compared how they feel about certain outcomes•Assigned a probability 𝑝 that the borrower would make a re-transfer Choose the strategy that maximizes your „utility“ (whatever this is)Economic decision rule for investor: „Invest“  iff  𝑝⋅𝑈15,15+1−𝑝⋅𝑈0,20≥𝑈(10,0)  „Not invest“ otherwise
12
Investor: 15 mil €Startup : 15 mil €Invest 10 mil €You(the investor)
Not invest 0 €
StartupWork hard and pay back
Work a little and run away with moneyInvestor: 0 €Startup : 20 mil €
Investor: 10 mil €Startup : 0 mil € 8. Mai 2025
Data driven decision-making: an exampleConsider the following economic transaction
11
Investor: 15 mil €Startup : 15 mil €Invest 10 mil €You(the investor)
Not invest 0 €
StartupWork hard and pay back
Work a little and run away with moneyInvestor: 0 €Startup: 20 mil €
Investor: 10 mil €Startup: 0 €
What would you do, and why? bekommt?
Sie als Manager haben zwar eine 
Prediction,
Wo ist der State of the World 
Tomorrow?
Aber sie selber müssen noch 
entscheiden,
Was sind die Konsequenzen 
gegeben?
Ich mache eine bestimmte Aktion.
Wenn Sie investieren, Sie 
wissen,
der Markt steigt Sie 
investieren,
müssen Sie immer noch 
vorhersagen Vorhersagen nicht,
aber Sie müssen für sich selber 
einschätzen,
um die Wörter nicht zu 
vermischen.
Was passiert mit meinem 
Unternehmen in der langen Frist,
wenn ich denn wirklich 
investiere
und der Aktienkurs steigt?
Investiere ich in eine Aktie,
die zum Beispiel von der General 
Public geschenkt wird?
Es ist eine Aktie, die irgendwie
negative Konsequenzen für mich 
hat.
All das muss ich als Mensch 
weiter durchdenken.
Die Maschine per se
gibt mir nur Informationen
erstmal über die 
Wahrscheinlichkeit.
Es ist ein Signal, das ich aber 
auch ignorieren kann.
Das ist was ich möchte Sie sich 
mitnehmen.
Wir haben ein Signal durch die 
Maschine,
die uns eine Sache sagen kann,
aber den Rest muss ich selber 
einschätzen.
Und als Beispiel davon Das fand 
ich immer ganz schön.
Das ist ein wirklich
so passierte Konversation 
zwischen Jerry Reinsdorf.
Es war damals der der Manager,
der weiß gar nicht,
ob es schon die Bulls waren,",11.96639109,1,The generated answer is semantically consistent with the ground truth. Both provide the correct economic decision rule for the investor in the given scenario.,1,"The generated answer is faithful. [cite_start]The context displays a slide with the exact title 'Economic decision rule for investor' and provides the formula: 'â€žInvestâ€œ iff ð‘â‹…ð‘ˆ(15,15)+(1âˆ’ð‘)â‹…ð‘ˆ(0,20)â‰¥ð‘ˆ(10,0) â€žNot investâ€œ otherwise'[cite: 1734].",1,"The context directly answers the question. It provides the economic decision rule for an investor in a clear, formatted equation: 'â€žInvestâ€œ iff ð‘â‹…ð‘ˆ(15,15)+(1âˆ’ð‘)â‹…ð‘ˆ(0,20)â‰¥ð‘ˆ(10,0) â€žNot investâ€œ otherwise'."
"According to the document, what are two phases of a productivity pattern that emerge when a General-Purpose Technology diffuses?",A short-run dip and a long-run rebound.,"Laut dem Dokument treten bei der Ausbreitung einer Allzwecktechnologie zwei Phasen eines Produktivitätsmusters auf:

1.  **Zuerst geht die Produktivität runter.** Die Produktivität sinkt zunächst, weil Investitionen in Schulungen, Infrastruktur und die Entwicklung von Know-how erforderlich sind.
2.  **Danach geht die Produktivität steil nach oben.** Nach diesen anfänglichen Investitionen steigt die Produktivität schnell an.","der Produktivität, dann sehen 
wir,
dass am Anfang bei vielen 
Technologien eigentlich
und das ist ein Average
erstmal die Produktivität runter 
geht.
Wir sind sozusagen an der 
unteren dieser Kurve,
diesem unteren Halbkreis von dem 
J.
Und erst danach geht es 
eigentlich nach oben.
Wir haben eine massiven 
Produktivität.
Das ist wie gesagt der die
Veränderung wir sehen hier ist 
erstmal runtergeht,
dann geht steil nach oben und 
das ist ein Phänomen,
was wir diese Kurve nennen.
Und das sehen wir immer wieder 
mit
verschiedenen General purpose 
technology.
Und das hat ganz einfache 
Gründe, nämlich,
dass am Anfang,
wenn wir in diese Technologien 
investieren,
wie in GPT investiert wird,
haben wir erstmal riesige 
anfängliche Investitionen,
die sich nicht sofort auszahlen.
Wir haben massive Investitionen,
beispielsweise darin,
dass Leute die Technologie 
richtig nutzen können.
Ich muss Schulungen machen,
ich muss die Infrastruktur 
schaffen,
ich muss die Anbindung an meine 
Datenbank schaffen.
Ich muss ganz viele intangible 
Assets Know how kreieren,
um dann letztlich auch wieder 
weitere Innovationen.
Wir reden über General Purpose 
Technologien,
komplementäre Investitionen 
anzuregen.
Und das führt natürlich dazu, müssen,
unsere Datenpipelines, unsere 
Sensorik,
unsere Organisationsprozesse 
allgemein,
die wir wie in diesem
Beispiel der Fabriken mit der 
Steam Engine,
mit Electricity wir abändern 
müssen.
Und das hilft uns dann 
letztlich,
das volle Potenzial dieser 
Innovation herauszuarbeiten.
Jetzt ist aber die Frage 
vielleicht
haben Sie es gehört oftmals die 
Diskussion.
Na ja, warum sehen wir denn 
jetzt
noch eigentlich keine 
Produktivitätssteigerung?
Ja, viele Manager stellen sich
hin und sagen Wir haben so viel 
investiert,
passiert ja gar nichts, Außer im 
Software Development.
Da sehen wir wirklich massive 
Anstiege in
der Produktion, in der 
Produktivität.
Aber wir sehen es nicht 
grundsätzlich überall.
In vielen Organisationen kostet 
bisher einfach nur Geld.
Und das ist ein Phänomen,
das ist gar nicht neu.
Das nennen wir die Kurve.
Wie so ein J. Wie Sie hier sehen 
können,
wo wir bei der Einführung der 
Technologie,
wenn wir hier die Jahre auf der 
Achse haben
und hier die Veränderung in
der Produktivität, dann sehen 
wir,
dass am Anfang bei vielen 
Technologien eigentlich
und das ist ein Average
erstmal die Produktivität runter 
geht.
Wir sind sozusagen an der 
unteren dieser Kurve,
diesem unteren Halbkreis von dem 
J. Und dieses Modell ist
vor allen Dingen aus der 
Perspektive
geschaffen worden damals.
Wie kriegen wir eigentlich Leute 
in Unternehmen dazu,
die bereitgestellte Technologie 
zu nutzen?
Es gibt mittlerweile auch zwei
Erweiterungen von diesem Modell
oder auch ein paar mehr kleinere 
Erweiterungen noch,
die es dann mehr auf
die Konsumentenperspektive 
erweitert haben.
Aber das Grundmodell und das 
ist,
was ich Ihnen beibringen möchte.
Und ich dachte eigentlich,
ich könnte es relativ schnell 
machen,
aber weil es so wichtig ist,
sprechen wir doch ein paar 
Minuten drüber.
Dieses Grundmodell, das ist 
wichtig zu verstehen.
Auf der einen Seite wurde 
argumentiert,
ob meine Mitarbeiter in
meinem Unternehmen eine 
Technologie,
die ich bereitstelle,
benutzen und das gilt auch 
grundsätzlich für Kunden
mit ein paar Abwandlungen ist,
ob es sogenannte Facilitating 
conditions gibt.
Habe ich einen Hilfscenter,
habe ich in meiner Organisation 
ein einen Lehrgang,
nenne ich es jetzt einfach mal
for lack of a better world,
wo mir beigebracht wird,
wie ich mit dem System 
interagiere.
Habe ich einen IQ, habe ich 
Gruppen Arbeitsgruppen,
die sich mit dem System 
beschäftigen,
habe ich die Möglichkeit,
bestimmte Fehler von diesem 
System",11.25601649,1,The generated answer is semantically consistent with the ground truth. Both correctly identify the two phases as a short-run dip and a long-run rebound.,1,"The generated answer is faithful. [cite_start]The context describes the J-Curve as a phenomenon where, when a new technology is introduced, 'erstmal die ProduktivitÃ¤t runter geht' (productivity first goes down), which represents the 'short-run dip', and 'danach geht es eigentlich nach oben' (then it actually goes up), which represents the 'long-run rebound'[cite: 1746, 1747, 1761].",1,"The context directly answers the question. It describes the 'J-curve' phenomenon, explaining that 'am Anfang bei vielen Technologien...erstmal die ProduktivitÃ¤t runter geht' (in the beginning, with many technologies, productivity first goes down), which is the short-run dip, and 'erst danach geht es eigentlich nach oben' (only after that does it actually go up), which is the long-run rebound."
What is the date of the first lecture?,45771,Der 12. Juni 2025.,"Informationen zur Vorlesung: Gehalten am Do. 12:00 bis 16:00; wöchentlich vom 24.04.2025 bis 24.07.2025; Ort: Hörsaalzentrum Westend - HZ 12 So. Herzlich Willkommen zur 
Vorlesung Nummer zwei.
Ich freue mich natürlich zu 
sehen,
dass der Raum noch nicht 
komplett leer ist.
Auch wenn jetzt die 
Einführungsveranstaltung
vorbei ist und Sie sich 
überlegen konnten,
ob sie diesen Kurs machen 
wollen.
Von daher sehr schön,
dass Sie noch dabei sind.
Nachdem ich Ihnen schon einmal 
auf die
Nerven gegangen bin mit Machine 
Learning.
Heute geht es direkt dort 
weiter,
wo wir letztes Mal aufgehört 
haben.
Wenn Sie sich erinnern wir haben 
angefangen,
darüber zu sprechen,
was Machine Learning von einer 
ganz,
ganz konzeptionellen Idee 
liefern kann.
Wir haben ein bisschen 
Terminologie
eingeführt und damit würde
ich gerne mit Ihnen anfangen.
Sozusagen, um alle hier wach zu 
machen, auch mich selber.
In den Vorlesungsmodus zu 
begeben.
Machen wir einen kurzen Recap 
auf zwei Folien.
Wenn Sie sich erinnern, sind das 
hier
Kernelemente von Machine 
Learning.
Sie können jede Machine Learning 
Funktion,
jedes Modell sogar GPT in
dieser Gleichung hier 
ausdrücken.
Wir haben drei verschiedene 
Komponenten.
Wir haben hier dieses Hütchen,
wir haben das fix und wir haben 
hier dieses Y Hütchen.
Meine erste Frage an Sie Was war 
das? F Hütchen.
Yes, genau richtig. 12. Juni 2025
Ourfirstsimplemodel",3.632798195,0,"The generated answer states the date is June 12, 2025, while the ground truth states it is April 24, 2025. The answers are factually contradictory.",1,"The generated answer is faithful. [cite_start]The context gives the date range for the weekly lecture as 'vom 24.04.2025 bis 24.07.2025'[cite: 1769], making April 24, 2025, the first lecture.",0,"The context is completely irrelevant. While it mentions the date range for the lecture series (24.04.2025 to 24.07.2025), it provides no information about which specific date corresponds to the first lecture."
What is the purpose of the tutorial sessions?,To work on applications (case studies & coding).,"Basierend auf dem Text ist der Zweck der Tutoriumsitzungen folgendermaßen:

*   **Durchlaufen einer strukturierten Methodik:** Die Sitzungen folgen einer bestimmten Reihenfolge: Business Understanding, Daten und Datenaufbereitung, Modellierung, und Evaluation.
*   **Erklärung der Herkunft von Vorhersagen:** Es geht darum zu verstehen, woher eine Vorhersage stammt.
*   **Unterscheidung zwischen menschlicher und maschineller Unterstützung:** Die Sitzungen untersuchen, welche Arten von Aufgaben besser von Menschen und welche von Maschinen gelöst werden können (subjektive vs. objektive Aufgaben).
*   **Erklärung von komplexen Systemen:** Es werden auch komplexe Systeme wie automatisierte Flugzeuge und selbstfahrende Autos erklärt, wobei der Mensch als Sicherheitsmechanismus eingebunden ist.

Zusammenfassend lässt sich sagen, dass die Tutoriumsitzungen darauf abzielen, ein Verständnis für den gesamten Prozess der Data Science, von der Problemdefinition bis zur Evaluation, zu vermitteln.","damit umzugehen.
Das heißt, hier befinden wir uns 
eigentlich immer.
Und vielleicht haben Sie das 
schon gehört in
so einer Sandbox Environment.
Wir haben ein abgeschlossenes,
in sich abgeschlossenes System,
wo bestimmte ausgesuchte 
Mitarbeiter
ihre Data Science Kollegen
und relevante Kollegen aus den 
Abteilungen,
für die dieses System relevant 
wird,
die entwickelten Modelle nutzen 
können,
Feedback geben können, bevor wir 
es live schalten und am
Ende massiv viel Investitionen 
in den Sand setzen.
Und wie gesagt, häufiger als 
nicht müssen wir zurück
an unseren Schreibtisch und den
ganzen Prozess wieder von vorne 
beginnen.
Und vielleicht sind wir 
irgendwann glücklich und
haben ein tolles Modell
gefunden und dann geht es ans 
Deployment.
Das färbe ich jetzt hier extra 
nicht ein.
Denn Deployment werden wir hier
uns nicht mit beschäftigen.
Also wir gehen bis zur 
Evaluation.
Wir fangen an, auch von dem Stil 
der Vorlesung her.
Business Understanding.
Wir befinden uns gerade hier.
Dann werden wir anfangen,
über Daten und Datenaufbereitung 
zu sprechen.
Dann werden wir verschiedene 
Modelle durchgehen
und dann sprechen wir über die 
Evaluation dieser Modelle.
Das Deployment per se.
Wir werden Ihnen da gerne zumindest durch eine bestimmte
Methode mir ein bisschen 
erklären kann.
Woher eigentlich diese 
Vorhersage stammt.
Sie sehen auch hier diese Task 
factors.
Die Natur des Tasks ist das,
worüber ich gerade gesprochen 
habe.
Spielt hochgradig eine Rolle,
wo wir tendenziell sehen,
dass Task, die wir als sehr 
subjektiv wahrnehmen,
wie Film Recommendations,
Wenn Menschen sich gegenseitig 
Witze erzählen sollen,
Einschätzungen davon,
ob ein bestimmter Urlaubsort 
interessant ist oder nicht,
diese ganzen sehr
subjektiv wahrgenommenen 
Aufgaben präferieren
wir eher von Menschen,
Hilfe anzunehmen,
dass von Menschen lösen zu 
lassen als von Maschinen.
Wohingegen für komplexe
objektive Tasks wie Berechnungen 
von Aktienkursen,
Einschätzungen von 
CompanyDefaults etc.
Da tendieren Menschen von dem,
was die Forschung aktuell zeigt 
und es
ist wie gesagt ein sehr aktives 
Feld dazu,
eher Hilfe von Maschinen 
anzunehmen.
Gibt es irgendwelche Fragen 
soweit?
So, jetzt kommen wir zu den zwei 
Modes of Collaboration.
Auch wieder sehr dichotom 
gedacht als über
Kategorien haben wir zwei und es 
gibt eine Strömung,
die mittlerweile so ein bisschen 
sagt Naja,
eigentlich haben wir drei 
Kategorien.
Hier streiten wir uns aber nicht 
drüber, um für abgewandelte Gewichte in 
den Turbinen,
die größer gemacht wurden, zu 
korrigieren.
Und diese Systeme haben dazu 
geführt,
dass sie bei bestimmten 
Informationssignalen,
die eingegangen sind,
einfach korrigieren wollte und 
die Nase nach
unten gemacht hat von dem 
Flieger in der Luft,
was dann dazu geführt hat.
Natürlich, wenn der Pilot das
nicht mehr korrigieren kann und
die Nase einfach nach unten 
gedrückt wird,
egal was der Pilot macht, 
automatisiert,
dass die Flieger abgestürzt 
sind.
Ähnliches Beispiel auch wieder 
mit Todesfällen ist,
wenn automatisierte Autos nicht 
funktionieren.
Da sitzt zwar ein Fahrer drin,
das ist eines der der Beispiele,
wo jetzt auch ein Urteil 
gesprochen wurde.
Vor ein paar Wochen in den Waymo 
Cars in Kalifornien,
die schon von alleine fahren,
haben sie meistens trotzdem noch 
einen Human Driver.
Aber dieser Human Driver ist 
nicht in
Entscheidungsgewalt
und muss sehr schnell reagieren 
manchmal.
Also wir haben automatisierte
Prozesse und eigentlich ist
da irgendwie noch so ein Mensch 
mit drin.
Der Mensch kann aber eigentlich 
nicht mehr eingreifen
und es hat dazu geführt,
dass dieser Safety Driver,
der drin war, das war irgendwie 
eine ältere Dame,
die irgendwie übermüdet war etc.",17.33801508,0,"The generated answer describes the purpose of the main lecture sessions, not the tutorial sessions. The ground truth correctly identifies the purpose of the tutorials is for applied work like case studies and coding. The answers are not semantically consistent.",0.5,"The generated answer is partially faithful. [cite_start]It correctly states that the tutorial sessions involve applications and case studies ('Wir werden verschiedene Modelle durchgehen und dann sprechen wir Ã¼ber die Evaluation dieser Modelle' [cite: 1793]). However, the claim about 'coding' is not explicitly supported. [cite_start]The main course description mentions 'praktischen Programmieraufgaben'[cite: 894], but this is not explicitly linked to the tutorial sessions described in this specific context.",0,"The context is irrelevant. It describes the overall structure of the course, breaking it down into different learning blocks (Business Understanding, Data Preparation, Modeling, Evaluation). It does not mention the purpose of specific tutorial sessions or case studies."
"According to the document, what is a Class 2 customer?",A Profitable customer.,"Das Dokument enthält keine Informationen über ""Klasse 2 Kunde"". Es beschreibt den Einsatz von Machine Learning, insbesondere im Kontext von Kreditwürdigkeitsprüfungen und der Verarbeitung von Kundendaten (wie Alter, Einkommen, etc.) durch Systeme wie Chat GPT.","Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. eigentlich besser als Maschine 
alleine?
Ist der Banker? Hat er 
eigentlich einen Beitrag dazu?
Macht er das Ganze schlechter?
Vielleicht sogar? Und dann?
Auf der anderen 
Konsumentenseite,
können wir untersuchen Wie 
reagiert eigentlich
der Banker, der Kunde darauf?
Möchte der Kunde eigentlich,
dass der Mensch mit ihm Lob
ist oder ist ihm das scheißegal?
Auf Deutsch gesagt das haben wir
uns angeschaut und wie gesagt,
das ist jetzt der 
Schnelldurchlauf,
weil ich sie hier nicht zu lange 
halten möchte.
Frage Nummer eins Macht der 
Mensch
es besser oder schlechter?
Naja, if anything macht der 
Mensch eher schlechter.
Wir sehen, die Maschine alleine 
hat eine
Accuracy aus den
73 % Mensch plus Maschine ist 
die Beratung richtig?
In 70 % der Fälle ein bisschen 
schlechter.
Statistisch gesehen haben unsere 
Tests aber gezeigt,
dass es nicht signifikant ist.
Deswegen ist so ein bisschen die
Message hier If anything macht 
der Mensch nicht besser,
aber ganz vorsichtig gesagt,
er macht es auch nicht 
statistisch
nachweislich schlechter.
Auch wichtig zu sehen der Mensch 
macht ein bisschen was.
Ja, wir sehen nicht,
dass der Mensch einfach die
Entscheidung der KI weitergibt,
sondern der interagiert 
wirklich.
Denkt anscheinend drüber nach. Dann haben wir die zweite 
Komponente.
Das war das XML. Was ist das?.X. 
Jemand eine Idee?
Jetzt dahinten? Genau das sind 
die Daten,
die wir in diese Maschine 
reintun.
Wir haben zum Beispiel, wenn Sie 
überlegen,
Sie interagieren mit Chat GPT 
auf der Website.
Sie prompten dieses System.
Sie geben einen Input Dieses ics 
kann der Text sein.
Dieses Ichs kann aber auch 
beispielsweise in Banken,
die ein Machine Learning Modell 
haben,
um zu berechnen, ob jemand 
kreditwürdig ist oder nicht.
Kann dieses Ichs eine Person 
repräsentieren?
Es können die Eigenschaften der 
Person sein,
das Alter der Person,
die Anzahl der Kinder, der 
Person,
das Einkommen der Person und 
vieles Weiteres.
Es kann sogar so weit gehen, 
dass wir Filme,
Audiofiles reinpacken 
unstrukturierte Daten ähnlich zu
texten und noch ein bisschen 
komplexer,
um dann wieder eine Vorhersage 
zu
machen und dann sind wir schon 
bei
was da rauskommt.
Die Vorhersage.
Jetzt habe ich es leider schon 
preisgegeben,
nämlich das hier.
Das ist unsere Prädiktion,
auf Englisch auch wieder 
indiziert durch das Hütchen.
Das Hütchen zeigt uns an dieser 
Stelle,
dass wir nicht ganz explizit 
wissen,
ob das eigentlich das reale 
Outcome ist.
Wenn Sie eine Machine Learning",7.29842186,0,"The generated answer is a refusal to answer, stating there is no information about a 'Class 2 customer'. The ground truth provides a specific definition. The answers are contradictory.",0,The generated answer is not faithful. The retrieved context contains no information about a 'Class 2 customer'. [cite_start]The context discusses using machine learning to determine creditworthiness based on features like age and income[cite: 1829].,0,"The context is entirely irrelevant. It discusses machine learning models for creditworthiness and the data they use (age, income, etc.). It does not contain any information about a customer classification system, let alone a 'Class 2 customer'."
What companies were mentioned as having faced discrimination and harassment allegations in 2020?,"Amazon, McDonald’s, and Pinterest.","Laut dem Artikel wurden im Jahr 2020 folgende Unternehmen mit Vorwürfen von Diskriminierung und Belästigung genannt:

*   Amazon
*   McDonald’s
*   Pinterest","against major companies like Amazon , 
McDonald’s, and Pinterest: These are some of 
the year ’s high -profile legal battles.  Business 
Insider. https://www.businessinsider.com/
every-company-that-was-sued-discrimination-
and-harassment-lawsuits-2020-2021-1  
Srivastava, M., Heidari, H., & Krause, A. (2019). 
Mathematical notions vs. human perception of 
fairness: A descriptive approach to fairness for 
machine learning. Proceedings of the 25th 
ACM SIGKDD International Conference on of inadvertently perpetuating or igniting algorithmic 
discrimination if these individuals engage in 
discriminatory practices. In this context, efforts aimed at 
identifying and mitigating (subconscious) discriminatory 
practices of organizational decision  makers, such as 
awareness training, become an indispensable 
complementary element to ensure that continuously 
updated ML models exhibit desirable behaviors. 
2 Theoretical and Conceptual 
Background 
In this section, we first provide the conceptual 
underpinnings of algorithmic discrimination. 
Subsequently, we discuss the literature gaps our work 
aims to address. that nonobjective variables, such as inadequate information,
contribute to biased outcomes (Dickinson and Oaxaca, 2009).
Lastly, we have the antecedent market discrimination hypothesis
as the fourth category.
Statistical discrimination theory. Statistical discrimination refers
to prejudice from assessment criteria that generalize group
characteristics to individuals (Tilcsik, 2021). It arises due to
limitations in employers’research techniques or the cost con-
straint of obtaining information in the asymmetry between
employers and job seekers. Even without monopolistic power,
statistical discrimination can occur in the labor market due to
information-gathering methods. Employers are primarily inter-
ested in assessing candidates ’ competitiveness when making
recruitment decisions. However, obtaining this information
directly is challenging, so employers rely on various indirect
techniques.
Discrimination carries both individual and societal economic
costs. The social cost arises from the decrease in overall economic
output caused by discrimination. However, this is still deemed
efﬁcient under imperfect information and aligns with the
employer’s proﬁt maximization goal. Therefore, it is likely that",6.686689138,1,"The generated answer is semantically consistent with the ground truth. Both correctly list Amazon, McDonald's, and Pinterest.",1,"The generated answer is faithful. [cite_start]The context lists 'Amazon, McDonaldâ€™s, and Pinterest' as companies facing 'high-profile legal battles' related to discrimination and harassment in 2020[cite: 1835].",1,"The context directly answers the question. It lists 'Amazon, McDonaldâ€™s, and Pinterest' as companies facing high-profile legal battles related to discrimination in 2020."
What is the URL for the document by Cowgill and Tucker (2019)?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3361280,Die URL des Dokuments von Cowgill und Tucker (2019) ist: https://aisel.aisnet.org/jais/vol25/iss4/9,"Informationen zur Vorlesung: Gehalten am Do. 12:00 bis 16:00; wöchentlich vom 24.04.2025 bis 24.07.2025; Ort: Hörsaalzentrum Westend - HZ 12 DOI: 10.17705/1jais.00853 
Available at: https://aisel.aisnet.org/jais/vol25/iss4/9 
This material is brought to you by the AIS Journals at AIS Electronic Library (AISeL). It has been accepted for 
inclusion in Journal of the Association for Information Systems by an authorized administrator of AIS Electronic 
Library (AISeL). For more information, please contact elibrary@aisnet.org. So lassen Sie uns beginnen. 
Herzlich willkommen.
Vorlesung drei.
Sind wir mittlerweile 
angekommen?
Also, wir nehmen langsam ein 
bisschen Fahrt auf.
Wie Sie vielleicht gemerkt 
haben,
hatte ich vergessen, heute 
Morgen
die Folien hoch zu laden.
Aber jetzt gerade live gemacht.
Das heißt, jetzt können Sie die
auf Olat wie gewohnt für sich 
runterladen.
Die Zusatzmaterialien wird
die Mitarbeiterin noch 
hochladen.
Wir sind uns noch nicht so ganz 
sicher,
was wir Ihnen da zur Verfügung 
stellen wollen,
ohne sie da irgendwie mit zu 
viel Material zuzuschmeißen,
wie wir es die letzten oder das 
letzte
Mal auch schon gemacht haben,
würde ich gerne wieder ganz kurz 
einen Recap machen.
Zu sehr zentralen Themen,
auf die wir heute auch wieder 
Bezug nehmen werden,
die uns helfen, das große Ganze 
zu sehen.
Wir haben in der allerersten 
Vorlesung
so ein bisschen die Motivation,
warum Machine Learning wichtig 
ist, auf einer ganz,
ganz High Level Perspektive uns 
angeschaut,
sind dann in eine Case Study 
gemacht,
wo ich ihnen gezeigt habe,
wie man Machine Learning 
anwenden kann.
Nicht immer nur zu negativen 
Aspekten,
aber diese Predictions,
die Machine Learning uns liefern 
kann,
wie man die auch dazu nutzen 
kann,",6.076426983,0,The generated answer provides an incorrect URL. The ground truth provides the correct URL. The answers are factually contradictory.,0,The generated answer is not faithful. The provided URL is incorrect. [cite_start]The context provides the correct URL for the document as 'https://aisel.aisnet.org/jais/vol25/iss4/9'[cite: 1851]. The URL in the answer leads to a different domain (ssrn.com).,0,"The context provides a URL to the Journal of the Association for Information Systems (https://aisel.aisnet.org/jais/vol25/iss4/9), but this is not the specific URL for the Cowgill and Tucker (2019) paper as requested."
"In the 'Feedback Loops in Machine Learning' study, what did the authors note about the batch learning methodology?",This technique retrains the learning algorithm on all the currently available training data.,"Die Autoren der Studie „Feedback Loops in Machine Learning“ haben festgestellt, dass kontinuierliches Aktualisieren von Modellen, auch Batch-Learning genannt, nicht vollständig die wirtschaftliche Effizienz auf das Niveau zurückbringen konnte, das ohne anfängliche Label-Ungleichgewichte in den Trainingsdaten erreicht worden wäre.","15. Mai 2025
(Unwanted) feedback loops
A core benefit of machine learning: continued learning•Tackles data drift issues •Update model using newly collected data regularly•Retraining v. incremental learning proceduresHowever, ML predictions influence decisions•Selective labels problems(Lakkarajuet al. 2017)•Can endogenize dataavailable for updates19
DataML ModelPredictionDecision
Feedback Feedback Loops in Machine Learning 
 
811 
3.2 Previous Empirical Studies 
We buil t our simulations on two secondary datasets, 
collected by several authors of this paper as part of 
different empirical studies. Study A was an incentivized 
field study conducted over three years from 2016 to 
2019. Study A measured participant s’ behavior in the 
investment game  defined above  in their  role as 
borrowers. The data from Study A allow ed us to 
develop an ML model predicting borrowers’ repayment 
decision and serves as the foundation for simulating 
borrower behavior. Study B, conducted in December 
2020, was an incentivized online experiment where 
participants engaged in the outlined investment game in 
the role of investors. In this experiment, investors could 
access an ML model predicting borrowers ’ repayment 
likelihood. Notably, this model, along with the 
borrowers with whom investors from Study B 
interacted, originated from Study A data. The data from 
Study B provide d the basis for simulating investor 
decisions. We present the exact instructions given in 
these studies in Appendix B.1. 
Study A: At the onset of each semester, first -semester 
economics students from a large German university were Feedback Loops in Machine Learning 
 
817 
Despite this result, the left panel in Figure 5 indicates 
that continuous updating could not entirely restore 
economic efficiency to the level it would have attained 
in the absence of initial label imbalances in the training 
data. Nevertheless, our findings underscore significant 
and noteworthy improvements in economic efficiency 
concerning female borrowers. For male borrowers, the 
development of both economic efficiency measures was 
nearly identical, regardless of the presence or absence of 
initial label imbalances for women in the training data. 
In presenting results for the most extreme label 
imbalance scenario —where no positive (repaying) 
examples exist for women —a question naturally 
arises concerning the role of the initial degree of label 
imbalance. Does the initial degree of label imbalance 
influence the ability of continuous updating to 
mitigate algorithmic discrimination and enhance 
economic efficiency?  
We address this question using regression analyses 
reported in Table 1 (See Figures A1-A6 in the Appendix 
for a graphical illustration). Columns (1) and (2) use the 
gender gap in the ML model ’s share of positive",7.969775677,1,The generated answer is semantically consistent with the ground truth. Both correctly state that the batch learning methodology involves retraining the algorithm on all currently available data.,0,"The generated answer is not faithful. It claims that batch learning could not 'entirely restore economic efficiency'. The provided context does not use the term 'batch learning'. [cite_start]It discusses continuous updating and notes that in one scenario, it 'could not entirely restore economic efficiency to the level it would have attained in the absence of initial label imbalances'[cite: 1868]. The generation incorrectly uses a technical term not found in the source.",0.9,"The context is highly relevant. While it doesn't use the term 'batch learning', it describes the process of updating the ML model 'by training it from scratch on the expanded dataset'. This is the definition of batch learning. The other parts of the context discuss the findings related to this continuous updating, noting its limitations."
"According to the document, what is one practical implication for organizations regarding continuously updated ML models?",Organizations should invest in comprehensive anti-discrimination and unconscious bias training for their decision makers.,"Gemäß dem Dokument ergibt sich für Organisationen folgende praktische Implikation hinsichtlich kontinuierlich aktualisierter ML-Modelle:

Wenn Menschen die endgültigen Entscheidungen in ML-gestützten Prozessen treffen, besteht das Risiko, dass sie diskriminierende Praktiken anwenden und die Modelle kontinuierlich aktualisieren, was zur unbeabsichtigten Verstärkung von algorithmischer Diskriminierung führen kann. Es werden Maßnahmen zur Identifizierung und Minderung solcher (unbewussten) diskriminierenden Praktiken gefordert.","Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. long term. Organizations adopting a dynamic 
sociotechnological perspective might succeed in 
creating a more equitable, effective, and efficient use 
of ML models. This approach aligns with societal 
expectations and regulatory requirements. 
From a policymaker ’s perspective, our findings 
regarding human involvement become particularly 
significant in light of impending regulations that 
mandate human participation in ML decision -making 
processes. These regulations pertain to final decisions in 
high-risk scenarios such as loan approval and hiring 
processes, as outlined in Article 22 of the General Data 
Protection Regulation and the European Commission’s 
Artificial Intelligence Act. However, our findings 
indicate a potential risk when humans have the final say 
in ML -supported decision -making processes. If 
individuals engage in discriminatory practices and the 
models update continuously, there is a risk of 
unintentionally perpetuating or amplifying algorithmic 
discrimination, as human discrimination hinders the self-
correcting capacities of ML models. Therefore, in 
conjunction with these regulations, we advocate 
measures aimed at identifying and mitigating 
(subconscious) discriminatory practices by affecting ML systems’ functionality by explaining the 
interplay b etween continuous model updating and 
algorithmic discrimination. Despite its critical importance 
in developing countermeasures and refining policy 
recommendations, the complex interplay between 
algorithmic discrimination and continuous ML model 
updating remains an underexplored area in the literature.  
Second, our paper complements the nascent body of 
studies exploring the origins and impacts of 
algorithmic feedback loops (Burghardt & Lerman, 
2022; Cowgill, 2018). For instance, Lum and Isaac 
(2016) revealed that the iterative updates of a 
predictive poli cing system led to increased 
discrimination against minority groups. Similarly, 
Ensign et al. (2017) showed how feedback loops could",11.69082642,1,The generated answer is semantically consistent with the ground truth. Both highlight the need for organizations to implement anti-discrimination and unconscious bias training for human decision-makers who work with continuously updated ML models.,1,The generated answer is faithful. [cite_start]The context advocates for 'measures aimed at identifying and mitigating (subconscious) discriminatory practices by organizational decision makers' [cite: 1885] in light of regulations that mandate human participation in ML decision-making. This aligns with the generated answer about investing in anti-discrimination and bias training.,1,"The context directly answers the question. It states that due to regulations mandating human involvement, there is a risk of 'unintentionally perpetuating or amplifying algorithmic discrimination, as human discrimination hinders the self-correcting capacities of ML models.' As a result, it advocates for 'measures aimed at identifying and mitigating (subconscious) discriminatory practices by organizational decision makers,' which aligns with providing anti-discrimination training."
"According to the document, what is one impact of human discrimination on the self-correction capabilities of continuously updated ML models?",It impedes the self-correction abilities.,"Menschliche Diskriminierung behindert die Selbstkorrekturfähigkeiten von kontinuierlich aktualisierten ML-Modellen. Wenn Menschen zunehmend voreingenommene Einstellungen und Verhaltensweisen zeigen, haben ML-Modelle weniger die Möglichkeit, anfängliche Verzerrungen zu korrigieren. Diese Verzerrungen können sogar dazu führen, dass ML-Modelle, die ursprünglich auf ausbalancierten Daten trainiert wurden und keine algorithmische Diskriminierung aufweisen, zunehmend diskriminierende Verhaltensweisen zeigen.","discrimination. Biases in human decision-making may 
directly influence the behavior of continuously 
updated ML models. While modern machine learning 
models inherently possess the capability to  “unlearn” 
initial biases over time given sufficiently diverse and 
unbiased data, human bias es can impede this process. 
This insight is especially relevant in the current era of 
growing political and social divisions in human 
societies (e.g., Allcott et al., 2020). When people 
increasingly adopt biased attitudes and behaviors, 
biased, continuously updated ML models are less discrimination, as human discrimination hinders the self-
correcting capacities of ML models. Therefore, in 
conjunction with these regulations, we advocate 
measures aimed at identifying and mitigating 
(subconscious) discriminatory practices by 
organizational decision makers. These measures could 
serve as essential complementary elements to ensure that 
continuously updated ML models demonstrate desirable 
behaviors when organizations implement regulatory 
requirements that involve humans in the decision loop. 
5.4 Limitations and Future Research  
Like any study, this study also has limitations—which, 
we believe , provide valuable directions for future 
research to enhance our understanding of how 
algorithmic discrimination evolves in environments 
where ML models undergo continuous updates. One imbalance combined with high or very high levels of 
human discrimination (see Columns 4 and 5).  
In sum, these results emphasize that the capacity of 
continuous ML model updating to mitigate algorithmic 
discrimination critically relies on the absence of 
discriminatory behavior by human decision makers. If 
such behaviors persist —potentially giving rise to the 
initial label imbalance in the training data—continuous 
updating has a minimal effect on improving the ML 
model’s behavior toward the discriminated group. Our 
findings even suggest that human discrimination can 
cause ML models, originally trained on balanced data and 
displaying no algorithmic discrimination, to adopt 
increasingly discriminatory behaviors, as measured by 
statistical parity. In the context of our loan approval 
example, the results reveal that the efficacy of 
continuously updated ML models notably declines if a 
loan officer persistently discriminates against female 
applicants, regardless of the creditworthiness assessment 
generated by the ML model. Consequently, the ML 
model’s prediction may persistently demonstrate gender 
disparity across two key dimensions: the ML model ’s 
propensity to deem female applicants as creditworthy and",10.74926519,1,The generated answer is semantically consistent with the ground truth. Both correctly state that human discrimination impedes the self-correction capabilities of ML models.,1,"The generated answer is faithful. [cite_start]The context states that 'human discrimination hinders the self-correcting capacities of ML models' [cite: 1896] [cite_start]and that it can 'cause ML models, originally trained on balanced data... to adopt increasingly discriminatory behaviors'[cite: 1902]. This directly supports the claim that human discrimination impedes self-correction.",1,"The context directly answers the question. It states that 'human discrimination hinders the self-correcting capacities of ML models' and that 'human discrimination can cause ML models, originally trained on balanced data... to adopt increasingly discriminatory behaviors'."
"According to the document, what is the approximate percentage point change in the share of positive predictions for female borrowers when there is no human discrimination and the maximum label imbalance is present?",0.22,"Gemäß dem Dokument beträgt die etwaige Veränderung im Anteil positiver Vorhersagen für weibliche Kreditnehmer, wenn keine menschliche Diskriminierung vorliegt und das maximale Label-Ungleichgewicht vorliegt, 22%.","investors’ probability to invest with female borrowers. 
Figure 6 shows that the share of positive predictions  
(the two panels at the top) and false-negative rates (two 
panels at the bottom) for female borrowers depends on 
the level of human discrimination and the degree of the 
initial label imbalance . To illustrate the change over 
time in a parsimonious way, we pre sent the 
visualization for the first and the last iteration only.  
Figure 6 reveals that the effectiveness of continuously 
updating an ML model in mitigating algorithmic 
discrimination diminishes in the presence of 
discrimination by human decision makers. Specifically, 
the extent of human discrimination negatively impacts the 
growth of positive predictions for female borrowers 
across iterations, regardless of the initial label imbalance. 
For instance, a comparison of the upper two panels shows 
that at the maximum label imbalance (x-axis), the share 
of positive predictions (y-axis) for women increases from 
0% in Iterations 1 (left panel) to 22% in Iteration 100 
(right panel) if there is no human discrimination (z-axis). 
However, this growth is significantly curtailed, reaching 
merely 1.2%, 6.9%, 14.3% under very high, high, and investments with repaying borrowers in the lower two 
panels) for female borrowers from Iteration 1 to 100 , 
conditional on combinations of initial label imbalances 
(x-axis) and the extent of persistent human 
discrimination ( z-axis).15 Echoing our results on the 
role of human discrimination in mitigating algorithmic 
discrimination over time, we f ound that the ability of 
continuous updating to enhance economic efficiency 
decreases as human discrimination intensifies. For 
instance, a comparison of the upper two panels shows 
that when the initial label imbalance is at its maximum 
(x-axis), the share of game outcomes with female 
borrowers that match the perfect information 
benchmark (y-axis), grows from 42.3% In Iteration 1 
(left panel)  to 62.5% in Iteration 100 (right panel)  if 
there is no human discrimination ( z-axis). A similar 
comparison of the two panels at the bottom reveals that 
the share of investments with repaying borrowers also 
grows from 5.7% in Iteration 1 (left panel) to 34.9% in 
Iteration 100 (right panel). 
 
15 We present corresponding figures for male borrowers in 
Figures A9 and A10 in the Appendix. 
Conversely, under conditions of medium, high, and model to make an informed approval decision. The 
model often inaccurately predicts that female 
applicants are not creditworthy, while it is almost 
always correct for men. If these biased predictions lead 
the officer to deny loans to women more often than 
men, the bank will collect more data on male loan 
repayment behavior than on that of women. This 
escalating gender bias in the data used to update the 
ML model may exacerbate the model ’s inaccuracies, 
particularly in its predictions for women. This could 
potentially initiate a self -perpetuating feedback loop, 
where the disparity in prediction quality between men 
and women widens (e.g., Kleinberg et al., 2018) . It is 
important to note that such feedback loops can arise 
not only from initially biased ML models but also from 
loan officers who independently discriminate against 
female applicants, even when using ML predictions. 
As a result, training data can be come increasingly 
unbalanced and distorted due to human behavior alone. 
In such a scenario, if the ML model is continually 
updated with the newly generated data, even an 
initially unbiased system may eventually start to 
discriminate against women.",8.990552187,1,The generated answer is semantically consistent with the ground truth. Both correctly state the percentage point change is 22%.,1,"The generated answer is faithful. [cite_start]The context explicitly states that 'at the maximum label imbalance (x-axis), the share of positive predictions (y-axis) for women increases from 0% in Iterations 1 (left panel) to 22% in Iteration 100 (right panel) if there is no human discrimination (z-axis)'[cite: 1909].",1,"The context directly answers the question. It states, 'at the maximum label imbalance (x-axis), the share of positive predictions (y-axis) for women increases from 0% in Iterations 1 (left panel) to 22% in Iteration 100 (right panel) if there is no human discrimination (z-axis)'."
"In the 'Feedback Loops in Machine Learning' study, what was the share of game outcomes matching the perfect information benchmark for female borrowers in the first iteration?",42.3%.,"Laut der Studie „Feedback Loops in Machine Learning“ entsprach der Anteil an positiven Ergebnissen für weibliche Kreditnehmer in der ersten Iteration dem Perfect-Information-Benchmark bei etwa +0,2 Prozentpunkten.","Feedback Loops in Machine Learning 
 
819 
 
 
Note: We illustrate how the mean share of positive predictions and mean false-negative error rates for female borrowers in Iterations 1 and 100 
depend on the initial label imbalance in the training data and the degree of human discrimination by the investor. A comparis on of panels for 
Iterations 1 and 100 for the two measures of algorithmic discrimination provides insights into their conditional development across iter ations. 
Abbreviations: False-neg. rate = false-negative rate; Init. lab. imb. = initial label imbalance; Human discr. = human discrimination. 
Figure 6. Development of the Mean Share of Positive Predictions and False-Negative Error Rates 
Figure 6 also shows that an increase in human 
discrimination undermines the reduction in false -
negative error rates for female borrowers over time. 
For instance, the lower two panels show that with a 
high initial label imbalance (x-axis), the false-negative 
error rate (y-axis) for female borrowers decreases from 
55.4% in Iteration 1 (left panel)  to 35.8% in Iteration 
100 (right panel)  if there is no human discrimination  
(z-axis). However, under very high human 
discrimination, this rate only drops to 52.2%  in perfect information benchmark (for female borrowers) is 
consistent across conditions (approx. +0.2 percentage 
points per iteration). However, the initial degree of 
economic efficiency diminishes with increasing label 
imbalance. Regarding the optimal investment with 
repaying female borrowers (Column 3), the positive time 
trend is higher in medium, high, and maximum label 
imbalance conditions (respectively +0.09, +0.13, +0.15 
percentage points) than in situations with low or no initial 
label imbalance (reference category). 
In summary, our findings highlight that the observed self-
correction properties of continuous updating are 
moderated by the degree of initial label imbalance in the 
training data. This holds, in particular, for algorithmic 
discrimination as measured by the gender gap in false-
negative error rates. These results, when interpreted in the 
context of our loan approval example, suggest that the 
extent of historical discrimination against female 
applicants, as reflected in the training data, influences the 
effectiveness of continuous model updating in mitigating 
the gender gap in the ML prediction model. This result 
holds for both the gap in the likelihood that the model will Feedback Loops in Machine Learning 
 
847 
Number of Investors and Borrowers Matched per Iteration: 60 
Table A28. OLS Regression Estimates  
 Fairness measures 
(gender gap) 
 Economic efficiency 
(female borrowers only) 
 (1) (2)  (3) (4) 
Dep. variable: Share of repay 
predictions 
False-negative 
error rates  Outcome under 
perf. inf. 
Invest in repay. 
borrower 
Iteration -0.0003 -0.0013***  0.0016*** 0.0016*** 
 (-1.18) (-4.98)  (9.00) (6.34) 
Low lab. imb. 0.0735*** 0.0386*  -0.0058 -0.0298 
 (3.58) (1.65)  (-0.40) (-1.46) 
Medium lab. imb. 0.2006*** 0.0937***  -0.0550*** -0.1643*** 
 (10.15) (4.18)  (-3.70) (-8.34) 
High lab. imb. 0.2938*** 0.1305***  -0.0982*** -0.2488*** 
 (14.44) (5.84)  (-6.56) (-13.28) 
Max lab. imb. 0.3526*** 0.1411***  -0.1295*** -0.3238*** 
 (18.68) (6.20)  (-8.65) (-18.05) 
Iteration*Low lab. imb. -0.0007** -0.0000  0.0001 0.0005 
 (-2.10) (-0.13)  (0.57) (1.42) 
Iteration*Medium lab. imb. -0.0013*** 0.0003  0.0003 0.0012*** 
 (-4.05) (0.91)  (1.07) (3.39) 
Iteration*High lab. imb. -0.0017*** 0.0007**  0.0002 0.0013*** 
 (-4.68) (2.00)  (0.86) (3.72) 
Iteration*Max lab. imb. -0.0017*** 0.0012***  0.0004 0.0017*** 
 (-5.31) (3.26)  (1.58) (5.23) 
N 1,500 1,500  42,400 23,020",9.084568501,0,"The generated answer states the share was approximately +0.2 percentage points, which is incorrect. The ground truth correctly identifies the share as 42.3%. The value provided in the generation refers to the rate of change per iteration, not the initial value.",0,"The generated answer is not faithful. It claims the share of game outcomes was approximately +0.2 percentage points. [cite_start]The context states that 'the share of game outcomes with female borrowers that match the perfect information benchmark (y-axis), grows from 42.3% In Iteration 1 (left panel) to 62.5% in Iteration 100'[cite: 1911]. The correct value for the first iteration is 42.3%.",0,"The context is irrelevant. It mentions that 'the share of game outcomes with female borrowers that match the perfect information benchmark (y-axis), grows from 42.3% In Iteration 1'. However, the generated answer incorrectly states the value as '+0.2 percentage points per iteration', which refers to the rate of change, not the initial value."
"In the ""Feedback Loops in Machine Learning"" study, what type of model was utilized to predict whether an investment would occur in the investment game simulation?",A gradient boosted forest.,"Zunächst wurde ein Machine Learning Modell zur Vorhersage der Rückzahlung durch Kreditnehmer verwendet. Dieses Modell wurde später durch das Training auf einem erweiterten Datensatz, der auch Informationen über Investoren enthielt, aktualisiert.","Feedback Loops in Machine Learning 
 
813 
Armed with this information, the investor decided 
whether to invest. Notably, in our simulation , we 
mimicked investor decisions using a trained model (see 
below for more information). If an investment was 
made, the borrower decided on repayment, and a new 
observation encapsulating a borrower’s specific 
personal traits (features) and actual repayment decision 
(label) was appended to the dataset used to train the ML 
model predicting repayment. 
Importantly, to avoid inappropriate overfitting and 
spillover effects, this observation was only included if 
the dataset didn’t already contain a record of this exact 
borrower. Conversely, if an investor declined to invest, 
the individual game conclude d without eliciting a 
repayment decision from the borrower or appending a 
new observation to the training data. In other words, the 
growth of the training data was endogenous and 
selectively include d borrowers who received an 
investment (Lakkaraju et al., 2017). After all decisions 
were made, the iteration concluded with an update of the 
ML model predicting repayment by training it from 
scratch on the expanded dataset incorporating records Feedback Loops in Machine Learning 
 
811 
3.2 Previous Empirical Studies 
We buil t our simulations on two secondary datasets, 
collected by several authors of this paper as part of 
different empirical studies. Study A was an incentivized 
field study conducted over three years from 2016 to 
2019. Study A measured participant s’ behavior in the 
investment game  defined above  in their  role as 
borrowers. The data from Study A allow ed us to 
develop an ML model predicting borrowers’ repayment 
decision and serves as the foundation for simulating 
borrower behavior. Study B, conducted in December 
2020, was an incentivized online experiment where 
participants engaged in the outlined investment game in 
the role of investors. In this experiment, investors could 
access an ML model predicting borrowers ’ repayment 
likelihood. Notably, this model, along with the 
borrowers with whom investors from Study B 
interacted, originated from Study A data. The data from 
Study B provide d the basis for simulating investor 
decisions. We present the exact instructions given in 
these studies in Appendix B.1. 
Study A: At the onset of each semester, first -semester 
economics students from a large German university were riskant, zu unsicher.
Wer weiß, wo das hinläuft.
Und ich würde Ihnen ein Machine 
Learning Modell geben,
bei dem ich Ihnen versichern 
kann
Sagt Ihnen zu 100 % korrekt
den Aktienkurs morgen vorher.
Es ist immer richtig.
Was würden Sie machen? Egal, wie 
risikoavers
Sie sind, Was würden Sie machen?
Genau. Wenn ich Ihnen versichern 
kann,
dass morgen der Aktienkurs 
steigt,
dann würden sogar die 
risikoaversen Menschen,
die es gibt, investieren.
Und wir haben das Investieren
vorher schon identifiziert als
in Relation die risikoreichere 
Choice,
weil ich hätte was verlieren 
können.
Jetzt habe ich aber die perfekte 
Maschine,
das heißt Machine Learning 
treibt mich eigentlich
dazu oder kann mich dazu 
treiben,
häufiger ins Risiko zu gehen.
Jetzt würde man natürlich 
konzeptionell sagen Naja,
wenn ich aber zu 100 % weiß,
was morgen passiert, ist 
überhaupt noch Risiko da.
Und da haben Sie vollkommen 
recht.
Es sieht so aus,
als ob wir in Risiko geschiftet 
werden.
In diesem Gedankenexperiment, wo 
ich sage, in einer Welt,
wo ich eine perfekte Maschine 
habe,
gibt es keine Risiko mehr,
weil ich alles perfekt 
vorhersagen kann.
Und ich bin mir gar nicht mehr
unsicher, was morgen passiert.
Naja, wo sehen Sie ein Problem?",8.012131214,0,"The generated answer claims a gradient boosted forest was used. The ground truth states a machine learning model was used to predict repayment, but does not specify the model type. The generation adds an unsupported detail, making it incorrect.",1,"The generated answer is faithful. [cite_start]The context states that 'we mimicked investor decisions using a trained model' [cite: 1946] [cite_start]and that this investor simulation was based on data from 'Study B'[cite: 1957]. While it doesn't specify the exact model type for the investor simulation in this snippet, it clearly states a model was used to predict the investment decision, separate from the repayment prediction model.",0,"The context is irrelevant to the question. It describes how investor decisions were mimicked using a trained model but does not specify the type of model used (e.g., gradient boosted forest)."
What are some contexts in which algorithmic discrimination has been observed?,"Algorithmic discrimination has been observed in recidivism risk assessments, education, recruitment, predictive policing, health risk evaluations, targeted advertising, crowdlending scenarios, and facial recognition tasks.","Algorithmische Diskriminierung wurde in folgenden Kontexten beobachtet:

*   **Rekrutierung:** Insbesondere in Bezug auf Geschlecht, Rasse, Hautfarbe und Persönlichkeit.
*   **Gesundheitswesen**
*   **Kreditgenehmigungen**
*   **Strafjustizsysteme**","Despite algorithms aiming for objectivity and clarity in their
procedures, they can become biased when they receive partial
input data from humans. Modern algorithms may appear neutral
but can disproportionately harm protected class members, posing
the risk of“agentic discrimination”(Prince and Schwarcz,2019).
If mishandled, algorithms can exacerbate inequalities and
perpetuate discrimination against minority groups (Lloyd,2018).
Within the recruitment process, algorithmic bias can manifest
concerning gender, race, color, and personality.
Research methodology
The primary research strategy was a literature review approach.
This review aimed to assess current research on recruitment
supported by artiﬁcial intelligence algorithms. The systematic
review process included gathering and evaluating the selected
studies’ literature and topics. Driven by the direction of the
research, studies focusing on algorithmic discrimination in
recruitment over the past 10 years were included unless past
literature was worth reviewing. This is because this is a relatively
new phenomenon that has become prominent over the past 10
years. In deﬁning the “algorithmic and hiring discrimination”
literature, a fairly broad approach was taken based on article of inadvertently perpetuating or igniting algorithmic 
discrimination if these individuals engage in 
discriminatory practices. In this context, efforts aimed at 
identifying and mitigating (subconscious) discriminatory 
practices of organizational decision  makers, such as 
awareness training, become an indispensable 
complementary element to ensure that continuously 
updated ML models exhibit desirable behaviors. 
2 Theoretical and Conceptual 
Background 
In this section, we first provide the conceptual 
underpinnings of algorithmic discrimination. 
Subsequently, we discuss the literature gaps our work 
aims to address. significant consequences, such as in healthcare, loan 
approval, hiring, or criminal justice systems. 
Mitigating algorithmic discrimination : The 
expansive literature on algorithmic discrimination 
proposes various methods to identify and alleviate 
such biases. According to d ’Alessandro et al. (2017), 
we can divide these mitigation strategies into three 
categories: pre -processing, in -processing, and post -
processing. Pre -processing strategies strive to 
eliminate disparities inherent in the dataset. Methods 
such as those proposed by Kamiran and Calders (2012) 
and Zafar et al. (2017) employ data pre -processing 
techniques like feature massaging and reweighting to 
balance the dataset based on social group 
characteristics. In -processing strategies involve 
conventional learning algorit hms during model 
training. Researchers often use techniques like naive 
Bayes and decision tr ees for debiasing (Calders & 
Verwer, 2010; Zhang et al., 2018). Additional research 
suggests placing constraints on the classification 
model to mandate the satisfaction of a proxy 
(Woodworth et al., 2017). Lastly, post -processing 
strategies aim to adjust the output to counter biases. 
For example, Corbett -Davies et al. (2017)",7.739610195,1,"The generated answer is semantically consistent with the ground truth. Both list several correct contexts where algorithmic discrimination has been observed, such as recruitment, healthcare, and criminal justice.",1,"The generated answer is faithful. [cite_start]The context mentions 'recruitment' and that 'algorithmic bias can manifest concerning gender, race, color, and personality'[cite: 1973]. [cite_start]It also refers to significant consequences in 'healthcare, loan approval, hiring, or criminal justice systems'[cite: 1983].",0.9,"The context is highly relevant. It discusses various contexts where algorithmic bias and discrimination have been observed, including recruitment (gender, race, personality), healthcare, loan approval, and criminal justice systems. This provides a strong basis for answering the question."
What is algorithmic discrimination?,Algorithmic discrimination refers to discriminatory hiring practices that arise from algorithmic bias.,"Algorithmusdiskriminierung ist, wenn ein Algorithmus (z. B. ein Machine-Learning-Modell) Ergebnisse produziert, die bestimmte Gruppen von Menschen unverhältnismäßig benachteiligen oder bevorzugen, auch wenn keine explizite Begründung dafür vorliegt. 

Hier sind die wichtigsten Punkte, die aus dem Text hervorgehen:

*   **Ursachen:** Sie kann durch Vorurteile in den Trainingsdaten entstehen, die von Menschen (z. B. Personalentscheidern) eingeführt wurden.
*   **Auswirkungen:** Algorithmen können trotz ihres Ziels der Objektivität und Klarheit, unverhältnismäßig geschützte Gruppen schädigen.
*   **Beispiele:** In der Personalauswahl kann dies sich auf Geschlecht, Rasse oder Persönlichkeit beziehen.

Ich hoffe, das beantwortet Ihre Frage!","Feedback Loops in Machine Learning 
 
807 
2.1 Algorithmic Discrimination 
Algorithmic discrimination: Discrimination involves 
statements or actions that unjustifiably disadvantage 
members of particular social groups. These actions 
typically stem from conscious or subconscious attitudes, 
prejudices, or emotional associations tied to 
characteristics such as  gender, age, disability, race, 
language, religion, or sexual identity (Scherr, 2008). In 
today’s era, where algorithmic systems based on ML 
models frequently aid human decisions, researchers and 
practitioners often employ the te rm “algorithmic 
discrimination” to refer to system outputs that 
disproportionately benefit or disadvantage specific 
groups, even when no justification for the disparate 
treatment exists from a ground -truth perspective 
(Kordzadeh & Ghasemaghaei, 2022).1  
Algorithmic discrimination can originate from various 
sources. First, it may stem from intentional or 
unintentional social biases encoded within the training 
data (Friedman & Nissenbaum, 1996; Romei & Ruggieri, 
2013; Kleinberg et al., 2018). For example, if a training 
dataset holds more positively labeled examples for men, 
the ML model may predict positive labels less accurately Despite algorithms aiming for objectivity and clarity in their
procedures, they can become biased when they receive partial
input data from humans. Modern algorithms may appear neutral
but can disproportionately harm protected class members, posing
the risk of“agentic discrimination”(Prince and Schwarcz,2019).
If mishandled, algorithms can exacerbate inequalities and
perpetuate discrimination against minority groups (Lloyd,2018).
Within the recruitment process, algorithmic bias can manifest
concerning gender, race, color, and personality.
Research methodology
The primary research strategy was a literature review approach.
This review aimed to assess current research on recruitment
supported by artiﬁcial intelligence algorithms. The systematic
review process included gathering and evaluating the selected
studies’ literature and topics. Driven by the direction of the
research, studies focusing on algorithmic discrimination in
recruitment over the past 10 years were included unless past
literature was worth reviewing. This is because this is a relatively
new phenomenon that has become prominent over the past 10
years. In deﬁning the “algorithmic and hiring discrimination”
literature, a fairly broad approach was taken based on article of inadvertently perpetuating or igniting algorithmic 
discrimination if these individuals engage in 
discriminatory practices. In this context, efforts aimed at 
identifying and mitigating (subconscious) discriminatory 
practices of organizational decision  makers, such as 
awareness training, become an indispensable 
complementary element to ensure that continuously 
updated ML models exhibit desirable behaviors. 
2 Theoretical and Conceptual 
Background 
In this section, we first provide the conceptual 
underpinnings of algorithmic discrimination. 
Subsequently, we discuss the literature gaps our work 
aims to address.",14.95216417,1,"The generated answer is semantically consistent with the ground truth. Both correctly define algorithmic discrimination as system outputs that unjustifiably disadvantage certain social groups, often stemming from biases in the training data.",1,"The generated answer is faithful. [cite_start]The context defines algorithmic discrimination as 'system outputs that disproportionately benefit or disadvantage specific groups, even when no justification for the disparate treatment exists'[cite: 1999]. [cite_start]It also mentions that it can stem from 'social biases encoded within the training data' [cite: 2000] [cite_start]and can 'disproportionately harm protected class members'[cite: 2002].",1,"The context provides a direct and clear answer. It defines algorithmic discrimination as 'system outputs that disproportionately benefit or disadvantage specific groups, even when no justification for the disparate treatment exists from a ground-truth perspective.' It also mentions sources like social biases in training data and how it can manifest in recruitment concerning gender, race, etc."
"According to the document, what software was used as an auxiliary tool to clarify ideas and improve work efficiency?",Nvivo 12.0 Plus qualitative analysis software.,"Ich kann die Frage nicht beantworten. Der Text enthält keine Informationen über eine bestimmte Software, die für die Klärung von Ideen und die Steigerung der Arbeitsleistung eingesetzt wurde.","Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. den besten Bewerber.
Finde aus einer größeren Menge 
von möglichen Bewerbern.
Ich denke also wieder mit Was 
sollte sich innerhalb
meines Prozesses
innerhalb dieses Workflows auch 
verändern?
Integriert mehr Integration?
Und ein Beispiel hierfür ist 
Ada. Kennt das jemand?
Hat jemand schon mal gehört,
es war ein Startup,
was in
der Pre Curve Zeit ein Customer 
Service Angebot hatte?
Die haben die Automatisierung
damals auch nicht mitgenerativen 
KI Systemen.
Aber ein sehr
clever zusammengestelltes 
Applikationssystem,
wo Customer Compliance gehandelt 
worden sind.
Das wurde aufgekauft innerhalb 
der
kurze Zeit von einem uns
allen bekannten großen Provider 
von digitalen Calls,
nämlich Zoom Zoom hat 
festgestellt,
als alle in die digitalen
Räume zu kurze Zeit gegangen 
sind,
dass es sehr viele Beschwerden
insbesondere von bestimmten 
Altersgruppen gab,
die mit dieser Technologie nicht 
klargekommen sind,
was dazu geführt hat,
dass dieser Ansturm, dieser 
Komplements,
die gesamte Service und
die gesamte Marketing Abteilung 
von Zoom
eigentlich den ganzen Tag auf 
Trab gehalten hatten.
Sie konnte trotzdem nicht alles
abarbeiten und dieses System,
was sie installiert haben,
war jetzt nicht einfach nur Ich 
habe ein System, nachzudenken,
ist diese Dekomposition von 
Workflows und die
Organisation von solchen 
Projekten
kann stattfinden über diese 
Scrips Modell.
Und letztlich haben wir 
unterschiedliche Level der
Integration von diesen Machine 
Learning Innovationen
innerhalb der Organisation.
Hört sich alles super an!
Problem ist da kann massiv viel 
schiefgehen.
Selbst wenn ich diesen ganzen 
Prozess durchgedacht habe,
sind es an vielen Ecken immer 
noch Probleme,
die sich beispielsweise hier bei 
Amazon vor einigen
Jahren trotz hochintelligenter 
Leute,
trotz super Strukturen,
trotz tollen technologischen 
Möglichkeiten
ist es da zu einem großen 
Skandal gekommen,
die man von diesem Skandal 
damals gehört.
Müsste ungefähr in die Zeit, wo 
sie alle
Abitur gemacht haben, gewesen 
sein.
Ja, das war weil die.
Also ich bin mir nicht mehr 
sicher.
Ich glaube, da wurden die 
früheren
Recruitingdaten von Amazon 
genommen,
in eine AI eingespeist.
Und da die früheren Recruiter
biased gegenüber Frauen waren,
hat die AI das Muster erkannt 
und ebenso übernommen.
Genau.
Wir haben ein System
gehabt und ich würde gar nicht 
mal sagen,
dass die Recruiter per se 
gebeizt waren.
Ich wahrscheinlich auch ein 
Teil.
Ich will den Leuten da nichts 
unterstellen.",6.886644125,0,"The generated answer is a refusal to answer, stating it cannot answer the question. The ground truth provides the specific name of the software. The answers are contradictory.",0,"The generated answer is not faithful. The retrieved context does not mention the software 'Nvivo 12.0 Plus'. [cite_start]The context describes an AI system built by a startup called Ada for customer service, which was acquired by Zoom[cite: 2021, 2023].",0,"The context is completely irrelevant. It describes an automated customer service system acquired by Zoom and the challenges of implementing AI solutions, with no mention of any qualitative analysis software."
What was the result of Microsoft revising their dataset for training the Face API?,A 20-fold reduction in the recognition error ratio between men and women with darker skin tones.,Die Überarbeitung des Datensatzes durch Microsoft für das Training der Face API führte zu einer 20-fachen Reduzierung des Erkennungsfehlerraten zwischen Männern und Frauen mit dunkler Hautfarbe und einer 9-fachen Reduzierung für Frauen.,"uncover hidden biases and remove them automatically. For
example, Microsoft revised their dataset for training the Face API,
resulting in a 20-fold reduction in the recognition error ratio
between men and women with darker skin tones and a 9-fold
reduction for women by balancing factors such as skin color, age,
and gender (Grabovskyi and Martynovych,2019).
Integrating “small data” and “big data” can enhance accuracy
(36KE, 2020). Data should not solely rely on extensive collections
but also focus on precision. While big data analysis tends to
emphasize correlations, which can lead to errors when inferring
causation, small data, which is more user-speciﬁc, offers detailed
information and helps avoid such mistakes. Combining the
vastness of big data with the precision of small data can help
somewhat mitigate hiring errors (Kitchin and Lauriault,2015).
Biases in datasets can be identi ﬁed through autonomous
testing. The inaccuracies stemming from incomplete past data
can be addressed through “oversampling” (Bornstein, 2018).
Researchers from MIT demonstrated how an AI system called
DB-VEA (unsupervised learning) can automatically reduce bias
by re-sampling data. This approach allows the model to learn 17. Juli 2025
Learning process
4
https://machinelearningknowledge.ai/wp-content/uploads/2019/10/Backpropagation.gif in ML. Therefore, transparency would
facilitate remediation when deviant algorithms are discovered and
solve the current“black box” dilemma (Shin and Park,2019).
Technological tools against bias. Data blending process. Blendoor
is inclusive recruiting and stafﬁng analytics software that miti-
gates unconscious bias. It takes candidate proﬁles from existing
online job boards and applicant tracking systems to reduce
unconscious bias. Blendoor “blends” candidate pro ﬁles by
removing names, photos, and dates (Yarger et al.,2019). Thus,
Blendoor promotes design fairness by assisting underrepresented
job seekers and encoding equal opportunity in the algorithm.
Decoupling technique. In resume screening, this technique
allows the algorithm to identify the best candidates by
considering variables optimized for other applicants based on
speciﬁc categories like gender or race rather than the entire
applicant pool (Raso et al.,2018). It means that the characteristics
selected for minority or female applicants will be determined
according to the trends of other minority or female applicants,
which may differ from the features identi ﬁed as successful
representatives.
Word embedding. Microsoft researchers found that words",7.37490201,1,The generated answer is semantically consistent with the ground truth. Both correctly state the 20-fold reduction in the error ratio for the specified demographic.,1,"The generated answer is faithful. [cite_start]The context states that after Microsoft 'revised their dataset for training the Face API', it resulted 'in a 20-fold reduction in the recognition error ratio between men and women with darker skin tones and a 9-fold reduction for women'[cite: 2032].",1,"The context is highly relevant. It states that Microsoft revised their dataset for the Face API, which resulted in a '20-fold reduction in the recognition error ratio between men and women with darker skin tones'."
What did Amazon do with their ML-based hiring tool?,Amazon withdrew the tool and developed a new unbiased algorithm.,"Amazon hat bei der Entwicklung seines ML-basierten Einstellungswerkzeugs zunächst das Geschlecht aus den Datensätzen entfernt. Sie hatten jedoch eine Spalte im Datensatz, in der das Geschlecht noch enthalten war, um die Performance der Maschine anhand von Männern, Frauen und nicht-binären Personen zu vergleichen.","Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. Forscher in diesem Gebiet.
Die haben eine Riesenstudie 
gemacht,
wo sie Generative KI Systeme
in Unternehmen eingesetzt haben
und wirklich mal gemessen haben 
hier
im Service Customer Service 
Bereich.
Was bringt das für die Firma?
Was bringt das für den 
Mitarbeiter?
Was bringt es für den Kunden?
Und die Message, Die Details 
erspare ich Ihnen.
Wie gesagt, kann ich Ihnen nur 
empfehlen,
das durchzulesen.
Die Message sind eigentlich drei 
Bilder.
Auf der einen Seite sehen wir, 
dass die.
Hier sehen wir die
Monate bis zum Deployment von AI 
und
das sind immer die Effekte auf 
die Produktivität hier.
Und Sie sehen, das hier ist der 
Zeitpunkt,
wann eben ein GPT ähnliches 
System eingeführt worden ist.
Das ist die Produktivität,
relativ, also der Wechsel.
Also wenn ich, bevor ich KI 
eingeführt habe,
habe ich natürlich
Produktivitätsschwankungen pro 
Monat immer
im Vergleich zum Vorjahr im 
Vergleich zum Durchschnitt.
Sobald aber diese Technologie 
eingeführt wurde,
sehen sie, dass die 
Produktivität massiv ansteigt.
0.1. 0.2. Wir sehen das.
Hier haben Sie drei Gruppen.
Die Gruppe, die neu angestellt 
wurde,
das ist die, die Monate,
wie lange die Person schon dort 
arbeitet.
Wir sehen hier den roten 
Graphen, der uns zeigt. Datensatz,
in dem man alles angibt,
außer das Geschlecht und lässt 
das durchlaufen.
Aber hierbei würden sie Gender 
mit rein nehmen.
Also in einem ersten Schritt,
um das zu kontrollieren.
Genau in diesem Beispiel von dem 
Amazon,
das haben Sie schon richtig 
erfasst,
war es so die haben Gender 
rausgelassen,
hatten aber eine Spalte im 
Datensatz,
wo Gender noch drin war,
haben die Maschine dann
basierend auf allen Features 
außer Gender die
Vorhersage machen lassen und 
konnten dann natürlich
innerhalb ihrer Daten trotzdem 
vergleichen.
Wie ist die Performance dort in 
den Einträgen,
wo wir Männer,
Frauen nonbinär hatten und haben 
das dann verglichen?
Praktisch ja.
Aber es gibt viele Argumente 
dafür,
dass wir diese Features, die 
protected sind,
dass wir eigentlich größere 
Probleme erzeugen,
wenn wir sie den Maschinen nicht 
zur Verfügung stellen,
weil diese Maschinen so mächtig 
sind,
Korrelationen herauszufinden,
die letztlich ablesen lassen,
ob es welches Geschlecht es ist 
und das implizit lernen.
Und das ist sehr, sehr, sehr 
versteckt ist,
wo eigentlich jetzt eine 
Diskriminierung herkommt.
Wenn wir es aber drin lassen,
gibt es bestimmte Methoden, das 
direkt abzulesen.
Aber die Frage was will man denn 
da,",8.18659544,0,The generated answer claims Amazon removed gender from the datasets. The ground truth states that Amazon withdrew the entire tool and developed a new one. These are different actions.,0,The generated answer is not faithful. It claims that Amazon removed gender from the datasets initially. [cite_start]The context states that 'the bias stemmed from training the AI system on predominantly male employeesâ€™ CVs'[cite: 2131]. [cite_start]It later compelled Amazon to 'withdraw the tool and develop a new unbiased algorithm'[cite: 2134]. The action described in the generated answer relates to a different example discussed elsewhere in the source document.,0.8,"The context is relevant. It describes the Amazon hiring tool case, where the system was biased against women. It states the reason was that the AI system was trained on 'predominantly male employeesâ€™ CVs', which led it to perceive this as the model for success. While the generated answer is also correct, the provided context focuses on the training data rather than specific features like hobbies or universities."
"According to the document, what is “agent discrimination”?","When partial human data is provided to a machine, it will eventually lead to the risk of “agent discrimination.”","Laut dem Dokument ist „agentenbedingte Diskriminierung“ die „unbeabsichtigte Perpetuierung oder Auslösung von Diskriminierung, wenn diese Personen diskriminierende Praktiken innerhalb von Entscheidungsprozessen anwenden“. Es geht also um die Gefahr, dass Mitarbeiter (als „Agenten“) diskriminierende Praktiken anwenden, was dann zu diskriminierenden Ergebnissen führen kann.","Theory background
Discrimination theory. Discrimination in the labor market is
deﬁned by the ILO’s Convention 111, which encompasses any
unfavorable treatment based on race, ethnicity, color, and gender
that undermines employment equality (Ruwanpura, 2008).
Economist Samuelson (1952) offers a similar deﬁnition, indicat-
ing that discrimination involves differential treatment based on
personal characteristics, such as ethnic origin, gender, skin color,
and age.
Various perspectives on the causes and manifestations of
discrimination can be broadly categorized into four theoretical
groups. Theﬁrst is the competitive market theory, which explains
discriminatory practices within an equilibrium of perfect
competition (Lundberg and Startz, 1983). This view attributes
discrimination primarily to personal prejudice. The second is the
monopoly model of discrimination, which posits that mono-
polistic power leads to discriminatory behavior (Cain,1986). The
third is the statistical theory of discrimination, which suggests
that nonobjective variables, such as inadequate information,
contribute to biased outcomes (Dickinson and Oaxaca, 2009).
Lastly, we have the antecedent market discrimination hypothesis
as the fourth category. of inadvertently perpetuating or igniting algorithmic 
discrimination if these individuals engage in 
discriminatory practices. In this context, efforts aimed at 
identifying and mitigating (subconscious) discriminatory 
practices of organizational decision  makers, such as 
awareness training, become an indispensable 
complementary element to ensure that continuously 
updated ML models exhibit desirable behaviors. 
2 Theoretical and Conceptual 
Background 
In this section, we first provide the conceptual 
underpinnings of algorithmic discrimination. 
Subsequently, we discuss the literature gaps our work 
aims to address. facial identiﬁcation.
Data protection and non-discrimination laws safeguard against
discriminatory practices in algorithmic decision-making. In the
EU region, Article 14 of the European Convention on Human
Rights (ECHR) guarantees the rights and freedoms outlined in
the Convention, prohibiting direct and indirect discrimination
(Zuiderveen Borgesius, 2020). Non-discrimination laws, particu-
larly those about indirect discrimination, serve as a means to
prevent various forms of algorithmic discrimination. The EU
General Data Protection Regulation (GDPR), implemented in
May 2018, addresses the impact of ML algorithms and offers a
“right to explanation” (e.g., Articles 13–15) (Peña et al., 2020),
enabling individuals to request explanations for algorithmic
decisions and demand measures to avoid discriminatory
inﬂuences when handling sensitive data. The GDPR mandates
organizations to conduct a Data Protection Impact Assessment
(DPIA), with each EU member state must maintain an
independent data protection authority vested with investigative
powers. Under the GDPR, a data protection authority can access
an organization’s premises and computers using personal data
(Zuiderveen Borgesius, 2020).
Investigation and analysis",8.689302921,0,"The generated answer provides an incorrect definition, stating agent discrimination comes from 'partial human data'. The ground truth correctly defines it as the risk of individuals ('agents') perpetuating discrimination through their practices when using AI systems.",1,"The generated answer is faithful. [cite_start]The context defines 'agentic discrimination' as the risk that modern algorithms, while appearing neutral, 'can disproportionately harm protected class members'[cite: 1971]. [cite_start]It also mentions the risk of 'inadvertently perpetuating or igniting algorithmic discrimination if these individuals engage in discriminatory practices'[cite: 2078].",0,The context is entirely irrelevant. It discusses discrimination theory and its application in the labor market but makes no mention of 'agent discrimination' as described in the generated answer.
"According to the document, what are some characteristics used in discrimination theory?","Race, ethnicity, color, and gender.","That’s correct. According to the document, discrimination theory addresses the potential for unintentional perpetuation or triggering of discrimination by individuals – referred to as “agents” – who engage in discriminatory practices within decision-making processes.","Theory background
Discrimination theory. Discrimination in the labor market is
deﬁned by the ILO’s Convention 111, which encompasses any
unfavorable treatment based on race, ethnicity, color, and gender
that undermines employment equality (Ruwanpura, 2008).
Economist Samuelson (1952) offers a similar deﬁnition, indicat-
ing that discrimination involves differential treatment based on
personal characteristics, such as ethnic origin, gender, skin color,
and age.
Various perspectives on the causes and manifestations of
discrimination can be broadly categorized into four theoretical
groups. Theﬁrst is the competitive market theory, which explains
discriminatory practices within an equilibrium of perfect
competition (Lundberg and Startz, 1983). This view attributes
discrimination primarily to personal prejudice. The second is the
monopoly model of discrimination, which posits that mono-
polistic power leads to discriminatory behavior (Cain,1986). The
third is the statistical theory of discrimination, which suggests
that nonobjective variables, such as inadequate information,
contribute to biased outcomes (Dickinson and Oaxaca, 2009).
Lastly, we have the antecedent market discrimination hypothesis
as the fourth category. of inadvertently perpetuating or igniting algorithmic 
discrimination if these individuals engage in 
discriminatory practices. In this context, efforts aimed at 
identifying and mitigating (subconscious) discriminatory 
practices of organizational decision  makers, such as 
awareness training, become an indispensable 
complementary element to ensure that continuously 
updated ML models exhibit desirable behaviors. 
2 Theoretical and Conceptual 
Background 
In this section, we first provide the conceptual 
underpinnings of algorithmic discrimination. 
Subsequently, we discuss the literature gaps our work 
aims to address. technical and managerial aspects to tackle discrimination in
algorithmic hiring. This study contends that resolving algorithmic
discrimination in recruitment requires technical solutions and the
implementation of internal ethical governance and external
regulations.
The subsequent study is structured intoﬁve parts. The ﬁrst
section provides the theoretical background for this research. The
following section outlines the research methodology employed in
the literature review and identiﬁes four key themes. The third
section delves into a detailed discussion of these four themes:
applications and beneﬁts of AI-based recruitment, factors con-
tributing to algorithmic recruitment discrimination, types of
discrimination in algorithmic recruitment, and measures to
mitigate algorithmic hiring discrimination. The fourth section
involves conducting a survey among respondents and analyzing
the primary data collected to support our study. Theﬁnal section
concludes by suggesting future directions for research.
Theory background
Discrimination theory. Discrimination in the labor market is
deﬁned by the ILO’s Convention 111, which encompasses any
unfavorable treatment based on race, ethnicity, color, and gender",9.175221205,1,"The generated answer is semantically consistent with the ground truth. Both correctly list characteristics like race, ethnicity, color, and gender.",0,"The generated answer is not faithful. It claims that discrimination theory addresses the 'unintentional perpetuation or triggering of discrimination by individuals'. [cite_start]The retrieved context defines discrimination theory based on the ILO's definition, which includes 'unfavorable treatment based on race, ethnicity, color, and gender' [cite: 2090][cite_start], and also mentions characteristics like 'ethnic origin, gender, skin color, and age'[cite: 2091]. The generated answer is too vague and doesn't include the specific characteristics mentioned in the context.",1,"The context directly answers the question. It defines discrimination in the labor market based on 'personal characteristics, such as ethnic origin, gender, skin color, and age' and also mentions a definition that includes 'race, ethnicity, color, and gender'."
What is the generic C R ISP-D M process model useful for?,"Planning, documentation and communication.","Laut dem Kontext ist das allgemeine CRISP-DM-Prozessmodell nützlich, um AI-Projekte zu strukturieren. Es besteht aus den folgenden Phasen:

1.  Business Understanding
2.  Data Understanding
3.  Data Preparation
4.  Modeling
5.  Evaluation
6.  Deployment","Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. 15. Mai 2025
Overview CRISP-DM
9 15. Mai 2025
Structuring an AI project: CRISP-DM 
6
1. Business Understanding2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment
Data 
Cross Industry Standard Process for Data Mining",7.177484751,0,"The generated answer claims the model is useful for structuring AI projects. The ground truth states it is useful for planning, documentation, and communication. While related, these are not semantically identical.",1,"The generated answer is faithful. [cite_start]The retrieved context provides an overview of the CRISP-DM model by listing its six phases, which are used to structure AI projects[cite: 2114]. This implies its usefulness for planning and documentation.",0,"The context is irrelevant. It provides an overview of the six phases of the CRISP-DM model but does not state what the generic model is useful for (e.g., planning, documentation)."
"According to the document, what can AI-based recruitment reduce?",Costs.,"Ja, das stimmt. Laut dem Dokument besagt: “KI-gestützte Personalauswahl kann das Geschlecht in den Ergebnissen reduzieren.”","Datensatz,
in dem man alles angibt,
außer das Geschlecht und lässt 
das durchlaufen.
Aber hierbei würden sie Gender 
mit rein nehmen.
Also in einem ersten Schritt,
um das zu kontrollieren.
Genau in diesem Beispiel von dem 
Amazon,
das haben Sie schon richtig 
erfasst,
war es so die haben Gender 
rausgelassen,
hatten aber eine Spalte im 
Datensatz,
wo Gender noch drin war,
haben die Maschine dann
basierend auf allen Features 
außer Gender die
Vorhersage machen lassen und 
konnten dann natürlich
innerhalb ihrer Daten trotzdem 
vergleichen.
Wie ist die Performance dort in 
den Einträgen,
wo wir Männer,
Frauen nonbinär hatten und haben 
das dann verglichen?
Praktisch ja.
Aber es gibt viele Argumente 
dafür,
dass wir diese Features, die 
protected sind,
dass wir eigentlich größere 
Probleme erzeugen,
wenn wir sie den Maschinen nicht 
zur Verfügung stellen,
weil diese Maschinen so mächtig 
sind,
Korrelationen herauszufinden,
die letztlich ablesen lassen,
ob es welches Geschlecht es ist 
und das implizit lernen.
Und das ist sehr, sehr, sehr 
versteckt ist,
wo eigentlich jetzt eine 
Diskriminierung herkommt.
Wenn wir es aber drin lassen,
gibt es bestimmte Methoden, das 
direkt abzulesen.
Aber die Frage was will man denn 
da, REVIEW ARTICLE
Ethics and discrimination in artiﬁcial intelligence-
enabled recruitment practices
Zhisheng Chen 1✉
This study aims to address the research gap on algorithmic discrimination caused by AI-
enabled recruitment and explore technical and managerial solutions. The primary research
approach used is a literature review. Theﬁndings suggest that AI-enabled recruitment has
the potential to enhance recruitment quality, increase efﬁciency, and reduce transactional
work. However, algorithmic bias results in discriminatory hiring practices based on gender,
race, color, and personality traits. The study indicates that algorithmic bias stems from
limited raw data sets and biased algorithm designers. To mitigate this issue, it is recom-
mended to implement technical measures, such as unbiased dataset frameworks and
improved algorithmic transparency, as well as management measures like internal corporate
ethical governance and external oversight. Employing Grounded Theory, the study conducted
survey analysis to collectﬁrsthand data on respondents’ experiences and perceptions of AI-
driven recruitment applications and discrimination.
Introduction
T The impact of gender stereotypes on AI hiring poses genuine
risks (Beneduce,2020). In 2014, Amazon developed an ML-based
hiring tool, but it exhibited gender bias. The system did not
classify candidates neutrally for gender (Miasato and Silva,2019).
The bias stemmed from training the AI system on predominantly
male employees ’ CVs (Beneduce, 2020). Accordingly, the
recruitment algorithm perceived this biased model as indicative
of success, resulting in discrimination against female applicants
(Langenkamp et al. 2019). The algorithm even downgraded
applicants with keywords such as “female” (Faragher, 2019).
These ﬁndings compelled Amazon to withdraw the tool and
develop a new unbiased algorithm. However, this discrimination
was inadvertent, revealing theﬂaws inherent in algorithmic bias
that perpetuates existing gender inequalities and social biases
(O’neil, 2016).
Race. Microsoft’s chatbot Tay learned to produce sexist and racist
remarks on Twitter. By interacting with users on the platform,
Tay absorbed the natural form of human language, using human
tweets as its training data. Unfortunately, the innocent chatbot
quickly adopted hate speech targeting women and black indivi-",6.292247057,0,The generated answer incorrectly claims AI-based recruitment can 'reduce gender in the results'. The ground truth correctly states it can reduce costs. The answers are not semantically consistent.,0,"The generated answer is not faithful. It claims that AI-based recruitment can reduce gender in the results. [cite_start]The retrieved context states that AI-enabled recruitment has the potential to 'enhance recruitment quality, increase efï¬ciency, and reduce transactional work'[cite: 2123]. [cite_start]The context does not mention reducing gender in the results; in fact, it states that algorithmic bias can lead to discriminatory practices based on gender[cite: 2124].",0.8,"The context is relevant. It states that AI-enabled recruitment has the potential to 'enhance recruitment quality, increase efï¬ciency, and reduce transactional work.' While the ground truth answer is 'Costs', reducing transactional work and increasing efficiency are directly related to cost reduction."
"According to the document, what is the aim of the C R ISP-D M process model?","To make large data mining projects less costly, more reliable, more repeatable, more manageable, and faster.","Das Dokument erwähnt das CRISP-DM-Prozessmodell, aber es gibt keine explizite Aussage über das Ziel dieses Modells. Es wird lediglich als ein Überblick (Overview) des CRISP-DM-Prozesses erwähnt.","Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. die das beeinflussen und
was hier Venkatesh und Kollegen 
gemacht haben,
die haben acht verschiedene 
Modelle
aus ganz unterschiedlichen
Disziplinen zusammengenommen und
haben jahrelang rumgewerkelt, um 
zu schauen,
was sind eigentlich die latent 
ähnlichen Faktoren,
was können wir irgendwie 
zusammenfassen und
was sind Faktoren,
die möglichst orthogonal einzeln 
gesehen
unterschiedlich sind und
viel Erklärungsgehalt dafür 
haben
in der Vorhersage,
ob ein Mensch die Technologie 
nutzen wird oder nicht.
Und das haben Sie das Modell, 
was entwickelt haben
letztlich auf ganz viele 
empirische Daten
gelegt und gezeigt,
dass dieses Modell um die 70 % 
der Variation darin,
ob Leute mit Technologie 
interagieren,
diese wirklich nutzen und 
akzeptieren, erklären kann.
Als Spoiler schon mal 70 % der
Variation zu erklären ist 
massiv,
insbesondere in solchen 
soziotechnischen Systemen,
wo wie immer der Mensch die 
Schwachstelle ist.
Womit haben Sie angefangen? Sie 
haben gesagt.
Und dieses Modell ist
vor allen Dingen aus der 
Perspektive
geschaffen worden damals.
Wie kriegen wir eigentlich Leute 
in Unternehmen dazu,
die bereitgestellte Technologie 
zu nutzen?
Es gibt mittlerweile auch zwei
Erweiterungen von diesem Modell 15. Mai 2025
Overview CRISP-DM
9",6.449851751,0,"The generated answer is a refusal to answer, stating there is no explicit statement about the model's aim. The ground truth provides the specific aim. The answers are contradictory.",0,The generated answer is not faithful. The retrieved context does not state a specific aim for the CRISP-DM process model. [cite_start]It only provides an 'Overview' of the model by listing its phases[cite: 2149].,0,"The context provides an overview of the CRISP-DM framework but does not state its specific aims, such as making data mining projects less costly or more reliable."
