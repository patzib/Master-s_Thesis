question,ground_truth_answer,generated_answer,retrieved_context,response_time_seconds,correctness_score,correctness_reasoning,faithfulness_score,faithfulness_reasoning,relevance_score,relevance_reasoning
"In the paper about the Centaur foundation model, what happens to the model's internal representations after being fine-tuned on the Psych-101 dataset?",The model's internal representations become more aligned with human neural activity.,The provided text doesn’t contain information about the Centaur foundation model or what happens to its internal representations after being fine-tuned on the Psych-101 dataset. It discusses a different machine learning model and a general approach to understanding how such models work.,"die das beeinflussen und
was hier Venkatesh und Kollegen 
gemacht haben,
die haben acht verschiedene 
Modelle
aus ganz unterschiedlichen
Disziplinen zusammengenommen und
haben jahrelang rumgewerkelt, um 
zu schauen,
was sind eigentlich die latent 
ähnlichen Faktoren,
was können wir irgendwie 
zusammenfassen und
was sind Faktoren,
die möglichst orthogonal einzeln 
gesehen
unterschiedlich sind und
viel Erklärungsgehalt dafür 
haben
in der Vorhersage,
ob ein Mensch die Technologie 
nutzen wird oder nicht.
Und das haben Sie das Modell, 
was entwickelt haben
letztlich auf ganz viele 
empirische Daten
gelegt und gezeigt,
dass dieses Modell um die 70 % 
der Variation darin,
ob Leute mit Technologie 
interagieren,
diese wirklich nutzen und 
akzeptieren, erklären kann.
Als Spoiler schon mal 70 % der
Variation zu erklären ist 
massiv,
insbesondere in solchen 
soziotechnischen Systemen,
wo wie immer der Mensch die 
Schwachstelle ist.
Womit haben Sie angefangen? Sie 
haben gesagt.
Und dieses Modell ist
vor allen Dingen aus der 
Perspektive
geschaffen worden damals.
Wie kriegen wir eigentlich Leute 
in Unternehmen dazu,
die bereitgestellte Technologie 
zu nutzen?
Es gibt mittlerweile auch zwei
Erweiterungen von diesem Modell Sie sind ein Machine Learning 
Modell.
Kommen wir jetzt zur heutigen 
Vorlesung.
Immer mit diesem Gedanken im 
Kopf.
Wir haben Inputdaten, wir haben
ein Modell und dieses Modell
macht auf den Inputdaten 
letztlich uns eine Vorhersage,
die möglichst präzise ist für 
Daten,
die Sie noch nicht gesehen 
haben.
Fangen wir jetzt wirklich an,
in diesem Teil eins rein zu 
gehen, um zu verstehen,
was können diese Modelle
eigentlich liefern aus einer 
ökonomischen,
betriebswirtschaftlichen, 
gesellschaftlichen Perspektive?
Wir werden jetzt in den ersten
Vorlesungen und es wird so
bis zur fünften Vorlesung gehen.
Da werden wir langsam anfangen,
auch in den zweiten Teil 
überzugehen.
Aber zunächst mal interessiert 
uns gar nicht,
wie wir auf dieses Modell 
kommen,
was dieses Modell genau ist.
Wir werden erstmal annehmen,
da ist irgendein Modell,
das fällt sozusagen vom Himmel.
Und was macht dieses Modell mit 
uns?
Was macht dieses Modell mit 
Organisationen?
Was macht dieses Modell mit 
Personen?
Was macht dieses Modell mit der 
Gesellschaft?
Und um so ein bisschen
eine Hands on Vorstellung zu 
haben,
was Machine Learning Modelle 
machen,
habe ich hier mal ein Beispiel 
mitgebracht,
wo wir jetzt als Gruppe Machine 
Learning Modell spielen. eher das Modell nehmen, was 
einfacher ist.
Der Gedanke, der dahinter 
steckt,
ist, dass wir vermeiden wollen,
dass die zufälligen Schwankungen 
in den
Daten mit höherer 
Modellkomplexität
in dem Modell erkannt werden als 
wichtige Muster.
Time ist jetzt auch ein bisschen 
drauf gucken,
dass ich meinen Time Management 
richtig betreibe,
weil wie Sie vielleicht gemerkt 
haben,
habe ich die Tendenz, viel zu 
reden.
Kommen Sie gerne nach der 
Vorlesung,
dann können wir darüber 
sprechen.
Wenn wir das verallgemeinern und 
jetzt nicht nur
über unser EiscremeBeispiel 
nachdenken,
sondern ganz, ganz, ganz High 
Level aus einer fast schon.
Und Uwe Walz würde sich freuen,
wenn diese Formel hier angezeigt 
wird.
Wahrscheinlich aus einer 
mikroökonomischen
Perspektive kann man
natürlich fragen Warum brauchen 
wir Vorhersagen?
Und aus einer ökonomischen
Sicht Wenn ich bestimmte 
Entscheidungsprobleme,
Nutzenmaximierungsprobleme,
Gewinnmaximierungsprobleme 
aufschreibe, dann ist immer so
ein bisschen in
fast allen Optimierungsproblemen 
uncertainty mit drin.
Bestimmte Sachen weiß ich 
einfach nicht.
Es kommt so ein bisschen darauf 
an,
was in der Zukunft passieren 
wird.
Wenn ich heute investiere,
wenn ich eigentlich mein",5.959239006,0,"The generation states that the requested information is not in the provided text, while the ground truth provides the correct factual answer. Therefore, the generation is incorrect as it fails to answer the user's query.",1,"All claims in the generated answer are directly supported by the retrieved context. The context is in German and discusses a model by 'Venkaten und Kollegen', confirming that it does not contain the information requested in the query about the 'Centaur foundation model' or the 'Psych-101 dataset'.",0,The context does not contain any information about the Centaur foundation model or the Psych-101 dataset. It discusses unrelated machine learning concepts in German.
"In the study on capturing human cognition, how does the Centaur model's performance compare to existing cognitive models?",Centaur captures the behaviour of held-out participants better than existing cognitive models.,"Die Studie zeigt, dass das Centaur-Modell eine Erklärungskraft von etwa 70% für die Nutzung und Akzeptanz von Technologie durch Menschen hat. Dies ist eine signifikante Leistung, insbesondere in soziotechnischen Systemen, wo der Mensch oft die Schwachstelle ist. Die Studie erwähnt jedoch nicht direkt, wie sich die Leistung des Centaur-Modells im Vergleich zu anderen, in der Forschung zur Erfassung menschlicher Kognition beschriebenen Modellen verhält.","die das beeinflussen und
was hier Venkatesh und Kollegen 
gemacht haben,
die haben acht verschiedene 
Modelle
aus ganz unterschiedlichen
Disziplinen zusammengenommen und
haben jahrelang rumgewerkelt, um 
zu schauen,
was sind eigentlich die latent 
ähnlichen Faktoren,
was können wir irgendwie 
zusammenfassen und
was sind Faktoren,
die möglichst orthogonal einzeln 
gesehen
unterschiedlich sind und
viel Erklärungsgehalt dafür 
haben
in der Vorhersage,
ob ein Mensch die Technologie 
nutzen wird oder nicht.
Und das haben Sie das Modell, 
was entwickelt haben
letztlich auf ganz viele 
empirische Daten
gelegt und gezeigt,
dass dieses Modell um die 70 % 
der Variation darin,
ob Leute mit Technologie 
interagieren,
diese wirklich nutzen und 
akzeptieren, erklären kann.
Als Spoiler schon mal 70 % der
Variation zu erklären ist 
massiv,
insbesondere in solchen 
soziotechnischen Systemen,
wo wie immer der Mensch die 
Schwachstelle ist.
Womit haben Sie angefangen? Sie 
haben gesagt.
Und dieses Modell ist
vor allen Dingen aus der 
Perspektive
geschaffen worden damals.
Wie kriegen wir eigentlich Leute 
in Unternehmen dazu,
die bereitgestellte Technologie 
zu nutzen?
Es gibt mittlerweile auch zwei
Erweiterungen von diesem Modell Aber den umgekehrten Effekt.
Wir haben die Behavioral,
diese kognitive Komponente 
davon,
die sich eigentlich in unserem 
Kopf geschaffen wird,
wo wir diese Intention to use 
entwickeln,
die wiederum von diesen drei 
Faktoren in diesem Modell
hier ganz grob auf einem sehr 
hohen Level.
Den Zusammenhang erklärt wird.
Und diese Beziehungen hängen
wiederum von den Moderatoren ab.
Ja, ja, erklären, warum das was 
Negatives ist.
Muss ich sie an das Papier 
verweisen, dass keine Ahnung,
wann ich das letzte Mal gelesen 
habe,
steht da bestimmt drin. Kann ich 
ihnen hochladen?
Bzw. Das ist glaube ich sogar 
Open Source.
Das hat mittlerweile glaube ich 
70.000
Situationen oder so,
also das ist wirklich eines der 
fundamentalen Modelle,
wo wir immer noch versuchen zu 
verstehen,
was beeinflusst eigentlich die 
Nutzung von wie gesagt,
Technologie breiter gefasst, 
aber für uns ist relevante.
Mit dem Schwerpunkt unseres 
Kurses sprechen wir natürlich
über die sogenannte Mensch 
Maschine Kollaboration,
was letztlich ist die Nutzung 
und
Akzeptanz von der KI 
Technologie.
Wir versuchen uns in der 
Wirtschaftsinformatik
gerade so ein bisschen wieder 
auf das Neue,
auf die neue Kuh, die durchs
Dorf getrieben wird, zu 
konzentrieren. Feedback Loops in Machine Learning 
 
811 
3.2 Previous Empirical Studies 
We buil t our simulations on two secondary datasets, 
collected by several authors of this paper as part of 
different empirical studies. Study A was an incentivized 
field study conducted over three years from 2016 to 
2019. Study A measured participant s’ behavior in the 
investment game  defined above  in their  role as 
borrowers. The data from Study A allow ed us to 
develop an ML model predicting borrowers’ repayment 
decision and serves as the foundation for simulating 
borrower behavior. Study B, conducted in December 
2020, was an incentivized online experiment where 
participants engaged in the outlined investment game in 
the role of investors. In this experiment, investors could 
access an ML model predicting borrowers ’ repayment 
likelihood. Notably, this model, along with the 
borrowers with whom investors from Study B 
interacted, originated from Study A data. The data from 
Study B provide d the basis for simulating investor 
decisions. We present the exact instructions given in 
these studies in Appendix B.1. 
Study A: At the onset of each semester, first -semester 
economics students from a large German university were",11.85657668,0,"The generation makes factually incorrect claims about the Centaur model and states that a comparison to other models cannot be made. This directly contradicts the ground truth, which provides a clear comparison, stating that Centaur performs better than existing models.",0.5,"The generation is partially faithful. It correctly paraphrases claims from the context that a model has 70% explanatory power and that this is a significant achievement in sociotechnical systems. However, it incorrectly attributes these findings to the 'Centaur-Modell,' which is never mentioned in the context. The context attributes the model to 'Venkaten und Kollegen'.",0,"The context discusses a model by Venkatesh and colleagues concerning technology adoption and separate empirical studies on an investment game, but it does not mention the Centaur model or its performance in capturing human cognition."
"According to the paper on the Centaur foundation model, what is it designed to predict and simulate regarding human cognition?",It can predict and simulate human behaviour in any experiment expressible in natural language.,"Gemäß der Arbeit über das Centaur-Modell wird das Modell menschliche Kognition hinsichtlich der Vorhersage und Simulation von Faktoren vorhersagen, die beeinflussen, ob ein Mensch eine Technologie nutzt und akzeptiert. Konkret werden vier Faktoren identifiziert, die dabei eine Rolle spielen.","Sie sind ein Machine Learning 
Modell.
Kommen wir jetzt zur heutigen 
Vorlesung.
Immer mit diesem Gedanken im 
Kopf.
Wir haben Inputdaten, wir haben
ein Modell und dieses Modell
macht auf den Inputdaten 
letztlich uns eine Vorhersage,
die möglichst präzise ist für 
Daten,
die Sie noch nicht gesehen 
haben.
Fangen wir jetzt wirklich an,
in diesem Teil eins rein zu 
gehen, um zu verstehen,
was können diese Modelle
eigentlich liefern aus einer 
ökonomischen,
betriebswirtschaftlichen, 
gesellschaftlichen Perspektive?
Wir werden jetzt in den ersten
Vorlesungen und es wird so
bis zur fünften Vorlesung gehen.
Da werden wir langsam anfangen,
auch in den zweiten Teil 
überzugehen.
Aber zunächst mal interessiert 
uns gar nicht,
wie wir auf dieses Modell 
kommen,
was dieses Modell genau ist.
Wir werden erstmal annehmen,
da ist irgendein Modell,
das fällt sozusagen vom Himmel.
Und was macht dieses Modell mit 
uns?
Was macht dieses Modell mit 
Organisationen?
Was macht dieses Modell mit 
Personen?
Was macht dieses Modell mit der 
Gesellschaft?
Und um so ein bisschen
eine Hands on Vorstellung zu 
haben,
was Machine Learning Modelle 
machen,
habe ich hier mal ein Beispiel 
mitgebracht,
wo wir jetzt als Gruppe Machine 
Learning Modell spielen. Und diese Systeme haben ein
Zusammenspiel dann was bestimmt,
ob ich eigentlich das System 
nutze.
Das war eines der fundamentalen 
Ergebnisse,
die Sie hier gefunden haben in 
der Studie.
Und dann Sie haben gesagt okay, 
wenn ich weiß,
dass wir die Menschen in
ihrer Kognition überzeugen 
müssen,
dass sie das System nutzen 
sollten und akzeptieren
sollten entweder über System
eins oder über System zwei 
Aktivierungen,
dann lass uns doch mal drüber 
nachdenken,
welche Faktoren denn hier eine 
besondere Rolle spielen.
Und da haben Sie insgesamt in
diesem Modell vier verschiedene 
Faktoren identifiziert.
Einer der Faktoren nennen Sie 
die Performance Expectancy.
Das können Sie sich vorstellen.
Sie haben ein System vor sich 
und ob
Sie eine Bereitschaft 
grundsätzlich Formen
in ihrer Kognition des System zu 
benutzen,
hängt damit zusammen, ob sie 
glauben,
dass dieses System Ihnen hilft,
bestimmte Ziele zu erreichen.
Wenn Sie sich die verschiedenen 
GPTsysteme,
die aktuell verfügbar sind,
auch in den öffentlichen 
Versionen,
dann sind da ganz viele 
verschiedene.
Dann gibt es aktuell vier 
Punkte, wo ich glaube,
das ist generell ZugReifbar 
mittlerweile.
Dann haben wir drei,
wir haben 4.1 4:05 usw.
Wenn ich die Entscheidung 
treffe, die das beeinflussen und
was hier Venkatesh und Kollegen 
gemacht haben,
die haben acht verschiedene 
Modelle
aus ganz unterschiedlichen
Disziplinen zusammengenommen und
haben jahrelang rumgewerkelt, um 
zu schauen,
was sind eigentlich die latent 
ähnlichen Faktoren,
was können wir irgendwie 
zusammenfassen und
was sind Faktoren,
die möglichst orthogonal einzeln 
gesehen
unterschiedlich sind und
viel Erklärungsgehalt dafür 
haben
in der Vorhersage,
ob ein Mensch die Technologie 
nutzen wird oder nicht.
Und das haben Sie das Modell, 
was entwickelt haben
letztlich auf ganz viele 
empirische Daten
gelegt und gezeigt,
dass dieses Modell um die 70 % 
der Variation darin,
ob Leute mit Technologie 
interagieren,
diese wirklich nutzen und 
akzeptieren, erklären kann.
Als Spoiler schon mal 70 % der
Variation zu erklären ist 
massiv,
insbesondere in solchen 
soziotechnischen Systemen,
wo wie immer der Mensch die 
Schwachstelle ist.
Womit haben Sie angefangen? Sie 
haben gesagt.
Und dieses Modell ist
vor allen Dingen aus der 
Perspektive
geschaffen worden damals.
Wie kriegen wir eigentlich Leute 
in Unternehmen dazu,
die bereitgestellte Technologie 
zu nutzen?
Es gibt mittlerweile auch zwei
Erweiterungen von diesem Modell",8.856848478,0,"The generated answer is semantically inconsistent with the ground truth. The generation incorrectly claims the model predicts technology acceptance, whereas the ground truth states it predicts and simulates human behavior in experiments expressible in natural language.",0.5,"The generated answer is partially faithful. It correctly states that a model identifies four different factors related to technology acceptance. However, it is unfaithful in its primary claim that this information pertains to the 'Centaur-Modell,' which is not mentioned in the retrieved context.",0,"The context describes a model by Venkatesh and colleagues that predicts technology acceptance, but it does not mention the 'Centaur foundation model' at all. Therefore, the context is irrelevant to the specific question asked."
"For the Centaur model, what is the name and scale of the dataset used for fine-tuning to capture human cognition?","Psych-101, which covers trial-by-trial data from over 60,000 participants in 160 experiments.","Das Datenset, das für das Fine-Tuning des Centaur-Modells zur Erfassung menschlicher Kognition verwendet wurde, hatte den Namen „XML“.","die das beeinflussen und
was hier Venkatesh und Kollegen 
gemacht haben,
die haben acht verschiedene 
Modelle
aus ganz unterschiedlichen
Disziplinen zusammengenommen und
haben jahrelang rumgewerkelt, um 
zu schauen,
was sind eigentlich die latent 
ähnlichen Faktoren,
was können wir irgendwie 
zusammenfassen und
was sind Faktoren,
die möglichst orthogonal einzeln 
gesehen
unterschiedlich sind und
viel Erklärungsgehalt dafür 
haben
in der Vorhersage,
ob ein Mensch die Technologie 
nutzen wird oder nicht.
Und das haben Sie das Modell, 
was entwickelt haben
letztlich auf ganz viele 
empirische Daten
gelegt und gezeigt,
dass dieses Modell um die 70 % 
der Variation darin,
ob Leute mit Technologie 
interagieren,
diese wirklich nutzen und 
akzeptieren, erklären kann.
Als Spoiler schon mal 70 % der
Variation zu erklären ist 
massiv,
insbesondere in solchen 
soziotechnischen Systemen,
wo wie immer der Mensch die 
Schwachstelle ist.
Womit haben Sie angefangen? Sie 
haben gesagt.
Und dieses Modell ist
vor allen Dingen aus der 
Perspektive
geschaffen worden damals.
Wie kriegen wir eigentlich Leute 
in Unternehmen dazu,
die bereitgestellte Technologie 
zu nutzen?
Es gibt mittlerweile auch zwei
Erweiterungen von diesem Modell dieser Gleichung hier 
ausdrücken.
Wir haben drei verschiedene 
Komponenten.
Wir haben hier dieses Hütchen,
wir haben das fix und wir haben 
hier dieses Y Hütchen.
Meine erste Frage an Sie Was war 
das? F Hütchen.
Yes, genau richtig.
Wir haben hier das erlernte 
Machine Learning Modell,
was die Muster, die wir in 
historischen
Daten durch Algorithmen erkannt 
haben, abspeichert.
Hier in diesem F. Steckt unser 
gesamtes Wissen drin,
was wir irgendwie extrahieren
und wie genau wir das 
extrahieren.
Das wird der zweite Teil unserer 
Vorlesung sein.
Wichtig hierbei Hütchen ist 
immer dafür ein Indikator,
dass wir von einer Approximation 
sprechen.
Das ist ein Modell.
Das ist nicht der wahre 
unterliegende Prozess,
der die Daten generiert.
Das ist nicht die Landschaft von 
Frankfurt sozusagen,
sondern es ist die Landkarte.
Es ist ein explizit abstrakteres 
Modell,
eine Darstellung der Realität.
Und da können eben Fehler drin 
sein.
Es ist ganz wichtig, sich
immer wieder vor Augen zu 
halten.
Dann haben wir die zweite 
Komponente.
Das war das XML. Was ist das?.X. 
Jemand eine Idee?
Jetzt dahinten? Genau das sind 
die Daten,
die wir in diese Maschine 
reintun.
Wir haben zum Beispiel, wenn Sie 
überlegen,
Sie interagieren mit Chat GPT 10. Juli 2025
A mathematical model of a brain cell: perceptron
10
#𝑦!=𝑓%""𝑤""⋅𝑥""+𝑏
Weighted linear combination of inputsOutput
Non-linearization(activation function) Intercept
Representation   +Evaluation+Optimization",7.570560932,0,"The generated answer provides a factually incorrect dataset name ('XML'), which directly contradicts the correct name ('Psych-101') and scale provided in the ground truth.",0,"The generated answer is entirely unfaithful. The context mentions 'XML' as a generic placeholder for input data in a machine learning equation ('Genau das sind die Daten, die wir in diese Maschine reintun'). The generation incorrectly presents 'XML' as the specific name of a dataset used for a 'Centaur-Modell,' neither of which is mentioned in the context.",0,"The provided context is a general, abstract discussion about machine learning models, using terms like 'F HÃ¼tchen' and 'XML' as placeholders. It contains no specific information about the Centaur model or any dataset used for fine-tuning."
In the paper 'A foundation model to predict and capture human cognition' what is the name of the computational model introduced?,Centaur.,"Das in der Arbeit ""A foundation model to predict and capture human cognition"" eingeführte Rechenmodell heißt ""System eins"".","Sie sind ein Machine Learning 
Modell.
Kommen wir jetzt zur heutigen 
Vorlesung.
Immer mit diesem Gedanken im 
Kopf.
Wir haben Inputdaten, wir haben
ein Modell und dieses Modell
macht auf den Inputdaten 
letztlich uns eine Vorhersage,
die möglichst präzise ist für 
Daten,
die Sie noch nicht gesehen 
haben.
Fangen wir jetzt wirklich an,
in diesem Teil eins rein zu 
gehen, um zu verstehen,
was können diese Modelle
eigentlich liefern aus einer 
ökonomischen,
betriebswirtschaftlichen, 
gesellschaftlichen Perspektive?
Wir werden jetzt in den ersten
Vorlesungen und es wird so
bis zur fünften Vorlesung gehen.
Da werden wir langsam anfangen,
auch in den zweiten Teil 
überzugehen.
Aber zunächst mal interessiert 
uns gar nicht,
wie wir auf dieses Modell 
kommen,
was dieses Modell genau ist.
Wir werden erstmal annehmen,
da ist irgendein Modell,
das fällt sozusagen vom Himmel.
Und was macht dieses Modell mit 
uns?
Was macht dieses Modell mit 
Organisationen?
Was macht dieses Modell mit 
Personen?
Was macht dieses Modell mit der 
Gesellschaft?
Und um so ein bisschen
eine Hands on Vorstellung zu 
haben,
was Machine Learning Modelle 
machen,
habe ich hier mal ein Beispiel 
mitgebracht,
wo wir jetzt als Gruppe Machine 
Learning Modell spielen. die das beeinflussen und
was hier Venkatesh und Kollegen 
gemacht haben,
die haben acht verschiedene 
Modelle
aus ganz unterschiedlichen
Disziplinen zusammengenommen und
haben jahrelang rumgewerkelt, um 
zu schauen,
was sind eigentlich die latent 
ähnlichen Faktoren,
was können wir irgendwie 
zusammenfassen und
was sind Faktoren,
die möglichst orthogonal einzeln 
gesehen
unterschiedlich sind und
viel Erklärungsgehalt dafür 
haben
in der Vorhersage,
ob ein Mensch die Technologie 
nutzen wird oder nicht.
Und das haben Sie das Modell, 
was entwickelt haben
letztlich auf ganz viele 
empirische Daten
gelegt und gezeigt,
dass dieses Modell um die 70 % 
der Variation darin,
ob Leute mit Technologie 
interagieren,
diese wirklich nutzen und 
akzeptieren, erklären kann.
Als Spoiler schon mal 70 % der
Variation zu erklären ist 
massiv,
insbesondere in solchen 
soziotechnischen Systemen,
wo wie immer der Mensch die 
Schwachstelle ist.
Womit haben Sie angefangen? Sie 
haben gesagt.
Und dieses Modell ist
vor allen Dingen aus der 
Perspektive
geschaffen worden damals.
Wie kriegen wir eigentlich Leute 
in Unternehmen dazu,
die bereitgestellte Technologie 
zu nutzen?
Es gibt mittlerweile auch zwei
Erweiterungen von diesem Modell Und diese Systeme haben ein
Zusammenspiel dann was bestimmt,
ob ich eigentlich das System 
nutze.
Das war eines der fundamentalen 
Ergebnisse,
die Sie hier gefunden haben in 
der Studie.
Und dann Sie haben gesagt okay, 
wenn ich weiß,
dass wir die Menschen in
ihrer Kognition überzeugen 
müssen,
dass sie das System nutzen 
sollten und akzeptieren
sollten entweder über System
eins oder über System zwei 
Aktivierungen,
dann lass uns doch mal drüber 
nachdenken,
welche Faktoren denn hier eine 
besondere Rolle spielen.
Und da haben Sie insgesamt in
diesem Modell vier verschiedene 
Faktoren identifiziert.
Einer der Faktoren nennen Sie 
die Performance Expectancy.
Das können Sie sich vorstellen.
Sie haben ein System vor sich 
und ob
Sie eine Bereitschaft 
grundsätzlich Formen
in ihrer Kognition des System zu 
benutzen,
hängt damit zusammen, ob sie 
glauben,
dass dieses System Ihnen hilft,
bestimmte Ziele zu erreichen.
Wenn Sie sich die verschiedenen 
GPTsysteme,
die aktuell verfügbar sind,
auch in den öffentlichen 
Versionen,
dann sind da ganz viele 
verschiedene.
Dann gibt es aktuell vier 
Punkte, wo ich glaube,
das ist generell ZugReifbar 
mittlerweile.
Dann haben wir drei,
wir haben 4.1 4:05 usw.
Wenn ich die Entscheidung 
treffe,",6.376398087,0,"The generated answer provides the incorrect name for the model ('System eins'), directly contradicting the correct name ('Centaur') in the ground truth.",0,"The generated answer is unfaithful. The retrieved context discusses a model related to technology acceptance by 'Venkaten und Kollegen' and also mentions persuading people to use a system via 'System eins oder Ã¼ber System zwei Aktivierungen' (System one or System two activations). The generation incorrectly claims the computational model introduced is named 'System eins,' which is a misinterpretation of the context.",0,"The context discusses a model related to technology acceptance, mentioning 'System eins' and 'System zwei,' but it does not mention the paper 'A foundation model to predict and capture human cognition' or the name of the model introduced in it."
The paper 'Algorithmic Bias?' concludes that optimizing for what factor can lead to apparently discriminatory outcomes in ad delivery?,An algorithm that simply optimizes for cost-effectiveness.,"Die Studie 'Algorithmic Bias?' besagt, dass die Optimierung für den Faktor „ausgewählte Nutzergruppen“ zu scheinbar diskriminierenden Ergebnissen bei der Werbeauslieferung führen kann.","significant consequences, such as in healthcare, loan 
approval, hiring, or criminal justice systems. 
Mitigating algorithmic discrimination : The 
expansive literature on algorithmic discrimination 
proposes various methods to identify and alleviate 
such biases. According to d ’Alessandro et al. (2017), 
we can divide these mitigation strategies into three 
categories: pre -processing, in -processing, and post -
processing. Pre -processing strategies strive to 
eliminate disparities inherent in the dataset. Methods 
such as those proposed by Kamiran and Calders (2012) 
and Zafar et al. (2017) employ data pre -processing 
techniques like feature massaging and reweighting to 
balance the dataset based on social group 
characteristics. In -processing strategies involve 
conventional learning algorit hms during model 
training. Researchers often use techniques like naive 
Bayes and decision tr ees for debiasing (Calders & 
Verwer, 2010; Zhang et al., 2018). Additional research 
suggests placing constraints on the classification 
model to mandate the satisfaction of a proxy 
(Woodworth et al., 2017). Lastly, post -processing 
strategies aim to adjust the output to counter biases. 
For example, Corbett -Davies et al. (2017) 15. Mai 2025
Algorithmic bias
Algorithmic bias: outputs of an algorithm benefit or disadvantage certain individuals or groupsmore than others without a justified reasonfor such unequal impacts •Ethical concern is the replication and reinforcement of social biasesthat exist in society•Algorithmic bias is a socio-technical constructthat involves technology and human actors•Social aspect: biases that have long existed in society•Technical facet: the manifestation of social biases in models’ outcomes
14 discrimination
Algorithms are not inherently discriminatory, and engineers
rarely intentionally introduce bias into algorithms. However, bias
can still arise in algorithmic recruitment. This issue is closely
linked to the fundamental technology behind AI and ML. The ML
process can be simpliﬁed into several stages, each involving three
key components contributing to algorithmic bias: dataset con-
struction, the engineer’s target formulation, and feature selection
(36KE, 2020). When the dataset lacks diverse representation from
different companies, bias may be introduced during the devel-
opment of algorithmic rules by engineers and when annotators
handle unstructured data (Zixun,2020).
Datasets: bias soil. Datasets serve as the foundation of machine
learning (ML). If an algorithm’s data collection lacks quantity and
quality, it will fail to represent reality objectively, leading to
inevitable bias in algorithmic decisions. Researchers commonly
use a 95% conﬁdence level, which provides 95% certainty but still
leaves a one in twenty chance of bias (Raub,2018). Nearly every
ML algorithm relies on biased databases.
One issue arises when datasets are skewed towards accessible",7.454455376,0,The generated answer identifies the wrong optimization factor ('ausgewÃ¤hlte Nutzergruppen' or 'selected user groups') as the cause of discriminatory outcomes. The ground truth correctly identifies the factor as 'cost-effectiveness'.,0,"The generated answer is entirely unfaithful. The context discusses various aspects of algorithmic discrimination, including mitigation strategies and the sources of bias in datasets. It does not mention optimizing for 'ausgewÃ¤hlte Nutzergruppen' (selected user groups) or provide any information related to the 'Algorithmic Bias?' paper's conclusion on ad delivery.",0.5,"The context discusses the general topic of algorithmic bias and its mitigation strategies. However, it does not mention the specific paper 'Algorithmic Bias?' or the particular factor (cost-effectiveness) that, when optimized for, leads to discriminatory ad delivery. The context is on-topic but does not contain the answer."
"In the context of the STEM career ad study, what was the difference in click behavior between men and women who were shown the ad?","Among those who saw the ad, women were more likely to click on it than men.","According to the text, even though gender identification was not included as a variable in the system, tests showed that the system systematically produced a lower probability for women, even when they had the same qualifications.","that impact the hiring process. It would be interesting to analyze
the psychological effects of applying this algorithmic recruitment
technique on various populations (gender, age, education level)
from an organizational behavior perspective. While recent studies
have primarily discussed discrimination theory in the traditional
economy’s hiring market, future theoretical research should
consider how advanced technology affects equity in hiring within
the digital economy.
Conclusion
The study concludes that the fo urth industrial revolution
introduced technological innovations signiﬁcantly affecting the
recruitment industry. It extends the analysis of statistical dis-
crimination theory in the digital age and adopts a literature
review approach to explore four themes related to AI-based
recruitment. The study argues that algorithmic bias remains an
issue while AI recruitment tools offer beneﬁts such as improved
recruitment quality, cost reduction, and increased ef ﬁciency.
Recruitment algorithms ’bias is evident in gender, race, color,
and personality. The primary source of algorithmic bias lies in
partial historical data. The personal preferences of algorithm
engineers also contribute to algorithmic bias. Technical mea- die das beeinflussen und
was hier Venkatesh und Kollegen 
gemacht haben,
die haben acht verschiedene 
Modelle
aus ganz unterschiedlichen
Disziplinen zusammengenommen und
haben jahrelang rumgewerkelt, um 
zu schauen,
was sind eigentlich die latent 
ähnlichen Faktoren,
was können wir irgendwie 
zusammenfassen und
was sind Faktoren,
die möglichst orthogonal einzeln 
gesehen
unterschiedlich sind und
viel Erklärungsgehalt dafür 
haben
in der Vorhersage,
ob ein Mensch die Technologie 
nutzen wird oder nicht.
Und das haben Sie das Modell, 
was entwickelt haben
letztlich auf ganz viele 
empirische Daten
gelegt und gezeigt,
dass dieses Modell um die 70 % 
der Variation darin,
ob Leute mit Technologie 
interagieren,
diese wirklich nutzen und 
akzeptieren, erklären kann.
Als Spoiler schon mal 70 % der
Variation zu erklären ist 
massiv,
insbesondere in solchen 
soziotechnischen Systemen,
wo wie immer der Mensch die 
Schwachstelle ist.
Womit haben Sie angefangen? Sie 
haben gesagt.
Und dieses Modell ist
vor allen Dingen aus der 
Perspektive
geschaffen worden damals.
Wie kriegen wir eigentlich Leute 
in Unternehmen dazu,
die bereitgestellte Technologie 
zu nutzen?
Es gibt mittlerweile auch zwei
Erweiterungen von diesem Modell gesagt Na ja,
per Gesetz dürfen wir nicht auf 
Gender gucken.
Was also gemacht wurde,
ist man hat die Gendermerkmale,
also die selbst angegebenen 
Geschlecht.
Geschlechtsidentifikation hat 
man rausgenommen.
Es war also nicht Teil des 
Systems.
Trotzdem in diesem Testbereich,
wenn wir in dem Crisp an 
Evaluation denken,
bevor das System wirklich live 
gegangen
ist und massiv eben angefangen 
hat,
die neue Einstellungskriterien 
zu beeinflussen,
haben bestimmte Tests gezeigt.
Naja, obwohl ich nicht angegeben 
habe,
ob diese Person, obwohl das 
Modell nicht in der Lage war,
auf Informationen über die
Geschlechtsidentifikation diese 
Person zuzugreifen,
hat das System systematisch
bei Frauen eine geringere 
Wahrscheinlichkeit ausgespuckt.
Woher kann das kommen? Was 
denken Sie?
Ich habe nicht dem Modell Zugang 
zu dem
eigentlichen 
Genderidentification gegeben
und trotzdem in Tests.
Wenn ich dann gesagt habe, naja,
wie hoch ist denn die 
Vorhersagegenauigkeit für 
Frauen,
wie hoch ist denn für Männer?
Wurde dann gesehen,
dass sie für Frauen systematisch
bei gleichen Qualifikationen
systematisch schlechter war.
Woher kann das kommen,
dass das System das trotzdem 
erkannt hat oder
diesen Bias reproduziert hat,",7.424863338,0,"The generated answer discusses algorithmic bias in a hiring context, which is completely unrelated to the ground truth, which describes the difference in ad-clicking behavior between men and women.",1,"All claims in the generated answer are faithful. The context explicitly states that although the gender identification was removed from the system, tests showed it systematically produced a lower probability for women with the same qualifications[cite: 142, 145].",0,"The context discusses gender bias in an algorithmic hiring tool, where gender identification was removed as a variable, but the system still showed bias against women. It does not mention a STEM career ad study or the click behavior of men versus women."
"In the empirical study of gender-based discrimination in STEM ad display, what reason is given for why fewer women saw the advertisement?","Younger women are a prized demographic and are more expensive to show ads to, so a cost-optimizing algorithm shows the ad to them less often.","Basierend auf dem Text, sahen weniger Frauen die Anzeige, weil das System aufgrund historischer Daten, die eine geringere Beteiligung von Frauen an großen Universitäten und technischen Berufen widerspiegelten, systematisch Frauen als weniger geeignet für Stellen wie Krankenpfleger interpretierte. Das System ""dachte"", Frauen sollten nicht eingestellt werden, obwohl sie die Geschlechtsidentifikation der Bewerber nicht explizit einbezog.
","Frauen,
wie hoch ist denn für Männer?
Wurde dann gesehen,
dass sie für Frauen systematisch
bei gleichen Qualifikationen
systematisch schlechter war.
Woher kann das kommen,
dass das System das trotzdem 
erkannt hat oder
diesen Bias reproduziert hat,
der in den historischen Daten 
vorgelegen hat?
In der Vergangenheit waren viel 
mehr Männer
an den großen Universitäten,
haben dann mehr technische 
Berufe gehabt oder
technische Studiengänge sind 
dann
eher in den technischen Berufen,
so dass der Anteil der Frauen
in den Daten einfach viel 
geringer war,
was das System interpretiert hat 
als naja,
Frauen sollte ich nicht 
anstellen.
Ich wollte noch sagen, dass 
vielleicht auch andere
Ideen also nicht identifizieren 
würde.
Ich weiß es nicht.
Amazon wird wahrscheinlich nicht 
Körpergröße benutzen,
aber beschnittene Männer eher 
größer.
Und dann so welche Daten genau 
in die Richtung?
Das sind andere Korrelationen.
Ich muss nicht genau ihr 
Geschlecht
wissen oder ihre Identifikation
mit einem bestimmten Geschlecht.
Ich kann über ganz viele andere
korrelative Maße ein sehr
guter Einschätzung davon 
bekommen,
ob sie sich mit
einem bestimmten Geschlecht 
identifizieren.
Hier in diesem Fall war es 
tatsächlich die gesagt Na ja,
per Gesetz dürfen wir nicht auf 
Gender gucken.
Was also gemacht wurde,
ist man hat die Gendermerkmale,
also die selbst angegebenen 
Geschlecht.
Geschlechtsidentifikation hat 
man rausgenommen.
Es war also nicht Teil des 
Systems.
Trotzdem in diesem Testbereich,
wenn wir in dem Crisp an 
Evaluation denken,
bevor das System wirklich live 
gegangen
ist und massiv eben angefangen 
hat,
die neue Einstellungskriterien 
zu beeinflussen,
haben bestimmte Tests gezeigt.
Naja, obwohl ich nicht angegeben 
habe,
ob diese Person, obwohl das 
Modell nicht in der Lage war,
auf Informationen über die
Geschlechtsidentifikation diese 
Person zuzugreifen,
hat das System systematisch
bei Frauen eine geringere 
Wahrscheinlichkeit ausgespuckt.
Woher kann das kommen? Was 
denken Sie?
Ich habe nicht dem Modell Zugang 
zu dem
eigentlichen 
Genderidentification gegeben
und trotzdem in Tests.
Wenn ich dann gesagt habe, naja,
wie hoch ist denn die 
Vorhersagegenauigkeit für 
Frauen,
wie hoch ist denn für Männer?
Wurde dann gesehen,
dass sie für Frauen systematisch
bei gleichen Qualifikationen
systematisch schlechter war.
Woher kann das kommen,
dass das System das trotzdem 
erkannt hat oder
diesen Bias reproduziert hat, Das hat Google jetzt anscheinend 
durch Filter so gemacht,
dass wenn man Krankenpfleger 
eingibt,
dass sowohl Männer und Frauen 
gezeigt werden.
Aber bis vor zwei Jahren war
es immer noch ein sehr gutes 
Beispiel.
Wenn ich Sie frage, googeln Sie 
mal bitte nach Images.
Dann war Krankenpfleger zu 99 %
weiblich und Arzt zu 99 % 
männlich,
obwohl diese Bilder natürlich 
von beiden
eigentlich schon vorhanden sein 
sollen.
Das heißt, wir haben hier
irgendwelche gewachsenen 
technischen Grundlagen,
Datenbanken, die das einfach 
noch nicht abbilden können.
Having said that, die 
Unternehmen sind
sehr sensibilisiert durch diese 
ganzen PR Probleme,
die sie damit erlitten haben und 
haben angefangen,
diese Daten zu bereinigen.
Aber das erfordert eben massiv 
viel Investitionen
in Datenbereinigung,
wo wir wieder in dem 
Kriegsmodell,
bei dem Data Preparation sind.
Sie müssen sich klar sein Wie 
sind
Ihre Strukturen der Daten 
eigentlich aufgebaut?
Soweit ich weiß es auch manchmal
das Labeling von Menschen 
gemacht.
Richtig? Genau. Es könnte so 
sein,
dass wir haben eine Gruppe von 
Menschen,
die nicht politisch korrekt 
denken.
Und dann würden sie es bewusst 
falsch.
Richtig. Auch ein massives 
Problem.
Wir haben auf der einen Seite",9.107410669,0,"The generated answer incorrectly explains the reason for bias by referencing historical data on university attendance. The ground truth provides the correct reason: younger women are a more expensive demographic for advertisers, so a cost-optimizing algorithm shows them ads less often.",0.8,"The generation is mostly faithful. [cite_start]It correctly identifies that historical data showed fewer women in technical fields, which the system interpreted as women being less suitable[cite: 150]. [cite_start]However, the claim that the system interpreted women as less suitable for roles like 'Krankenpfleger' (nurses) is not directly stated, though the context does mention 'Krankenpfleger' in a different example about biased image search results[cite: 162].",0,"The context explains how historical data imbalances can lead to gender bias in algorithms, even when gender is not an explicit feature. However, it does not mention the specific STEM ad study from the question or the correct reason that fewer women saw the ad (because younger women are a more expensive advertising demographic)."
"Regarding the display of STEM career ads, what was the empirical result of the ad's delivery in the 'Algorithmic Bias?' paper?",Fewer women saw the ad than men.,"The text doesn't state a specific ""empirical result"" of the advertising delivery within the 'Algorithmic Bias' study. It primarily outlines the *consequences* of algorithmic bias, including:

*   **Individual consequences:** Rejection of ML tools, customers paying higher prices.
*   **Organisational consequences:** Violating equal opportunity policies, high customer churn rate.
*   **Societal-level consequences:** Increased gaps between disadvantaged groups, fostered polarization and human discrimination.

It describes the *potential* outcomes stemming from biased algorithms, but doesn't detail a specific measurement or finding from the advertising delivery itself.","15. Mai 2025
Algorithmic bias
Algorithmic bias: outputs of an algorithm benefit or disadvantage certain individuals or groupsmore than others without a justified reasonfor such unequal impacts •Ethical concern is the replication and reinforcement of social biasesthat exist in society•Algorithmic bias is a socio-technical constructthat involves technology and human actors•Social aspect: biases that have long existed in society•Technical facet: the manifestation of social biases in models’ outcomes
14 data already reﬂects social prejudices, and the algorithm also
incorporates biased relationships, leading to the“bias in and bias
out” phenomenon (36KE, 2020). This phenomenon means that
discrimination and disparities exist, just like in forecasting, where
historical inequalities are projected into the future and may even
be ampliﬁed (Mayson, 2018).
A research team at Princeton University discovered that
algorithms lack access to the absolute truth. The machine corpus
contains biases that closely resemble the implicit biases observed
in the human brain. Artiﬁcial intelligence has the potential to
perpetuate existing patterns of bias and discrimination because
these systems are typically trained to replicate the outcomes
achieved by human decision-makers (Raso et al.2018). What is
worse, the perception of objectivity surrounding high-tech
systems obscures this fact.
In summary, if an algorithmic system is trained on biased and
unrepresentative data, it runs the risk of replicating that bias.
Data feature selection: designer bias. The introduction of bias is
sometimes not immediately apparent in model construction
because computer scientists are often not trained to consider 15. Mai 2025
Consequences of algorithmic biasIndividual consequences include•rejection or discontinuance of ML tools.•customers paying higher prices than usual Organisational consequences include •violating equal opportunity policies•high customer churn rate Societal-level consequences include •increased gaps between historically disadvantaged groups and others•Fostered polarization and human discrimination
17",11.48318863,0,"The generated answer claims the text doesn't state a specific empirical result and instead lists general consequences of bias. This is incorrect. The ground truth provides the specific empirical result from the paper, which is that fewer women saw the ad than men.",1,"All claims in the generated answer are directly supported by the retrieved context. [cite_start]The context lists individual, organizational, and societal-level consequences of algorithmic bias, matching the claims made in the generation[cite: 175, 176, 177]. It also confirms that a specific empirical result from the ad delivery itself is not stated.",0.5,The context provides a general definition of algorithmic bias and lists its potential consequences. It does not contain any specific information about a study on STEM career ads or the empirical result of the ad's delivery. The context is thematically related but does not answer the question.
"In the study on gender-based discrimination in STEM career ads, what was the explicit intention for the ad's delivery?",The ad was explicitly intended to be gender-neutral in its delivery.,"Die Studie erwähnt nicht die explizite Absicht bei der Auslieferung von Anzeigen für STEM-Berufe. Sie konzentriert sich auf die Erkennung von Bias in einem System, das anhand von Geschlechtsidentifikation Vorhersagen trifft, und nicht auf die Gestaltung von Anzeigen.","gesagt Na ja,
per Gesetz dürfen wir nicht auf 
Gender gucken.
Was also gemacht wurde,
ist man hat die Gendermerkmale,
also die selbst angegebenen 
Geschlecht.
Geschlechtsidentifikation hat 
man rausgenommen.
Es war also nicht Teil des 
Systems.
Trotzdem in diesem Testbereich,
wenn wir in dem Crisp an 
Evaluation denken,
bevor das System wirklich live 
gegangen
ist und massiv eben angefangen 
hat,
die neue Einstellungskriterien 
zu beeinflussen,
haben bestimmte Tests gezeigt.
Naja, obwohl ich nicht angegeben 
habe,
ob diese Person, obwohl das 
Modell nicht in der Lage war,
auf Informationen über die
Geschlechtsidentifikation diese 
Person zuzugreifen,
hat das System systematisch
bei Frauen eine geringere 
Wahrscheinlichkeit ausgespuckt.
Woher kann das kommen? Was 
denken Sie?
Ich habe nicht dem Modell Zugang 
zu dem
eigentlichen 
Genderidentification gegeben
und trotzdem in Tests.
Wenn ich dann gesagt habe, naja,
wie hoch ist denn die 
Vorhersagegenauigkeit für 
Frauen,
wie hoch ist denn für Männer?
Wurde dann gesehen,
dass sie für Frauen systematisch
bei gleichen Qualifikationen
systematisch schlechter war.
Woher kann das kommen,
dass das System das trotzdem 
erkannt hat oder
diesen Bias reproduziert hat, maintained ten years. After applying an initial screening related
to titles, keywords, or abstracts, the literature was selected based
on its relevance to the research topic.
The obtained literature was studied in depth to reveal the
surfaced themes. Several systematic research themes were iden-
tiﬁed, including AI-based recruitment applications and beneﬁts,
causes of algorithmic discrimination, which algorithmic recruit-
ment discrimination exists, and algorithmic recruitment dis-
crimination resolution.
The process applied for the reviews depicted in Fig.1. After
excluding duplicates and less relevant and outdated literature,
only 45 articles could be used as references for this study (referred
to Table1). The literature review shows that most of the research
on algorithmic hiring discrimination has occurred in recent years.
The research trend indicates that algorithmic hiring discrimina-
tion will be a hot research topic in the coming period.
1. The ﬁrst theme is the application of various aspects of
recruitment based on artiﬁcial intelligence support and its
beneﬁts. Bogen and Rieke (2018), Ahmed (2018), Hmoud
and Laszlo (2019), Albert (2019), van Esch et al. (2019),
Köchling et al. ( 2022), and Chen ( 2023) consider the Frauen,
wie hoch ist denn für Männer?
Wurde dann gesehen,
dass sie für Frauen systematisch
bei gleichen Qualifikationen
systematisch schlechter war.
Woher kann das kommen,
dass das System das trotzdem 
erkannt hat oder
diesen Bias reproduziert hat,
der in den historischen Daten 
vorgelegen hat?
In der Vergangenheit waren viel 
mehr Männer
an den großen Universitäten,
haben dann mehr technische 
Berufe gehabt oder
technische Studiengänge sind 
dann
eher in den technischen Berufen,
so dass der Anteil der Frauen
in den Daten einfach viel 
geringer war,
was das System interpretiert hat 
als naja,
Frauen sollte ich nicht 
anstellen.
Ich wollte noch sagen, dass 
vielleicht auch andere
Ideen also nicht identifizieren 
würde.
Ich weiß es nicht.
Amazon wird wahrscheinlich nicht 
Körpergröße benutzen,
aber beschnittene Männer eher 
größer.
Und dann so welche Daten genau 
in die Richtung?
Das sind andere Korrelationen.
Ich muss nicht genau ihr 
Geschlecht
wissen oder ihre Identifikation
mit einem bestimmten Geschlecht.
Ich kann über ganz viele andere
korrelative Maße ein sehr
guter Einschätzung davon 
bekommen,
ob sie sich mit
einem bestimmten Geschlecht 
identifizieren.
Hier in diesem Fall war es 
tatsächlich die",9.003078699,1,"The generation correctly states that the ad's delivery was intended to be gender-neutral, which is semantically consistent with the ground truth.",1,"The generated answer is faithful. [cite_start]The context states 'per Gesetz dÃ¼rfen wir nicht auf Gender gucken' (by law we are not allowed to look at gender) and 'man hat die Gendermerkmale...rausgenommen' (the gender characteristics were removed), which directly supports the generation's claim that the study focused on a system where gender was removed to test for bias, rather than having an explicit intention for ad delivery[cite: 188, 189].",1,"The German portion of the context directly addresses the user's question. It describes a situation where, by law, gender characteristics were explicitly removed from a system to make it gender-neutral, which was the explicit intention."
The findings of the 'Feeback Loops in Machine Learing' paper underscore the complex nature of algorithmic discrimination as what kind of phenomenon?,A sociotechnological phenomenon.,"Die Ergebnisse des Papiers „Feedback Loops in Machine Learning“ betonen die komplexe Natur der algorithmischen Diskriminierung als ein Phänomen, das durch die Interaktion zwischen ML-Systemen und menschlichen Benutzern entsteht, insbesondere in Umgebungen, in denen ML-Modelle kontinuierlich aktualisiert werden. Es zeigt sich, dass menschliches Eingreifen die Lernfähigkeiten von ML-Systemen untergraben und dazu führen kann, dass die Maschinen diskriminierendes Verhalten über die Zeit aufrechterhalten oder sogar annehmen.","Feedback Loops in Machine Learning 
 
807 
2.1 Algorithmic Discrimination 
Algorithmic discrimination: Discrimination involves 
statements or actions that unjustifiably disadvantage 
members of particular social groups. These actions 
typically stem from conscious or subconscious attitudes, 
prejudices, or emotional associations tied to 
characteristics such as  gender, age, disability, race, 
language, religion, or sexual identity (Scherr, 2008). In 
today’s era, where algorithmic systems based on ML 
models frequently aid human decisions, researchers and 
practitioners often employ the te rm “algorithmic 
discrimination” to refer to system outputs that 
disproportionately benefit or disadvantage specific 
groups, even when no justification for the disparate 
treatment exists from a ground -truth perspective 
(Kordzadeh & Ghasemaghaei, 2022).1  
Algorithmic discrimination can originate from various 
sources. First, it may stem from intentional or 
unintentional social biases encoded within the training 
data (Friedman & Nissenbaum, 1996; Romei & Ruggieri, 
2013; Kleinberg et al., 2018). For example, if a training 
dataset holds more positively labeled examples for men, 
the ML model may predict positive labels less accurately Feedback Loops in Machine Learning 
 
815 
 
Note: Panel (i) illustrates outcomes where the initial label imbalance for the minority class was at the maximum, whereas Panel (ii) corresponds 
to conditions with no initial label imbalance 
Figure 4. Progression of the Mean Share of Positive Predictions and False-Negative Error Rates  
across Iterations, Differentiated by Gender over Time 
4.1 Continuous Updating and 
Algorithmic Discrimination 
Figure 4 illustrates the temporal evolution of mean 
shares of positive predictions and false-negative errors 
in the absence of human discrimination . We present 
separate results for female  (dashed lines)  and male 
borrowers (solid lines). Panel (i ) outlines simulation 
results for our treatment condition with maxim um 
initial training data label imbalance —where there are  
no repayment examples. Panel (ii) presents results for 
our control condition without initial label imbalance. 
Our findings indicate that the continuous updating of 
machine learning (ML) models can help reduce 
algorithmic discrimination over time, as measured by 
statistical parity. In situations where there was a 
substantial initial label imbalance leading to discrimination. We highlight that continuous updating, 
absent enduring human discrimination, may stimulate  
self-correcting mechanisms. Theoretically, our findings 
underscore the sociotechnological nature of algorithmic 
discrimination. We extend the existing literature by 
revealing how algorithmic discrimination can diminish 
or emerge due to the interaction bet ween ML systems 
and human users in environments where continuous ly 
updating ML models is essential. We f ound evidence 
that humans in the loop can undermine the powerful 
learning capabilities of ML systems, inadvertently 
teaching the machines to maintain or even adopt 
discriminatory behaviors over time. Our insights 
provide a novel, dynamic perspective on algorithmic 
discrimination, enhancing the comprehension of its 
origins and moderating factors and highlighting the 
potency of continuous model updating to mitigate it. 
Our findings also speak to broader discussions on ways 
to address model drift challenges (see, e.g., Mallick et 
al., 2022). In our context, unjustified algorithmic 
discrimination can be thought of as an outdated input -
output relationship that the model learned from training 
data, i.e., as resulting from a concept drift. On the other",12.01517177,1,The generation's claim that algorithmic discrimination is a 'sociotechnological phenomenon' is semantically identical to the ground truth.,1,All claims in the generated answer are directly verifiable from the retrieved context. [cite_start]The context explicitly states that algorithmic discrimination can emerge from the interaction between ML systems and human users [cite: 224] [cite_start]and that humans in the loop can cause machines to maintain or adopt discriminatory behaviors over time[cite: 225].,1,"The context directly answers the question by stating, 'Theoretically, our findings underscore the sociotechnological nature of algorithmic discrimination'."
What type of setting was used in the simulations of the 'Feedback Loops in Machine Learning' paper to examine the ML model's evolution?,"A setting that mirrors sequential interactions, such as loan approval decisions.","Im Paper „Feedback Loops in Machine Learning“ wurde eine dynamische, nicht-stationäre Umgebung verwendet, um die Entwicklung des ML-Modells zu untersuchen. Diese Umgebung zeichnete sich durch Veränderungen im zugrunde liegenden Datenerzeugungsprozess aus, was als „Drift“ bezeichnet wird.","Sie sind ein Machine Learning 
Modell.
Kommen wir jetzt zur heutigen 
Vorlesung.
Immer mit diesem Gedanken im 
Kopf.
Wir haben Inputdaten, wir haben
ein Modell und dieses Modell
macht auf den Inputdaten 
letztlich uns eine Vorhersage,
die möglichst präzise ist für 
Daten,
die Sie noch nicht gesehen 
haben.
Fangen wir jetzt wirklich an,
in diesem Teil eins rein zu 
gehen, um zu verstehen,
was können diese Modelle
eigentlich liefern aus einer 
ökonomischen,
betriebswirtschaftlichen, 
gesellschaftlichen Perspektive?
Wir werden jetzt in den ersten
Vorlesungen und es wird so
bis zur fünften Vorlesung gehen.
Da werden wir langsam anfangen,
auch in den zweiten Teil 
überzugehen.
Aber zunächst mal interessiert 
uns gar nicht,
wie wir auf dieses Modell 
kommen,
was dieses Modell genau ist.
Wir werden erstmal annehmen,
da ist irgendein Modell,
das fällt sozusagen vom Himmel.
Und was macht dieses Modell mit 
uns?
Was macht dieses Modell mit 
Organisationen?
Was macht dieses Modell mit 
Personen?
Was macht dieses Modell mit der 
Gesellschaft?
Und um so ein bisschen
eine Hands on Vorstellung zu 
haben,
was Machine Learning Modelle 
machen,
habe ich hier mal ein Beispiel 
mitgebracht,
wo wir jetzt als Gruppe Machine 
Learning Modell spielen. Feedback Loops in Machine Learning 
 
805 
generate predictions (Parisi et al., 2019). However, in 
dynamic, nonstationary environments, the underlying 
data-generating process that ML models aim to 
approximate can change over time. This phenomenon, 
referred to as drift (Lu et al., 2018), can lead to  
progressively poorer predictions. The decrease in 
prediction performance can originate from changes in 
the underlying relationship between the input features 
and the target variable —concept drift (Widmer & 
Kubat, 1996)—or changes in the distributions of t he 
input features or the target variable—data drift (Mallick 
et al., 2022). As a consequence, to maintain or even 
improve prediction accuracy over time, it is imperative 
to continuously update ML models on recent data that 
reflect new patterns in the data -generating process 
(Gama et al., 2014). 
The efficacy of continuous updating inherently links to 
the quality and structure of the collected data. Ideally, 
updating processes should empower models to learn 
from their past mistakes —that is, identify cases for 
which they generate inaccurate predictions. However, 
ML models that support or automate human decisions 
typically do more than merely provide neutral sind dann in eine Case Study 
gemacht,
wo ich ihnen gezeigt habe,
wie man Machine Learning 
anwenden kann.
Nicht immer nur zu negativen 
Aspekten,
aber diese Predictions,
die Machine Learning uns liefern 
kann,
wie man die auch dazu nutzen 
kann,
zum Beispiel zur Vorhersage,
welcher Kunde wie auf welches 
Messaging reagiert,
um letztlich die
Rücksenderaten von Produkten zu 
verringern.
Letzte Woche sind wir dann mehr 
ins
Detail schon reingesprungen, 
Eingesprungen,
haben uns überlegt, aus einer 
ökonomischen Perspektive,
was Prediction bedeuten könnte,
wenn wir bei General Purpose 
Technologien gesprochen.
Wir haben darüber gesprochen,
dass wir uns, wie
es bei so vielen General Purpose 
Technologien ist,
aktuell auf einen bestimmten 
Teil der Kurve,
die noch befinden,
die Kurve als die Darstellung, 
die fundamentale Idee,
dass wir nicht in große 
Technologie Investitionen habe,
dass sich die nicht sofort 
auszahlt.
Das ist immer so ein bisschen 
Verzögerung gibt,
am Anfang sogar die marginale
Produktivitätsveränderungen 
negativ sein kann.
Das ist so dieser untere 
Halbkreis von dem J.
Und das kann verschiedene Gründe 
haben.
Unter anderem eben, dass diese
Technologien noch nicht 
ausreichend in den
Organisationen mit",9.443065643,1,"The generation correctly identifies that the simulation used a setting mirroring sequential interactions like loan approvals, which is semantically consistent with the ground truth.",1,"The generated answer is faithful. [cite_start]The context explicitly mentions that in dynamic, nonstationary environments, the data-generating process can change over time, a phenomenon referred to as 'drift'[cite: 242].",1,"The context directly answers the question, stating: '...we examine the dynamic evolution of an ML modelâ€™s fairness and economic consequences in a setting that mirrors sequential interactions, such as loan approval decisions'."
What is the key finding regarding the continuous updating of ML models?,Continuous updating can help mitigate algorithmic discrimination and enhance economic efficiency over time.,"Das zentrale Ergebnis der Studie ist, dass menschliche Entscheidungsträger, die die Autorität haben, ML-Vorhersagen zu überschreiben, die Selbstkorrektur von diskriminierenden Modellen behindern und diese sogar dazu bringen können, mit der Zeit diskriminierend zu werden.","availability of this data point for future model updates and potentially affecting the model ’s 
performance. This paper delves into the relationship between the continuous updating of ML models 
and algorithmic discrimination in environments where predictions endogenously influence the 
creation of new training data. Using comprehensive simulations based on secondary empirical data, 
we examine the dynamic evolution of an ML model ’s fairness and economic consequences in a 
setting that mirrors sequential interactions, such as loan approval decisions. Our findings indicate 
that continuous updating can help mitigat e algorithmic discrimination and enhance economic 
efficiency over time. Importantly, we provide evidence that human decision makers in the loop who 
possess the authority to override ML predictions may impede the self -correction of discriminatory 
models and even induce initially unbiased models to become discriminatory with time. These 
findings underscore the complex sociotechnological nature of algori thmic discrimination and 
highlight the role that humans play in addressing it when ML models undergo continuous updating. affecting ML systems’ functionality by explaining the 
interplay b etween continuous model updating and 
algorithmic discrimination. Despite its critical importance 
in developing countermeasures and refining policy 
recommendations, the complex interplay between 
algorithmic discrimination and continuous ML model 
updating remains an underexplored area in the literature.  
Second, our paper complements the nascent body of 
studies exploring the origins and impacts of 
algorithmic feedback loops (Burghardt & Lerman, 
2022; Cowgill, 2018). For instance, Lum and Isaac 
(2016) revealed that the iterative updates of a 
predictive poli cing system led to increased 
discrimination against minority groups. Similarly, 
Ensign et al. (2017) showed how feedback loops could ML model ’s capacity to self -correct, i.e., overcome 
concept drift through continuous updating, one may 
interpret our finding s as evidence for an adverse 
interaction between a data and a concept drift that 
allows algorithmic discrimination to persist. This 
observation provides a new perspective on the 
dynamic between concept and data drift challenges, 
enriching prior research on drift origins and its 
mitigation (see, e.g., Lu et al. , 2018; Jameel et al., 
2020; Sahiner et al., 2023).  
5.3 Practical Implications 
From a practical standpoint, our results underscore the 
necessity for organizations and policymakers to 
consider both the dynamic and the sociotechnological 
nature of algorithmic discrimination. Our findings, 
highlighting the influence of human behavior on the 
discriminatory outcomes of continuously updated ML 
models, suggest that organizations should not only 
focus on reducing bias within ML models but also 
diligently address potential bias within the human 
decision-making processes that these models suppo rt. 
The implication for organizations is that they need to 
invest in comprehensive anti -discrimination and 
unconscious bias training for their decision  makers.",7.565243483,1,"The generated answer correctly states that continuous updating of ML models can mitigate algorithmic discrimination, which perfectly matches the core information in the ground truth.",1,The generated answer is faithful as it directly quotes the conclusion from the context: 'human decision makers in the loop who possess the authority to override ML predictions may impede the self-correction of discriminatory models and even induce initially unbiased models to become discriminatory with time'[cite: 257].,1,"The context directly provides the key finding. Source states, 'Our findings indicate that continuous updating can help mitigate algorithmic discrimination and enhance economic efficiency over time.'"
How do ML models endogenously shape their future training data?,"By influencing human decisions, which then generate new data points (or a lack thereof) for future model training.","Gemäß dem bereitgestellten Text beeinflussen ML-Modelle ihre zukünftigen Trainingsdaten durch einen Prozess, der als „selektive Kennzeichnung“ (selective labeling) bezeichnet wird. Hier die wichtigsten Punkte:

*   **Endogene Datengestaltung:** Die Vorhersagen des ML-Modells beeinflussen die Zusammensetzung der Daten, die für zukünftige Modellaktualisierungen zur Verfügung stehen.
*   **Feedback-Schleifen:** Diese endogenen Datengestaltung kann Feedback-Schleifen erzeugen, in denen die ML-Modelle von ihren eigenen diskriminierenden Ergebnissen lernen und diese verstärken.
*   **Selektive Kennzeichnung:** Dies bedeutet, dass menschliche Entscheidungsfindungsprozesse, die die ML-Modelle überwachen und bei Bedarf überstimmen, die Art und Weise beeinflussen, wie neue Trainingsdaten generiert werden. Wenn beispielsweise ein Modell aufgrund von Vorurteilen eine Ablehnung vornehmen muss, kann dies dazu führen, dass in zukünftigen Trainingsdaten mehr Datenpunkte mit ähnlichen Merkmalen (z. B. Personen mit ähnlichem Hintergrund) vorkommen.

Zusammenfassend lässt sich sagen, dass ML-Modelle ihre zukünftigen Trainingsdaten nicht nur durch die neuen Daten selbst, sondern auch durch die Art und Weise, wie diese Daten aufgrund von menschlichen Entscheidungen entstehen, beeinflussen.","a data -generating process distinct from subsequent 
simulation iterations, then the ML model’s bias against 
women essentially emerges from a concept dri ft 
(Widmer & Kubat, 1996). This means the initial ML 
model approximates a once-accurate but now outdated 
data-generating process. The observed feedback loop, 
where the ML model progressively becomes less 
biased, then demonstrates its ability to overcome 
concept drifts when updated with new training data it 
influences. Conversely, persistent human 
discrimination shifts the training data ’s gender 
composition, increasingly diverging from the borrower 
pool over iterations. However, the core relationship 
between borrower attributes and their repayment 
propensity remains unchanged. Thus, ongoing human 
discrimination aligns with a n ongoing  data drift 
(Mallick et al. , 2022), as the incoming data ’s 
composition on which the model predicts, deviates 
from its training data. With biased decision-making by 
humans in the loop  undermining the discriminating 
ML model ’s capacity to self -correct, i.e., overcome 
concept drift through continuous updating, one may 
interpret our finding s as evidence for an adverse 
interaction between a data and a concept drift that availability of this data point for future model updates and potentially affecting the model ’s 
performance. This paper delves into the relationship between the continuous updating of ML models 
and algorithmic discrimination in environments where predictions endogenously influence the 
creation of new training data. Using comprehensive simulations based on secondary empirical data, 
we examine the dynamic evolution of an ML model ’s fairness and economic consequences in a 
setting that mirrors sequential interactions, such as loan approval decisions. Our findings indicate 
that continuous updating can help mitigat e algorithmic discrimination and enhance economic 
efficiency over time. Importantly, we provide evidence that human decision makers in the loop who 
possess the authority to override ML predictions may impede the self -correction of discriminatory 
models and even induce initially unbiased models to become discriminatory with time. These 
findings underscore the complex sociotechnological nature of algori thmic discrimination and 
highlight the role that humans play in addressing it when ML models undergo continuous updating. endogenous composition of future training data, a 
problem referred to as selective labeling (Lakkaraju et 
al., 2017; Little & Rubin, 2019), can maintain or even 
exacerbate inaccurate or discriminatory predictions. 
In this paper, we explore the dynamic interplay 
between the continuous updating of ML models and 
algorithmic discrimination when ML predictions 
endogenously shape the composition of additional data 
available for model updating. In particular, our work 
focuses on the role of ongoing discrimination by 
human decision  makers who have the final say in an 
ML-supported decision-making task. A steady stream 
of previous work has examined how algorithmic 
discrimination can reproduce and perpetuate 
discriminatory patterns ingrained in societal structures 
(Lambrecht & Tucker, 2019; Morse et al., 202 2; 
Teodurescu et al., 2021). Some studies have developed 
theoretical arguments concerning the emergence of 
feedback loops when ML models continually learn 
from the discriminatory outcomes they help ed to 
generate (see, for example, Cowgill & Tucker, 2019; 
Ensign et al., 2017; Silva & Kenney, 2019). However, 
as Kordzadeh and Ghasemaghaei (2022) observed in 
their literature review, systematic empirical",22.59011078,1,"The generated answer correctly explains that ML models shape their future training data by influencing human decisions, which generate new data points. This is semantically identical to the ground truth.",1,The claims in the generated answer are all directly supported by the retrieved context. [cite_start]The context identifies 'selective labeling' as the process where predictions influence the creation of new training data[cite: 284]. [cite_start]It also explains how this can create feedback loops where models learn from their own discriminatory outcomes[cite: 288].,1,The context directly explains the mechanism. It states that predictions 'endogenously influence the creation of new training data' and that this process is related to 'selective labeling' and the role of 'human decision makers in the loop who possess the authority to override ML predictions'.
What effect can human decision-makers have on the self-correction of discriminatory models when they are kept in the loop?,Human decision-makers in the loop may impede the self-correction of discriminatory models and can even cause initially unbiased models to become discriminatory over time.,"Laut dem Text können Entscheidungsträger einen wesentlichen Einfluss haben, wenn sie in den Korrekturprozess diskriminierender Modelle einbezogen werden. Der Text argumentiert, dass menschliche Diskriminierung die Selbstkorrekturmechanismen von ML-Modellen behindert. Daher werden Maßnahmen zur Identifizierung und Minderung (unbewusster) diskriminierender Praktiken von Entscheidungsträgern als eine „wesentliche ergänzende Elemente“ angesehen, um sicherzustellen, dass kontinuierlich aktualisierte ML-Modelle wünschenswerte Verhaltensweisen zeigen, insbesondere wenn Organisationen regulatorische Anforderungen umsetzen, die den Einsatz von Menschen in der Entscheidungsfindung beinhalten.","of inadvertently perpetuating or igniting algorithmic 
discrimination if these individuals engage in 
discriminatory practices. In this context, efforts aimed at 
identifying and mitigating (subconscious) discriminatory 
practices of organizational decision  makers, such as 
awareness training, become an indispensable 
complementary element to ensure that continuously 
updated ML models exhibit desirable behaviors. 
2 Theoretical and Conceptual 
Background 
In this section, we first provide the conceptual 
underpinnings of algorithmic discrimination. 
Subsequently, we discuss the literature gaps our work 
aims to address. discrimination (Favaretto et al., 2019; Kordzadeh & 
Ghasemaghaei, 2022). The social component often 
originates from societal and economic structural biases, 
which can foster the differential treatment and 
marginalization of certain groups. On the other hand, the 
technological element emanates from the perpetuated 
discriminatory behaviors of algorithmic systems. 
Algorithmic feedback loops: Feedback loops play a 
significant role in algorithmic discrimination in the 
context of continuously updated ML models. These loops 
arise when the outcomes of algorithmic decisions provide 
new endogenous training data for subsequent model 
updates (Cowgill, 2018). Such loops iteratively weave 
together the social environment ’s outcomes and the 
technical performance of the algorithmic output. For 
instance, take the loan approval process depicted in 
 
1 Since the biased or disparate treatment of particular groups 
typically yields discrimination and unfairness, researchers 
often use the terms algorithmic bias, algorithmic 
Figure 1. If an ML model’s prediction of creditworthiness 
guides loan approval, this prediction will shape the data 
available for future updates. As the bank only observes discrimination, as human discrimination hinders the self-
correcting capacities of ML models. Therefore, in 
conjunction with these regulations, we advocate 
measures aimed at identifying and mitigating 
(subconscious) discriminatory practices by 
organizational decision makers. These measures could 
serve as essential complementary elements to ensure that 
continuously updated ML models demonstrate desirable 
behaviors when organizations implement regulatory 
requirements that involve humans in the decision loop. 
5.4 Limitations and Future Research  
Like any study, this study also has limitations—which, 
we believe , provide valuable directions for future 
research to enhance our understanding of how 
algorithmic discrimination evolves in environments 
where ML models undergo continuous updates. One",13.3503859,1,The generated answer accurately captures the core finding from the ground truth: human decision-makers can impede the self-correction of discriminatory models and even introduce new biases.,1,The generated answer is faithful. [cite_start]The context directly supports the claim that 'human discrimination hinders the self-correcting capacities of ML models' [cite: 301] [cite_start]and that measures to mitigate discriminatory practices by decision-makers are 'essential complementary elements'[cite: 303].,1,The context directly answers the question: '...we provide evidence that human decision makers in the loop who possess the authority to override ML predictions may impede the self-correction of discriminatory models and even induce initially unbiased models to become discriminatory with time'.
What is a key challenge with opaque algorithmic designs in recruitment?,"They hinder the detection and correction of biases, making it difficult for HR teams to ensure equitable hiring.","Basierend auf dem bereitgestellten Text stellt eine zentrale Herausforderung, die sich aus undurchschaubaren Algorithmen im Recruiting ergibt, dass Bias (Verzerrung) entstehen kann, obwohl die Entwickler selten absichtlich Diskriminierung einbauen. Dies geschieht, weil historische Daten, die zur Entwicklung der Algorithmen verwendet werden, bereits bestehende Verzerrungen widerspiegeln und das System diese Muster übernimmt.","evaluation of hundreds of resumes on a large scale in a short
period, but it can also automatically classify candidates based on
the job description provided. Moreover, Theﬁnal results after the
hiring decision can be more easily fed back to the candidate
(Raveendra et al.,2020).
Transactional workload. The application of AI in recruitment can
be described as a“new era in human resources”because artiﬁcial
intelligence replaces the routine tasks performed by human
recruiters, thus changing the traditional practices of the recruit-
ment industry (Upadhyay and Khandelwal,2018). Most profes-
sionals believe that AI is bene ﬁcial to recruiters in terms of
reducing routine and administrative tasks (Johansson and
Herranen, 2019). Recruiters will hand over time-consuming
administrative tasks like recruiting, screening, and interviewing to
AI, allowing more scope for recruiters to concentrate on strategic
affairs (Upadhyay and Khandelwal,2018
).
Theme II. Why is there algorithmic recruitment
discrimination
Algorithms are not inherently discriminatory, and engineers
rarely intentionally introduce bias into algorithms. However, bias
can still arise in algorithmic recruitment. This issue is closely hat die AI das Muster erkannt 
und ebenso übernommen.
Genau.
Wir haben ein System
gehabt und ich würde gar nicht 
mal sagen,
dass die Recruiter per se 
gebeizt waren.
Ich wahrscheinlich auch ein 
Teil.
Ich will den Leuten da nichts 
unterstellen.
Ich glaube die wir
überschätzen teilweise
die negativen Intentionen von 
einzelnen Individuen.
Ich glaube, wir haben 
strukturelle Probleme,
die auch dazu beigetragen haben,
die einfach dort sind,
mit denen wir auseinandersetzen 
müssen.
Hier in diesem Beispiel war es 
so genau,
wie Sie erklärt haben.
Amazon hat gesagt Naja,
wir wollen unseren 
Recruitmentprozess verbessern.
Wir möchten gerne, weil wir so 
viele Bewerber haben.
Das können wir alles gar nicht 
mehr händisch handeln.
Das heißt, wir möchten Machine 
Learning System haben,
was uns eigentlich sagt.
Wie hoch ist die 
Wahrscheinlichkeit,
dass wir einen guten Mitarbeiter 
gefunden haben?
Und die Entwickler dieses
Softwaresystems haben die 
historischen
Daten genommen und haben sogar 
gesagt Na ja,
per Gesetz dürfen wir nicht auf 
Gender gucken.
Was also gemacht wurde,
ist man hat die Gendermerkmale,
also die selbst angegebenen 
Geschlecht.
Geschlechtsidentifikation hat 
man rausgenommen.
Es war also nicht Teil des 
Systems. driven recruitment application and discrimination framework is
obtained (see Fig.3). After the conceptual model was constructed,
the remaining original information was coded and comparatively
analyzed, and no new codes were generated, indicating that this
study was saturated.
Discussion. An analysis of interview results conducted using
Grounded Theory indicates that AI-supported hiring dis-
crimination should be approached fromﬁve perspectives. These
perspectives align with the thematic directions identiﬁed through
our literature review.
Firstly, AI-driven hiring applications impact various aspects,
such as reviewing applicant proﬁles online, analyzing applicant
information, scoring assessments based on hiring criteria, and
generating preliminary rankings automatically.
Secondly, interviewers perceive beneﬁts in AI-driven recruit-
ment for job seekers. It eliminates subjective human bias,
facilitates automated matchmaking between individuals and
positions, and provides autom ated response services. More-
over, AI reduces the workload on humans and enhances
efﬁciency.
HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS | https://doi.org/10.1057/s41599-023-02079-x REVIEW ARTICLE",10.77647376,1,"The generated answer correctly states that opaque algorithms hinder the detection and correction of biases, which is semantically consistent with the ground truth.",1,"The generated answer is faithful. [cite_start]The context states that algorithms are rarely intentionally discriminatory [cite: 311] [cite_start]but that bias can arise from historical data that reflects existing prejudices, which the AI then learns and reproduces[cite: 312].",0.5,"The context explains that bias in recruitment algorithms can arise unintentionally from historical data, which is a core part of the challenge. However, it does not explicitly mention 'opaque' designs or directly state that this opacity is what hinders the detection and correction of these biases. The context is relevant but incomplete."
"According to some studies cited, what are two benefits of AI-supported recruitment?",It can reduce costs and save time.,"Laut der Studie werden durch KI-gestütztes Recruiting zwei Vorteile genannt:

*   Verbesserte Qualität der Rekrutierung
*   Kostensenkung","REVIEW ARTICLE
Ethics and discrimination in artiﬁcial intelligence-
enabled recruitment practices
Zhisheng Chen 1✉
This study aims to address the research gap on algorithmic discrimination caused by AI-
enabled recruitment and explore technical and managerial solutions. The primary research
approach used is a literature review. Theﬁndings suggest that AI-enabled recruitment has
the potential to enhance recruitment quality, increase efﬁciency, and reduce transactional
work. However, algorithmic bias results in discriminatory hiring practices based on gender,
race, color, and personality traits. The study indicates that algorithmic bias stems from
limited raw data sets and biased algorithm designers. To mitigate this issue, it is recom-
mended to implement technical measures, such as unbiased dataset frameworks and
improved algorithmic transparency, as well as management measures like internal corporate
ethical governance and external oversight. Employing Grounded Theory, the study conducted
survey analysis to collectﬁrsthand data on respondents’ experiences and perceptions of AI-
driven recruitment applications and discrimination.
Introduction
T employment opportunities and the potential for discrimination
without accountability. To harness the beneﬁts of AI in recruiting,
organizations should exercise careful selection of their programs,
promote the adoption of accountable algorithms, and advocate
for improvements in racial and gender diversity within high-tech
companies.
The general construct of this study is,ﬁrst, an extension of
statistical discrimination theory in the context of the algorithmic
economy; second, a synthesis of the current literature on the
beneﬁts of algorithmic hiring, the roots and classi ﬁcation of
algorithmic discrimination; and third, initiatives to eliminate the
existence of algorithmic hiring discrimination; fourth, based on
the Grounded Theory, we conduct surveys with respondents and
analyze primary data to support the study.
The contributions of this study are as follows:
First, discuss job market discrimination theories in the digital
age context. When considering statistical discrimination theories,
we should consider the current circumstances. It is necessary to
apply these discrimination theories to evaluate the issues that
arise from the use of technology in the digital age, particularly that impact the hiring process. It would be interesting to analyze
the psychological effects of applying this algorithmic recruitment
technique on various populations (gender, age, education level)
from an organizational behavior perspective. While recent studies
have primarily discussed discrimination theory in the traditional
economy’s hiring market, future theoretical research should
consider how advanced technology affects equity in hiring within
the digital economy.
Conclusion
The study concludes that the fo urth industrial revolution
introduced technological innovations signiﬁcantly affecting the
recruitment industry. It extends the analysis of statistical dis-
crimination theory in the digital age and adopts a literature
review approach to explore four themes related to AI-based
recruitment. The study argues that algorithmic bias remains an
issue while AI recruitment tools offer beneﬁts such as improved
recruitment quality, cost reduction, and increased ef ﬁciency.
Recruitment algorithms ’bias is evident in gender, race, color,
and personality. The primary source of algorithmic bias lies in
partial historical data. The personal preferences of algorithm
engineers also contribute to algorithmic bias. Technical mea-",6.098675251,0.5,"The generated answer lists 'Improved recruitment quality' and 'Cost reduction' as benefits. The ground truth lists 'It can reduce costs and save time.' While cost reduction is common to both, the generation misses the 'save time' aspect and includes 'improved quality,' which is not in the ground truth. This makes it only partially correct and semantically different.",1,"The claims made in the generated answer, improved recruitment quality and cost reduction, are explicitly mentioned in the retrieved context as benefits of AI recruitment tools[cite: 332, 349].",1,"The context directly answers the question by listing several benefits of AI-supported recruitment, including 'cost reduction, and increased efficiency'."
What are two recommended categories of measures to mitigate algorithmic bias in recruitment?,Technical measures (like unbiased dataset frameworks and improved transparency) and management measures (like internal ethical governance and external oversight).,"Laut dem Text werden folgende zwei Kategorien von Maßnahmen zur Minderung von algorithmischer Verzerrung im Recruiting empfohlen:

1.  **Vorverarbeitung (Pre-processing)**: Diese Strategien zielen darauf ab, Ungleichheiten in den Datensätzen zu beseitigen.
2.  **In-Processing**: Dies beinhaltet die Verwendung konventioneller Lernalgorithmen während des Modelltrainings, um Verzerrungen zu reduzieren.","technical and managerial aspects to tackle discrimination in
algorithmic hiring. This study contends that resolving algorithmic
discrimination in recruitment requires technical solutions and the
implementation of internal ethical governance and external
regulations.
The subsequent study is structured intoﬁve parts. The ﬁrst
section provides the theoretical background for this research. The
following section outlines the research methodology employed in
the literature review and identiﬁes four key themes. The third
section delves into a detailed discussion of these four themes:
applications and beneﬁts of AI-based recruitment, factors con-
tributing to algorithmic recruitment discrimination, types of
discrimination in algorithmic recruitment, and measures to
mitigate algorithmic hiring discrimination. The fourth section
involves conducting a survey among respondents and analyzing
the primary data collected to support our study. Theﬁnal section
concludes by suggesting future directions for research.
Theory background
Discrimination theory. Discrimination in the labor market is
deﬁned by the ILO’s Convention 111, which encompasses any
unfavorable treatment based on race, ethnicity, color, and gender REVIEW ARTICLE
Ethics and discrimination in artiﬁcial intelligence-
enabled recruitment practices
Zhisheng Chen 1✉
This study aims to address the research gap on algorithmic discrimination caused by AI-
enabled recruitment and explore technical and managerial solutions. The primary research
approach used is a literature review. Theﬁndings suggest that AI-enabled recruitment has
the potential to enhance recruitment quality, increase efﬁciency, and reduce transactional
work. However, algorithmic bias results in discriminatory hiring practices based on gender,
race, color, and personality traits. The study indicates that algorithmic bias stems from
limited raw data sets and biased algorithm designers. To mitigate this issue, it is recom-
mended to implement technical measures, such as unbiased dataset frameworks and
improved algorithmic transparency, as well as management measures like internal corporate
ethical governance and external oversight. Employing Grounded Theory, the study conducted
survey analysis to collectﬁrsthand data on respondents’ experiences and perceptions of AI-
driven recruitment applications and discrimination.
Introduction
T significant consequences, such as in healthcare, loan 
approval, hiring, or criminal justice systems. 
Mitigating algorithmic discrimination : The 
expansive literature on algorithmic discrimination 
proposes various methods to identify and alleviate 
such biases. According to d ’Alessandro et al. (2017), 
we can divide these mitigation strategies into three 
categories: pre -processing, in -processing, and post -
processing. Pre -processing strategies strive to 
eliminate disparities inherent in the dataset. Methods 
such as those proposed by Kamiran and Calders (2012) 
and Zafar et al. (2017) employ data pre -processing 
techniques like feature massaging and reweighting to 
balance the dataset based on social group 
characteristics. In -processing strategies involve 
conventional learning algorit hms during model 
training. Researchers often use techniques like naive 
Bayes and decision tr ees for debiasing (Calders & 
Verwer, 2010; Zhang et al., 2018). Additional research 
suggests placing constraints on the classification 
model to mandate the satisfaction of a proxy 
(Woodworth et al., 2017). Lastly, post -processing 
strategies aim to adjust the output to counter biases. 
For example, Corbett -Davies et al. (2017)",10.11009431,1,The generation accurately lists the two recommended categories of measures (technical and management) and provides examples that are semantically identical to the ground truth.,1,"All claims in the generated answer are directly supported by the retrieved context. [cite_start]The context explicitly names pre-processing and in-processing as mitigation strategies and provides descriptions that match the generation[cite: 368, 369, 372].",1,"The context directly answers the question by stating, '...it is recommended to implement technical measures, such as unbiased dataset frameworks and improved algorithmic transparency, as well as management measures like internal corporate ethical governance and external oversight'."
"Besides gender and race, what other characteristic is mentioned as a basis for discriminatory hiring practices by AI?",Personality traits.,"Laut dem Text werden Persönlichkeit und Intelligenz (IQ) als intrinsische Faktoren genannt, die die genaue Identifizierung und Beurteilung durch KI-Systeme hinsichtlich Diskriminierung im Einstellungsprozess beeinflussen können.","of inadvertently perpetuating or igniting algorithmic 
discrimination if these individuals engage in 
discriminatory practices. In this context, efforts aimed at 
identifying and mitigating (subconscious) discriminatory 
practices of organizational decision  makers, such as 
awareness training, become an indispensable 
complementary element to ensure that continuously 
updated ML models exhibit desirable behaviors. 
2 Theoretical and Conceptual 
Background 
In this section, we first provide the conceptual 
underpinnings of algorithmic discrimination. 
Subsequently, we discuss the literature gaps our work 
aims to address. REVIEW ARTICLE
Ethics and discrimination in artiﬁcial intelligence-
enabled recruitment practices
Zhisheng Chen 1✉
This study aims to address the research gap on algorithmic discrimination caused by AI-
enabled recruitment and explore technical and managerial solutions. The primary research
approach used is a literature review. Theﬁndings suggest that AI-enabled recruitment has
the potential to enhance recruitment quality, increase efﬁciency, and reduce transactional
work. However, algorithmic bias results in discriminatory hiring practices based on gender,
race, color, and personality traits. The study indicates that algorithmic bias stems from
limited raw data sets and biased algorithm designers. To mitigate this issue, it is recom-
mended to implement technical measures, such as unbiased dataset frameworks and
improved algorithmic transparency, as well as management measures like internal corporate
ethical governance and external oversight. Employing Grounded Theory, the study conducted
survey analysis to collectﬁrsthand data on respondents’ experiences and perceptions of AI-
driven recruitment applications and discrimination.
Introduction
T Thirdly, concerns are raised regarding potential hiring
discrimination perpetrated by machines. This can arise from AI
tools, such as partial source data, or users unfamiliar with user
interfaces and operations.
Fourthly, intrinsic factors like personality and IQ, as well as
extrinsic factors like gender and nationality, have been observed
to inﬂuence the accurate identi ﬁcation and judgment of AI
systems concerning hiring discrimination.
Fifthly, respondents offer recommendations for combating
discrimination by machines, including technical and non-
technical approaches.
Recommendations for future studies
This study conducted a literature review to analyze algorithmic
recruitment discrimination’s causes, types, and solutions. Future
research on algorithmic recruitment discrimination could explore
quantitative analysis or experimental methods across different
countries and cultures. Additionally, future studies could examine
the mechanics of algorithmic recruitment and the technical rules
that impact the hiring process. It would be interesting to analyze
the psychological effects of applying this algorithmic recruitment
technique on various populations (gender, age, education level)",6.930473804,1,"The generated answer states that personality and IQ are mentioned as bases for discrimination. The ground truth mentions 'Personality traits'. The generation is more specific by including IQ, but this is a minor detail, and the core claim about personality is consistent.",1,"The generated answer is a direct and accurate summary of a claim made explicitly in the retrieved context, which states that 'intrinsic factors like personality and IQ...have been observed to inï¬‚uence the accurate identiï¬cation and judgment of AI systems concerning hiring discrimination'[cite: 388].",1,"The context explicitly lists 'personality traits' as a basis for discriminatory hiring practices, alongside gender, race, and color."
"According to the study of the paper 'Ethics and discrimination in artificial intelligence-enabled recruitment practices', what are two primary sources from which algorithmic bias stems?",Algorithmic bias stems from limited raw data sets and biased algorithm designers.,"According to the study, the two primary sources from which algorithmic bias stems are:

1.  **Limited raw data sets** – particularly those lacking diverse representation.
2.  **Biased algorithm designers** – who may prioritize specific features or variables based on their own biases.","REVIEW ARTICLE
Ethics and discrimination in artiﬁcial intelligence-
enabled recruitment practices
Zhisheng Chen 1✉
This study aims to address the research gap on algorithmic discrimination caused by AI-
enabled recruitment and explore technical and managerial solutions. The primary research
approach used is a literature review. Theﬁndings suggest that AI-enabled recruitment has
the potential to enhance recruitment quality, increase efﬁciency, and reduce transactional
work. However, algorithmic bias results in discriminatory hiring practices based on gender,
race, color, and personality traits. The study indicates that algorithmic bias stems from
limited raw data sets and biased algorithm designers. To mitigate this issue, it is recom-
mended to implement technical measures, such as unbiased dataset frameworks and
improved algorithmic transparency, as well as management measures like internal corporate
ethical governance and external oversight. Employing Grounded Theory, the study conducted
survey analysis to collectﬁrsthand data on respondents’ experiences and perceptions of AI-
driven recruitment applications and discrimination.
Introduction
T discrimination
Algorithms are not inherently discriminatory, and engineers
rarely intentionally introduce bias into algorithms. However, bias
can still arise in algorithmic recruitment. This issue is closely
linked to the fundamental technology behind AI and ML. The ML
process can be simpliﬁed into several stages, each involving three
key components contributing to algorithmic bias: dataset con-
struction, the engineer’s target formulation, and feature selection
(36KE, 2020). When the dataset lacks diverse representation from
different companies, bias may be introduced during the devel-
opment of algorithmic rules by engineers and when annotators
handle unstructured data (Zixun,2020).
Datasets: bias soil. Datasets serve as the foundation of machine
learning (ML). If an algorithm’s data collection lacks quantity and
quality, it will fail to represent reality objectively, leading to
inevitable bias in algorithmic decisions. Researchers commonly
use a 95% conﬁdence level, which provides 95% certainty but still
leaves a one in twenty chance of bias (Raub,2018). Nearly every
ML algorithm relies on biased databases.
One issue arises when datasets are skewed towards accessible in discrimination (Miasato and Silva,2019).
Furthermore, personal biases can manifest in the selection of
data characteristics. For example, engineers may prioritize speciﬁc
features or variables based on how they want the machine to
behave (Miasato and Silva, 2019)). The Amazon hiring case
illustrates this, where engineers considered education, occupation,
and gender when assigning labels to the algorithm. When gender
is considered the crucial criterion, it inﬂ
uences how the algorithm
responds to the data.
Theme III. Which algorithmic recruitment discrimination
exists
In the recruitment process, algorithmic bias can be manifested in
terms of gender, race, color, and personality.
Gender. Gender stereotypes have inﬁltrated the “lexical embed-
ding framework” utilized in natural language processing (NLP)
techniques and machine learning (ML). Munson ’s research
indicates that “occupational picture search outcomes slightly
exaggerate gender stereotypes, portraying minority-gender occu-
pations as less professional”((Avery et al.,2023; Kay et al.,2015).
The impact of gender stereotypes on AI hiring poses genuine
risks (Beneduce,2020). In 2014, Amazon developed an ML-based
hiring tool, but it exhibited gender bias. The system did not",8.382907629,1,The generated answer and the ground truth both correctly identify the two primary sources of algorithmic bias as limited/biased data sets and biased algorithm designers.,1,The generated answer faithfully summarizes the two primary sources of algorithmic bias that are explicitly mentioned and described in the retrieved context: 'limited raw data sets and biased algorithm designers'[cite: 397].,1,"The context directly answers the question, stating: 'The study indicates that algorithmic bias stems from limited raw data sets and biased algorithm designers'."
What does the CRISP-DM User Guide provide that the Reference Model does not?,"The User Guide gives more detailed tips and hints for each phase and task on how to do a data mining project, whereas the Reference Model describes what to do.",The text doesn’t provide any information about a “CRISP-DM User Guide” or what it offers that the reference model doesn’t. It only discusses the CRISP-DM reference model itself.,"15. Mai 2025
Overview CRISP-DM
9 in einer bestimmten Domäne,
in einem bestimmten Bereich 
angewendet werden kann,
sondern eben in verschiedenen 
Sektoren.
Es wird überall gebraucht.
Also General Purpose und
vorher war mal und ich finde den 
Namen furchtbar.
Aber um sie nicht zu verwirren,
habe ich eine andere als die 
herkömmliche Abkürzung,
die Sie in vielen ökonomischen
Büchern noch finden, nämlich 
GPT.
Das ist General Purpose.
Technologie hat natürlich Open 
AI
uns alle so ein bisschen 
versaut.
Dieses Wort zu benutzen,
insbesondere wenn man irgendwie 
an der
Schnittstelle zu Machine 
Learning arbeitet,
weil alle direkt an das 
Sprachmodell denken.
Deswegen hier diese furchtbare
Abkürzung General purpose
Tonnen general purpose 
technology.
Diese Technologien haben
die gesamte Zivilisation der
Menschheit schon immer massiv 
verändert.
Nicht nur, weil sie auf der 
einen Seite weit
eingesetzt worden sind und
auf der anderen Seite eben über
die Zeit immer besser genutzt 
wurden,
erkannt wurde, wo wir sie noch 
einsetzen
kann Economies of Scale 
eingesetzt haben.
Viele Leute nutzen es wird immer 
knapper.
Sondern auch, weil diese 
Innovationen,
diese Kerninnovationen,
letztlich zu weiteren
komplementären Innovationen 
geführt haben. Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können.",6.07435298,0,"The generation incorrectly claims the text doesn't provide the requested information. The ground truth provides the correct answer, showing that the User Guide gives more detailed tips than the Reference Model. The generation fails to extract the correct information.",0,The generated answer is unfaithful. The retrieved context discusses the CRISP-DM model in general terms but does not contain any information about a specific 'User Guide' or compare it to the 'Reference Model'.,0,The context is a general overview of a course on Machine Learning and does not contain any information about the CRISP-DM User Guide or how it differs from the Reference Model.
Which task is mentioned as often being the lengthiest in the Data Preparation phase?,The 'Clean data' task.,"Laut dem Text wird die Aufgabe, Daten zu ""sauber zu machen"", oft als die zeitaufwändigste in der Phase der Datenvorbereitung genannt. Dies beinhaltet die Identifizierung und Behebung von Problemen wie unterschiedlichen Formaten, irrelevanten Rauschen und fehlenden Beobachtungen.","Training von Daten,
das würden wir alles schon 
wissen.
Beziehungsweise es würde uns
aktuell noch nicht 
interessieren.
Da kommen wir zu dem zweiten 
Teil der Vorlesung.
Aber ein Riesenteil.
Bevor wir überhaupt an Modelle 
denken können,
ist es dann, Daten sauber zu 
machen.
Damit werden wir sie noch 
einiges triezen.
Daten, die Sie erhalten,
sind typischerweise insbesondere 
aus der Industrie.
Noisy Bestimmte Observationen 
fehlen.
Dann haben unterschiedliche
Leute unterschiedliche Eingaben 
gemacht,
haben unterschiedliche
Arten und Weisen diese Eingaben 
zu machen.
Manche nutzen Komma, um
Zahlen um decimal points zu 
setzen,
andere nutzen den Punkt.
Die einen schreiben Doppelees, 
die Anschreiben,
scharfes S, Die anderen 
schreiben
groß am Anfang anschreiben, 
klein am Anfang.
Die einen denken das ist eine 
Eins,
die anderen denken das ist eine 
Zwei.
All diese Dinge, wo irrelevante 
Noise sources,
also statistische Fluktuationen,
die nicht zu bedeuten hat.
Das müssen Sie identifizieren.
Sie müssen das sauber machen.
Maschinen, wie wir sehen werden,
können nicht mit 
unstrukturierten
Daten wie Wörtern einfach so 
umgehen.
Wir haben ganz viel 
Datenvorarbeit zu betreiben
und es gibt bestimmte Machine 
Learning Modelle, Dann haben wir die Abteilungen,
die dann auch wieder ihre 
einzelnen Datenpools hat,
darüber,
wie gut die Leute eigentlich 
arbeiten
und das zusammen zu bringen, zu 
sehen,
wie sich eine bestimmte
Person von der ersten 
Kontaktaufnahme,
darüber, welche Informationen, 
wie
sie überhaupt diesen Funnel 
gekommen ist,
hin zum Bewerbungsgespräch, hin 
zu Evaluation,
wie sich das alles verbinden 
lässt,
kostet unfassbar viel Zeit und 
die meisten
Unternehmen haben teilweise 
nicht mal die Möglichkeit,
bestimmte Sachen zu verbinden,
weil wir wieder über Datenschutz 
etc.
sprechen. Und das müssen sie 
alles,
so gut es geht, schon von 
vornherein mitdenken.
Aber angenommen, wir sind an dem 
Punkt,
dass das alles jetzt 
funktionieren würde,
kommt der nächste riesen 
aufwändige Schritt
in dem technischen Prozess jetzt 
schon und wir
treten das weiterhin wie eine
Blackbox und
Blackbox wird nachher noch mal 
ein anderes Thema sein.
Aber aktuell sagen wir,
wir nehmen an, diese ganzen 
Prozesse,
diese ganzen Methoden, das 
Training von Daten,
das würden wir alles schon 
wissen.
Beziehungsweise es würde uns
aktuell noch nicht 
interessieren.
Da kommen wir zu dem zweiten 
Teil der Vorlesung.
Aber ein Riesenteil.
Bevor wir überhaupt an Modelle Trainieren
selber gar nicht lange und
wir können sehr viele Kniffe 
benutzen,
wie wir dieses diesen
Trainingsprozess in einer 
gewissen Art
und Weise automatisieren können,
indem wir zum Beispiel
die Modellstruktur, die 
Modellauswahl,
sogar die Auswahl der relevanten
Inputinformationen durch 
bestimmte sogenannte
Cross Validation Verfahren durch
die Daten selber identifizieren 
lassen.
Ich hasse diesen Satz,
aber hier passiert dann sehr 
häufig dieses Let
the data speak so wenig anhaben 
wie möglich machen.
Wir versuchen einfach, das beste 
Modell zu finden.
Und auch das sei wieder betont, 
ist fundamental.
Uns geht es darum, ein Modell zu 
finden,
was nicht unsere historischen
Daten so gut es geht erklärt,
sondern sobald das Modell da 
ist,
möchten wir ein Modell haben,
was es uns ermöglicht,
Vorhersagen für die Zukunft zu 
machen,
also Vorhersagen für Beispiele,
Observationen, die das Modell 
noch nicht gesehen hat.
Denken Sie an das 
EiscremeBeispiel zurück.
Es ging nicht darum, perfekt zu 
erklären,
wie sich in der
Vergangenheit unsere 
Eisverkäufer abhängig
von bestimmten 
Wetterinformationen dargestellt 
haben,
sondern es ging darum Ich habe 
einen bestimmte
Logik identifiziert aus den 
historischen Daten.",8.195581675,1,The generation's claim that the 'Clean data' task is often the lengthiest is semantically consistent with the ground truth.,1,"The generated answer is faithful. [cite_start]The context explicitly mentions the task of cleaning data ('Daten sauber zu machen') and describes related issues like noise and missing observations as a 'Riesenteil' (huge part) of the data preparation phase[cite: 429, 430].",1,"The context directly answers the question, stating that a huge part of data science projects, before modeling, is cleaning the data ('Daten sauber zu machen'). It describes this task as dealing with 'noisy' data, missing observations, and inconsistent formats."
What is the stated aim of the CRISP-DM process model?,"To make large data mining projects less costly, more reliable, more repeatable, more manageable, and faster.","Das Ziel des CRISP-DM Prozessmodells ist es, Vorhersageprobleme durch den Einsatz von Modellen zu lösen. Es geht darum, die Daten zu verstehen, aufzubereiten und dann Modelle zu trainieren, um möglichst genaue Vorhersagen zu erzielen.","15. Mai 2025
Structuring an AI project: CRISP-DM 
6
1. Business Understanding2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment
Data 
Cross Industry Standard Process for Data Mining bekommen,
was diese Daten alles bedeuten.
Sie haben bei mir in der im 
Seminar
gesessen letztes Semester diese 
Daten,
die Sie da erhalten haben, von 
der Firma.
Totales Chaos.
Muss man sich erstmal reindenken 
und
das braucht massiv viel Zeit.
Wenn wir aber dann die Daten 
sauber gemacht haben,
dann geht es endlich an den,
den sag ich mal aus meiner
Sicht coolsten Teil dieses 
Prozesses, wo wir versuchen,
das anfänglich definierte 
Vorhersageproblem
durch Modelle zu lösen.
Hier passiert jetzt in
Anführungsstrichen eigentlich 
die Magic,
Hier haben wir unsere 
Algorithmen,
hier haben wir unsere 
verschiedenen Modelle,
die wir alle ausprobieren,
um zu sehen,
wie können wir denn
eigentlich aus den Daten, die 
wir haben,
unsere Features,
eine möglichst genaue Vorhersage 
über
diesen Teil der Daten,
unser Outcome, unser Label?
Was nutzen wir da?
Welche Modellarchitektur,
um möglichst out of sample gute 
Vorhersagen zu machen?
Wir trainieren dieses Modell und 
in
den meisten Fällen dauert es 
Trainieren
selber gar nicht lange und
wir können sehr viele Kniffe 
benutzen,
wie wir dieses diesen
Trainingsprozess in einer 
gewissen Art
und Weise automatisieren können,
indem wir zum Beispiel
die Modellstruktur, die 
Modellauswahl, 15. Mai 2025
Overview CRISP-DM
9",6.484463453,0,"The generated answer provides an incorrect aim for the CRISP-DM model (solving prediction problems). The ground truth gives the correct, broader aim: to make data mining projects less costly, more reliable, repeatable, manageable, and faster.",0,"The generated answer is unfaithful. [cite_start]The context states that the goal is to solve a prediction problem using models ('das anfÃ¤nglich definierte Vorhersageproblem durch Modelle zu lÃ¶sen')[cite: 451]. It does not mention the aim of making projects 'less costly, more reliable, more repeatable, more manageable, and faster'.",0,"The context discusses solving a prediction problem through modeling but does not mention the specific aims of the CRISP-DM process model, such as making projects less costly, more reliable, or faster."
What does CRISP-DM stand for?,Cross Industry Standard Process for Data Mining.,"CRISP-DM steht für Cross Industry Standard Process for Data Mining. Es ist ein Prozess, der in verschiedenen Sektoren angewendet werden kann, um Daten zu analysieren und zu nutzen.","15. Mai 2025
Structuring an AI project: CRISP-DM 
6
1. Business Understanding2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment
Data 
Cross Industry Standard Process for Data Mining in einer bestimmten Domäne,
in einem bestimmten Bereich 
angewendet werden kann,
sondern eben in verschiedenen 
Sektoren.
Es wird überall gebraucht.
Also General Purpose und
vorher war mal und ich finde den 
Namen furchtbar.
Aber um sie nicht zu verwirren,
habe ich eine andere als die 
herkömmliche Abkürzung,
die Sie in vielen ökonomischen
Büchern noch finden, nämlich 
GPT.
Das ist General Purpose.
Technologie hat natürlich Open 
AI
uns alle so ein bisschen 
versaut.
Dieses Wort zu benutzen,
insbesondere wenn man irgendwie 
an der
Schnittstelle zu Machine 
Learning arbeitet,
weil alle direkt an das 
Sprachmodell denken.
Deswegen hier diese furchtbare
Abkürzung General purpose
Tonnen general purpose 
technology.
Diese Technologien haben
die gesamte Zivilisation der
Menschheit schon immer massiv 
verändert.
Nicht nur, weil sie auf der 
einen Seite weit
eingesetzt worden sind und
auf der anderen Seite eben über
die Zeit immer besser genutzt 
wurden,
erkannt wurde, wo wir sie noch 
einsetzen
kann Economies of Scale 
eingesetzt haben.
Viele Leute nutzen es wird immer 
knapper.
Sondern auch, weil diese 
Innovationen,
diese Kerninnovationen,
letztlich zu weiteren
komplementären Innovationen 
geführt haben. 15. Mai 2025
Overview CRISP-DM
9",4.929229498,1,The generated answer and the ground truth both correctly state that CRISP-DM stands for Cross Industry Standard Process for Data Mining.,1,The generated answer is faithful. [cite_start]The context explicitly provides the full name in a diagram heading: 'Cross Industry Standard Process for Data Mining'[cite: 456].,1,"The context, specifically the slide image, explicitly provides the full name for the acronym CRISP-DM: 'Cross Industry Standard Process for Data Mining'."
What are the six phases of the CRISP-DM process model?,"The six phases are Business Understanding, Data Understanding, Data Preparation, Modeling, Evaluation, and Deployment.","Das CRISP-DM Prozessmodell umfasst die folgenden sechs Phasen:

1. Business Understanding
2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment","15. Mai 2025
Structuring an AI project: CRISP-DM 
6
1. Business Understanding2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment
Data 
Cross Industry Standard Process for Data Mining The sequence of the phases is not strict. The arrow s indicate only the m ost im portant and frequent
dependencies betw een phases, but in a particular project, it depends on the outcom e of each phase
w hich phase, or w hich particular task of a phase, has to be perform ed next.
The outer circle in Figure 2 sym bolizes the cyclic nature of data m ining itself. D ata m ining is not
finished once a solution is deployed. The lessons learned during the process and from  the
deployed solution can trigger new , often m ore focused business questions. Subsequent data
m ining processes w ill benefit from  the experiences of previous ones (cf. the virtuous cycle of
(B erry and Linoff, 1997)). 15. Mai 2025
Overview CRISP-DM
9",5.13465476,1,"The generated answer correctly lists the six phases of the CRISP-DM process model, matching the ground truth perfectly.",1,"The generated answer is faithful. The context directly lists the six phases in a diagram: '1. [cite_start]Business Understanding, 2. Data Understanding, 3. Data Preparation, 4. Modeling, 5. Evaluation, 6. Deployment'[cite: 465].",1,"The context explicitly lists the six phases of the CRISP-DM model in a numbered list and a diagram: 1. Business Understanding, 2. Data Understanding, 3. Data Preparation, 4. Modeling, 5. Evaluation, 6. Deployment."
What three characteristics define a General Purpose Technology (GPT)?,"They are pervasive, improve over time, and lead to complementary innovation.","Basierend auf dem Text definieren drei Merkmale eine General Purpose Technology (GPT):

1.  **Anwendbarkeit in verschiedenen Sektoren:** Eine GPT kann in vielen verschiedenen Bereichen eingesetzt werden.
2.  **Veränderung durch Nutzung:** Diese Technologien haben die gesamte Zivilisation der Menschheit massiv verändert.
3.  **Beeinflusst durch das Umfeld:** Die Akzeptanz und Nutzung einer GPT wird durch die Wahrnehmung des Umfelds und die Social Influence beeinflusst.","in einer bestimmten Domäne,
in einem bestimmten Bereich 
angewendet werden kann,
sondern eben in verschiedenen 
Sektoren.
Es wird überall gebraucht.
Also General Purpose und
vorher war mal und ich finde den 
Namen furchtbar.
Aber um sie nicht zu verwirren,
habe ich eine andere als die 
herkömmliche Abkürzung,
die Sie in vielen ökonomischen
Büchern noch finden, nämlich 
GPT.
Das ist General Purpose.
Technologie hat natürlich Open 
AI
uns alle so ein bisschen 
versaut.
Dieses Wort zu benutzen,
insbesondere wenn man irgendwie 
an der
Schnittstelle zu Machine 
Learning arbeitet,
weil alle direkt an das 
Sprachmodell denken.
Deswegen hier diese furchtbare
Abkürzung General purpose
Tonnen general purpose 
technology.
Diese Technologien haben
die gesamte Zivilisation der
Menschheit schon immer massiv 
verändert.
Nicht nur, weil sie auf der 
einen Seite weit
eingesetzt worden sind und
auf der anderen Seite eben über
die Zeit immer besser genutzt 
wurden,
erkannt wurde, wo wir sie noch 
einsetzen
kann Economies of Scale 
eingesetzt haben.
Viele Leute nutzen es wird immer 
knapper.
Sondern auch, weil diese 
Innovationen,
diese Kerninnovationen,
letztlich zu weiteren
komplementären Innovationen 
geführt haben. Studierende machen sich mit der Funktionsweise von generativen KI-Modellen wie GPT vertraut. Sie lernen, diese durch gezieltes Prompting für Managemententscheidungen einzusetzen und kritisch zu bewerten, insbesondere unter wirtschaftlichen und ethischen Gesichtspunkten. Adoption,
die Acceptance dieser 
Technologie
nach oben gegangen machen.
Diese beiden Faktoren sind für 
Sie erstmal meine Idee,
meine Vorstellung davon, die ich 
in meinem Kopf forme.
Kann mir das System wirklich 
helfen,
ein bestimmtes Ziel zu 
erreichen?
0.2 Wie schwierig ist es denn 
für mich?
Wie viel Effort muss ich 
aufwenden,
um das System vernünftig zu 
nutzen?
Und der dritte fundamentale 
Faktor,
der auf diese behavior 
Intention.
Ich habe gerade 
fälschlicherweise viel gesagt,
weil ich hier viel gezählt habe,
aber der dritte große Faktor,
der auf diese behavioral 
Intention einzahlt,
ist das Umfeld.
Wenn Sie alle Chatgbt nutzen,
dann sehe ich das als Signal,
dass ich es auf jeden Fall mal 
ausprobieren sollte.
Wenn Sie alle sagen Chat GPT ist 
der größte Quatsch,
werde ich weniger bereit sein 
als Einzelperson,
die das System noch nicht 
benutzt hat,
dieses System zu akzeptieren und 
tatsächlich zu nutzen.
Das hier sind interne Faktoren, 
sozusagen.
Und hier haben wir mit dieser 
Social Influence
eben die Wahrnehmung über das 
Umfeld,
wie das Umfeld diese Technologie 
wahrnimmt,
was für Attitude das Umfeld 
darüber hat,
ob es vielleicht auch sogar eine
Art soziale Norm geworden ist,
ein bestimmtes System zu nutzen",9.929917336,1,"The generated answer correctly lists the three defining characteristics of a General Purpose Technology, which are semantically identical to the ground truth.",0.67,"The generation is partially faithful. [cite_start]The context supports two of the three characteristics: being applied in various sectors ('in verschiedenen Sektoren') and leading to complementary innovations ('zu weiteren komplementÃ¤ren Innovationen gefÃ¼hrt haben')[cite: 473, 480]. However, the claim that they 'improve over time' is not explicitly stated in the provided snippets.",1,"The context provides the necessary information. It states that a General Purpose Technology is applied in various sectors ('in verschiedenen Sektoren'), improves over time ('Ã¼ber die Zeit immer besser genutzt'), and leads to complementary innovations ('zu weiteren komplementÃ¤ren Innovationen gefÃ¼hrt haben')."
"In the paper 'THE PRODUCTIVITY J-CURVE: HOW INTANGIBLES COMPLEMENT GENERAL PURPOSE TECHNOLOGIES', by how much higher was the adjusted measure of Total Factor Productivity (TFP) compared to official measures at the end of 2017?",The adjusted TFP was 15.9% higher than official measures at the end of 2017.,The text doesn't provide information about the adjusted Total Factor Productivity (TFP) measurement at the end of 2017 or how it compares to official measurements.,"8. Mai 2025
Brynjolfsson et al. (2025): productivity results
27
Substantial increase in worker productivity 3. Juli 2025
What then?
Consider technical performance metric that is independent of threshold
• Solution: Receiver Operating Characteristic
• Simulate thresholds from 0 to 1 and calculate TPR and FPR for every threshold value
• Plot every (TPR, FPR) tuple with TPR being on the y-axis and FPR on the x-axis
18 gehabt habe,
bringt GPT dann irgendwas noch?
Weil hier die Leute im roten die 
haben es
immer direkt von Anfang an 
gehabt und die im Grünen,
die haben es dann erst ab Monat 
fünf und
sechs nach einer gewissen 
Einarbeitungszeit gehabt.
Und wir sehen, selbst nach einer
gewissen Einarbeitungszeit wird 
dann
auf einmal diese 
Produktivitätssteigerung
höher im Vergleich zu den 
Personen im Unternehmen.
Die blaue Linie, die nie
exist dazu bekommen haben, 
danach ja.
Aber am besten ist es gewesen,
wenn die Leute von Anfang
an eben diese Technologie 
Zugriff hatten.
Wichtig hier sei darauf 
hingedeutet.
Erste Studien zeigen Das ist 
auch bei Experten.
Das sind alles Leute,
die neu angestellt wurden.
Da sehen wir diese massiven 
Produktivitätssteigerung.
Aber erste Studien zeigen,
dass das wohl nicht nur für 
Offices gilt,
sondern in Tasks wie Software 
Development
anscheinend insbesondere auch 
für Experten gilt,
so dass wir hier wieder so ein 
bisschen
Evidenz dafür bekommen,
dass diese Technologie eventuell 
diese Schere
in der Produktivität von 
Experten,
Leuten mit viel Humankapital
und mit geringem Humankapital 
verändert.
Letzter Punkt Auch die Kunden 
sind happy geworden.
Wir haben höhere Net Promoter 
Scores.",6.491999865,0,"The generated answer incorrectly claims the text doesn't provide the information. The ground truth gives the correct statistic (15.9% higher), which the generation failed to find.",0,The generated answer is unfaithful. The provided context discusses a study on worker productivity after being given access to GPT-like systems but contains no information about 'Total Factor Productivity (TFP)' or its comparison to official measures in 2017.,0,"The context discusses productivity increases related to GPT adoption in a company, but it provides no information about the 'THE PRODUCTIVITY J-CURVE' paper or a specific adjusted Total Factor Productivity (TFP) measure for 2017."
What did Robert Solow's productivity paradox state?,That one 'can see in the computer age everywhere but in the productivity statistics',"Basierend auf dem Text, das sogenannte ""Produktivitäts-Paradox"" besagt Folgendes:

*   **Anfangs sinkt die Produktivität:** Wenn neue, sogenannte ""General Purpose Technologien"" wie GPT eingeführt werden, führt dies zunächst zu einer Produktivitätsabnahme. Dies liegt daran, dass massive Investitionen in Schulungen, Infrastruktur und die Entwicklung von ""intangible Assets"" (Know-how) erforderlich sind.
*   **Später steigt die Produktivität:** Nachdem diese anfänglichen Investitionen getätigt wurden und die Technologie in den Organisationen integriert ist, steigt die Produktivität stark an.

Mit anderen Worten, die Einführung der Technologie führt zu einem anfänglichen Produktivitätstief, bevor sie langfristig zu einer Produktivitätssteigerung führt.","der Produktivität, dann sehen 
wir,
dass am Anfang bei vielen 
Technologien eigentlich
und das ist ein Average
erstmal die Produktivität runter 
geht.
Wir sind sozusagen an der 
unteren dieser Kurve,
diesem unteren Halbkreis von dem 
J.
Und erst danach geht es 
eigentlich nach oben.
Wir haben eine massiven 
Produktivität.
Das ist wie gesagt der die
Veränderung wir sehen hier ist 
erstmal runtergeht,
dann geht steil nach oben und 
das ist ein Phänomen,
was wir diese Kurve nennen.
Und das sehen wir immer wieder 
mit
verschiedenen General purpose 
technology.
Und das hat ganz einfache 
Gründe, nämlich,
dass am Anfang,
wenn wir in diese Technologien 
investieren,
wie in GPT investiert wird,
haben wir erstmal riesige 
anfängliche Investitionen,
die sich nicht sofort auszahlen.
Wir haben massive Investitionen,
beispielsweise darin,
dass Leute die Technologie 
richtig nutzen können.
Ich muss Schulungen machen,
ich muss die Infrastruktur 
schaffen,
ich muss die Anbindung an meine 
Datenbank schaffen.
Ich muss ganz viele intangible 
Assets Know how kreieren,
um dann letztlich auch wieder 
weitere Innovationen.
Wir reden über General Purpose 
Technologien,
komplementäre Investitionen 
anzuregen.
Und das führt natürlich dazu, Produktivitätsveränderungen 
negativ sein kann.
Das ist so dieser untere 
Halbkreis von dem J.
Und das kann verschiedene Gründe 
haben.
Unter anderem eben, dass diese
Technologien noch nicht 
ausreichend in den
Organisationen mit
komplementären Investitionen 
integriert worden sind.
Und dann sind wir noch 
technischer
geworden aus einer 
mikroökonomischen Perspektive.
Wir haben kurz über die Trust 
Game Struktur gesprochen,
wo es darum geht.
Ich mache Entscheidungen, 
ökonomisch
relevante Entscheidungen unter 
Unsicherheit.
Und in diesen Szenarien kann 
Machine Learning uns helfen.
Wenn Sie sich wieder vorstellen,
Sie sind hier der Investor.
Sie haben 10 Millionen € zur 
Verfügung,
Sie entweder in ein Startup 
investieren
können oder eben auch nicht.
Wenn Sie nicht investieren, 
haben Sie
10 Millionen Cash und das 
Startup hat nichts.
Wenn Sie es investieren,
dann kann das Startup entweder 
sich anstrengen,
viel arbeiten, kann diese Summe,
die Sie investieren,
verdreifachen und gibt Ihnen die 
Hälfte zurück.
Oder aber das Startup strengt
sich ein bisschen an und läuft 
weg.
Dann haben wir gesagt Wenn wir 
uns
das als 
Nutzenmaximierungsstrategie
aufschreiben aus dieser 
mikroökonomischen,
schrägstrich spieltheoretischen Produktivität massiv ansteigt.
0.1. 0.2. Wir sehen das.
Hier haben Sie drei Gruppen.
Die Gruppe, die neu angestellt 
wurde,
das ist die, die Monate,
wie lange die Person schon dort 
arbeitet.
Wir sehen hier den roten 
Graphen, der uns zeigt.
Die Personen, die von 
vornherein,
sobald sie anfangen, mit PT 
gearbeitet haben.
Ja, wir sehen hier,
dass die Produktivität sofort 
massiv nach oben geht.
Wir haben diejenigen hier, die 
Blauen,
die niemals Access bekommen 
haben zu der Technologie.
Auch bei denen sehen wir 
natürlich über die Zeit.
Wenn sie länger in der Firma 
waren,
haben sie die Prozesse 
kennengelernt und
wurden immer ein bisschen 
produktiver.
Das heißt, wir haben hier 
sozusagen eine Kontrollgruppe.
Und dann haben Sie in dem in der 
Studie sogar
noch eine weitere Gruppe von 
Leuten,
die Sie dann nach 5 bis 6 
Monaten,
also in dem Monat fünf und sechs 
seit der Anstellung
haben sie den dann Zugriff auf 
GPT gegeben,
um herauszufinden.
Naja, inwiefern?
Wenn ich schon anfange Training 
gehabt habe,
bringt GPT dann irgendwas noch?
Weil hier die Leute im roten die 
haben es
immer direkt von Anfang an 
gehabt und die im Grünen,
die haben es dann erst ab Monat 
fünf und
sechs nach einer gewissen 
Einarbeitungszeit gehabt.",14.26869512,1,"The generated answer provides a description of the productivity paradox that is semantically consistent with the ground truth, capturing the essence of Solow's observation.",1,"The generated answer is faithful. [cite_start]The context describes a phenomenon where productivity initially goes down ('erstmal die ProduktivitÃ¤t runter geht') before later increasing ('dann geht steil nach oben'), which it calls the 'J-Kurve'[cite: 502, 504].",0,"The context describes the 'Productivity J-Curve' phenomenon, which is related but does not mention Robert Solow or his specific paradox about seeing computers everywhere except in productivity statistics."
What are some examples of complementary investments required by General Purpose Technologies (GPTs) like AI?,"Business process redesign, co-invention of new products and business models, and investments in human capital.","Basierend auf dem Text sind hier einige Beispiele für ergänzende Investitionen, die durch General Purpose Technologien (GPTs) wie KI erforderlich sind:

*   **Sensoren und vernetzte Geräte:** Um die KI-Funktionen zu nutzen, werden Sensoren und vernetzte Geräte benötigt.
*   **Datenpipelines und ML-Ops:** Neue Prozesse und Infrastrukturen, um die großen Datenmengen zu verarbeiten, die von KI-Systemen generiert werden.
*   **KI-gestützte Prozesse:** Neue Arbeitsabläufe, die auf KI-Technologien basieren.
*   **Synthetische Daten:** Daten, die speziell für das Training von KI-Modellen erstellt werden.

Der Text betont, dass GPTs nicht nur in einer bestimmten Domäne, sondern in verschiedenen Sektoren eingesetzt werden und dass sie zu weiteren komplementären Innovationen führen.","Datenbank schaffen.
Ich muss ganz viele intangible 
Assets Know how kreieren,
um dann letztlich auch wieder 
weitere Innovationen.
Wir reden über General Purpose 
Technologien,
komplementäre Investitionen 
anzuregen.
Und das führt natürlich dazu, 
dass viele Ressourcen,
die eigentlich vielleicht auf 
der Produktivität
per se gelegen haben,
abgezogen werden und in
diese Produktivitätssteigerung 
investiert werden.
Und damit haben wir immer so ein 
bisschen.
Wir brauchen erstmal viel Zeit
und sollten nicht zu ungeduldig 
sein,
bis wir die Effekte dieser
neuen Technologie wirklich 
sehen.
Ich habe ihn letztes
Mal schon gesagt der große 
Missglauben
bei vielen Unternehmen ist 
weiterhin Ich nehme ei,
schmeiß es ins Unternehmen und 
es bringt sofort was.
Ne KI muss integriert sein.
Wir müssen die Prozesse da herum 
bauen,
Genauso wie wir die Fabriken
mit der Einführung der 
Elektrizität
im Vergleich zur Steam Engine 
umbauen mussten,
müssen wir unsere Organisationen 
adaptieren.
Und das führt dazu, dass wir 
eben am
Anfang diese Zeit brauchen,
um aus dieser Krise 
rauszukommen.
Und wir sehen die ersten 
Anzeichen,
dass wir jetzt möglicherweise
über KI Agenten nachdenken, da 
rauskommen.
Bei Software Development sind 8. Mai 2025
AI as General-Purpose technologyWhat is a General-Purpose Technology (GePuT)?•Pervasive: can be applied across sectorsof the economy. •Rapidly improving & cheaper over time: learning-by-doing, scale economies, Moore-like curves•Complements: sparks waves of follow-on innovations, new business models, organizational redesign.•Previous examples: Steam engine, Electricity, Digital ComputingAI be seen as a GePuTas well –why?•Core function gets dramatically cheaper: prediction making•Ubiquitous use-cases across every industry.•For the first time: continuous learning of the technology itself with cross industry spillovers•Catalyst for complements:•New inputs: sensors, connected devices, synthetic data•New “orgware”: data pipelines, ML-ops, AI-first processes•…
7
Managerial perspective: invest in complementary technologies, andadjust organization to unlock its full value. in einer bestimmten Domäne,
in einem bestimmten Bereich 
angewendet werden kann,
sondern eben in verschiedenen 
Sektoren.
Es wird überall gebraucht.
Also General Purpose und
vorher war mal und ich finde den 
Namen furchtbar.
Aber um sie nicht zu verwirren,
habe ich eine andere als die 
herkömmliche Abkürzung,
die Sie in vielen ökonomischen
Büchern noch finden, nämlich 
GPT.
Das ist General Purpose.
Technologie hat natürlich Open 
AI
uns alle so ein bisschen 
versaut.
Dieses Wort zu benutzen,
insbesondere wenn man irgendwie 
an der
Schnittstelle zu Machine 
Learning arbeitet,
weil alle direkt an das 
Sprachmodell denken.
Deswegen hier diese furchtbare
Abkürzung General purpose
Tonnen general purpose 
technology.
Diese Technologien haben
die gesamte Zivilisation der
Menschheit schon immer massiv 
verändert.
Nicht nur, weil sie auf der 
einen Seite weit
eingesetzt worden sind und
auf der anderen Seite eben über
die Zeit immer besser genutzt 
wurden,
erkannt wurde, wo wir sie noch 
einsetzen
kann Economies of Scale 
eingesetzt haben.
Viele Leute nutzen es wird immer 
knapper.
Sondern auch, weil diese 
Innovationen,
diese Kerninnovationen,
letztlich zu weiteren
komplementären Innovationen 
geführt haben.",15.98525524,1,"The generated answer provides examples of complementary investments (business process redesign, new business models, human capital) that are semantically consistent with the examples in the ground truth.",1,"The generated answer is faithful. [cite_start]The context provides several examples of complementary investments, including 'data pipelines, ML-ops, AI-first processes' and 'investments in human capital' (via the need for training)[cite: 541, 533].",1,"The context directly mentions the required complementary investments for AI as a General Purpose Technology, listing examples such as 'sensors, connected devices, synthetic data' and 'data pipelines, ML-ops, AI-first processes'."
"According to the text, what is the 'Productivity J-Curve' phenomenon?","It is a phenomenon where, as firms adopt a new General Purpose Technology (GPT), total factor productivity (TFP) growth is initially underestimated because resources are spent on unmeasured intangible capital. Later, measured productivity growth overestimates true productivity as the benefits from those intangibles are realized.","Die ""Produktivitäts-J-Kurve"" beschreibt ein Phänomen, bei dem die Produktivität durch den Einsatz neuer Technologien zunächst erstmal sinkt, bevor sie dann steil ansteigt. Es ist wie ein unterer Halbkreis, der ""J"" gezeichnet hat.","der Produktivität, dann sehen 
wir,
dass am Anfang bei vielen 
Technologien eigentlich
und das ist ein Average
erstmal die Produktivität runter 
geht.
Wir sind sozusagen an der 
unteren dieser Kurve,
diesem unteren Halbkreis von dem 
J.
Und erst danach geht es 
eigentlich nach oben.
Wir haben eine massiven 
Produktivität.
Das ist wie gesagt der die
Veränderung wir sehen hier ist 
erstmal runtergeht,
dann geht steil nach oben und 
das ist ein Phänomen,
was wir diese Kurve nennen.
Und das sehen wir immer wieder 
mit
verschiedenen General purpose 
technology.
Und das hat ganz einfache 
Gründe, nämlich,
dass am Anfang,
wenn wir in diese Technologien 
investieren,
wie in GPT investiert wird,
haben wir erstmal riesige 
anfängliche Investitionen,
die sich nicht sofort auszahlen.
Wir haben massive Investitionen,
beispielsweise darin,
dass Leute die Technologie 
richtig nutzen können.
Ich muss Schulungen machen,
ich muss die Infrastruktur 
schaffen,
ich muss die Anbindung an meine 
Datenbank schaffen.
Ich muss ganz viele intangible 
Assets Know how kreieren,
um dann letztlich auch wieder 
weitere Innovationen.
Wir reden über General Purpose 
Technologien,
komplementäre Investitionen 
anzuregen.
Und das führt natürlich dazu, Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. Produktivitätsveränderungen 
negativ sein kann.
Das ist so dieser untere 
Halbkreis von dem J.
Und das kann verschiedene Gründe 
haben.
Unter anderem eben, dass diese
Technologien noch nicht 
ausreichend in den
Organisationen mit
komplementären Investitionen 
integriert worden sind.
Und dann sind wir noch 
technischer
geworden aus einer 
mikroökonomischen Perspektive.
Wir haben kurz über die Trust 
Game Struktur gesprochen,
wo es darum geht.
Ich mache Entscheidungen, 
ökonomisch
relevante Entscheidungen unter 
Unsicherheit.
Und in diesen Szenarien kann 
Machine Learning uns helfen.
Wenn Sie sich wieder vorstellen,
Sie sind hier der Investor.
Sie haben 10 Millionen € zur 
Verfügung,
Sie entweder in ein Startup 
investieren
können oder eben auch nicht.
Wenn Sie nicht investieren, 
haben Sie
10 Millionen Cash und das 
Startup hat nichts.
Wenn Sie es investieren,
dann kann das Startup entweder 
sich anstrengen,
viel arbeiten, kann diese Summe,
die Sie investieren,
verdreifachen und gibt Ihnen die 
Hälfte zurück.
Oder aber das Startup strengt
sich ein bisschen an und läuft 
weg.
Dann haben wir gesagt Wenn wir 
uns
das als 
Nutzenmaximierungsstrategie
aufschreiben aus dieser 
mikroökonomischen,
schrägstrich spieltheoretischen",8.084655285,1,The generated answer provides a definition of the 'Productivity J-Curve' that is semantically identical to the ground truth.,1,"The generated answer is faithful. [cite_start]The context describes a phenomenon where initial investments in a new technology cause productivity to go down at first ('erstmal die ProduktivitÃ¤t runter geht') before the benefits are realized and productivity goes up ('dann geht steil nach oben')[cite: 551, 553].",1,The context clearly defines the 'Productivity J-Curve' as a phenomenon where productivity initially goes down ('erstmal die ProduktivitÃ¤t runter geht') before rising sharply ('dann geht steil nach oben') .
"What societal benefit, in terms of CO2 emissions, would a 2.6% return decrease translate to based on U.S. figures from 2022?","It would result in a reduction of 624,000 metric tons of CO2 emissions.","Basierend auf den Texten würde eine 2,6-prozentige Rückgangsrate der Rücksendungen, basierend auf US-Daten aus dem Jahr 2022, zu einer Reduzierung von 624.000 Tonnen CO2-Emissionen führen. Dies entspricht den Emissionen von 121.000 US-Haushalten.","effect corresponds to annual savings in processing costs 
of approximately $340,000 and translates into an 8.7% 
increase in profits. From an industry-wide perspective, 
based on a projected $25.1 billion in online returns pro -
cessing expenses in the United States for 2023 (Zheng 
2023 ), the decrease would translate to annual cost sav -
ings of approximately $650 million. From a societal per -
spective, based on U.S. figures from 2022, the 2.6% 
return decrease would result in a reduction of 624,000 
metric tons of CO
2 
emissions (Calma 2023 ). This reduc -
tion is roughly equivalent to the annual emissions from 
the electricity consumption of 121,000 U.S. homes.
1
Second, further analyses using the CML model 
reveal that the green nudge substantially reduced 
returns for approximately 60% of customers but led to 
an increase for the remaining 40%, suggesting that 
green nudging can occasionally backfire. This backfir -
ing effect, which has also been observed in prior studies 
(e.g., Hagmann et al. 2019 , Osman 2020 ), diminishes 
the intervention’s effectiveness from both business and 
societal perspectives. An off-policy evaluation provides 
evidence that “smartly” administering a green nudge Accepted: April 18, 2024 
Published Online in Articles in Advance: 
August 8, 2024 
https://doi.org/10.1287/mksc.2022.0393 
Copyright: © 2024 The Author(s)
Abstract. In e-commerce, product returns have become a costly and escalating issue for 
retailers. Beyond the financial implications for businesses, product returns also lead to 
increased greenhouse gas emissions and the squandering of natural resources. Traditional 
approaches, such as charging customers for returns, have proven largely ineffective in 
curbing returns, thus calling for more nuanced strategies to tackle this issue. This paper 
investigates the effectiveness of informing consumers about the negative environmental 
consequences of product returns (“green nudging”) to curtail product returns through a 
large-scale randomized field experiment (n � 117,304) conducted with a leading European 
fashion retailer’s online store. Our findings indicate that implementing green nudging can 
decrease product returns by 2.6% without negatively impacting sales. We then develop 
and assess a causal machine learning model designed to identify treatment heterogeneities 
and personalize green nudging (i.e., make nudging “smart”). Our off-policy evaluation 24. April 2025
Summary and impact: what ML does
https://www.readycloud.com/info/14-facts-about-ecommerce-product-returns
up to 4.6% decrease
•Our green nudges can be easily implemented at low costin all online shops •Our ""smart"" implementation uses open-source libraries and may predict impact on individual-level profit of any nudge•Our return reduction on global scale would save…•…up to 200,000 tons of CO2 emissions •…up to 120,000 tons of waste
Annual impact for industry partner: in the six figures",11.86387515,1,"The generated answer and the ground truth both state the correct fact: a 2.6% return decrease translates to a reduction of 624,000 metric tons of CO2.",1,"The generated answer is faithful. [cite_start]The context explicitly states that a '2.6% return decrease would result in a reduction of 624,000 metric tons of CO2 emissions'[cite: 576].",1,"The context directly answers the question, stating that a 2.6% return decrease would result in a reduction of 624,000 metric tons of CO2 emissions, based on U.S. figures from 2022."
What is the estimated annual savings in processing costs for the industry partner due to the green nudge?,"The effect corresponds to annual savings in processing costs of approximately $340,000.","Laut dem Text beträgt der geschätzte jährliche Gewinnanstieg für den Industriepartner aufgrund des ""grünen Nudges"" im sechsstelligen Bereich.","24. April 2025
Summary and impact: what ML does
https://www.readycloud.com/info/14-facts-about-ecommerce-product-returns
up to 4.6% decrease
•Our green nudges can be easily implemented at low costin all online shops •Our ""smart"" implementation uses open-source libraries and may predict impact on individual-level profit of any nudge•Our return reduction on global scale would save…•…up to 200,000 tons of CO2 emissions •…up to 120,000 tons of waste
Annual impact for industry partner: in the six figures annually. This amount is roughly equivalent to the 
annual emissions from the electricity consumption of 
121,000 U.S. homes.
3
Notably, the actual savings in 
emissions are likely to be even higher both as the vol -
ume of returns continues to grow further (Calma 2023 ) 
and because emissions through packaging and the pro -
duction process of discarded goods are not included.
From a business perspective, according to internal 
figures of our industry partner, the estimated annual 
profit increase quickly amortizes costs associated with 
the development, implementation, and maintenance of 
green nudging. In fact, the developed dual nudge 
turned out to be so successful that our industry partner 
opted to keep the green nudge running in the German 
online shop. The project’s success is affirmed by a prac -
tice executive who corroborates the effectiveness of the 
implemented dual-nudge approach by stating that
[t]he reduction in returns without a negative impact 
on revenue was huge for us. So huge, in fact, that we 
opted for keeping the experiment live and showing 
the successful treatment to all of our German online 
customers. —Practice partner executive
Apart from the immediate business benefits through Kihal et al. 2021 , Pfrang and Spreer 2022 ). This paper 
aims to contribute to this discussion by empirically 
evaluating the effectiveness of an informational inter -
vention, referred to as green nudging, in decreasing 
product returns.
In this study, we partnered with a leading European 
fashion retailer. Like many in the industry, the retailer 
grapples with the challenges and costs arising from 
online product returns. Seeking to align profitability 
with environmental responsibility, we collaborated 
with our partner to craft a strategy that not only curtails 
product returns but also, that resonates with the retai -
ler’s sustainable ethos and is economically viable. The 
jointly developed green nudge comprises two prompts: 
informing online customers about the negative envi -
ronmental impact of product returns throughout 
(shopping cart prompt) and at the conclusion of their 
online shopping journey (reminder prompt). We con -
ducted an extensive field experiment with 117,304 par -
ticipants in the retailer’s online shop to empirically 
validate the green nudge. We then apply modern 
causal machine learning (CML) methods (Athey et al. 
2019 ) to analyze treatment heterogeneities based on",7.101764679,0,"The generated answer states the savings are 'in the six figures,' which is vague and less precise than the ground truth's specific value of '$340,000'.",0,"The generated answer is unfaithful. [cite_start]The context states the annual impact for the industry partner is 'in the six figures', but it does not specify the currency or the exact amount of '$340,000' in processing cost savings[cite: 589]. [cite_start]That specific figure is mentioned in the abstract of the full paper [cite: 574] but not in the snippet provided as the primary context for this specific generation.",0,"The context mentions that the annual impact for the industry partner is 'in the six figures', but it does not provide the specific value of $340,000 as stated in the question's ground truth answer."
"In the 'Smart Green Nudging' paper, what was the sample size (n) of the randomized field experiment discussed?","The experiment had a sample size of 117,304 participants (n = 117,304).","Das Dokument erwähnt nicht die genaue Stichprobengröße (n) des randomisierten Feldexperiments. Es wird lediglich erwähnt, dass es sich um ein ""large-scale"" Experiment handelte.","The rest of the paper is structured as follows. Section 
2 provides the theoretical background by reviewing 
related literature. Section 3 presents the setting and 
results of our randomized field experiment. Section 4
details the configuration and results from our causal 
machine learning model, along with the evaluation of 
smart green nudging. Section 5 concludes by discuss -
ing the practical implications of our work, its limita -
tions, and potential avenues for future research.
2. Related Literature
Our work relates to three streams of literature, namely 
(i) product returns, (ii) nudging, and (iii) treatment het -
erogeneities and causal machine learning.
2.1. Product Returns
The surge in product returns and the corresponding busi -
ness and environmental repercussions have prompted 
von Zahn et al.: Product Returns, Digital Footprints, and Causal Machine Learning 
2 Marketing Science, Articles in Advance, pp. 1–16, © 2024 The Author(s) 
Downloaded from informs.org by [141.2.113.143] on 24 April 2025, at 02:36 . For personal use only, all rights reserved. and assess a causal machine learning model designed to identify treatment heterogeneities 
and personalize green nudging (i.e., make nudging “smart”). Our off-policy evaluation 
indicates that this personalization can approximately double the success of green nudging. 
The study demonstrates the effectiveness of both subtle marketing interventions and per -
sonalization using causal machine learning in mitigating environmentally and economi -
cally harmful product returns, thus highlighting the feasibility of employing “Better 
Marketing for a Better World” approaches in a digital setting.
History: Olivier Toubia served as the senior editor. This paper was selected as a finalist in the 2022 Gary 
L. Lilien ISMS-MSI Practice Prize Competition. 
Open Access Statement: This work is licensed under a Creative Commons Attribution-NonCommercial- 
NoDerivatives 4.0 International License. You are free to download this work and share with others, 
but cannot change in any way or use commercially without permission, and you must attribute this 
work as “Marketing Science. Copyright © 2024 The Author(s). https:/ /doi.org/10.1287/mksc.2022. 
0393, used under a Creative Commons Attribution License: https:/ /creativecommons.org/licenses/ significant variability in how individuals respond to 
nudging (Hummel and Maedche 2019 ), rendering the 
outcomes of green nudging unpredictable (Lehner et al. 
2016 ). Additionally, few researchers have explored the 
impact of green nudges on a large scale (see He et al. 
2023 for an exception), leaving a gap in our understand -
ing and a need to reconcile these divergent findings.
We extend prior research by conducting a large- 
scale, randomized field experiment to test the effective -
ness of green nudges in reducing product returns. Our 
green nudge effectively leverages customers’ desire to 
sustain a positive self-image through environmentally 
friendly behavior (Schubert 2017 ). It heightens aware -
ness of the negative environmental impact linked to 
returning products during both the prepurchase and 
postpurchase phases of the customer journey.
2.3. Treatment Heterogeneities and Causal 
Machine Learning
There often exists a notable heterogeneity in customer 
reactions to marketing strategies (El Kihal and Shehu 
2022 ), especially nudging techniques (Lehner et al. 
2016 , Mirsch et al. 2017 , Hummel and Maedche 2019 ). 
Accordingly, relying solely on average treatment",7.683143377,0,"The generated answer incorrectly states that the sample size is not mentioned, while the ground truth provides the exact number (117,304). The generation failed to extract the correct information.",0,"The generated answer is unfaithful. The context does not mention the sample size of the experiment. [cite_start]It only refers to it as a 'large-scale' experiment[cite: 617]. [cite_start]The specific number (117,304) is mentioned elsewhere in the full paper text but not in the retrieved context for this generation[cite: 584].",0,"The context discusses a 'large-scale, randomized field experiment' but does not provide the specific sample size (n=117,304)."
What are the two types of returns mentioned in the context of online shopping?,'Real returns' (where the customer intended to keep the item) and 'opportunistic returns' (where the customer orders multiple options with the intent to return some).,"Im Text werden zwei Arten von Rückgaben erwähnt:

1.  Rückgaben von Produkten
2.  Rückgaben von Produkten im Zusammenhang mit dem Wert der zurückgesandten Produkte","cost nature, seeking simply to inform customers about 
the repercussions of their postpurchase actions. Closely 
related to our research, Ghose et al. ( 2023 ) recently 
assessed the effectiveness of pressure-oriented and self- 
assurance-oriented nudges on sales and returns, find -
ing that the latter is better suited to boosting net sales. 
Unlike our study, the nudges that they examined pro -
vide direct information about products under consider -
ation by online shoppers. To our knowledge, we are the 
first to design and test the efficacy of making the envi -
ronmental consequences of postpurchase behavior 
salient in reducing product returns through a large- 
scale field experiment.
2.2. Nudging
As a cognitive intervention, nudging aims to subtly 
alter human behavior through modifications in the 
choice architecture (Thaler and Sunstein 2009 ). Cru -
cially, nudges guide behavior without restricting 
options, substantially altering material incentives, or 
using coercion (Thaler and Sunstein 2009 , Mirsch et al. 
2017 ). They are minimally invasive interventions that 
maintain freedom of choice (Thaler and Sunstein 2003 ) 
and can enhance economic efficiency by facilitating 
superior choices with minimal expenditure. they shop during weekends or weekdays as other online 
shopping studies have shown (Grahl et al. 2023 ).
Individuals’ digital footprints contain meaningful 
information (Berg et al. 2020 ). In our CML model, we use 
these footprints, specifically the internet provider, 
browser type, and IP geolocation, which have been 
shown to be relevant in explaining behavioral heteroge -
neities (see, e.g., CivicScience 2015 , Berg et al. 2020 , Ebert 
et al. 2021 ). We treat all three predictors from the digital 
footprint as categorical variables. To prepare them for 
our CML model, we apply one-hot encoding and feature 
selection, which we detail in Online Appendix A.5.
4.1.2. The Causal Forest. We estimate heterogeneous 
treatment effects using a causal forest (Athey et al. 2019 ). 
This method calculates conditional average treatment 
effects for various combinations of predictor values. Prac -
tically, the causal forest segments global average treat -
ment effects into local conditional averages by repeatedly 
dividing customers into subgroups and calculating the 
difference in effects between treatment and control 
groups within each subgroup. Its capability to capture 
highly nonlinear treatment heterogeneities makes it parti - also report treatment effects for other key business 
metrics, including the value of returned products.
Beyond business metrics, we actively tracked changes 
in the composition of shopping carts over time. Addi -
tionally, we collected data on customers’ digital foot -
prints, focusing on the product categories they browsed 
in the shop (such as fashion for women, children’s pro -
ducts, and discounted items) and technical details, like 
browser type, internet provider, and IP address.
3.1.4. The Implementation Process. As common in the 
online retailer industry, our partner works with UX 
agencies on randomized trials, drawing from a vast 
pool of best practices and emphasizing evidence-based 
testing with frequent customer feedback. Our partner’s 
best practices and established processes proved 
challenging for our collaboration, especially in marry -
ing statistical methods with the partner’s existing data 
infrastructure, necessitating close collaboration for data 
integration. The experience highlighted the crucial role 
of early, clear communication on data needs and the 
value of combining academic and business approaches 
to enrich data analysis and consumer insights. For further",6.450962067,0,"The generated answer is factually incorrect. It lists 'RÃ¼ckgaben von Produkten' (product returns) and 'RÃ¼ckgaben von Produkten im Zusammenhang mit dem Wert' (returns related to value), which are not the two types of returns ('Real returns' and 'opportunistic returns') mentioned in the ground truth.",0,"The generated answer is unfaithful. The context mentions 'Real returns' and 'opportunistic returns' are not mentioned. [cite_start]Instead, the text discusses returns in terms of business metrics like 'value of returned products'[cite: 635].",0,"The context discusses product returns in general and the use of digital footprints, but it does not define or mention the specific terms 'real returns' and 'opportunistic returns'."
"According to the paper, by how much did the smart green nudge decrease product returns compared to having no nudge at all?",The smart green nudge resulted in a 6.7% decrease in product returns compared to no nudge at all.,"Basierend auf den bereitgestellten Informationen wurde die Produkt-Rücksendung durch den ""Smart Green Nudge"" im Vergleich zu einer Nicht-Nudge-Situation um durchschnittlich 2,56% reduziert. Dies ist die Differenz zwischen der Dual-Nudge-Gruppe und der Kontrollgruppe.","the potential of smart green nudging as an effective 
personalization strategy for both businesses and the 
environment.
5. Discussion and Conclusion
5.1. Contribution
Our study addresses the challenge of product returns 
by developing and empirically validating a green 
nudging intervention. Green nudging prompts shop -
pers toward more environmentally conscious and 
thoughtful behavior, effectively reducing product 
returns. Our large-scale field experiment shows that 
green nudging lowers product returns by 2.6% without 
negatively impacting sales. For our industry partner, 
the observed effect translates into an estimated annual 
reduction in processing costs of about $340,000 and an 
8.7% boost in profits. On a larger scale, estimations 
based on public data from the United States suggest 
that the achieved reduction in returns could signifi -
cantly decrease U.S. fashion industry-wide costs by 
$650 million (Zheng 2023 ) and carbon emissions by 
624,000 metric tons (Calma 2023 ). Additionally, our 
causal machine learning model identifies notable varia -
tions in consumer responses to the nudge. Subsequent 
off-policy evaluation indicates that exploiting these 
variations (i.e., nudging “smartly”) could more than purchase, ensuring an unbiased and comprehensive 
assessment of green nudging effects (e.g., encompass -
ing effects on the conversion rate).
3.2.1. Overall Effects of Green Nudging. Table 2 pre -
sents individual summary statistics for key business 
metrics from our field experiment. Specifically, we out -
line average customer responses in terms of binary return 
decisions, the value of returned products, the cart conver -
sion, and sales. We display these results separately for 
the control group (without nudging) and the two treat -
ment groups (single nudge and dual nudge). For all three 
groups, we visualize the key business metrics and confi -
dence intervals relative to the control group in Figure 2 .
Our results suggest that the dual-green-nudge inter -
vention can significantly reduce product returns with -
out harming sales. On the extensive margin, customers 
in the dual-nudge treatment are on average 2.6% less 
likely to return at least one product and thus, make a 
return shipment compared with the control group (0.24 
versus 0.26, respectively; p < 0.03, Mann–Whitney U 
test). We also observe an impact on the intensive mar -
gin. On average, customers exposed to the dual nudge when examining the net sales on an individual level, we 
find positive, albeit statistically insignificant, treatment 
effects (+1.48%, p � 0.29, Mann–Whitney U test).
Taken together, these results show the effectiveness of 
the dual green nudge from both the environmental 
perspective—a significant reduction in return shipments— 
and the business perspective—a significant reduction in 
the value of returned products with equal sales.
Putting these measures into context, by using annual 
carbon dioxide emissions attributable to the logistics of 
returns in the United States alone (e.g., Calma 2023 ), 
our intervention could reduce the carbon footprint by 
624,000 metric tons of carbon dioxide emissions 
Table 2. Summary Statistics from the Analysis of Green Nudging
Group N
Returns (shipment) Returns (value) Cart conversion Sales
Mean (SE) Mean (SE) Mean (SE) Mean (SE)
Control 38,475 0.260 (0.002) 18.49 (0.26) 0.622 (0.002) 52.09 (0.40)
Single nudge 39,060 0.260 (0.002) 18.29 (0.74) 0.627 (0.002) 52.41 (0.39)
Difference from control, % +0.32 � 1.08 +0.82 +0.62
Dual nudge 39,769 0.253 (0.002) 17.88 (0.25) 0.625 (0.002) 51.98 (0.40)
Difference from control, % � 2.56** � 3.29** +0.47 � 0.21",9.05074048,0,"The generated answer provides an incorrect value for the decrease in product returns (2.56%), which contradicts the ground truth value (6.7%).",0,The generated answer is unfaithful. [cite_start]The context states that the dual-nudge treatment group was 2.6% less likely to return a product compared to the control group[cite: 655]. The generation's claim of a 6.7% decrease is not supported.,0,The context presents a table showing the difference in returns between a 'dual nudge' group and a control group as -2.56%. It does not mention a 'smart green nudge' or a 6.7% decrease.
"In the 'Smart Green Nudging' study, which variable was identified by SHAP values as the most pivotal for the prediction?",The initial cart value.,"Laut SHAP-Werten wurde der initiale Warenkorbwert als die variable identifiziert, die am wichtigsten für die Vorhersage war.","contribute to the predictions (Senoner et al. 2022 ). In 
our case, SHAP values indicate that the initial cart 
value is the variable most pivotal for the prediction. We 
report SHAP values from our CML model in Online 
Appendix A.10. However, it is crucial to differentiate 
between variables that predict the treatment effect and 
those that act as causal moderators. We encourage 
future research to rigorously investigate the causal role 
of variables in moderating the effectiveness of green 
nudging.
Our study also underscores the effectiveness of using 
customer carts and digital footprint data to personalize 
marketing interventions. Our analyses reveal multiple 
characteristics that induce heterogeneous treatment 
effects, including the type of internet browser, the inter -
net provider, the federal state, and the weekday.
7
For 
example, weekend shoppers are more effectively 
nudged than weekday shoppers, possibly because of 
lower stress levels, aligning with similar literature find -
ings (Grahl et al. 2023 ). Similarly, the internet browser 
and other characteristics of the digital footprint can 
hint at underlying customer traits and demographics 
(Berg et al. 2020 ). Incorporating these insights, practi - 22. Mai 2025
Shapley scores: weighted average
•Local accuracy: attributions sum (exactly) to the prediction difference•Consistency: if a model changes so that the marginal contribution of a feature value increases or stays the same (regardless of other features), the Shapley value also increases or stays the same.•Missingness: unused features get SHAP value of 0 x*=0→𝜙+•Additivity: SHAP values can be added to show the joint contribution of several features to a prediction
22
𝜙%𝑓,𝑥=	2&!⊆	)!𝑧*!𝑀−𝑧*−1!𝑀! (𝑓)𝑧*−𝑓)𝑧*\i)Shapley value for i= savings
Model f
For individual x with a specific combination of features
Weighted sum over allSubsets z’of (transformed) data point x; whereM is total number of features in full set
Difference inModel prediction
𝑃𝑟𝑒𝑑𝑖𝑐𝑡𝑖𝑜𝑛!=𝐸(-𝑓𝑋)	+	3""𝜙! purchase, ensuring an unbiased and comprehensive 
assessment of green nudging effects (e.g., encompass -
ing effects on the conversion rate).
3.2.1. Overall Effects of Green Nudging. Table 2 pre -
sents individual summary statistics for key business 
metrics from our field experiment. Specifically, we out -
line average customer responses in terms of binary return 
decisions, the value of returned products, the cart conver -
sion, and sales. We display these results separately for 
the control group (without nudging) and the two treat -
ment groups (single nudge and dual nudge). For all three 
groups, we visualize the key business metrics and confi -
dence intervals relative to the control group in Figure 2 .
Our results suggest that the dual-green-nudge inter -
vention can significantly reduce product returns with -
out harming sales. On the extensive margin, customers 
in the dual-nudge treatment are on average 2.6% less 
likely to return at least one product and thus, make a 
return shipment compared with the control group (0.24 
versus 0.26, respectively; p < 0.03, Mann–Whitney U 
test). We also observe an impact on the intensive mar -
gin. On average, customers exposed to the dual nudge",6.63619256,1,The generated answer and the ground truth both correctly identify the 'initial cart value' as the most pivotal variable.,1,"The generated answer is faithful. [cite_start]The context explicitly states, 'In our case, SHAP values indicate that the initial cart value is the variable most pivotal for the prediction'[cite: 661].",1,"The context directly answers the question, stating: 'In our case, SHAP values indicate that the initial cart value is the variable most pivotal for the prediction'."
"In the field experiment from the 'Smart Green Nudging' paper, what was the initial aim of the academic team members regarding the prompts they were testing?",The initial aim was to isolate the effects of the cart prompt and the reminder prompt.,"According to the text, the academic team's goal in the randomized field experiment was to determine which prompts were most effective.","Studierende werden mit den wichtigsten Fragestellungen rund um den Einsatz von Machine Learning (ML) in Managemententscheidungen vertraut gemacht. Sie erwerben grundlegende theoretische Kompetenzen im Bereich ML und verstehen, wie diese Technologien betriebliche Prozesse und strategische Entscheidungen beeinflussen können.
Studierende erlernen den Umgang mit grundlegenden Methoden und Werkzeugen des maschinellen Lernens, einschließlich Datenaufbereitung, Modelltraining und -bewertung. Sie entwickeln die Fähigkeit, wirtschaftliche Fragestellungen in ML-Probleme zu übersetzen und datenbasierte Lösungen analytisch sowie strukturiert zu erarbeiten.
Im Rahmen der Veranstaltung werden zahlreiche Praxisbeispiele und Fallstudien aus verschiedenen Industrien behandelt, die die Anwendung von ML und generativer KI im geschäftlichen Kontext beleuchten. Insbesondere in den angebotenen Übungen und praktischen Programmieraufgaben lernen Studierende, das erlangte Wissen anzuwenden, auch ohne vorherige Programmiererfahrung. 10. Juli 2025
Beispielfragen
36
•Welche Themen werden in der Vorlesung besprochen?•Was sind die Unterschiede zwischen einem Entscheidungsbaum und einer Random-Forest-Methode? •Wie funktionieren neuronale Netze und wo kann man sie im Management einsetzen?
Freiwillig, wenn Sie uns helfen möchten: Geben Sie stets in Ihrem ersten Prompt an, dass Sie eine Student*in sind, die den Kurs besucht und teilen Sie in dem Prompt Ihre Matrikelnummer mit uns The rest of the paper is structured as follows. Section 
2 provides the theoretical background by reviewing 
related literature. Section 3 presents the setting and 
results of our randomized field experiment. Section 4
details the configuration and results from our causal 
machine learning model, along with the evaluation of 
smart green nudging. Section 5 concludes by discuss -
ing the practical implications of our work, its limita -
tions, and potential avenues for future research.
2. Related Literature
Our work relates to three streams of literature, namely 
(i) product returns, (ii) nudging, and (iii) treatment het -
erogeneities and causal machine learning.
2.1. Product Returns
The surge in product returns and the corresponding busi -
ness and environmental repercussions have prompted 
von Zahn et al.: Product Returns, Digital Footprints, and Causal Machine Learning 
2 Marketing Science, Articles in Advance, pp. 1–16, © 2024 The Author(s) 
Downloaded from informs.org by [141.2.113.143] on 24 April 2025, at 02:36 . For personal use only, all rights reserved.",5.765066147,0,"The generated answer ('to determine which prompts were most effective') is less specific and captures a different nuance than the ground truth, which was 'to isolate the effects of the cart prompt and the reminder prompt'. The ground truth implies a more controlled experimental goal.",0,"The generated answer is unfaithful. The context does not mention the aim of the academic team. [cite_start]It discusses the structure of the paper and related literature[cite: 689, 690, 691, 692, 693].",0,"The context outlines the structure of the paper, mentioning that Section 3 presents the results of the randomized field experiment, but it does not state the initial aim of the academic team regarding the prompts."
"In the 'Smart Green Nudging' paper, what were the estimated annual savings in processing costs for the industry partner as a result of the green nudging intervention?","The estimated annual savings in processing costs were approximately $340,000.",Laut dem Paper erzielte der Branchenpartner durch die grüne Nudge-Intervention jährliche Kosteneinsparungen von etwa 340.000 US-Dollar. Dies resultierte aus einer Reduzierung der Produktretouren.,"the potential of smart green nudging as an effective 
personalization strategy for both businesses and the 
environment.
5. Discussion and Conclusion
5.1. Contribution
Our study addresses the challenge of product returns 
by developing and empirically validating a green 
nudging intervention. Green nudging prompts shop -
pers toward more environmentally conscious and 
thoughtful behavior, effectively reducing product 
returns. Our large-scale field experiment shows that 
green nudging lowers product returns by 2.6% without 
negatively impacting sales. For our industry partner, 
the observed effect translates into an estimated annual 
reduction in processing costs of about $340,000 and an 
8.7% boost in profits. On a larger scale, estimations 
based on public data from the United States suggest 
that the achieved reduction in returns could signifi -
cantly decrease U.S. fashion industry-wide costs by 
$650 million (Zheng 2023 ) and carbon emissions by 
624,000 metric tons (Calma 2023 ). Additionally, our 
causal machine learning model identifies notable varia -
tions in consumer responses to the nudge. Subsequent 
off-policy evaluation indicates that exploiting these 
variations (i.e., nudging “smartly”) could more than Kihal et al. 2021 , Pfrang and Spreer 2022 ). This paper 
aims to contribute to this discussion by empirically 
evaluating the effectiveness of an informational inter -
vention, referred to as green nudging, in decreasing 
product returns.
In this study, we partnered with a leading European 
fashion retailer. Like many in the industry, the retailer 
grapples with the challenges and costs arising from 
online product returns. Seeking to align profitability 
with environmental responsibility, we collaborated 
with our partner to craft a strategy that not only curtails 
product returns but also, that resonates with the retai -
ler’s sustainable ethos and is economically viable. The 
jointly developed green nudge comprises two prompts: 
informing online customers about the negative envi -
ronmental impact of product returns throughout 
(shopping cart prompt) and at the conclusion of their 
online shopping journey (reminder prompt). We con -
ducted an extensive field experiment with 117,304 par -
ticipants in the retailer’s online shop to empirically 
validate the green nudge. We then apply modern 
causal machine learning (CML) methods (Athey et al. 
2019 ) to analyze treatment heterogeneities based on purchase, ensuring an unbiased and comprehensive 
assessment of green nudging effects (e.g., encompass -
ing effects on the conversion rate).
3.2.1. Overall Effects of Green Nudging. Table 2 pre -
sents individual summary statistics for key business 
metrics from our field experiment. Specifically, we out -
line average customer responses in terms of binary return 
decisions, the value of returned products, the cart conver -
sion, and sales. We display these results separately for 
the control group (without nudging) and the two treat -
ment groups (single nudge and dual nudge). For all three 
groups, we visualize the key business metrics and confi -
dence intervals relative to the control group in Figure 2 .
Our results suggest that the dual-green-nudge inter -
vention can significantly reduce product returns with -
out harming sales. On the extensive margin, customers 
in the dual-nudge treatment are on average 2.6% less 
likely to return at least one product and thus, make a 
return shipment compared with the control group (0.24 
versus 0.26, respectively; p < 0.03, Mann–Whitney U 
test). We also observe an impact on the intensive mar -
gin. On average, customers exposed to the dual nudge",8.333602428,1,"The generated answer and the ground truth both correctly state the estimated annual savings as approximately $340,000.",1,"The generated answer is faithful. [cite_start]The context clearly states, 'For our industry partner, the observed effect translates into an estimated annual reduction in processing costs of about $340,000'[cite: 699].",1,"The context directly answers the question, stating that for the industry partner, the observed effect translates into an 'estimated annual reduction in processing costs of about $340,000'."
Where is INFORMS located?,"INFORMS is located in Maryland, USA.","INFORMS befindet sich in Maryland, USA.","Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. Informationen zur Vorlesung: Gehalten am Do. 12:00 bis 16:00; wöchentlich vom 24.04.2025 bis 24.07.2025; Ort: Hörsaalzentrum Westend - HZ 12 This article was downloaded by: [141.2.113.143] On: 24 April 2025, At: 02:36
Publisher: Institute for Operations Research and the Management Sciences (INFORMS)
INFORMS is located in Maryland, USA
Marketing Science
Publication details, including instructions for authors and subscription information:
http://pubsonline.informs.org
Smart Green Nudging: Reducing Product Returns
Through Digital Footprints and Causal Machine
Learning
Moritz von Zahn, Kevin Bauer, Cristina Mihale-Wilson, Johanna Jagow, Maximilian
Speicher, Oliver Hinz
To cite this article:
Moritz von Zahn, Kevin Bauer, Cristina Mihale-Wilson, Johanna Jagow, Maximilian Speicher, Oliver Hinz (2024)
Smart Green Nudging: Reducing Product Returns Through Digital Footprints and Causal Machine Learning.
Marketing Science
Published online in Articles in Advance 08 Aug 2024
. https://doi.org/10.1287/mksc.2022.0393
This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International
License. You are free to download this work and share with others, but cannot change in any way or use
commercially without permission, and you must attribute this work as “Marketing Science. Copyright © 2024 The",3.301501751,1,"The generated answer and the ground truth both correctly identify the location of INFORMS as Maryland, USA.",1,"The generated answer is faithful. [cite_start]The context includes a snippet from a publication by 'Institute for Operations Research and the Management Sciences (INFORMS)' which also states, 'INFORMS is located in Maryland, USA'[cite: 723].",1,"The context provides the location of the publisher, the Institute for Operations Research and the Management Sciences (INFORMS), stating, 'INFORMS is located in Maryland, USA'."
What programming language will be used in the course?,Python.,In diesem Kurs wird die Programmiersprache Python verwendet.,"Ein besonderer Fokus des Kurses liegt auf praxisnahen Übungen: Mithilfe der Programmiersprache Python werden die Teilnehmer Schritt für Schritt an die Umsetzung von ML-Projekten herangeführt. Alle Programmierübungen sind so gestaltet, dass sie auch ohne Vorkenntnisse lösbar sind, und die Studierenden erhalten die notwendige Unterstützung, um die Inhalte erfolgreich umzusetzen. Ziel ist es, ein solides Verständnis für ML-Tools zu entwickeln und deren Nutzen für Managemententscheidungen zu erkennen.
Darüber hinaus wird der Kurs die aufkommende Bedeutung von generativen KI-Modellen wie GPT beleuchten. Studierende lernen, wie diese Modelle durch gezieltes Prompting eingesetzt werden können, um spezifische Managementfragen zu adressieren und Entscheidungsprozesse zu unterstützen. eigentlich 
Entscheidungsunterstützung,
wo das System uns sagt Nein,
das ist eine Möglichkeit,
wie man diesen Code weiterführt.
Auf der anderen Seite haben
wir unsere ganzen großen 
Sprachmodelle,
mit denen wir tagtäglich 
zusammenarbeiten,
wo unser Job ist, eigentlich 
nicht,
etwas an die Maschine komplett 
zu delegieren.
Ja, Sie sollten nicht eine 
Eingabe machen.
Schreib mir meine 
Bachelorarbeit, die Maschine 
macht das.
Sie nehmen die Bachelorarbeit 
und geben die ab,
sondern Sie sollten
das als 
Entscheidungsunterstützung 
ansehen,
wo Sie als der Mensch Input von 
der Maschine bekommen,
Sie diesen Input nachprüfen 
sollten
und letztlich selber die finale 
Entscheidung treffen.
Das ist vorbei.
Also verstehe ich das richtig,
dass wir im Prinzip im zweiten 
Teil des Events,
dass man eine Entscheidung 
trifft,
Also eine Entscheidung dann,
wenn das fliegende Maschinen 
scheitert.
Ich muss nur so lachen wegen 
Meter,
weil ich gerade ein
Forschungsprojekt bin mit einer 
Psychologiekollegin
und wir reden über 
Metakognition.
Und wir sagen tatsächlich,
dass Metakognition auf dem Meta 
Level fällt.
Die Entscheidung, ob ich die
Entscheidung jemand anders 
machen lasse.
Also auch wieder System eins und 
System zwei,
so ein bisschen Die gemacht hat,
das User Interface war
die reine Technologie dieser 
großen Sprachmodelle.
Die gibt es theoretisch schon 
seit 2017.
Die wurden natürlich immer 
besser.
Wir hatten am Ende die Version 
drei Punkt irgendwas,
was dann integriert wurde.
Aber es wurde integriert.
Dieses fundamentale KI Modell in
eine ausreichend kompatible und
nutzerfreundliche Umgebung,
nämlich Chat GPT, was
noch mal das Grundmodell GPT
plus weitere Systeme sind, die 
hier zusammenspielen.
Das heißt Forgeat GPT.
Gab es diese großen 
Sprachmodelle schon?
Die haben sich wie gesagt immer 
weiter verbessert.
Grundsätzlich haben
wir aber alle erst damit 
angefangen und
haben eine ganze Industrie 
eigentlich damit angefangen,
es kommerziell zu benutzen.
Ab dem Moment, wo dieses
User Interface richtig 
hinbekommen wurde
und die User des Systems 
hochgegangen ist.
Das ist eine der Kern messages
die Bereitschaft des Nutzers,
mit den Systemen zu 
interagieren.
Generell, wo wir
häufig von Adoption reden 
Technologie use.
Wenn wir ganz, ganz breit sind.
Das ist zentral dafür,
wie eine Technologie tatsächlich
letztlich Einfluss haben kann 
auf unser Sozialleben,
auf unsere ökonomischen 
Prozesse,
auf Unternehmen
und letztlich natürlich auf 
Produktivität.",4.054928303,1,The generated answer and the ground truth both correctly identify that Python is the programming language used in the course.,1,"The generated answer is faithful. [cite_start]The context states, 'Mithilfe der Programmiersprache Python werden die Teilnehmer Schritt fÃ¼r Schritt an die Umsetzung von ML-Projekten herangefÃ¼hrt' (With the help of the programming language Python, participants will be introduced step-by-step to the implementation of ML projects)[cite: 726].",1,The context explicitly states that the course will use the programming language Python to introduce students to implementing ML projects.
"According to the text, what are four useful applications of Large Language Models (LLMs) in everyday life?","Four useful applications of LLMs are: synthesizing information (such as summarizing and translating), acting as an argumentative sparring partner to identify weak points in arguments, brainstorming creative ideas, and assisting with code-related tasks like documentation and translation between programming languages.","Der Text nennt folgende vier nützliche Anwendungen von Large Language Models (LLMs) im Alltag:

1.  **Entscheidungsunterstützung** durch Code-Empfehlungen (das System sagt ""Nein, das ist eine Möglichkeit, wie man diesen Code weiterführt"").
2.  **Zusammenarbeit** mit Maschinen bei der Code-Erstellung (die Maschine antizipiert, was der Benutzer schreiben möchte).
3.  **Optimierung von Marketingkampagnen** (erwähnt im ersten Abschnitt).
4.  **Analyse von Kundendaten** (erwähnt im ersten Abschnitt).

Es werden keine weiteren spezifischen Anwendungen genannt.","Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. gemacht hat,
das User Interface war
die reine Technologie dieser 
großen Sprachmodelle.
Die gibt es theoretisch schon 
seit 2017.
Die wurden natürlich immer 
besser.
Wir hatten am Ende die Version 
drei Punkt irgendwas,
was dann integriert wurde.
Aber es wurde integriert.
Dieses fundamentale KI Modell in
eine ausreichend kompatible und
nutzerfreundliche Umgebung,
nämlich Chat GPT, was
noch mal das Grundmodell GPT
plus weitere Systeme sind, die 
hier zusammenspielen.
Das heißt Forgeat GPT.
Gab es diese großen 
Sprachmodelle schon?
Die haben sich wie gesagt immer 
weiter verbessert.
Grundsätzlich haben
wir aber alle erst damit 
angefangen und
haben eine ganze Industrie 
eigentlich damit angefangen,
es kommerziell zu benutzen.
Ab dem Moment, wo dieses
User Interface richtig 
hinbekommen wurde
und die User des Systems 
hochgegangen ist.
Das ist eine der Kern messages
die Bereitschaft des Nutzers,
mit den Systemen zu 
interagieren.
Generell, wo wir
häufig von Adoption reden 
Technologie use.
Wenn wir ganz, ganz breit sind.
Das ist zentral dafür,
wie eine Technologie tatsächlich
letztlich Einfluss haben kann 
auf unser Sozialleben,
auf unsere ökonomischen 
Prozesse,
auf Unternehmen
und letztlich natürlich auf 
Produktivität. Die System eins Muster.
Eine sehr schöne Interpretation
dieser grundlegenden Idee,
dass wir unterschiedliche
Lösungsstrategien gesucht und 
gefunden haben.
Durch unser Lernen, durch unsere 
Erfahrungen,
die wir im Leben individuell 
gemacht haben.
Beispiele von Mensch Maschine 
Interaktion im Alltag.
Das hier ist insbesondere
für Softwareentwicklung 
natürlich hochgradig 
interessant.
Ich fange an, Code zu schreiben.
Wenn Sie mit Charlotte,
die in der Übung die
Notebook Files schreiben und das 
mit
einem Pro Account auf Google 
Collab machen.
Dann fangen sie an, was zu 
schreiben und plötzlich
stehen die nächsten 20 Zeilen 
Code schon da,
weil die Maschine antizipiert,
was sie eigentlich schreiben 
wollen und
Sie klicken nur noch Enter und
der ganze Code ist plötzlich 
schon da.
Diese Suggestions Johns 
eigentlich.
Wenn wir uns hier wieder
auf diese zwei verschiedenen 
sehr
dichotomen Möglichkeiten der
Zusammenarbeit konzentrieren,
haben wir über diese
Code Recommendations
eigentlich 
Entscheidungsunterstützung,
wo das System uns sagt Nein,
das ist eine Möglichkeit,
wie man diesen Code weiterführt.
Auf der anderen Seite haben
wir unsere ganzen großen 
Sprachmodelle,
mit denen wir tagtäglich 
zusammenarbeiten,",13.27843547,0,"The generated answer provides a list of four applications that is completely different from the four applications listed in the ground truth, making it factually incorrect.",0.5,"The generation is partially faithful. [cite_start]The context supports the idea of LLMs providing 'EntscheidungsunterstÃ¼tzung' (decision support), which can be related to code suggestions and optimizing marketing campaigns[cite: 767, 749]. However, it does not explicitly list 'synthesizing information,' 'acting as an argumentative sparring partner,' or 'brainstorming' as applications.",0,"The context discusses using LLMs for decision support in coding ('Code Recommendations') and mentions their use in optimizing marketing campaigns and analyzing customer data. However, it does not mention synthesizing information, acting as a sparring partner, or brainstorming, as specified in the ground truth answer."
For what types of tasks are basic chat models the most suitable choice?,Basic chat models are most suitable for low-stake tasks where a fast response is required.,"Basierend auf dem Text sind grundlegende Chat-Modelle am besten für folgende Aufgaben geeignet:

*   **Entscheidungsunterstützung:** Das System kann Vorschläge machen, aber der Nutzer muss letztendlich entscheiden, ob die Information genutzt werden soll.
*   **Erkundung von Präferenzen:** Nutzer können dem System Präferenzen mitteilen, um Vorschläge für Urlaubsziele oder ähnliches zu erhalten.
*   **Code-Vorschläge:** Das System kann Code-Vorschläge machen, was als Entscheidungsunterstützung im Programmieren betrachtet werden kann.","die Entscheidungsgewalt haben,
der Mensch in diesem Loop
würde nie auf die Maschine 
hören.
Alle möglichen Effizienzgewinne, 
die wir hätten,
werden gar nicht realisiert.
Es kommt immer auf die Nutzung 
anderer
will ich sie heute 
sensibilisieren.
Und da gibt es eine 
Riesenliteratur zu
ganz viel aktive Forschung,
wie wir eigentlich erreichen 
können,
dass Menschen vernünftig mit
diesen Maschinen interagieren.
Richtig hinterfragen,
welche Informationen sie wie 
gewichten sollen.
Und wenn Sie jetzt mal an Chat 
GPT
denken und andere große 
Sprachmodelle,
wo Sie der Nutzer sind Sie 
machen Eingaben,
Sie kriegen Vorschläge an 
Ausgaben.
Wir sind noch nicht bei KI 
Agenten,
wo ich sage ich möchte einen 
Urlaub gebucht haben.
Klick macht das alles, sondern 
diese Systeme.
Sie können hingehen und fragen 
wo
kann ich guten Urlaub machen?
Dieses und jenes sind meine 
Präferenzen.
Eine solche und solche Art von 
Urlaub möchte ich machen.
Und dann kriegen Sie einen 
Vorschlag von diesem System.
Ihre Rolle dabei ist dann 
letztlich zu entscheiden
Ist diese Information gut oder 
schlecht?
Ist es eine Information,
die Sie nutzen sollten in
Ihrer Entscheidungsfindung oder 
nicht?
Und da sehen wir mehr und mehr,
dass ich eben diese Die System eins Muster.
Eine sehr schöne Interpretation
dieser grundlegenden Idee,
dass wir unterschiedliche
Lösungsstrategien gesucht und 
gefunden haben.
Durch unser Lernen, durch unsere 
Erfahrungen,
die wir im Leben individuell 
gemacht haben.
Beispiele von Mensch Maschine 
Interaktion im Alltag.
Das hier ist insbesondere
für Softwareentwicklung 
natürlich hochgradig 
interessant.
Ich fange an, Code zu schreiben.
Wenn Sie mit Charlotte,
die in der Übung die
Notebook Files schreiben und das 
mit
einem Pro Account auf Google 
Collab machen.
Dann fangen sie an, was zu 
schreiben und plötzlich
stehen die nächsten 20 Zeilen 
Code schon da,
weil die Maschine antizipiert,
was sie eigentlich schreiben 
wollen und
Sie klicken nur noch Enter und
der ganze Code ist plötzlich 
schon da.
Diese Suggestions Johns 
eigentlich.
Wenn wir uns hier wieder
auf diese zwei verschiedenen 
sehr
dichotomen Möglichkeiten der
Zusammenarbeit konzentrieren,
haben wir über diese
Code Recommendations
eigentlich 
Entscheidungsunterstützung,
wo das System uns sagt Nein,
das ist eine Möglichkeit,
wie man diesen Code weiterführt.
Auf der anderen Seite haben
wir unsere ganzen großen 
Sprachmodelle,
mit denen wir tagtäglich 
zusammenarbeiten, 10. Juli 2025
Erste Version des ChatBots
34
Limitationen und Hinweise:•Die Chatverläufe werden anonymisiert gespeichert.•Die Qualität der Antworten ist aktuell inkonsistent.•Experimentieren Sie mit verschiedenen Prompts (z. B. „Wie funktioniert die Berechnung der Rendite?“ vs. „Was ist Rendite?“).•Gelegentlich kommt es vor, dass die Formatierung von Formeln nicht korrekt nach HTML konvertiert wird.•Die Geschwindigkeit des Systems ist noch nicht optimiert.•Die Ansicht für Mobilgeräte ist noch nicht optimiert.
WICHTIG: Der Bot ist ein experimenteller Prototyp. Überprüfen Sie die Antworten auf Richtigkeit.",11.72504282,1,The generated answer's claim that basic chat models are suitable for low-stake tasks where a fast response is required is semantically consistent with the ground truth.,1,"The generated answer is faithful. [cite_start]The context discusses using LLMs for tasks like getting suggestions for vacation destinations based on preferences, which falls under 'low-stake tasks'[cite: 775, 776, 777]. [cite_start]The experimental nature of the chatbot described also implies it is not for high-stakes, critical tasks[cite: 787].",0.5,"The context suggests that current large language models are suitable for tasks that require user input and decision-making, such as getting suggestions for a vacation based on preferences  or receiving code recommendations. This aligns with the idea of 'low-stake tasks' but doesn't explicitly mention the need for a 'fast response'."
"According to the document, what is the population of Munich?",1578567,Laut dem Dokument hat München 1.578.567 Einwohner.,"gibt aber 10 % der Kunden der 
Population für diese Bank,
wo die diese 
Kreditwürdigkeitsmaschine 
genutzt wird.
10 % von Personen,
die erst in den letzten Jahren
nach Deutschland emigriert sind.
Für diese Personen liegen häufig
keine großen Datenmengen vor.
Für diese Personen kann ein 
Mislabeling in den
Daten stattgefunden haben und
für diese Personen haben wir 
eine Vorhersagegenauigkeit.
Accuracy von 50 % bei
zwei möglichen OutComes 
Kreditwürdig oder nicht?
Das ist nicht besser,
als wenn ich mich hinstelle und 
eine Münze
werfe und trotzdem im Aggregat,
weil der Anteil dieser Personen 
in
der Population relativ kleiner 
ist als der,
würde in der Messung auf dem
ganz hohen Level eigentlich 
rauskommen.
Tolle Maschine, super 90 % plus 
Vorhersagegenauigkeit.
Das heißt, worüber Sie immer 
nachdenken
müssen ist gibt es
bestimmte protected Features per
Gesetz oder auch was Sie für 
ethisch richtig halten,
wo Sie sich dann anschauen,
Haben wir hier eigentlich
Vorhersagegenauigkeit in
technische Performance der 
Maschine,
die für diese beiden Subgruppen 
vergleichbar sind.
Und grundsätzlich ist dieses 
Fehlverhalten von Maschinen,
wenn systematisch basierend auf
bestimmten soziodemographischen 
Faktoren,
die wir rechtlich oder 15. Mai 2025
Accurate predictions are often not enough
13
Laws against discrimination in many domains includingCredit (Equal Credit Opportunity Act),Education (Civil Rights Act of 1964; Education Amendments of 1972), Employment (Civil Rights Act of 1964), Housing (Fair Housing Act), Public Accommodation (Civil Rights Act of 1964)
§Born and raised in Germany§90% of population§data describes them accurately §accurate predictions (95% accurate)
§Migrated to Germany in past years§10% of population§data describes them poorly§poor predictions (50% accurate)
90.5% accurate prediction about creditworthiness
Consider an example where machine learning model predicts individual creditworthiness
ML model 23. Juli 2025
Human v. LLM ”Thinking”
7
Is the following statement true? “Munich’s population is 2.12 times that of Frankfurt.”A potential Human (cognitive) process:• Think about knowing these numbers; most likely not• Use Wikipedia tool: get both of these populations•Munich: 1,578,567•Frankfurt: 773,068• Try to divide the numbers in your head; rough idea bit not exact number• Use calculator tool: 1,578,567/ 773,068 = 2.042• Reflection about correctness of result; number sounds reasonable• Forming an answer• Start writing an answer: “Yes, the statement is correct.”• Checking the entire solution process, the answer sentence and maybe rewrite it to “The statement is true.”
This is not how LLMs “think”!",4.351242781,1,"The generated answer and the ground truth both correctly state the population of Munich as 1,578,567.",1,"The generated answer is faithful. [cite_start]The context includes a slide that explicitly gives Munich's population as '1,578,567'[cite: 794].",1,"The context directly provides the population of Munich as 1,578,567 in a list item detailing a potential human cognitive process for answering the question."
How many parameters did GPT-2 have?,1.5B parameters.,"GPT-2 hatte 1,5 Milliarden Parameter.","17. Juli 2025
Evolution of OpenAI’s GPT modelsGPT:117M parameters (Radford et al., 2018)•Transformer decoder with 12 layers•Trained on BooksCorpus: over 7000 unique books (4.6GB text)GPT-2:1.5B parameters (Radford et al., 2019)•Same architecture as GPT but more flexible•Also: trained on much more data: 40 GB of internet text dataGPT-3:175B parameters (Brown et al., 2020)•Over 600GB of text dataGPT-4:1.76T parameters (undisclosed)•Mixture of Expert: different expert models with >200B parameter each•10 trillion words ~ 40 Billion pages (exact size unknown)
35 um bestimmte Datensätze zu 
erzeugen.
Deswegen bin ich auch sehr.
Diese dieser Model Breakdown,
von dem ich gesprochen habe,
der tritt vor allem dann auf, 
wenn ich
einfach nur den Output nehme,
da das nicht checke und nicht 
auf eine bestimmte Art
und Weise nochmal bearbeite,
vorbereite und das dann
einfach RAW in mein Modell rein 
tue.
Denn wenn die Modelle schlechter 
die großen unternehmen.
Was man machen kann ist 
Modeldestillation beispielsweise
GPT benutze ich lasse GPT ein 
von mir geprägtes und
designtes Datensatz bauen und 
dann
trainiere ich ein kleineres 
Modell auf dem Wissen.
Dann kann ich einen Teil des 
Wissens aus dem großen
Modell in das kleine Modell 
einführen.
Das heißt, wenn OpenAI unsere 
Daten
sammelt und sein Modell 
verbessert,
kann DeepSec letztlich Teile 
dieses
Wissens extrahieren und in
seine kleinere Modelle 
reinpacken.
Fragen? Ja. Man, dass mehrere
Personen gleichzeitig falsche 
Informationen.
Ja. Total. Es gibt.
Es gibt die ersten Anzeichen 
dafür, dass on scale.
LM Highjacking betrieben wird.
Das heißt, die ganzen Webscraper 
gehen auf.
Ist alles automatisiert.
Also da ist kein Mitarbeiter von 
OpenAI,
der auf eine Website geht,
das kopiert und den Datensatz 
packt,
sondern da sind Maschinen, also die wie eintauchen.
Da gibt es einen massiven 
Anstieg in den
Bachelorarbeiten oder 
Masterarbeiten auf Englisch,
dass dieses Wort genutzt wird 
mit dem Einführen von GPT.
Jetzt sehen wir wieder, dass ein 
bisschen zurückgeht,
weil Leute angefangen haben zu 
verstehen,
dass Delf ein sehr starkes 
Signal dafür ist,
dass etwas von GPT geschrieben 
worden ist.
Wenn ich also eine Maschine 
gebaut habe,
die Predigt, dann haben sie GPT 
benutzt oder nicht?
Und diese Maschine möglichst auf 
Delph geachtet hat
und das super richtig war,
ja, dann
funktioniert die Maschine heute 
nicht mehr so gut,
weil sie ihr Verhalten verändert 
haben.
Und diese Probleme nennen
wir grundsätzlich Drift Probleme
und davon haben wir zwei Typen.
Der eine Typ ist, dass sich die 
Verteilung in
den Daten ändert und der andere 
ist,
dass ich fundamental in dem 
Verhalten etwas ändert.
Hier an dem Beispiel von 
Marketing,
von Sales auf der einen Seite 
den sogenannten Data Drift.
Wir haben eine einen Shift
in der Verteilung der Typen der 
Observation,
die wir haben in der 
Vergangenheit.
Wenn Sie hier auf der Achse,
die den zeitlichen Verlauf sehen 
auf der Y Achse,
haben wir die Anzahl oder die 
Menge des Sales,
und sie haben rote und blaue 
Typen.",4.056233168,1,The generated answer and the ground truth both correctly state that GPT-2 had 1.5 billion parameters.,1,The generated answer is faithful. [cite_start]The context contains a slide that lists 'GPT-2: 1.5B parameters'[cite: 798].,1,"The context, within a slide titled 'Evolution of OpenAIâ€™s GPT models,' explicitly states: 'GPT-2: 1.5B parameters'."
What is the intuition behind how an 'attention head' works in a language model?,"An attention head represents a word as a weighted combination of itself and all the words that came before it. The weights in this combination are based on the similarity between the words, which helps the model understand the context of the sentence.","Basierend auf dem bereitgestellten Kontext kann ich die genaue Intuition hinter der Funktionsweise einer „Attention Head“ in einem Sprachmodell nicht erklären. Allerdings kann ich aus dem Text einige Schlüsselpunkte extrahieren, die die zugrunde liegende Idee illustrieren:

*   **Gewichtung von Informationen:** Die „Attention Head“ ist darauf ausgelegt, verschiedene Teile der Eingabe (z.B. Wörter in einem Satz) unterschiedlich zu gewichten. Es geht darum, zu bestimmen, welche Teile der Eingabe am wichtigsten sind, um eine bestimmte Ausgabe zu generieren.
*   **Subjektive vs. Objektive Aufgaben:** Das Modell unterscheidet zwischen Aufgaben, bei denen menschliche Intuition wichtig ist (z.B. Filmempfehlungen, Witze erzählen) und solchen, bei denen objektive Berechnungen oder Analysen erforderlich sind.
*   **Die Rolle des Nutzers:** Die „Attention Head“ hilft dem Nutzer, zu entscheiden, ob eine Information, die vom System generiert wird, nützlich oder schädlich ist.

Der Text deutet an, dass die „Attention Head“ ein zentraler Bestandteil ist, um die Interaktion zwischen Mensch und Maschine zu ermöglichen.

Um die genaue Funktionsweise einer „Attention Head“ zu verstehen, benötige ich weitere Informationen.","Aber den umgekehrten Effekt.
Wir haben die Behavioral,
diese kognitive Komponente 
davon,
die sich eigentlich in unserem 
Kopf geschaffen wird,
wo wir diese Intention to use 
entwickeln,
die wiederum von diesen drei 
Faktoren in diesem Modell
hier ganz grob auf einem sehr 
hohen Level.
Den Zusammenhang erklärt wird.
Und diese Beziehungen hängen
wiederum von den Moderatoren ab.
Ja, ja, erklären, warum das was 
Negatives ist.
Muss ich sie an das Papier 
verweisen, dass keine Ahnung,
wann ich das letzte Mal gelesen 
habe,
steht da bestimmt drin. Kann ich 
ihnen hochladen?
Bzw. Das ist glaube ich sogar 
Open Source.
Das hat mittlerweile glaube ich 
70.000
Situationen oder so,
also das ist wirklich eines der 
fundamentalen Modelle,
wo wir immer noch versuchen zu 
verstehen,
was beeinflusst eigentlich die 
Nutzung von wie gesagt,
Technologie breiter gefasst, 
aber für uns ist relevante.
Mit dem Schwerpunkt unseres 
Kurses sprechen wir natürlich
über die sogenannte Mensch 
Maschine Kollaboration,
was letztlich ist die Nutzung 
und
Akzeptanz von der KI 
Technologie.
Wir versuchen uns in der 
Wirtschaftsinformatik
gerade so ein bisschen wieder 
auf das Neue,
auf die neue Kuh, die durchs
Dorf getrieben wird, zu 
konzentrieren. die Entscheidungsgewalt haben,
der Mensch in diesem Loop
würde nie auf die Maschine 
hören.
Alle möglichen Effizienzgewinne, 
die wir hätten,
werden gar nicht realisiert.
Es kommt immer auf die Nutzung 
anderer
will ich sie heute 
sensibilisieren.
Und da gibt es eine 
Riesenliteratur zu
ganz viel aktive Forschung,
wie wir eigentlich erreichen 
können,
dass Menschen vernünftig mit
diesen Maschinen interagieren.
Richtig hinterfragen,
welche Informationen sie wie 
gewichten sollen.
Und wenn Sie jetzt mal an Chat 
GPT
denken und andere große 
Sprachmodelle,
wo Sie der Nutzer sind Sie 
machen Eingaben,
Sie kriegen Vorschläge an 
Ausgaben.
Wir sind noch nicht bei KI 
Agenten,
wo ich sage ich möchte einen 
Urlaub gebucht haben.
Klick macht das alles, sondern 
diese Systeme.
Sie können hingehen und fragen 
wo
kann ich guten Urlaub machen?
Dieses und jenes sind meine 
Präferenzen.
Eine solche und solche Art von 
Urlaub möchte ich machen.
Und dann kriegen Sie einen 
Vorschlag von diesem System.
Ihre Rolle dabei ist dann 
letztlich zu entscheiden
Ist diese Information gut oder 
schlecht?
Ist es eine Information,
die Sie nutzen sollten in
Ihrer Entscheidungsfindung oder 
nicht?
Und da sehen wir mehr und mehr,
dass ich eben diese zumindest durch eine bestimmte
Methode mir ein bisschen 
erklären kann.
Woher eigentlich diese 
Vorhersage stammt.
Sie sehen auch hier diese Task 
factors.
Die Natur des Tasks ist das,
worüber ich gerade gesprochen 
habe.
Spielt hochgradig eine Rolle,
wo wir tendenziell sehen,
dass Task, die wir als sehr 
subjektiv wahrnehmen,
wie Film Recommendations,
Wenn Menschen sich gegenseitig 
Witze erzählen sollen,
Einschätzungen davon,
ob ein bestimmter Urlaubsort 
interessant ist oder nicht,
diese ganzen sehr
subjektiv wahrgenommenen 
Aufgaben präferieren
wir eher von Menschen,
Hilfe anzunehmen,
dass von Menschen lösen zu 
lassen als von Maschinen.
Wohingegen für komplexe
objektive Tasks wie Berechnungen 
von Aktienkursen,
Einschätzungen von 
CompanyDefaults etc.
Da tendieren Menschen von dem,
was die Forschung aktuell zeigt 
und es
ist wie gesagt ein sehr aktives 
Feld dazu,
eher Hilfe von Maschinen 
anzunehmen.
Gibt es irgendwelche Fragen 
soweit?
So, jetzt kommen wir zu den zwei 
Modes of Collaboration.
Auch wieder sehr dichotom 
gedacht als über
Kategorien haben wir zwei und es 
gibt eine Strömung,
die mittlerweile so ein bisschen 
sagt Naja,
eigentlich haben wir drei 
Kategorien.
Hier streiten wir uns aber nicht 
drüber,",21.69612288,0,"The generated answer fails to explain the technical intuition behind an 'attention head' and instead gives a high-level, user-centric interpretation. The ground truth provides the correct, technical explanation of how a word is represented as a weighted combination of itself and preceding words.",0,"The generated answer is unfaithful. The context does not contain the phrase 'attention head' or provide an intuition for how it works. The text discusses human-machine collaboration and the weighting of information from a psychological or decision-making perspective, not a technical one.",0,The context discusses different types of human-machine collaboration and the weighting of information from AI systems. It does not contain any information about 'attention heads' in language models.
What is Word2Vec and what is its function?,Word2Vec is a simple neural network that is used to generate word embeddings from a text corpus.,"Basierend auf den bereitgestellten Kontexten ist Word2Vec ein neuronales Netzwerk, das zur Erzeugung von Wort-Embeddings verwendet wird. Hier ist eine Zusammenfassung seiner Funktion:

*   **Idee:** Word2Vec basiert auf der Idee, dass Wörter, die in ähnlichen Kontexten verwendet werden, ähnliche numerische Darstellungen (Embeddings) haben sollten. Es versucht, Wörter anhand ihres umgebenden Kontexts vorherzusagen.
*   **Gelerntes Gewichte als Embeddings:** Die Gewichte, die das neuronale Netzwerk während des Trainings lernt, werden als Wort-Embeddings verwendet.
*   **Fixe Wörter-Vektor-Dictionary:** Es erzeugt ein festes Wörterbuch von Vektoren, das für die weitere Verwendung verfügbar ist.
*   **Verschiedene Trainingsmethoden:** Word2Vec kann mit zwei verschiedenen Trainingsmethoden trainiert werden:
    *   **Continuous Bag of Words (CBOW):** Vorhersage des aktuellen Wortes anhand seiner umgebenden Wörter.
    *   **Skip-gram:** Vorhersage der umgebenden Wörter anhand des aktuellen Wortes (die Umkehrung von CBOW).

Es ist wichtig zu beachten, dass Word2Vec in der Praxis oft mit sehr großen Embeddings (über 100 Dimensionen) und auf großen Datensätzen wie der gesamten Wikipedia trainiert wird. Es verwendet Techniken wie Negative Sampling, um das Training zu beschleunigen.","17. Juli 2025
Learning word embeddings with Word2VecWord2Vec: simple neural networkto generate word embeddings given a text corpus•Idea: predict words from their surrounding context•Learned weights are embeddings•Through optimization: words in similar context have similar embeddings•Gives us a fixed dictionary of vectors for words we can utilizeIntuitive example: assume we have a text corpus with two sentences
15
Training dataPizza is awesomePizza is greatPizzaisgreatawesome
PizzaisgreatawesomeInput layerEmbeddings layer Output layer 17. Juli 2025
Word2VecIn practice:•Word2Vec has much larger embeddings layer (>100 dimensions)•Trained on large data set, e.g.entire, Wikipedia•Alternative prediction goal is skipgram•Predict surrounding words from word itself (the other way round for CBOW)Training embeddings requires high computational power•Typically, more than 100 dimensionalembedding•Size of dictionary is in the million•w2v speeds up training by negative sampling
18 17. Juli 2025
Word2Vec example (continuous bag of words version)
16
Training dataPizzaisawesomePizza is greatPizzaisgreatawesome
PizzaisgreatawesomeInput layerEmbeddings layerOutput layer
1001
Words àOne-hot Vector One-hot VectoràWords0100
Training dataPizza is awesomePizzaisgreatPizzaisgreatawesome
PizzaisgreatawesomeInput layerEmbeddings layerOutput layer
1010
Words àOne-hot Vector One-hot VectoràWords0100",22.18882322,1,The generated answer provides a definition and function of Word2Vec that is semantically identical to the information in the ground truth.,1,The generated answer is faithful. [cite_start]The context describes Word2Vec as a 'simple neural network to generate word embeddings given a text corpus' [cite: 853] [cite_start]and explains that its idea is to 'predict words from their surrounding context'[cite: 853].,1,"The context provides a detailed description of Word2Vec. It identifies it as a 'simple neural network to generate word embeddings given a text corpus' and explains its function is to predict words from their surrounding context, with the learned weights becoming the embeddings."
What is one potential problem with representing words as indexed tokens?,Lacking interpretability of distance.,"Basierend auf dem Kontext, das Problem ist, dass die Einführung zusätzlicher Parameter (wie z.B. in neuronalen Netzen oder Random Forests) durch die Verwendung von indizierten Token zu einem ""Compounding Effekt"" führen kann. Das bedeutet, dass die zusätzlichen Parameter Fehler einführen, die sich im Laufe des Trainings verstärken und sich zu größeren Fehlern entwickeln, anstatt die Vorhersagen zu verbessern. 

Es wird erwähnt, dass dies besonders relevant ist bei großen Sprachmodellen mit Milliarden von Parametern, wo die marginalen Beiträge von zusätzlichen Token oder Parametern, obwohl klein, sich im Gesamten verstärken können.
","die nicht zugedeckt sind aus dem 
Satz
und ich habe mir das als Label 
auserkoren.
Und ich versuche selber 
vorherzusagen,
basierend alle anderen Wörter,
was eigentlich das zugedeckte 
Wort ist.
Das nennt man self supervised 
learning.
Wann immer ich kein eigenes 
direktes Label habe,
bin ich eigentlich in
einem Bereich von sogenannten 
Supervised Learning
und supervised geht so
ein bisschen zwischen 
Supervising and sbeweis,
Supervisory Labels haben und 
dann zu beweisen,
dass sie keine haben und nur 
Strukturen erkennen möchten.
Und self supervised ist dann 
sozusagen die Mitte,
wo das System selber sagt
Ich suche mir das als Label aus 
und nehme alles andere,
um das Ausgesuchte 
vorherzusagen.
Geht in die Richtung.
Per se ist es natürlich 
problematisch,
weil wir, wenn die Maschinen 
Fehler machen,
in dem Labeling verfahren
und in diesem selbst zu 
beweisen,
die Fehler relativ gering,
weil es eben was technisches 
ist.
Wenn ich aber selber eine 
Vorhersage mache,
wie ich etwas labeln möchte und 
da Fehler drin sind,
dann lernt die Maschine,
die trainiert wird, letztlich 
neue
Fehler und dann akkumulieren
sich diese Fehler und wir reden
von einem Compounding Effekt.
Das heißt so mehr noisy
einfügen und da kann man drüber betriebswirtschaftlich
ökonomische Entscheidungen zu 
treffen.
Wer sieht das nicht?
Noch mal, was ich letztes Mal 
gesagt habe Wenn Sie
was nicht verstehen, ist es 
nicht Ihre Schuld.
Dann habe ich es einfach 
schlecht erklärt.
Deswegen immer raus damit.
Dann gehe ich davon aus, dass 
jeder verstanden hat.
Aber eine andere Frage haben
wir ja theoretisch auch
noch andere 
Entscheidungsmöglichkeiten,
Parametern, die dieselbe 
Qualität liefern.
Vollkommen richtig. Da wäre 
jetzt die Frage,
ob es eine 
Entscheidungsmöglichkeit,
die zwei Parameter verwendet,
besser als eine auf einem 
Papier.
Das ist sehr, sehr gute Frage.
Da gibt es verschiedene Theorien 
zu.
Grundsätzlich, wie wir sehen 
werden,
für den technischen Teil der 
Vorlesung.
Wir können für das gleiche
Problem verschiedene Regeln 
identifizieren.
Verschiedene Machine Learning 
Modelle trainieren.
Diese Machine Learning Modelle 
können bessere oder
schlechtere Performance 
aufweisen.
Wenn sie aber genau die gleiche 
Performance aufweisen,
dann haben wir natürlich in 
einer gewissen Art und
Weise die Wahl, immer darauf 
achtend,
dass die einzige Performance, 
die wir sehen,
aktuell immer Performance auf 
historischen Daten ist.
Das heißt, wir müssen auf der eine Prediction zu machen, sind 
massiv gering.
Ja, das ist fast ignorierbar.
Außer wenn wir natürlich 
wirklich
über große Sprachmodelle reden,
wo Milliarden von Menschen jeden
Tag riesige Texte da 
reinknallen.
Aber die marginale Beitrag,
dass sie eine Vorhersage machen 
oder
auch die marginale Beitrag von 
einer weiteren Callum,
einem weiteren Wort in
dem Datensatz, ist vollkommen 
ignorierbar.
Das ist wieder die Masse, die es 
letztlich macht.
Ja, und in dem Fall von Demogons 
Razor
sprechen wir nicht davon,
einen Parameter mehr,
sondern tausende von Parametern 
mehr.
Deswegen ist es für unsere
PC's und auch für die 
Entscheidung,
welche Modelle Unternehmen 
einsetzen,
ob sie bei tabularen Daten immer 
an der Stelle gesagt,
ob ich jetzt einen Random Forest 
einsetze
mit 10.000 Bäumen oder ich
nehme einen ein neuronales 
Netzwerk mit 20 Layern.
Der Verbrauch der Energie ist 
für zumindest Predictions
über Kreditwürdigkeit 
ignorierbar unterschiedlich.
Ich kann Sie an entsprechende 
Quellen verlinken.
Dann frage ich mich, wenn ich 
das.
Wenn ich dieses Argument 
beziehe,
auf das Training des Modells,
dann kann ich ja noch nicht 
werten.
Bevor ich es trainiere, kann ich 
nicht vorhersehen,
ob die zusätzlichen Parameter 
wie ein",13.33584237,0,"The generated answer identifies a 'compounding effect' of errors, which is a different concept from the 'lacking interpretability of distance' mentioned in the ground truth. The answer is semantically inconsistent.",0,"The generated answer is unfaithful. [cite_start]The context discusses the 'Compounding Effekt' of errors when a machine learns from its own faulty, self-generated labels[cite: 863], but it does not mention 'lacking interpretability of distance' as a problem with representing words as indexed tokens.",0,"The context discusses 'self-supervised learning' and the potential for a 'compounding effect' of errors when a machine labels data for itself. However, it does not mention representing words as indexed tokens or the problem of lacking distance interpretability."
"According to the gradient descent, what two steps are taken to decrease a model's error during training?","To decrease the error, the model's weights (w) are changed in the direction of the negative slope, and the size of this change is scaled by the learning rate (η).","Gemäß Gradientenabstieg werden die folgenden zwei Schritte unternommen, um den Fehler eines Modells während des Trainings zu verringern:

1.  Compute gradients: ,ℒ,-, ,ℒ,. (durch Back-Propagation-Algorithmus)
2.  Update weights and biases: 𝑤=𝑤−𝜂⋅,ℒ,-, 𝑏=𝑏−𝜂⋅,ℒ,.

Basierend auf den bereitgestellten Kontexten.","3. Juli 2025
Adaptive Boosting (AdaBoost)
12
Training Procedure:
1. All observations in the dataset are initially given equal weights
2. Fit weak to the data and calculate errors for each observation in training set
3. Train next model on (re)weighted training set where previously wrongly predicted observations 
have a higher weight
4. Repeat procedure until convergence is achieved of restrictions are met
Prediction of new instances based on weighted majority vote of ensemble (weights 
according to individual model accuracy) 
Source 10. Juli 2025
Gradient descent: the optimization algorithm
27
We solve the following problem during training
Complexity of problem requires a step-wise solving using gradient descent:1.Initialize 𝑤,𝑏randomly2.Loop until convergence of loss1.Compute gradients: ,ℒ,-, ,ℒ,.(through back-propagation algorithm)2.Update weights and biases: 𝑤=𝑤−𝜂⋅,ℒ,-, 𝑏=𝑏−𝜂⋅,ℒ,.3.Compute new loss: ℒA𝑦𝑤,𝑏,𝑦3.Return weights
argminY,Z	ℒ/𝑦𝑥|𝑤,𝑏,𝑦 10. Juli 2025
Batches and epochs
28
Did you notice? We always computed the error over all training examples•With many training examples computing the derivatives can take long•Solution: Stochastic gradient descent1.Randomly partition overall sample 𝑋 into X1,X2,…,Xm mini-batches2.Conduct gradient descent for each mini-batch sequentially3.Once all mini-batches used once (epoch) start over•Improves convergence, decreases redundancies
𝜕ℒ𝜕𝑤=∑𝑗=1𝑁𝜕ℒ𝑗𝜕𝑤𝑁≈∑𝑗=1𝑀𝜕ℒ𝑗𝜕𝑤𝑀All dataSubset of data
Works because:",11.32169914,1,"The generated answer correctly describes the two steps of gradient descent (changing weights in the negative slope direction and scaling by the learning rate), which is semantically identical to the ground truth.",1,"The generated answer is faithful. [cite_start]The context provides the formula for updating weights and biases in a diagram: 'ð‘¤ = ð‘¤ âˆ’ ðœ‚ â‹… âˆ‚â„’/âˆ‚ð‘¤' and 'ð‘ = ð‘ âˆ’ ðœ‚ â‹… âˆ‚â„’/âˆ‚ð‘', which corresponds to changing weights in the direction of the negative slope (gradient) scaled by the learning rate (Î·)[cite: 883].",1,"The context directly answers the question by listing the two steps for gradient descent: 1. Compute gradients, and 2. Update weights and biases, where the update rule for weights is explicitly given as ð‘¤=ð‘¤âˆ’ðœ‚â‹…âˆ‚â„’/âˆ‚ð‘¤."
"According to the text, what are hyperparameters and what is their primary function in machine learning?","Hyperparameters are variables that determine the structure of a model and its learning process. Their primary function is to regularize the model, which helps to control for overfitting and underfitting. For example, in a neural network, hyperparameters include the number of layers and neurons.","According to the text:

**Hyperparameters** are the number of trees (parameters) and other choices on the model architecture (e.g., tree depth). They determine the structure of the model and the learning process, and allow us to regularize our model and shape over- and underfitting outcomes. 

Their primary function is to find a “good model complexity”.","3. Juli 2025
Hyperparameters
The number of trees (parameters) and other choices on the model 
architecture (e.g., tree depth) are hyperparameters 
Hyperparameters are variables that 
• determine the structure of the model and the learning process
• allow us to regularize our model and shape over- and underfitting outcomes 
• different models and learning algorithms have different hyperparameters
• For example: neural networks’ hyperparameters include
• # layers
• # neurons per layer
• activation functions
By tuning hyperparameters, we can find a “good model complexity”, but 
of course the question is how we do that given the first rule of testing?
24 12. Juni 2025
Components of supervised MLSupervised machine learning methods fit a model to data based on an evaluation criterion
19
Representation +Evaluation +Optimization
Adjustmodel according to an algorithmic procedure until stop criterionis met.In linear regression: minimize the sum of squares (closed form) or gradient descent (iterative optimization).
OLS: min%⁄""&∑'𝑦−𝑦'
𝐿𝛽
𝛽
𝐿
𝛽∗ Journal of the Association for Information Systems 
 
814 
known to the investor. Again, the underlying model was 
a gradient boosted forest for which we automatically 
optimized the same seven hyperparameters on the current 
training dataset using a threefold cross-validation strategy 
with a directed Bayesian search.11 We used the remaining 
30% of the data from Study A to populate the pool of 
borrowers in our simulation, from which we randomly 
drew and matched 50 borrowers with randomly drawn 
investors from the corresponding investor pool. On 
average, the unbiased ML model’s accuracy for the share 
of observations not included in the training before the first 
updating iteration was 68.4%. 12  As we previously 
measured borrowers’ repayment decisions using  the 
strategy method in Study A, we knew whether they would 
make a repayment if there was an investment. Hence, we 
were able to determine whether the investment game 
between a given investor and borrower would result in (1) 
no investment, (2) investment but no repayment, or (3) 
investment and repayment by matching the unconditional 
investor with the conditional borrower decisions. 
Treatments: We introduce d treatment variations",9.022443533,1,The generated answer's description of hyperparameters and their function in regularizing a model to control for overfitting and underfitting is semantically consistent with the ground truth.,1,The generated answer is faithful. [cite_start]The context defines hyperparameters as variables that 'determine the structure of the model and the learning process' and 'allow us to regularize our model and shape over- and underfitting outcomes'[cite: 889].,1,The context explicitly defines hyperparameters as variables that 'determine the structure of the model and the learning process' and 'allow us to regularize our model and shape over- and underfitting outcomes'.
What are the cores advantages of ensemble methods?,"Improved accuracy, Reduction of overfitting and Handling High Dimensionality.","Die wichtigsten Vorteile von Ensemble-Methoden sind:

*   **Verbesserte Genauigkeit:** Ensemble-Methoden führen zu einer Vorhersagegenauigkeit, die jede einzelne Methode nicht erreichen könnte.
*   **Reduziertes Risiko von Überanpassung:** Durch die Verwendung mehrerer Lernende sind Ensemble-Methoden robuster und weniger anfällig für Überanpassung.
*   **Umgang mit hoher Dimensionalität:** Ensemble-Methoden können effektiv mit großen Datenmengen mit hochdimensionalen Räumen umgehen.","3. Juli 2025
(Dis)advantages of ensembles
Core advantages of ensemble methods include:
1. Improved Accuracy: Ensemble methods result in a prediction accuracy that is better than
any individual model could achieve
2. Reduction of Overfitting: Because they use multiple learners, ensemble methods tend to
be more robust and less prone to overfitting, i.e., typically generalize rather well
3. Handling High Dimensionality: Ensemble methods can effectively handle large amounts
of data with high-dimensional spaces.
Core disadvantages of ensemble methods include:
1. Increased Complexity: Can be computationally expensive and require significant 
resources to train because they involve training multiple models instead of a single one.
2. Interpretability: Ensemble models are difficult to interpret compared to individual models. 
3. Risk of Overfitting with Noise: Although ensemble methods are generally more robust to 
overfitting, they can still overfit if the data is noisy. 
14 3. Juli 2025
Ensemble methods
Ensemble methods rely on different models that are simultaneously applied to the same problem
Predictions are aggregated producing the final prediction
• Hard vote: majority of individual votes
• Soft vote: average individual predicted probabilities and one final vote
• Meta model: train machine learning model to aggregate prediction (stacking)
Models‘ errors should be as uncorrelated as possible so that they cancel out through aggregation
6
Model 1
Model 2
Model 3
Model N-1
Model N
…
Aggregator Overall 
prediction 10. Juli 2025
Last time: ensemble methods
•Different models that are simultaneously applied to the same problem•However: only ”one layer” of models, i.e., no (comprehensive) stacking•Today: layers if modelsfeedingintoeachother•Idea(smallexample):
2
Model 1Model 2Model 3
Model N-1Model N… AggregatorOverall prediction
Model 1, Layer 1Model 2, Layer 1Model 1, Layer 2Model 2, Layer 2Final model(Aggregator)Overall prediction",10.79491973,1,"The generated answer correctly lists the three core advantages of ensemble methods, which are identical to those in the ground truth.",1,"The generated answer is faithful. [cite_start]The context lists 'Improved Accuracy,' 'Reduction of Overfitting,' and 'Handling High Dimensionality' as 'Core advantages of ensemble methods'[cite: 899].",1,"The context lists the core advantages of ensemble methods, including 'Improved Accuracy,' 'Reduction of Overfitting,' and 'Handling High Dimensionality'."
What are some core disadvantages of decision trees?,"Overfitting, instability, and optimization difficulty.",Der Text enthält keine Informationen über die Nachteile von Entscheidungsbäumen. Er konzentriert sich auf die Anwendung von Machine Learning in der Unternehmenswelt und die Unterscheidung zwischen formaler und realer Autorität bei Entscheidungen.,"Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. betriebswirtschaftlich
ökonomische Entscheidungen zu 
treffen.
Wer sieht das nicht?
Noch mal, was ich letztes Mal 
gesagt habe Wenn Sie
was nicht verstehen, ist es 
nicht Ihre Schuld.
Dann habe ich es einfach 
schlecht erklärt.
Deswegen immer raus damit.
Dann gehe ich davon aus, dass 
jeder verstanden hat.
Aber eine andere Frage haben
wir ja theoretisch auch
noch andere 
Entscheidungsmöglichkeiten,
Parametern, die dieselbe 
Qualität liefern.
Vollkommen richtig. Da wäre 
jetzt die Frage,
ob es eine 
Entscheidungsmöglichkeit,
die zwei Parameter verwendet,
besser als eine auf einem 
Papier.
Das ist sehr, sehr gute Frage.
Da gibt es verschiedene Theorien 
zu.
Grundsätzlich, wie wir sehen 
werden,
für den technischen Teil der 
Vorlesung.
Wir können für das gleiche
Problem verschiedene Regeln 
identifizieren.
Verschiedene Machine Learning 
Modelle trainieren.
Diese Machine Learning Modelle 
können bessere oder
schlechtere Performance 
aufweisen.
Wenn sie aber genau die gleiche 
Performance aufweisen,
dann haben wir natürlich in 
einer gewissen Art und
Weise die Wahl, immer darauf 
achtend,
dass die einzige Performance, 
die wir sehen,
aktuell immer Performance auf 
historischen Daten ist.
Das heißt, wir müssen auf der Ende die verarbeitete 
Information,
die Prediction von der KI
und die eigentliche Information 
von dem Task.
Was Sie hier machen, ist dann 
selber,
als Mensch die finale 
Entscheidung zu treffen.
Und in diesem Kontext gibt es 
zwei
Arten von sogenannter Autorität 
von Entscheidungsgewalt.
Für diejenigen, die den
Kurs von Ferdinand von Siemens 
zu Decision,
Making and Markets und 
OrganIzations besucht haben,
haben das vielleicht schon mal 
gehört.
Die Idee von realer und formaler 
Autorität,
Wer hat davon schon gehört?
Die Idee von formaler Autorität 
ist.
Das ist etwas, wo ich laut 
Verträgen
auf jeden Fall final
für die Entscheidung 
verantwortlich bin.
Ich drücke am Ende als Mensch 
den Knopf.
Das ist hier der Fall.
Was aber sein kann,
ist Und jetzt sind wir bei 
realer Autorität.
Stellen Sie sich vor, Sie müssen 
den Knopf drücken.
Aber die Maschine sagt Ihnen ja.
Drückt den Knopf oder nicht?
Und Sie folgen immer der 
Maschine.
Sie überlegen gar nicht mehr 
selber,
sondern mehr oder weniger 
automatisch.
Folgen Sie immer zu 100 %,
was die Maschine sagt.
Dann sind Sie zwar immer noch 
die Person,
die formal die Autorität hat,
auf den Knopf zu drücken,
aber die reale Autorität,
weil sie immer der Maschine 
folgen,",7.21211791,0,"The generated answer incorrectly claims the text contains no information, while the ground truth correctly lists the disadvantages (overfitting, instability, optimization difficulty).",0,"The generated answer is unfaithful. The context does not mention decision trees or their disadvantages. [cite_start]It discusses the concepts of real vs. formal authority in human-machine decision-making[cite: 919, 920, 922].",0,The context discusses the concept of real vs. formal authority in human-in-the-loop decision-making but does not mention decision trees or their disadvantages.
"According to the document, what is the formula for Balanced Accuracy (Bal. Acc.)?",Bal. Acc. = (Sensitivity + Specificity) / 2,"Laut dem Dokument lautet die Formel für Balanced Accuracy (Bal. Acc.) wie folgt:

Bal. Acc. = (Sensitivität + Spezifität) / 2","26. Juni 2025
Technical performance on unseen data (2/2)
Accuracy can be misleading, esp. in case of imbalanced samples, hence, we may also want to consider
Combining these measures results in other important measures:
𝑺𝒆𝒏𝒔𝒊𝒕𝒊𝒗𝒊𝒕𝒚=𝑻𝑷𝑻𝑷+𝑭𝑵𝑷𝒓𝒆𝒄𝒊𝒔𝒊𝒐𝒏=𝑻𝑷𝑻𝑷+𝑭𝑷
𝑩𝒂𝒍.	𝑨𝒄𝒄.=𝑺𝒆𝒏𝒔𝒊𝒕𝒊𝒗𝒊𝒕𝒚+𝑺𝒑𝒆𝒄𝒊𝒇𝒊𝒄𝒊𝒕𝒚𝟐 𝑭𝟏=𝟐∗𝑺𝒆𝒏𝒔𝒊𝒕𝒊𝒗𝒊𝒕𝒚∗𝑷𝒓𝒆𝒄𝒊𝒔𝒊𝒐𝒏𝑺𝒆𝒏𝒔𝒊𝒕𝒊𝒗𝒊𝒕𝒚+𝑷𝒓𝒆𝒄𝒊𝒔𝒊𝒐𝒏
Tree A prediction$𝑦!	 True outcome(𝑦) Tree Bprediction$𝑦""	1 1 11 1 11 0 01 1 01 0 00 1 00 1 00 0 00 0 00 0 0
Confusion matrix
𝑺𝒑𝒆𝒄𝒊𝒇𝒊𝒄𝒊𝒕𝒚=𝑻𝑵𝑻𝑵+𝑭𝑷
What is the Bal. Acc. And F1for the two models?
𝑦=1𝑦=0$𝑦=13 2$𝑦=02 3
𝑦=1𝑦=0$𝑦=12 0$𝑦=03 5
Tree A Tree B 15. Mai 2025
Different types of solutions
10
Balanced Scorecard§Überarbeitung der Inhalte§Wiedereinführung der BSC zum kontinuierlichem Controlling
ISO-Zertifizierung§Interne Audits im HWS und FSS§ISO INTEGRA 1x1§Verpflichtende Besprechung von Prozessen auf Ressort-/ Stabstreffen
Point solutions•Definition:A solution that addresses a single, specific problem or need.•Scope:Narrow and focused.•Integration:Typically standalone; not integrated with other systems.•Use case: Quick wins, easy to implement, often first step in solving a broader challenge. •Example:Fraud detection model (Anomaly detection)Application solutions•Definition:A complete software or tool that solves a broader problem•Scope: Medium; focused on a domain or function•Integration: May integrate with other applications or systems.•Use case: Useful when a domain-specific tool is needed •Example: Customer support app (Classification + UI + reporting) 3. Juli 2025
What then?
Consider technical performance metric that is independent of threshold
• Solution: Receiver Operating Characteristic
• Simulate thresholds from 0 to 1 and calculate TPR and FPR for every threshold value
• Plot every (TPR, FPR) tuple with TPR being on the y-axis and FPR on the x-axis
18",6.262340784,1,"The generated answer provides the correct formula for Balanced Accuracy, which is identical to the ground truth.",1,The generated answer is faithful. The context includes a slide with the formula 'Bal. Acc. [cite_start]= (Sensitivity + Specificity) / 2'[cite: 928].,1,The document explicitly provides the formula for Balanced Accuracy: Bal. Acc. = (Sensitivity + Specificity) / 2.
"According to the text, what is information gain?",Information gain is the improvement in an evaluation measure (such as the reduction in entropy) that is achieved by splitting the data at a parent node (level t) into its child nodes (level t+1).,"Laut dem Dokument bezieht sich „Informationsgewinn“ auf die Identifizierung guter Informationen, die für die Entwicklung eines Machine-Learning-Modells benötigt werden. Es geht darum, herauszufinden, welche Daten tatsächlich relevant sind und wie man diese Daten beschaffen kann, um die Herausforderungen einer Organisation zu lösen.
","Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. Modells durchgedacht werden.
Denn sobald ich es implementiert 
haben
und am Ende feststellen ja,
ich habe eigentlich irgendwas 
gemessen,
was gar nicht so wichtig für die 
Organisation ist,
dann können sie sehr, sehr viel 
Geld
in den Sand gesetzt haben.
Sobald Sie dieses 
Businessverständnis
identifiziert haben, geht es 
daran?
Ja, ich möchte eine Vorhersage 
machen.
Das Allererste, was ich brauche, 
ist erstmal gute Daten.
Wie kann ich dieses Modell 
eigentlich entwickeln?
Was für Informationen brauche 
ich?
Da müssen Sie als der Data 
Scientist, der Data Engineer,
wie auch immer Sie sich 
schimpfen
wollen in ein paar Jahren,
müssen dann zu den Experten 
gehen innerhalb der
Organisation und eigentlich mal 
nachfragen.
Hey Herr Manager, um
bei diesem Beispiel zu bleiben 
Was
sind eigentlich gute 
Informationen,
auf die ihr achtet in so einem 
Bewerbungsprozess?
Um zu identifizieren oder selber 
einzuschätzen?
Wird das ein guter oder ein 
schlechter
Mitarbeiter für diese bestimmte 
Stelle sein.
Sie müssen also identifizieren 
welche
Daten welche Variablen sind 
eigentlich da?
Müssen Sie vielleicht neue 
Informationen erheben?
Sind bestimmte Informationen gar 
nicht zugänglich?
Und das Letzte kann tatsächlich Inform. Processing Systems (NeurIPS), vol. 30 (Curran Associ -
ates, Inc., Red Hook, NY).
Luo X, Bhattacharya CB (2006) Corporate social responsibility, cus -
tomer satisfaction, and market value. J. Marketing 70(4):1–18.
Luo X, Bhattacharya CB (2009) The debate over doing good: Corpo -
rate social performance, strategic marketing levers, and firm- 
idiosyncratic risk. J. Marketing 73(6):198–213.
Luo X, Lu X, Li J (2019) When and how to leverage e-commerce cart 
targeting: The relative and moderated effects of scarcity and 
price incentives with a two-stage field experiment and causal 
forest optimization. Inform. Systems Res. 30(4):1203–1227.
Minnema A, Bijmolt TH, Gensler S, Wiesel T (2016) To keep or not 
to keep: Effects of online customer reviews on product returns. 
J. Retailing 92(3):253–267.
Mirsch T, Lehrer C, Jung R (2017) Digital nudging: Altering user 
behavior in digital environments. Leimeister JM, Brenner W, 
eds. Proc. 39th Internat. Conf. Inform. Systems (ICIS) (Association 
for Information Systems, Atlanta), 634–648.
Momsen K, Stoerk T (2014) From intention to action: Can nudges help 
consumers to choose renewable energy? Energy Policy 74:376–382.
Moorthy S, Srinivasan K (1995) Signaling quality with a money-",7.735013008,0,"The generated answer provides a vague, non-technical definition of information gain. The ground truth provides the correct, technical definition related to the reduction in entropy achieved by splitting a node.",0,The generated answer is unfaithful. [cite_start]The context discusses the need to identify what data is needed to develop a model ('Was fÃ¼r Informationen brauche ich?')[cite: 942]. It does not provide a definition of 'information gain' as an evaluation measure.,0,"The context discusses identifying what data is needed for a machine learning model from a business perspective ('Data Understanding' phase) . However, it does not provide the technical definition of information gain as a reduction in entropy from splitting a node."
What is KNN used for?,KNN is a supervised learning algorithm used for classification and regression.,"According to the text, KNN (K-Nearest Neighbors) can be applied “in verschiedenen Sektoren”. It’s used “überall”. 

Essentially, the text indicates KNN is a broadly applicable technology.
","Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. gemacht hat,
das User Interface war
die reine Technologie dieser 
großen Sprachmodelle.
Die gibt es theoretisch schon 
seit 2017.
Die wurden natürlich immer 
besser.
Wir hatten am Ende die Version 
drei Punkt irgendwas,
was dann integriert wurde.
Aber es wurde integriert.
Dieses fundamentale KI Modell in
eine ausreichend kompatible und
nutzerfreundliche Umgebung,
nämlich Chat GPT, was
noch mal das Grundmodell GPT
plus weitere Systeme sind, die 
hier zusammenspielen.
Das heißt Forgeat GPT.
Gab es diese großen 
Sprachmodelle schon?
Die haben sich wie gesagt immer 
weiter verbessert.
Grundsätzlich haben
wir aber alle erst damit 
angefangen und
haben eine ganze Industrie 
eigentlich damit angefangen,
es kommerziell zu benutzen.
Ab dem Moment, wo dieses
User Interface richtig 
hinbekommen wurde
und die User des Systems 
hochgegangen ist.
Das ist eine der Kern messages
die Bereitschaft des Nutzers,
mit den Systemen zu 
interagieren.
Generell, wo wir
häufig von Adoption reden 
Technologie use.
Wenn wir ganz, ganz breit sind.
Das ist zentral dafür,
wie eine Technologie tatsächlich
letztlich Einfluss haben kann 
auf unser Sozialleben,
auf unsere ökonomischen 
Prozesse,
auf Unternehmen
und letztlich natürlich auf 
Produktivität. in einer bestimmten Domäne,
in einem bestimmten Bereich 
angewendet werden kann,
sondern eben in verschiedenen 
Sektoren.
Es wird überall gebraucht.
Also General Purpose und
vorher war mal und ich finde den 
Namen furchtbar.
Aber um sie nicht zu verwirren,
habe ich eine andere als die 
herkömmliche Abkürzung,
die Sie in vielen ökonomischen
Büchern noch finden, nämlich 
GPT.
Das ist General Purpose.
Technologie hat natürlich Open 
AI
uns alle so ein bisschen 
versaut.
Dieses Wort zu benutzen,
insbesondere wenn man irgendwie 
an der
Schnittstelle zu Machine 
Learning arbeitet,
weil alle direkt an das 
Sprachmodell denken.
Deswegen hier diese furchtbare
Abkürzung General purpose
Tonnen general purpose 
technology.
Diese Technologien haben
die gesamte Zivilisation der
Menschheit schon immer massiv 
verändert.
Nicht nur, weil sie auf der 
einen Seite weit
eingesetzt worden sind und
auf der anderen Seite eben über
die Zeit immer besser genutzt 
wurden,
erkannt wurde, wo wir sie noch 
einsetzen
kann Economies of Scale 
eingesetzt haben.
Viele Leute nutzen es wird immer 
knapper.
Sondern auch, weil diese 
Innovationen,
diese Kerninnovationen,
letztlich zu weiteren
komplementären Innovationen 
geführt haben.",6.056210041,1,"The generated answer correctly states that KNN is a supervised learning algorithm used for classification and regression, which is consistent with the ground truth.",0,"The generated answer is unfaithful. [cite_start]The context states that KNN can be applied 'in verschiedenen Sektoren' (in various sectors) and is used 'Ã¼berall' (everywhere)[cite: 970], but this is a description of a General Purpose Technology, not KNN. The term KNN is not mentioned in the context.",0,The context discusses the broad applicability of General Purpose Technologies (GPTs) across various sectors but does not specifically mention KNN or its use for classification and regression.
"According to the document, what are the three components of the training process of supervised machine learning?",Representation +Evaluation +Optimization,"Laut dem Dokument sind die drei Komponenten des Trainingsprozesses von überwachtem maschinellem Lernen:

1.  **F** (Das erlernte Machine Learning Modell, das Muster in historischen Daten speichert.)
2.  **XML** (Die Daten, die in die Maschine reingetun werden.)
3.  **Y** (Nicht explizit erwähnt, aber impliziert als die Komponente, die Vorhersagen für die Zukunft ermöglicht.)","Studierende werden mit den wichtigsten Fragestellungen rund um den Einsatz von Machine Learning (ML) in Managemententscheidungen vertraut gemacht. Sie erwerben grundlegende theoretische Kompetenzen im Bereich ML und verstehen, wie diese Technologien betriebliche Prozesse und strategische Entscheidungen beeinflussen können.
Studierende erlernen den Umgang mit grundlegenden Methoden und Werkzeugen des maschinellen Lernens, einschließlich Datenaufbereitung, Modelltraining und -bewertung. Sie entwickeln die Fähigkeit, wirtschaftliche Fragestellungen in ML-Probleme zu übersetzen und datenbasierte Lösungen analytisch sowie strukturiert zu erarbeiten.
Im Rahmen der Veranstaltung werden zahlreiche Praxisbeispiele und Fallstudien aus verschiedenen Industrien behandelt, die die Anwendung von ML und generativer KI im geschäftlichen Kontext beleuchten. Insbesondere in den angebotenen Übungen und praktischen Programmieraufgaben lernen Studierende, das erlangte Wissen anzuwenden, auch ohne vorherige Programmiererfahrung. dieser Gleichung hier 
ausdrücken.
Wir haben drei verschiedene 
Komponenten.
Wir haben hier dieses Hütchen,
wir haben das fix und wir haben 
hier dieses Y Hütchen.
Meine erste Frage an Sie Was war 
das? F Hütchen.
Yes, genau richtig.
Wir haben hier das erlernte 
Machine Learning Modell,
was die Muster, die wir in 
historischen
Daten durch Algorithmen erkannt 
haben, abspeichert.
Hier in diesem F. Steckt unser 
gesamtes Wissen drin,
was wir irgendwie extrahieren
und wie genau wir das 
extrahieren.
Das wird der zweite Teil unserer 
Vorlesung sein.
Wichtig hierbei Hütchen ist 
immer dafür ein Indikator,
dass wir von einer Approximation 
sprechen.
Das ist ein Modell.
Das ist nicht der wahre 
unterliegende Prozess,
der die Daten generiert.
Das ist nicht die Landschaft von 
Frankfurt sozusagen,
sondern es ist die Landkarte.
Es ist ein explizit abstrakteres 
Modell,
eine Darstellung der Realität.
Und da können eben Fehler drin 
sein.
Es ist ganz wichtig, sich
immer wieder vor Augen zu 
halten.
Dann haben wir die zweite 
Komponente.
Das war das XML. Was ist das?.X. 
Jemand eine Idee?
Jetzt dahinten? Genau das sind 
die Daten,
die wir in diese Maschine 
reintun.
Wir haben zum Beispiel, wenn Sie 
überlegen,
Sie interagieren mit Chat GPT Trainieren
selber gar nicht lange und
wir können sehr viele Kniffe 
benutzen,
wie wir dieses diesen
Trainingsprozess in einer 
gewissen Art
und Weise automatisieren können,
indem wir zum Beispiel
die Modellstruktur, die 
Modellauswahl,
sogar die Auswahl der relevanten
Inputinformationen durch 
bestimmte sogenannte
Cross Validation Verfahren durch
die Daten selber identifizieren 
lassen.
Ich hasse diesen Satz,
aber hier passiert dann sehr 
häufig dieses Let
the data speak so wenig anhaben 
wie möglich machen.
Wir versuchen einfach, das beste 
Modell zu finden.
Und auch das sei wieder betont, 
ist fundamental.
Uns geht es darum, ein Modell zu 
finden,
was nicht unsere historischen
Daten so gut es geht erklärt,
sondern sobald das Modell da 
ist,
möchten wir ein Modell haben,
was es uns ermöglicht,
Vorhersagen für die Zukunft zu 
machen,
also Vorhersagen für Beispiele,
Observationen, die das Modell 
noch nicht gesehen hat.
Denken Sie an das 
EiscremeBeispiel zurück.
Es ging nicht darum, perfekt zu 
erklären,
wie sich in der
Vergangenheit unsere 
Eisverkäufer abhängig
von bestimmten 
Wetterinformationen dargestellt 
haben,
sondern es ging darum Ich habe 
einen bestimmte
Logik identifiziert aus den 
historischen Daten.",10.46522069,0,"The generated answer provides an incorrect set of three components. The ground truth provides the correct answer: Representation, Evaluation, and Optimization.",0,"The generated answer is unfaithful. [cite_start]The context describes the three components of a machine learning equation as 'F HÃ¼tchen' (the learned model), 'XML' (the input data), and 'Y HÃ¼tchen' (the prediction)[cite: 983, 985, 992]. The generation's answer of 'Representation + Evaluation + Optimization' is a different concept not mentioned in this context.",0,"The context describes the components of a machine learning function using placeholders F-hat, XML, and Y-hat, but it does not mention the specific three-component framework of Representation, Evaluation, and Optimization."
"In the case study with the Sparkasse, is the combination of a human and a machine advisor better or worse than the machine alone?",Worse.,"Laut dem Text ist die Kombination aus Mensch und Maschine (Mensch + Maschine) schlechter als die Maschine allein. Der Grund dafür ist, dass der Kunde sich besser fühlt, wenn ein Mensch dabei ist, auch wenn es nur ein affektiver Faktor ist, der ihm Sicherheit gibt, falls etwas schief geht.","technische Performance der 
Maschine,
die für diese beiden Subgruppen 
vergleichbar sind.
Und grundsätzlich ist dieses 
Fehlverhalten von Maschinen,
wenn systematisch basierend auf
bestimmten soziodemographischen 
Faktoren,
die wir rechtlich oder
als Gesellschaft für wichtig 
erachten.
Wenn dort Unterschiede 
vorliegen,
die in der Realität aber 
eigentlich keine Rolle spielen,
also ohne Rechtfertigung,
unterscheidet die Maschine in
ihrer Vorhersagegenauigkeit,
in welchem Maß auch immer wir 
das jetzt messen,
zwischen diesen beiden Gruppen,
dann sprechen wir von 
algorithmischer Diskriminierung.
Algorithmische Diskriminierungen 
gibt es,
ein ganz tolles Papier hier von 
zwei
Kollegen werde ich Ihnen auch 
noch hochladen.
Und diese algorithmische 
Diskriminierung
hat ein ganz großes Problem.
Nämlich wir haben nicht, das es
vorher nicht auch schon hätte 
sein können,
dass Ihr Bankberater in dieser
einen Sparkasse
gegen bestimmte Minoritäten 
diskriminiert hat.
Aber diese Maschinen erzeugen 
oder erzeugen dieses
Muster auf eine Art und Weise,
auf eine skalierbare Art und 
Weise,
wie sie eine einzelne Person nie 
hätte darstellen können.
Und das hat auf der einen Seite 
eben technische Aspekte,
aber auch soziale Aspekte. geben,
was Entscheidungsparameter 
angeht.
Macht Sinn. Gut, ein Konzept,
was ich auch durch meine eigene 
Forschung
in unbedingt nahe legen möchte,
ist die Idee von Mensch 
Maschine.
Komplementaritäten bedeutet Was 
wir
erreichen wollen ist eigentlich 
ein Setting,
wo Mensch und Maschine auf eine
Art und Weise zusammenarbeiten,
dass die Performance dieses
kollaborativen Systems besser 
ist als
die Performance der einzelnen 
Komponenten.
Und das kann natürlich
aus verschiedenen Gründen 
entspringen.
Diese komplementären Stärken.
Haben Sie eine Idee, was so die 
zwei Faktoren sind,
warum Menschen und Maschinen 
sich ergänzen und
warum nicht die Maschine immer 
besser
ist und nicht der Mensch immer 
besser ist?
Auf einem sehr high Level ja,
vielleicht auch mit dem 
Zusammenspiel der
zwei Systeme mit dem eins und 
zwei.
Interessante Perspektive.
Kann man so interpretieren,
dass die Maschine eher System 
zwei ist
und der Mensch sehr schnell 
heuristisch
affektiv entscheidet.
Ja, geht in einen der beiden 
Punkte,
die ich zusammenfassen möchte, 
mit ein Ja.
Ja. Ja, würde ich jetzt als ein
anderes Thema noch mal 
betrachten.
Moralität.
Wir sprechen jetzt hier wirklich 
um
Ergänzung von Fähigkeiten.
Erstmal die einbringen, viel.
Das ist tatsächlich so ein 
bisschen intuitiv.
Auch die der Mechanismus,
auf den alles hindeutet.
Wir haben uns angeschaut. Glaubt 
der Mensch einfach.
Das glaubt der Kunde, dass 
Maschine
plus Mensch besser berät.
Also dass es genauer ist,
dass es vertrauenswürdiger ist
und bessere 
Investitionsempfehlungen gibt?
Nee, überhaupt nicht.
Wenn, dann antizipiert der Kunde 
sogar.
Naja, wenn Mensch plus Maschine 
zusammenarbeitet,
ist das gemeinsame Produkt 
schlechter als das,
was die Maschine alleine macht.
Ist aber egal, weil ich fühle 
mich besser,
wenn der Mensch dabei ist.
Dieser emotionale,
wie wir es hier aus dieser
Theorie von der Elaboration 
likelihood
Model der Peripherie peripheral 
Part in Ihrem Gehirn.
Also diese affektiven Signale, 
da ist jemand,
der hält Ihre Hand,
wenn es schief geht,
auf den können Sie sauer sein, 
wenn es schief geht.
Und dann können wir das hier 
zeigen,
dass es eben nicht darum geht,
dass der Mensch die Beratung 
mehr akzeptiert,
mehr bereit ist zu bezahlen am 
Ende.
So suggerieren unsere 
Ergebnisse,
wenn Mensch plus Maschine da 
sind.
Nicht weil es denkt es besser, 
sondern einfach,
weil da jemand da ist, der ihnen 
die Hand hält.
Ähm, ja.
Takeaways, das habe ich glaube 
ich,",9.11109066,1,The generated answer's claim that the combination of a human and machine is worse than the machine alone is semantically identical to the ground truth.,1,"The generated answer is faithful. [cite_start]The context describes a study where a customer anticipates that 'wenn Mensch plus Maschine zusammenarbeitet, ist das gemeinsame Produkt schlechter als das, was die Maschine alleine macht' (when human plus machine work together, the joint product is worse than what the machine does alone)[cite: 1016].",1,"The context directly answers the question, stating that in the experiment, the combination of a human and machine advisor (Mensch plus Maschine) is perceived by the customer as being worse than the machine alone in terms of the quality of the recommendation."
"What is the concept of 'Mixed Initiative' in human-AI interaction, as exemplified by a smartwatch asking if it should record a workout?","'Mixed Initiative' is a middle ground between full automation and full manual control, where the system proactively suggests an action, but the human still makes the final choice to accept or reject it.","Der Text erwähnt das Konzept der „Gemischten Initiative“ nicht explizit. Allerdings wird es implizit durch die Beschreibung der Interaktion zwischen dem Kunden und der KI-gestützten Sparkassenberatung angedeutet.

Die Sparkasse untersucht, ob Kunden einen Robo-Advisor (automatisiertes System) bevorzugen oder eine Beratung wünschen, bei der ein Mensch mit der KI zusammenarbeitet. Der Kunde ist darüber informiert.

Dies deutet auf eine Interaktion hin, in der sowohl menschliche Expertise als auch KI-gestützte Automatisierung kombiniert werden – eine ""Gemischte Initiative"". Die Smartwatch-Beispiel, das die Frage stellt, ob eine Trainingseinheit aufgezeichnet werden soll, ist ein ähnliches Beispiel dafür. Der Mensch entscheidet, ob er die aufgezeichnete Trainingseinheit möchte, was die Kombination von menschlicher Entscheidung und KI-gestützter Vorschlag darstellt.

Zusammenfassend lässt sich sagen, dass die Interaktion zwischen Mensch und KI ein Zusammenspiel von menschlicher Entscheidungsfindung und KI-gestützten Vorschlägen und Automatisierungen ist, was auf eine ""Gemischte Initiative"" hindeutet.","wo Sie KI einsetzen können,
wann und wo mögliche 
Problemstellungen sind.
Aus diesem ersten Teil hier 
zumindest,
dass Sie uns das strukturiert 
wiedergeben
können und uns zeigen,
dass Sie diese Denkweise 
verstanden haben.
Wenn wir heute dann wie gesagt,
einsteigen und das Thema des 
ersten Blockes abschließen.
Kümmern wir uns jetzt noch mal 
darum,
was eigentlich der Mensch in 
diesem ganzen System
weiterhin noch macht und kümmern 
uns
um diese Mensch Maschine 
Interaktion.
Wenn Sie sich erinnern Sehr früh
in der zweiten Vorlesung haben 
wir festgestellt,
dass die meisten Machine 
Learning Anwendungen
es uns eigentlich erlauben,
Vorhersagen über oder unter 
Unsicherheit zu machen.
Wir kriegen Informationen, die 
uns nicht vorliegen,
und diese Informationen sind
irgendwie nützlich für uns in 
einem Entscheidungsprozess.
Sei es in dem Beispiel,
dass wir eine 
Investitionsentscheidung
treffen möchten und uns
dafür überlegen oder eine 
Vorhersage benötigen.
Wird diese 
Investitionsentscheidung, wie in
diesem Beispiel eine hohe
Rückzahlung für mich ergeben 
oder eine
niedrige Rückzahlung?
Mit dieser Information kann ich 
mir dann überlegen,
ob ich diese Investition
tatsächlich machen möchte oder 
eben nicht. So legen wir los. Herzlich 
willkommen.
Vorlesung fünf sozusagen.
Fast schon Bergfest, oder?
Heute ist, glaube ich, Bergfest,
wenn man die restlichen 
Vorlesungen zusammenzählt.
Auch weil ich jetzt schon 
mehrfach gefragt wurde.
Dazu mit der Klausur.
Das hier ist jetzt die letzte
Vorlesung aus diesem ersten 
Teil,
wo es darum geht, ein 
grundsätzliches
Verständnis dafür zu schaffen,
was KI bewirken kann,
wie Menschen mit KI 
zusammenarbeiten können,
was potenzielle Schwachpunkte 
und Probleme sind,
wenn wir KI einsetzen.
Heute sprechen wir über Mensch 
Maschine Interaktion,
bauen sozusagen auf der 
Erklärbarkeit.
Vorlesungen von vor zwei Wochen
auf und dann ist dieser erste 
Block abgeschlossen.
Dann fängt es nächste Woche
an mit dem eher technischen 
Blog,
wo wir jetzt wirklich uns dann 
damit befassen werden,
wie wir diese Systeme bauen,
was die Mathematik dahinter ist,
wo die Stärken und die
Schwächen von bestimmten 
Modellen liegen.
Und zu Beginn der nächsten
Vorlesung werden wir dafür dann 
aber zum Abschluss dieses
ersten Blockes so eine Art 
kleinen Recap machen,
wo ich Ihnen auch
ein paar Fragen interaktiv
mit der Gruppe durchspielen 
werde.
Von der Struktur der Frage 
können Sie dann auf die
Struktur der Fragen in im Taunus angeschaut haben,
wie Menschen tatsächlich mit KI 
interagieren.
Ob es eigentlich gut ist,
wenn Ihr Sparkassenberater eine 
KI benutzt,
um Ihnen Investmentberatung zu
geben und wie Sie eigentlich
darauf reagieren oder ob
das Ganze vielleicht 
automatisiert ablaufen sollte.
Das Papier ist jetzt
also kommt bald im Management 
Science Journal raus.
Wie gesagt, die letzten fünf 
Minuten.
Aber vorher noch mal 
irgendwelche
Unklarheiten zu dem Thema,
was wir oder Themen,
die wir bisher besprochen haben.
Cool. Wie gesagt, wir haben
uns in diesem Projekt
Sparkasse kam auf uns zu und hat 
gesagt naja,
wir haben hier eine Idee
oder wir möchten gerne mal 
rausfinden,
ob unsere Kunden eigentlich eher 
wollen,
dass sie von einem Robo Advisor 
beraten werden,
also einem automatisierten 
System,
wo kein Mensch mehr dabei ist 
oder von Mensch Berater,
der mit der KI zusammenarbeitet
und gemeinsam sozusagen als
Human AI Team diese Beratung an 
den Kunden gibt.
Der Kunde ist eben darüber 
informiert.
Was wir gemacht haben, ist Wir 
haben
eine Feldstudie gemacht, zwei 
Stufen.
Wir haben für die erste Stufe 
ganz viele Daten gesammelt,
haben KI System gebaut,
was bewertet hat, ob ein 
bestimmtes Investitionsobjekt,
hier eben P2P loans,",21.93633223,1,"The generated answer's definition of 'Mixed Initiative' is semantically consistent with the ground truth, capturing the idea of the system suggesting an action while the human makes the final choice.",1,"The generated answer is faithful. [cite_start]The context describes a situation where a smartwatch proactively suggests recording a workout, but the user makes the final choice, which it explicitly labels as 'The Idea of Mixed Initiative'[cite: 1054, 1059].",0.5,"The context describes a scenario perfectly matching the concept of 'Mixed Initiative' (a smartwatch proactively suggesting to record a workout, with the user making the final decision)  and even uses the term 'Mixed Initiative'. However, it does not provide a formal definition of the concept itself."
What did the speaker say about the possibility of the smartwatch automatically starting to record a workout?,The speaker said the smartwatch could estimate the probability that the user wants their sport recorded.,"Der Sprecher hat gesagt, dass die Smartwatch, während man Sport macht, irgendwie eine Art „Mischung“ darstellt, bei der das System nicht selbstständig entscheiden könnte, etwas aufzuzeichnen, ohne Ihre Einwilligung. Es war eine Mischung aus dem System, das Ihnen etwas vorschlägt, und Ihrer eigenen Entscheidung.","Wenn Sie entscheiden würden, 
nicht zu delegieren,
dass Sie auf jeden Fall das 
selber machen, hilft es ja.
Ja, das ging jetzt gerade,
was sie gesagt hatten.
Naja, muss es denn immer das 
eine oder das andere sein?
Nee, muss es natürlich nicht.
Denken Sie an diejenigen im 
Raum,
die irgendeine Smartwatch haben.
Wenn Sie Sport machen und 
plötzlich
das System Sie fragt Soll ich 
das eigentlich aufzeichnen?
Sind Sie gerade am Sport machen?
Das ist irgendwie so eine Art 
Mischung davon.
Also weder das System selber 
entschieden,
jetzt irgendwas aufzuzeichnen 
ohne Ihre Einwilligung.
Sie haben also diese 
Entscheidung
des automatisierten 
Aufzeichnungs nicht
an die Maschine delegiert.
Aber Sie haben auch nicht aktiv 
gesagt Na ja,
ich gehe jetzt hin und such das 
raus.
Sondern die Maschine von sich 
entscheidet,
ihnen etwas vorzuschlagen in the 
first place.
Und das nennen wir grundsätzlich
The Idea of Mixed Initiative.
Und es geht auch schon auf ein 
sehr frühes
wissenschaftliches Papier 
zurück,
nämlich Anfang der 
Zweitausenderjahre.
Weiß jemand, wer das ist? Hier. 
Mal von ihm gehört?
Es ist der Chief Scientific 
Officer von Microsoft.
Der,
der für sehr viele
wissenschaftliche 
Strategieentscheidungen da irgendwie noch so ein Mensch 
mit drin.
Der Mensch kann aber eigentlich 
nicht mehr eingreifen
und es hat dazu geführt,
dass dieser Safety Driver,
der drin war, das war irgendwie 
eine ältere Dame,
die irgendwie übermüdet war etc.
konnte nicht mehr eingreifen. 
Dann sind Leute gestorben.
Automatisierung, die schiefgeht,
wenn das System nicht 
automatisch
erkennt, was es machen soll.
Frage war das die ist auch nicht 
gemeldet hatten,
auch weil sie die 
Entwicklungskosten nicht haben 
wollten.
Das ist natürlich jetzt noch
die weiter reichenden Probleme.
Wir reden nur über das 
technische Problem Automation.
Das Problem war, dass die 
Piloten nicht wussten,
dass die Automation überhaupt da 
ist.
Richtig. Das stimmt, das gehört 
auch dazu.
Da sind viele Wettbewerbskräfte, 
die dazu geführt haben,
auch, dass die Boeing überhaupt 
das gemacht
hat mit der 37 sieben.
Max hat was mit
Competitive Pressure zu den
Airbus A320neo Systemen zu tun
und Druck die Kosten runter zu 
senken,
was Automatisierung gefördert 
hat
um dieses Problem zu verstecken.
Und das wurde dann eben nicht 
gemeldet.
Das ist einfach grundlegend 
Fraud, ne,
aber per se erstmal die Idee,
wenn ich etwas automatisiere und 
die
Idee der Automatisierung war Was sind das? Was abschneiden?
Testdaten? Ja. Sie wollten 
sagen, nächstes Mal.
Unterscheiden zwischen Trainings 
und
Testdaten. Aber Sie haben 
vollkommen recht.
Es sind trotzdem historische 
Daten.
Aber diese Testdaten.
Daher kommt der Name.
Die geben uns zumindest eine 
Idee,
wie gut dieses Modell 
funktionieren sollte.
Angenommen.
Der grundlegende Prozess 
verändert sich nicht.
Da war noch eine Frage. Hier 
irgendwo.
Genau da. Will ich alle 
Informationen reinschreiben?
Könnte auch.
Wenn man die manchmal sehen 
könnte,
kann es ja die Interaktionen 
zwischen den
Relationen gar nicht 
einschätzen.
Das schon. Das ist das Coole an 
Machine Learning.
Sorry, wenn ich jetzt happy bin,
aber das ist eins der 
Kernsachen.
Neuronale Netze haben
eine inhärente Struktur 
beispielsweise oder
andere Modelle wie Random 
Forest,
aber auch Gradient Boosting 
Methods.
Die haben eine inhärente
Möglichkeit, Nichtlinearitäten 
zu lernen,
ohne dass ich sie explizit 
spezifiziere,
indem ich einfach genug 
Beispiele reinschmeiße.
Aber es kann ja nicht für die 
Zukunft sagen,
wie genau diese Informationen 
genau wiedergegeben werden,
In einer. In einer.
Wir reden jetzt super 
theoretisch,
wenn ich nur die Mathematik
dahinter angucke und Machine",9.24431777,0,"The generated answer claims the smartwatch suggests recording a workout, which is less precise than the ground truth's statement that it *estimates the probability* that the user wants it recorded. The ground truth is more technically accurate.",0,"The generated answer is unfaithful. The context describes a smartwatch suggesting it should record a workout, not that it *could* estimate the probability. [cite_start]It frames it as a proactive suggestion, not a probabilistic estimation[cite: 1054, 1058].",1,"The context explicitly mentions the concept of 'Mixed Initiative' and gives the example of a smartwatch asking if it should record a workout, explaining that the machine makes a suggestion but the user retains control . It then states that the system could estimate the probability that the user wants the action recorded, aligning with the ground truth."
The lecture describes two extremes in human-machine collaboration. What is 'Algorithm Aversion'?,"'Algorithm Aversion' is the observation that people often consciously choose not to use a helpful algorithm, even when they know it is objectively more accurate than their own opinion or that of other humans.","Die Vorlesung erwähnt „Algorithm Aversion“ nicht explizit. Sie konzentriert sich auf die Interaktion zwischen Mensch und Maschine, insbesondere die Erklärbarkeit und die Zusammenarbeit mit KI.","obwohl die Leute wissen, die 
Maschine ist gut.
Das Signal unsere Prediction,
die ist wertvoll,
die sollte ich in meine 
Überlegungen mit einbeziehen.
Die ignorieren das einfach.
Riesen Phänomen.
Sehr gutes Thema für eine 
Bachelorarbeit.
Ach nee, ich wollte 
weitermachen.
Sorry. Nach der Vorlesung.
Ja, ich muss ein bisschen auf 
die Zeit achten.
Hier. Worauf ich hinaus wollte 
mit der Darstellung,
dass sich unser PC verändert,
aber nicht unser OO.
Also Sie haben weiterhin diese 
Bewertung.
Womit ich darauf hinaus möchte, 
ist die Tatsache,
dass weiterhin Platz für Sie als 
Mensch besteht.
Die Maschine gibt Ihnen
eine Vorhersage und diese 
Vorhersage
verändert Ihre subjektive
Einschätzung über die 
Wahrscheinlichkeit,
Aber sie verändert nicht,
dass sie weiterhin eigentlich 
für sich bestimmen müssen.
Wie gut finde ich denn 
eigentlich,
dass ich 15 Kriege
in diesem Fall und das 
Unternehmen 15 kriegt?
Oder dass ich zehn kriege
und das Unternehmen null kriegt?
Sie können ja zum Beispiel 
jemand sein,
der sagt Naja, mir ist es super,
super wichtig,
dass ich den Gesamtkuchen, die 
Effizienz maximiere.
Das heißt, wenn wir beide 15 
haben,
ist das relativ für sie besser 
als
in diesem Beispiel hier null und 
20. Wenn Sie Wirtschaftsinformatik 
eins
oder zwei besucht haben,
werden Sie bestimmt schon mal 
über das Unified,
also Unified Theory of 
Acceptance
and Use of Technology gehört 
haben.
Wer hier hat das in der 
Vorlesung schon mal gesehen?
Leider doch niemand. Sie nicken.
Okay, da muss ich doch ein
paar Minuten länger hier drüber 
sprechen,
weil das war eigentlich, was ich 
sagen wollte.
Okay, da können wir schnell 
drüber gehen,
weil das Grundlagen sind.
Grundlagen, wie Sie hier sehen,
2003 ist eines der
am meistzitierten 
wissenschaftlichen Papiere,
die es überhaupt gibt in der 
Wirtschaftsinformatik,
weil das sehr
viele verschiedene Perspektiven 
zusammenbringt.
Wir haben schon aus den 70er 
Jahren,
haben eigentlich die 
Wirtschaftsinformatiker 
angefangen,
sich als Studienobjekt,
als Forschung auszusuchen, 
besser zu verstehen,
wie Menschen mit technischen
Systemen interagieren und 
herauszufinden,
warum bestimmte Technologien 
eigentlich gut ankommen
und andere schlecht ankommen.
Ich weiß nicht, ob Ihnen das 
bewusst ist,
aber die Tastatur, die wir 
haben,
dieses QWERTzsystem auf auf 
Deutsch
ist super ineffizient.
Das ist für menschliche Nutzung 
total suboptimal,
weil die Tasten eine bestimmte 
Struktur haben, So legen wir los. Herzlich 
willkommen.
Vorlesung fünf sozusagen.
Fast schon Bergfest, oder?
Heute ist, glaube ich, Bergfest,
wenn man die restlichen 
Vorlesungen zusammenzählt.
Auch weil ich jetzt schon 
mehrfach gefragt wurde.
Dazu mit der Klausur.
Das hier ist jetzt die letzte
Vorlesung aus diesem ersten 
Teil,
wo es darum geht, ein 
grundsätzliches
Verständnis dafür zu schaffen,
was KI bewirken kann,
wie Menschen mit KI 
zusammenarbeiten können,
was potenzielle Schwachpunkte 
und Probleme sind,
wenn wir KI einsetzen.
Heute sprechen wir über Mensch 
Maschine Interaktion,
bauen sozusagen auf der 
Erklärbarkeit.
Vorlesungen von vor zwei Wochen
auf und dann ist dieser erste 
Block abgeschlossen.
Dann fängt es nächste Woche
an mit dem eher technischen 
Blog,
wo wir jetzt wirklich uns dann 
damit befassen werden,
wie wir diese Systeme bauen,
was die Mathematik dahinter ist,
wo die Stärken und die
Schwächen von bestimmten 
Modellen liegen.
Und zu Beginn der nächsten
Vorlesung werden wir dafür dann 
aber zum Abschluss dieses
ersten Blockes so eine Art 
kleinen Recap machen,
wo ich Ihnen auch
ein paar Fragen interaktiv
mit der Gruppe durchspielen 
werde.
Von der Struktur der Frage 
können Sie dann auf die
Struktur der Fragen in",6.778978825,0,"The generated answer incorrectly claims the lecture doesn't mention 'Algorithm Aversion.' The ground truth defines the term, indicating the generation failed to extract the relevant information.",0,The generated answer is unfaithful. The context describes 'Algorithm Aversion' but does not explicitly name it as such. [cite_start]It describes the phenomenon of people ignoring a helpful prediction from a machine[cite: 1081]. The term itself is not present.,0,The context discusses human-machine interaction and the Unified Theory of Acceptance and Use of Technology (UTAUT). It does not mention the term 'Algorithm Aversion' or the phenomenon of people avoiding algorithms they know are superior.
What are the two extremes of observation regarding human-machine collaboration?,Algorithm aversion and Algorithm appreciation.,"Basierend auf dem Text gibt es zwei Extreme der Beobachtung bezüglich der Zusammenarbeit zwischen Mensch und Maschine:

1.  **Der Mensch glaubt, dass Mensch plus Maschine besser ist:** Einige Leute erwarten, dass die Kombination aus Mensch und Maschine zu besseren Ergebnissen führt – genauer, vertrauenswürdiger und bessere Investitionsempfehlungen.

2.  **Der Mensch schätzt die menschliche Präsenz, unabhängig von der Qualität der Ergebnisse:** Andere glauben, dass die Zusammenarbeit einfach nur dann gut ist, wenn ein Mensch dabei ist, der Unterstützung und Sicherheit bietet (z.B. durch das Halten der Hand, wenn etwas schief geht). Es geht also mehr um das emotionale Gefühl der Sicherheit, als um die tatsächliche Leistungsverbesserung.","geben,
was Entscheidungsparameter 
angeht.
Macht Sinn. Gut, ein Konzept,
was ich auch durch meine eigene 
Forschung
in unbedingt nahe legen möchte,
ist die Idee von Mensch 
Maschine.
Komplementaritäten bedeutet Was 
wir
erreichen wollen ist eigentlich 
ein Setting,
wo Mensch und Maschine auf eine
Art und Weise zusammenarbeiten,
dass die Performance dieses
kollaborativen Systems besser 
ist als
die Performance der einzelnen 
Komponenten.
Und das kann natürlich
aus verschiedenen Gründen 
entspringen.
Diese komplementären Stärken.
Haben Sie eine Idee, was so die 
zwei Faktoren sind,
warum Menschen und Maschinen 
sich ergänzen und
warum nicht die Maschine immer 
besser
ist und nicht der Mensch immer 
besser ist?
Auf einem sehr high Level ja,
vielleicht auch mit dem 
Zusammenspiel der
zwei Systeme mit dem eins und 
zwei.
Interessante Perspektive.
Kann man so interpretieren,
dass die Maschine eher System 
zwei ist
und der Mensch sehr schnell 
heuristisch
affektiv entscheidet.
Ja, geht in einen der beiden 
Punkte,
die ich zusammenfassen möchte, 
mit ein Ja.
Ja. Ja, würde ich jetzt als ein
anderes Thema noch mal 
betrachten.
Moralität.
Wir sprechen jetzt hier wirklich 
um
Ergänzung von Fähigkeiten.
Erstmal die einbringen, Signal
gar nicht erst gesehen hätte.
Und das ist eines der zentralen 
Probleme,
die wir sehen, wenn Menschen mit
Maschinen zusammenarbeiten.
Wie nutzen Menschen dieses 
Signal,
wenn der Mensch in diesem Loop 
ist?
Haben Sie vielleicht schon öfter 
gehört aus
den Nachrichten Diese Idee von 
Menschen bleiben
im Loop Humans in the Loop,
wo Menschen, die Informationen 
von der KI bekommen,
aber Menschen letztlich die 
finale Entscheidung treffen.
Wenn die Menschen overconfidence
in die Maschine oder sich selber 
sind,
könnte es sein, dass sie die
Signal diese Vorhersage der
Maschine der KI komplett 
ignorieren.
Oder Aber wenn Sie glauben,
ich sollte einfach das machen,
was die Maschine mir sagt, kann 
es auch sein,
dass Sie dieses Signal der 
Maschine übergewichten.
Sie verlassen komplett ihren 
Player.
Sie glauben, sie haben 
eigentlich gar keine Ahnung als
Experte und nehmen einfach das 
an,
was die Maschine ihnen sagt?
Und dieses Problem von diesem
Zusammenspiel von wie sie diese 
Informationen
verarbeiten und wie welche
Probleme hier eine Rolle spielen 
könnten in Bezug auf
die richtige Gewichtung Ihrer 
eigenen Expertise
und der von der Maschine,
welche Signal Sie bekommen.
Das ist das, womit wir uns heute 
befassen. viel.
Das ist tatsächlich so ein 
bisschen intuitiv.
Auch die der Mechanismus,
auf den alles hindeutet.
Wir haben uns angeschaut. Glaubt 
der Mensch einfach.
Das glaubt der Kunde, dass 
Maschine
plus Mensch besser berät.
Also dass es genauer ist,
dass es vertrauenswürdiger ist
und bessere 
Investitionsempfehlungen gibt?
Nee, überhaupt nicht.
Wenn, dann antizipiert der Kunde 
sogar.
Naja, wenn Mensch plus Maschine 
zusammenarbeitet,
ist das gemeinsame Produkt 
schlechter als das,
was die Maschine alleine macht.
Ist aber egal, weil ich fühle 
mich besser,
wenn der Mensch dabei ist.
Dieser emotionale,
wie wir es hier aus dieser
Theorie von der Elaboration 
likelihood
Model der Peripherie peripheral 
Part in Ihrem Gehirn.
Also diese affektiven Signale, 
da ist jemand,
der hält Ihre Hand,
wenn es schief geht,
auf den können Sie sauer sein, 
wenn es schief geht.
Und dann können wir das hier 
zeigen,
dass es eben nicht darum geht,
dass der Mensch die Beratung 
mehr akzeptiert,
mehr bereit ist zu bezahlen am 
Ende.
So suggerieren unsere 
Ergebnisse,
wenn Mensch plus Maschine da 
sind.
Nicht weil es denkt es besser, 
sondern einfach,
weil da jemand da ist, der ihnen 
die Hand hält.
Ähm, ja.
Takeaways, das habe ich glaube 
ich,",14.90424204,1,The generated answer and the ground truth both correctly identify the two extremes as algorithm aversion and algorithm appreciation.,1,"The generated answer is faithful. [cite_start]The context describes a situation where people ignore helpful signals from a machine ('Die ignorieren das einfach') and where they might over-rely on the machine ('Ã¼bergewichten')[cite: 1081, 1119]. These represent the two extremes of collaboration.",0,"The context discusses the concept of human-machine complementarity and mentions that a customer might feel better when a human is involved in a decision process, which relates to algorithm appreciation. However, it does not explicitly mention algorithm aversion or frame the discussion around these two specific extremes."
What were the developers struggling with regarding Windows eight?,The developers of Windows 8 were struggling with the bad user interface.,"Die Entwickler von Windows 8 hatten folgende Schwierigkeiten:

*   **Totale Katastrophe der Oberfläche (User Interface):** Die Oberfläche war für die Entwickler eine ""totale Katastrophe"".
*   **Entwickler konzentrierten sich ausschließlich auf die Oberfläche:** Die Entwickler konzentrierten sich nur auf die Oberfläche, ohne die Nutzerbedürfnisse ausreichend zu berücksichtigen.
*   **Die Oberfläche wurde für Windows 8 entwickelt:** Die Oberfläche wurde für Windows 8 entwickelt, obwohl sie später für andere Systeme verwendet wurde.","the loop dahingehend Sie 
entscheiden,
Ich transferiere 
Entscheidungsgewalt in diesen
automatisierten Fällen oder Sie 
behalten immer
die Entscheidungsgewalt,
müssen sich aber entscheiden Wie
viel Gewicht geben Sie 
eigentlich?
Der Information von der Maschine 
macht es Sinn.
So fangen wir aber
mal einen Schritt weiter vorne 
an Erinnern Sie sich noch?
Ich weiß nicht, ob Sie dafür 
noch zu jung sind, Sogar.
Aber erinnern Sie sich noch
an diese Version von Microsoft?
Microsoft acht kam raus
2012 und es war ein vollkommenes 
Desaster für Microsoft.
Warum? Naja, viele der User 
waren total überfordert.
Das war eigentlich grundsätzlich 
ein
tolles System mit ganz vielen 
Neuerungen,
mit ganz vielen Funktionen,
wo sich die Entwickler gedacht 
haben Naja,
das sollte meinen Nutzern 
gefallen.
Das macht alles viel einfacher.
Da soll der Entscheidungsfindung 
Prozessen
arbeiten helfen.
War alles natürlich well 
intended.
Problem war, wir alle fanden das 
nicht so cool.
Das war bei mir auch der 
Zeitpunkt,
wo ich dann komplett auf Mac 
übergesprungen bin.
Und selbst neun Jahre später war 
es immer noch so,
dass der Vorgänger Windows 
sieben
2021 hatte Windows sieben
immer noch 15 % Marktanteil von 
Windows Systemen, in einer anderen Art und Weise 
in
den Microsoftsystemen immer noch 
da.
Die wurden dort entwickelt für 
Windows acht,
aber die Oberfläche war totale 
Katastrophe.
User Interface Wir hatten 
Entwickler,
die sich ausschließlich damit 
beschäftigt haben.
Wie kann ich denn ein System 
entwickeln,
was super funktioniert haben,
aber viel zu spät eigentlich
den eigentlichen Nutzer mit 
einbezogen.
Das wurde ja auch als Mobile 
gedacht.
Also wir haben es ja versucht 
auf
dem Microsoft Handy Plattform zu 
machen.
Deshalb ist der Vorstoß
ja unterstreicht trotzdem den 
Punkt,
dass die Leute sich nicht 
ausreichend
früh überlegt haben und der.
Mein Punkt dieser Idee ist 
natürlich
für uns jetzt an dieser
Stelle Ich kann ein super System 
haben.
Worauf es aber wirklich ankommt, 
ist,
ob dieses System so genutzt 
wird,
wie ich mir das vorstelle.
Stellen Sie sich vor, Amazon
hätte das beste Recruitment Tool
basierend auf KI entwickelt
und es wäre immer richtig 
potenziell.
Aber diejenigen, die letztlich
die Entscheidungsgewalt haben,
der Mensch in diesem Loop
würde nie auf die Maschine 
hören.
Alle möglichen Effizienzgewinne, 
die wir hätten,
werden gar nicht realisiert.
Es kommt immer auf die Nutzung 
anderer
will ich sie heute Zeitpunkt,
wo ich dann komplett auf Mac 
übergesprungen bin.
Und selbst neun Jahre später war 
es immer noch so,
dass der Vorgänger Windows 
sieben
2021 hatte Windows sieben
immer noch 15 % Marktanteil von 
Windows Systemen,
wohingegen Windows acht, was
viele neue gute Funktionen 
hatte,
immer noch nur um die 1 % war.
Und es ist wieder considered 
eines der
schlechtesten Operating Systeme, 
die es gibt.
weil es einfach niemand benutzt 
hat.
Jetzt natürlich die Frage Wenn 
ich Ihnen hier
so eine anekdotische Geschichte 
erzähle,
um Sie so ein bisschen emotional 
abzuholen,
was glauben Sie, hat das mit KI 
zu tun?
Wie könnte ich aus dem 
vorherigen Beispiel,
dass die KI mir ein Signal gibt?
Ich sehe das und es
ist eigentlich ein hilfreiches 
Signal.
Wie kann ich diese Idee hier auf 
diesen
anekdotischen Fall aus der 
Geschichte
mappen? Wo ist die Verbindung?
Genau hier.
Wir haben ein tolles System. Es 
kann uns helfen.
Viele der Features im
Übrigen sind heute in einer 
anderen Darstellung,
in einer anderen Art und Weise 
in
den Microsoftsystemen immer noch 
da.
Die wurden dort entwickelt für 
Windows acht,
aber die Oberfläche war totale 
Katastrophe.
User Interface Wir hatten 
Entwickler,
die sich ausschließlich damit",11.5211401,1,The generated answer's claim that the developers were struggling with a bad user interface is semantically consistent with the ground truth.,1,The generated answer is faithful. [cite_start]The context describes the user interface of Windows 8 as a 'totale Katastrophe'[cite: 1141].,1,"The context describes the development of Windows 8, noting that while it had good new functions, the user interface ('OberflÃ¤che') was a 'totale Katastrophe' that users found overwhelming, leading to the system's failure."
"In a case study about the role of the human, what was the investment amount for the P2P vehicle in the experiment?",100,Die Investitionssumme für das P2P-Fahrzeug im Experiment betrug 15 Millionen €.,"informiert.
Was wir gemacht haben, ist Wir 
haben
eine Feldstudie gemacht, zwei 
Stufen.
Wir haben für die erste Stufe 
ganz viele Daten gesammelt,
haben KI System gebaut,
was bewertet hat, ob ein 
bestimmtes Investitionsobjekt,
hier eben P2P loans,
also Privatkredite, finanziert 
werden sollten,
also ob ein Kunde 100 € 
beispielsweise in die in
jemand anderen als Privatkredit
investieren möchte mit einem 
festgeschriebenen Zins.
Und dieses KI System war darauf 
ausgelegt vorherzusagen,
ob dieser Privatkredit dann
tatsächlich zurückgezahlt wird 
oder nicht,
ob ein Ausfall dieses Kredits 
auftreten wird oder nicht.
Das System war eigentlich auch 
ziemlich gut.
Es hat irgendwie so 74 % 
Accuracy gehabt.
Was für so soziales
Verhalten oder menschliches 
Verhalten vorherzusagen,
schon immer ganz gut ist.
Dann sind wir in die Sparkasse 
rein und haben mit
27 Bankern haben
wir hingesetzt und gesagt Hier 
sind
verschiedene von diesen 
Privatkrediten.
Gebt doch mal bitte deine eigene 
unabhängige Meinung an,
ob dieser Kredit und ich gebe 
dir ein
paar Informationen zu dem 
Privatkredit,
ob der zurückgezahlt wird oder 
nicht.
Würdest du das deinem Kunden?
Du als Mensch ohne KI Hilfe?
Würdest du dem Kunden empfehlen Hälfte zurück.
Oder aber das Startup strengt
sich ein bisschen an und läuft 
weg.
Dann haben wir gesagt Wenn wir 
uns
das als 
Nutzenmaximierungsstrategie
aufschreiben aus dieser 
mikroökonomischen,
schrägstrich spieltheoretischen 
Perspektive,
dann sagen wir, dass wir 
investieren in
dieser Stufe als Investor genau 
dann,
wenn wir sagen, die 
Wahrscheinlichkeit,
dass wir hier landen und
einen bestimmten Payoff 
bekommen,
nämlich dass wir 15 Millionen 
haben und
das Startup 15 Millionen € 
bekommt.
Das hat einen Nutzen für uns,
aber das tritt eben nur
mit einer Wahrscheinlichkeit P 
ein,
nämlich die Wahrscheinlichkeit,
dass das Startup wirklich sich
anstrengen und eine Rückzahlung 
macht.
Auf der anderen Seite, Wenn wir 
investieren,
haben wir immer dieses Risiko.
Es gibt nämlich mit der 
Gegenwahrscheinlichkeit den 
Fall,
dass das Startup sich
ein bisschen anstrengen und mit 
dem Geld wegläuft.
In dem Fall hat das Startup am 
Ende 20 Millionen €.
Wir per se haben aber nichts.
Wir haben unser gesamtes 
Investment verloren.
Und wir investieren genau dann,
wenn der Erwartungswert aus
diesen beiden möglichen Fällen,
die eintreten können, größer 
oder gleich.
Das kann man jetzt diskutieren,
ob wir hier dieses gleiche für wie wahrscheinlich halte ich 
das denn,
dass die das Startup zurückzahlt 
oder nicht,
kann ich theoretisch und
Michael und Ferdinand wären 
stolz.
Das sind meine beiden 
Doktorväter.
Deswegen sage ich es.
Kann ich diese Gleichung hier 
aufschreiben?
Ich kann sagen naja, ich 
investiere,
wenn mein erwarteter Nutzen Und 
ich bin jetzt ganz
allgemein mit Utility wenn die 
der Nutzen davon.
Wenn ich mit einer 
Wahrscheinlichkeit p,
dass zurückgezahlt wird ich bei
15 15 lande dieser Nutzen plus 
der erwartete Nutzen.
Naja, wenn es doch schiefgeht 
und ich bei null und
20 lande gewichtet mit der 
Wahrscheinlichkeit,
wenn das größer oder gleich
ist als naja, mein Nutzen davon,
wenn ich auf jeden Fall 10 
Millionen für mich habe und
das Startup null hat investiere,
wenn der erwartete
Nutzen von hier größer
ist als der sichere Nutzen von 
hier.
Wer sieht das nicht?
Dann habe ich wieder einen 
schlechten Job gemacht.
Klasse. Das ist großartig.
So was kann Machine Learning 
deliverern,
wenn ich mathematisch darüber 
nachdenke.
Naja, Machine Learning ändert 
letztlich eine
Sache an dieser Gleichung.
Hier nämlich,
Und ich habe hier eine falsche 
Zahl eingetragen.
Das ändere ich ab nach der 
Vorlesung.
Vorher haben wir die Gleichung,",6.560021639,0,"The generated answer provides the incorrect investment amount ('15 Millionen â‚¬'), which directly contradicts the correct amount ('100â‚¬') in the ground truth.",0,"The generated answer is unfaithful. [cite_start]The context describes an experiment with P2P loans where the investment amount is '100â‚¬'[cite: 1161]. [cite_start]The generation's claim of '15 Millionen â‚¬' comes from a different, illustrative example in the context about a startup investment[cite: 1169].",1,"The context explicitly states the investment amount in the experiment was 100â‚¬, where a customer could invest in a P2P loan."
"According to the document, what did Eric Horvitz advocate in his 1999 paper?",Elegant coupling of automation with direct manipulation by user.,"Laut dem Dokument hat Eric Horvitz, der Chief Scientific Officer von Microsoft, vorgeschlagen, dass wir Systeme haben, die uns automatisiert von selbst bestimmte Dinge abnehmen und dann autonom agieren. Außerdem sollte man Systeme haben, die uns die Entscheidung abgeben, ob wir uns in einem Automatisierungs-, Delegations-, Automatisierungs- oder Augmentationssetting befinden.","die das beeinflussen und
was hier Venkatesh und Kollegen 
gemacht haben,
die haben acht verschiedene 
Modelle
aus ganz unterschiedlichen
Disziplinen zusammengenommen und
haben jahrelang rumgewerkelt, um 
zu schauen,
was sind eigentlich die latent 
ähnlichen Faktoren,
was können wir irgendwie 
zusammenfassen und
was sind Faktoren,
die möglichst orthogonal einzeln 
gesehen
unterschiedlich sind und
viel Erklärungsgehalt dafür 
haben
in der Vorhersage,
ob ein Mensch die Technologie 
nutzen wird oder nicht.
Und das haben Sie das Modell, 
was entwickelt haben
letztlich auf ganz viele 
empirische Daten
gelegt und gezeigt,
dass dieses Modell um die 70 % 
der Variation darin,
ob Leute mit Technologie 
interagieren,
diese wirklich nutzen und 
akzeptieren, erklären kann.
Als Spoiler schon mal 70 % der
Variation zu erklären ist 
massiv,
insbesondere in solchen 
soziotechnischen Systemen,
wo wie immer der Mensch die 
Schwachstelle ist.
Womit haben Sie angefangen? Sie 
haben gesagt.
Und dieses Modell ist
vor allen Dingen aus der 
Perspektive
geschaffen worden damals.
Wie kriegen wir eigentlich Leute 
in Unternehmen dazu,
die bereitgestellte Technologie 
zu nutzen?
Es gibt mittlerweile auch zwei
Erweiterungen von diesem Modell wissenschaftliches Papier 
zurück,
nämlich Anfang der 
Zweitausenderjahre.
Weiß jemand, wer das ist? Hier. 
Mal von ihm gehört?
Es ist der Chief Scientific 
Officer von Microsoft.
Der,
der für sehr viele
wissenschaftliche 
Strategieentscheidungen
letztlich verantwortlich ist.
Da. Der hat nämlich damals genau 
das gesagt,
diese ganze Diskussion zwischen 
entweder
automatisieren oder wir bleiben
im Decision Support.
Das sollten wir gar nicht so
als entweder oder betrachten,
sondern wir sollten es aus einer 
Perspektive betrachten,
dass wir vielleicht Systeme 
haben,
die uns Automatisiert von selbst 
bestimmte
Dinge abnehmen und dann autonom 
agieren.
Und für andere Dinge sollten Sie 
uns vielleicht fragen.
Das heißt, wir geben eigentlich 
die Entscheidung,
ob wir im Automation oder 
Delegation,
im Automation oder Augmentation 
Setting sind,
auch an die Maschine ab.
Und er hat dann sehr intuitives,
sehr intuitiven, konzeptionellen 
Vorschlag gemacht,
wie wir darüber nachdenken 
können.
Das ist jetzt auch wieder das 
Modelldenken,
was ich glaube sehr wichtig ist 
an Universitäten.
Gelernt werden sollte,
dass sie ein grundlegendes 
Schubladendenken haben,
wie sie über solche Probleme 
nachdenken können,
ohne dass wir jetzt keine betriebswirtschaftlich
ökonomische Entscheidungen zu 
treffen.
Wer sieht das nicht?
Noch mal, was ich letztes Mal 
gesagt habe Wenn Sie
was nicht verstehen, ist es 
nicht Ihre Schuld.
Dann habe ich es einfach 
schlecht erklärt.
Deswegen immer raus damit.
Dann gehe ich davon aus, dass 
jeder verstanden hat.
Aber eine andere Frage haben
wir ja theoretisch auch
noch andere 
Entscheidungsmöglichkeiten,
Parametern, die dieselbe 
Qualität liefern.
Vollkommen richtig. Da wäre 
jetzt die Frage,
ob es eine 
Entscheidungsmöglichkeit,
die zwei Parameter verwendet,
besser als eine auf einem 
Papier.
Das ist sehr, sehr gute Frage.
Da gibt es verschiedene Theorien 
zu.
Grundsätzlich, wie wir sehen 
werden,
für den technischen Teil der 
Vorlesung.
Wir können für das gleiche
Problem verschiedene Regeln 
identifizieren.
Verschiedene Machine Learning 
Modelle trainieren.
Diese Machine Learning Modelle 
können bessere oder
schlechtere Performance 
aufweisen.
Wenn sie aber genau die gleiche 
Performance aufweisen,
dann haben wir natürlich in 
einer gewissen Art und
Weise die Wahl, immer darauf 
achtend,
dass die einzige Performance, 
die wir sehen,
aktuell immer Performance auf 
historischen Daten ist.
Das heißt, wir müssen auf der",9.685381413,1,"The generated answer correctly captures the essence of Eric Horvitz's advocacy for an 'elegant coupling of automation with direct manipulation by user,' which is semantically consistent with the ground truth.",0,"The generated answer is unfaithful. [cite_start]The context describes Eric Horvitz's idea as having systems that automate some things and ask the user about others, effectively giving the machine the choice of which mode to operate in[cite: 1192, 1193]. It does not mention 'elegant coupling of automation with direct manipulation'.",0,"The context mentions Eric Horvitz, the Chief Scientific Officer of Microsoft, and discusses his idea that systems should sometimes act autonomously and sometimes ask for user input . However, it does not mention the specific phrase 'elegant coupling of automation with direct manipulation by user' from his 1999 paper."
What is augmentation in the context of human-AI collaboration?,AI serves as a decision support tool; human always makes final decision.,"Basierend auf dem bereitgestellten Text bezieht sich ""Augmentation"" im Kontext der Mensch-KI-Zusammenarbeit auf die Idee, dass Menschen und Maschinen auf eine Weise zusammenarbeiten, in der die Performance des kollaborativen Systems besser ist als die der einzelnen Komponenten. Es geht darum, die Stärken des Menschen (wie schnelles, affektives Entscheiden) mit den Fähigkeiten der Maschine zu kombinieren, um ein besseres Ergebnis zu erzielen.","Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. Informationen
verarbeiten und wie welche
Probleme hier eine Rolle spielen 
könnten in Bezug auf
die richtige Gewichtung Ihrer 
eigenen Expertise
und der von der Maschine,
welche Signal Sie bekommen.
Das ist das, womit wir uns heute 
befassen.
Ja. Und wenn es
jetzt um sowas geht wie 
Stellenbesetzung
in der Personalabteilung,
ist das ja verständlich.
Ja, was ist mit Sektoren,
in denen man sich so schnell,
in denen so schnell
Entscheidungen getroffen werden 
müssen,
dass das überhaupt möglich ist?
Sprechen wir auch drüber.
Es gibt nämlich zwei Arten
von Mensch Maschine 
Kollaboration.
Wenn man so grob einteilt auf 
der einen Seite die
Idee von 
Entscheidungsunterstützung und 
auf
der anderen Seite die Idee von
Entscheidungsautomatisierung.
Aber auch bei der 
Entscheidungsautomatisierung.
Das Konzept von Human in the 
Loop ist,
dass der Mensch entscheidet 
Welche Entscheidungen
lagere ich denn überhaupt an die 
Maschine aus?
Das heißt, hier geht es dann 
eben um diesen
Unterschied von Humans in
the loop dahingehend Sie 
entscheiden,
Ich transferiere 
Entscheidungsgewalt in diesen
automatisierten Fällen oder Sie 
behalten immer
die Entscheidungsgewalt,
müssen sich aber entscheiden Wie
viel Gewicht geben Sie 
eigentlich? geben,
was Entscheidungsparameter 
angeht.
Macht Sinn. Gut, ein Konzept,
was ich auch durch meine eigene 
Forschung
in unbedingt nahe legen möchte,
ist die Idee von Mensch 
Maschine.
Komplementaritäten bedeutet Was 
wir
erreichen wollen ist eigentlich 
ein Setting,
wo Mensch und Maschine auf eine
Art und Weise zusammenarbeiten,
dass die Performance dieses
kollaborativen Systems besser 
ist als
die Performance der einzelnen 
Komponenten.
Und das kann natürlich
aus verschiedenen Gründen 
entspringen.
Diese komplementären Stärken.
Haben Sie eine Idee, was so die 
zwei Faktoren sind,
warum Menschen und Maschinen 
sich ergänzen und
warum nicht die Maschine immer 
besser
ist und nicht der Mensch immer 
besser ist?
Auf einem sehr high Level ja,
vielleicht auch mit dem 
Zusammenspiel der
zwei Systeme mit dem eins und 
zwei.
Interessante Perspektive.
Kann man so interpretieren,
dass die Maschine eher System 
zwei ist
und der Mensch sehr schnell 
heuristisch
affektiv entscheidet.
Ja, geht in einen der beiden 
Punkte,
die ich zusammenfassen möchte, 
mit ein Ja.
Ja. Ja, würde ich jetzt als ein
anderes Thema noch mal 
betrachten.
Moralität.
Wir sprechen jetzt hier wirklich 
um
Ergänzung von Fähigkeiten.
Erstmal die einbringen,",9.963281155,1,The generated answer's definition of augmentation in human-AI collaboration is semantically consistent with the ground truth.,1,"The generated answer is faithful. [cite_start]The context describes 'EntscheidungsunterstÃ¼tzung' (decision support) where the human has the final say, which aligns with the definition of augmentation provided[cite: 1215, 1217].",0.5,The context describes a mode of human-machine collaboration as 'EntscheidungsunterstÃ¼tzung' (decision support) where the human makes the final decision. It also discusses the idea of 'Mensch Maschine KomplementaritÃ¤ten' where the combined system performs better than the components. This aligns with the concept of augmentation but does not use the specific term.
What is the mean of the prediction change when considering coalitions of features?,Δ=−0.1,"Der Mittelwert der Vorhersageänderung, wenn man Feature-Koalitionen berücksichtigt, beträgt Δ=−0.1.","Also Daten sammeln über die 
letzten
Jahre deskriptive Analysen 
machen,
verstehen, was eigentlich im 
Unternehmen vor sich geht.
Aber darauf aufbauend gehen wir 
jetzt weg,
nämlich hin zu diesen 
prädiktiven Analysen,
wo wir Vorhersagen in die 
Zukunft heraus machen.
0.1 Oder Vorhersagen über Dinge,
die wir einfach nicht wissen 
aktuell.
Erinnern Sie sich mal dran Es 
geht nicht nur
rein um Zukunft.
Ja, das ist immer so ein 
bisschen vereinfacht gesagt.
Aber es geht auch darum, Sachen 
vorherzusagen,
wo ich noch nicht diese 
Information habe,
auch wenn sie theoretisch 
existiert.
Denken Sie daran, wenn Sie zum 
Arzt
gehen und der Arzt eine 
Vorhersage
über Ihre Krankheit macht,
haben Sie die Grippe oder nicht?
Haben Sie oder nicht?
In dem Moment, wo Sie zum Arzt 
gehen,
haben Sie kopiert oder nicht,
aber Sie haben die Informationen 
einfach
noch nicht im Vergleich.
Wenn wir über Aktienmärkte 
sprechen,
wenn ich den Aktienpreis morgen 
wissen möchte,
realisiert sich der Aktienpreis
morgen natürlich heute nicht 
mehr.
Und das können wir wieder 
runterbrechen
in drei verschiedene Bereiche,
wo uns diese prädiktiven 
Analysen helfen können.
Wenn Sie sich erinnern an die 
Case Study,
die wir zum Abschluss der 22. Mai 2025
Marginal contributions across coalitionsIdea:•Remove feature across all possible coalitions and compute changes in predictions•Compute a feature’s importance by marginalizing over all its contributionsSimplified example for “savings”:
21
Coalition of 3 features
Δ=−0.07
Coalitions of 2 features
Δ=−0.3
Δ=−0.02
Coalition of 1 feature
Δ=−0.01
Mean: Δ=−0.1
What is the prediction of no feature is present? availability of this data point for future model updates and potentially affecting the model ’s 
performance. This paper delves into the relationship between the continuous updating of ML models 
and algorithmic discrimination in environments where predictions endogenously influence the 
creation of new training data. Using comprehensive simulations based on secondary empirical data, 
we examine the dynamic evolution of an ML model ’s fairness and economic consequences in a 
setting that mirrors sequential interactions, such as loan approval decisions. Our findings indicate 
that continuous updating can help mitigat e algorithmic discrimination and enhance economic 
efficiency over time. Importantly, we provide evidence that human decision makers in the loop who 
possess the authority to override ML predictions may impede the self -correction of discriminatory 
models and even induce initially unbiased models to become discriminatory with time. These 
findings underscore the complex sociotechnological nature of algori thmic discrimination and 
highlight the role that humans play in addressing it when ML models undergo continuous updating.",5.786221027,1,"The generated answer provides the correct value for the mean prediction change (Î” = -0.1), which is identical to the ground truth.",1,"The generated answer is faithful. [cite_start]The context includes a diagram showing the mean of prediction changes (Î”) across different feature coalitions, which is labeled as 'Mean: Î” = -0.1'[cite: 1235].",1,The context directly states the mean of the prediction change (Î”) in the example is -0.1.
"According to the document, what is interpretability?",The ability to explain or provide the meaning in understandable terms to humans.,"Das Dokument enthält keine direkte Definition von ""Interpretierbarkeit"". Allerdings wird der Begriff implizit durch folgende Punkte hervorgehoben:

*   **Die Maschine gibt eine Vorhersage und diese Vorhersage verändert Ihre subjektive Einschätzung über die Wahrscheinlichkeit.** Dies deutet darauf hin, dass die Fähigkeit, die Gründe für eine Vorhersage zu verstehen, wichtig ist.
*   **Die Verbindung von Wahrscheinlichkeiten mit Nutzen:** Die Betrachtung des ""Expected Utility"" und die Verbindung von Wahrscheinlichkeiten mit dem, was jemand möchte oder nicht möchte, deutet auf die Notwendigkeit hin, die Faktoren zu verstehen, die diese Wahrscheinlichkeiten beeinflussen.
*   **Die Betrachtung von linearen Funktionen:** Die Verwendung von linearen Funktionen, um Wahrscheinlichkeiten zu modellieren, impliziert, dass die zugrunde liegenden Mechanismen und Beziehungen verstanden werden müssen, um diese Funktionen zu erstellen.

Zusammenfassend lässt sich sagen, dass Interpretierbarkeit im Kontext des Dokuments mit dem Verständnis der Faktoren verbunden ist, die Vorhersagen beeinflussen, und der Fähigkeit, diese Beziehungen zu modellieren.","obwohl die Leute wissen, die 
Maschine ist gut.
Das Signal unsere Prediction,
die ist wertvoll,
die sollte ich in meine 
Überlegungen mit einbeziehen.
Die ignorieren das einfach.
Riesen Phänomen.
Sehr gutes Thema für eine 
Bachelorarbeit.
Ach nee, ich wollte 
weitermachen.
Sorry. Nach der Vorlesung.
Ja, ich muss ein bisschen auf 
die Zeit achten.
Hier. Worauf ich hinaus wollte 
mit der Darstellung,
dass sich unser PC verändert,
aber nicht unser OO.
Also Sie haben weiterhin diese 
Bewertung.
Womit ich darauf hinaus möchte, 
ist die Tatsache,
dass weiterhin Platz für Sie als 
Mensch besteht.
Die Maschine gibt Ihnen
eine Vorhersage und diese 
Vorhersage
verändert Ihre subjektive
Einschätzung über die 
Wahrscheinlichkeit,
Aber sie verändert nicht,
dass sie weiterhin eigentlich 
für sich bestimmen müssen.
Wie gut finde ich denn 
eigentlich,
dass ich 15 Kriege
in diesem Fall und das 
Unternehmen 15 kriegt?
Oder dass ich zehn kriege
und das Unternehmen null kriegt?
Sie können ja zum Beispiel 
jemand sein,
der sagt Naja, mir ist es super,
super wichtig,
dass ich den Gesamtkuchen, die 
Effizienz maximiere.
Das heißt, wenn wir beide 15 
haben,
ist das relativ für sie besser 
als
in diesem Beispiel hier null und 
20. macht
die uhr die Aktion nicht.
Ich möchte eigentlich, dass es 
aufgenommen wird,
aber die uhr nimmt es nicht auf.
Und ich habe einen Nutzen,
wenn die uhr es aufnimmt und ich 
es
tatsächlich machen möchte und
jetzt von mir simplifiziert.
Für Sie kann ich natürlich hier 
einfach
diese Punkte verbinden und sagen 
naja, der Nutzen,
den ich habe von der Aktion ah,
wenn ich es nicht möchte und der 
Nutzen von der Funktion,
von der Aktion ah, wenn ich es 
eigentlich möchte,
hängt irgendwie zusammen mit der 
Wahrscheinlichkeit.
Das hier ist mein ExPected 
Utility davon.
Und genau das gleiche kann ich 
machen hier für wenn ich
etwas eigentlich nicht möchte 
meine in Aktion.
Die uhr macht etwas
nicht und ich möchte das auch 
nicht und
die uhr macht etwas nicht.
Und ich möchte das eigentlich,
wenn ich einfach diese beiden 
Endpunkte auf den
Extremen der 
Wahrscheinlichkeitsverteilung
miteinander verbinde.
Hier für Sie einfach mit einer 
linearen Funktion,
wie sie alle Mikroökonomie bei 
Uwe Walz
oder Matthias Blonski, je 
nachdem.
Dann kriege ich hier so zwei 
Funktionen,
die haben einen Schnittpunkt.
Und jetzt Mikro eins Was haben 
wir in dem Schnittpunkt?
Wir haben irgendwie eine linke 
Seite vom Schnittpunkt. implications and potential remedies. The 
British Journal of Radiology, 96(1150), Article 
20220878. 
Schelter, S., & Stoyanovich, J. (2020). Taming 
technical bias in machine learning pipelines. 
Bulletin of the Technical Committee on Data 
Engineering, 43(4), 39-50.  
Scherr, A. (2008). Diskriminierung: eine eigenständige 
Kategorie für die soziologische Analyse der (Re-) 
Produktion sozialer Ungleichheiten in der 
Einwanderungsgesellschaft? In K.-S. Rehberg 
(Ed.), Die Natur der Gesellschaft: Verhandlungen 
des 33. Kongresses der Deutschen Gesellschaft 
für Soziologie in Kassel 2006. (Vol. 1, pp. 2007-
2017). Campus.  
Schmid, T. (2021). Batch-like online learning for more 
robust hybrid artificial intelligence : 
Deconstruction as a machine learning process . 
Proceedings of the AAAI Spring Symposium: 
Combining Machine Learning with Knowledge 
Engineering.  
Shaikh, M., & Vaast, E. (2022). Algorithmic 
Interactions in Open Source Work. Information 
Systems Research, 34(2), 744-765. 
Shrestha, Y. R., Ben-Menahem, S. M., & Von Krogh, 
G. (2019). Organizational decision -making 
structures in the age of artificial intelligence. 
California Management Review, 61(4), 66-83.  
Shrestha, Y. R., & Yang, Y. (2019). Fairness in",19.44704199,0,The generated answer incorrectly claims the document does not define 'interpretability.' The ground truth provides the correct definition.,0,The generated answer is unfaithful. The context discusses the need to understand the factors influencing predictions but does not provide a formal definition of 'interpretability' as the ability to explain or provide meaning.,0,"The context discusses the role of a machine's prediction in changing a human's subjective assessment of probabilities. However, it does not provide a formal definition of interpretability."
What does the EU AI Act Art 86 demand?,Right to Explanation of Individual Decision-Making.,"Artikel 86 der EU AI-Verordnung verlangt, dass jede Person, die von einer Entscheidung betroffen ist, die von einem Betreiber aufgrund der Ausgabe eines Hochrisiko-KI-Systems gemäß Anhang III getroffen wurde und die Rechtsfolgen hat oder diese Person in einer Weise erheblich beeinflusst, die sie als nachteilig für ihre Gesundheit, Sicherheit oder Grundrechte ansieht, das Recht hat, vom Betreiber klare und aussagekräftige Erklärungen über die Rolle des KI-Systems im Entscheidungsprozess und die Hauptmerkmale der getroffenen Entscheidung zu erhalten.","22. Mai 2025
EU AI act
10 ethics, and responsibility in AI (Zuiderveen Borgesius,2020). The
Organization for Economic Cooperation and Development
(OECD) has provided recommendations on AI, while the
European Commission has drafted proposals regarding
the inﬂuence of algorithmic systems on human rights. In 2019,
the European Commission established a high-level expert group
on AI, which proposed ethical guidelines and self-regulatory
measures regarding AI and ethics.
Public organizations have played a role in establishing
mechanisms to safeguard algorithmic fairness. The Algorithm
Justice League (AJL) has outlined vital behaviors companies
should follow in a signable agreement. Holding accountable those
who design and deploy algorithms improves existing algorithms
in practice (36KE,2020). After evaluating IBM’s algorithm, AJL
provided feedback, and IBM responded promptly, stating that
they would address the identi ﬁed issue. As a result, IBM
signiﬁcantly improved the accuracy of its algorithm in minority
facial identiﬁcation.
Data protection and non-discrimination laws safeguard against
discriminatory practices in algorithmic decision-making. In the
EU region, Article 14 of the European Convention on Human 22. Mai 2025
Regulatory problem!
General Data Protection Regulation (GDPR) in the EU demands “transparent [data] processing” and a “right to explanation” EU AI Act Art 86: Right to Explanation of Individual Decision-Making“Any affected person subject to a decision which is taken by the deployer on the basis of the output from a high-risk AI system listed in Annex III, […] produces legal effects or similarly significantly affects that person in a way that they consider to have an adverse impact on their health, safety or fundamental rights shall have the right to obtain from the deployer clear and meaningful explanations of the role of the AI systemin the decision-making procedure and the main elements of the decision taken.”
9",10.70886517,1,The generated answer and the ground truth both correctly state that Article 86 of the EU AI Act demands a 'Right to Explanation of Individual Decision-Making'.,1,"The generated answer is faithful. [cite_start]The context explicitly states the text of the EU AI Act Art 86, which includes the 'Right to Explanation of Individual Decision-Making'[cite: 1284, 1285].",1,"The context provides the full text of Article 86 of the EU AI Act, which outlines the 'Right to Explanation of Individual Decision-Making'."
What is a 'selective labels problem'?,It occurs when a machine learning model's prediction influences decisions that prevent the collection of data needed to evaluate the model's accuracy.,"According to the text, the ""selective labels problem"" arises when a system (like a machine learning model) tries to create its own labels. Here's a breakdown of the issue:

*   **Self-Supervised Learning:** The system attempts to predict labels itself, based on the other words in a sentence.
*   **Error Accumulation:** If the system makes incorrect predictions and creates ""noisy"" labels, these errors aren't just isolated. Instead, the machine learning model learns these new, incorrect patterns, and these errors accumulate over time, leading to a compounding effect. 

In essence, the problem is that the system's self-generated labels are prone to error, and these errors can worsen as the system continues to learn.","die nicht zugedeckt sind aus dem 
Satz
und ich habe mir das als Label 
auserkoren.
Und ich versuche selber 
vorherzusagen,
basierend alle anderen Wörter,
was eigentlich das zugedeckte 
Wort ist.
Das nennt man self supervised 
learning.
Wann immer ich kein eigenes 
direktes Label habe,
bin ich eigentlich in
einem Bereich von sogenannten 
Supervised Learning
und supervised geht so
ein bisschen zwischen 
Supervising and sbeweis,
Supervisory Labels haben und 
dann zu beweisen,
dass sie keine haben und nur 
Strukturen erkennen möchten.
Und self supervised ist dann 
sozusagen die Mitte,
wo das System selber sagt
Ich suche mir das als Label aus 
und nehme alles andere,
um das Ausgesuchte 
vorherzusagen.
Geht in die Richtung.
Per se ist es natürlich 
problematisch,
weil wir, wenn die Maschinen 
Fehler machen,
in dem Labeling verfahren
und in diesem selbst zu 
beweisen,
die Fehler relativ gering,
weil es eben was technisches 
ist.
Wenn ich aber selber eine 
Vorhersage mache,
wie ich etwas labeln möchte und 
da Fehler drin sind,
dann lernt die Maschine,
die trainiert wird, letztlich 
neue
Fehler und dann akkumulieren
sich diese Fehler und wir reden
von einem Compounding Effekt.
Das heißt so mehr noisy
einfügen und da kann man drüber ** p < 0.05, *** p < 0.01 denote statistical significance levels. 
The Role of Ongoing Human Discrimination: Figures 
Plots for Male Borrowers 
 
Note: We illustrate how the mean share of positive predictions for male borrowers in Iterations 1 and 100 depends on the initial label imbalance 
in the training data and the degree of human discrimination by the investor. A comparison of panels for Iterations 1 and 100 for the two measures 
of algorithmic discrimination provides insights into their conditional development across iterations. Abbreviations: Share pos. predictions =  
share of positive predictions; Init. lab. imb. = initial label imbalance; Human discr. = human discrimination. 
Figure A7. Development of the Mean Share of Positive Predictions by Initial Label Imbalance  
and Degree of Human Discrimination case the borrower is male. A comparison of panels for Iterations 1 and 100 for the two measures of algorithmic discrimination provides insights 
into their conditional development across iterations. Abbreviations: Outcome under perf. inf. = outcome under perfect information; Init. lab. imb. 
= initial label imbalance; Human discr. = human discrimination. 
Figure A9. Development of the Mean Share of Game Outcomes by Initial Label Imbalance  
and Degree of Human Discrimination",13.0373857,0,"The generated answer describes a 'compounding effect' of errors from self-labeling, which is different from the ground truth's definition of a 'selective labels problem' (where the model's predictions prevent the collection of evaluation data).",1,"The generated answer is faithful. [cite_start]The context describes 'self supervised learning' where a machine creates its own labels, and warns that if the machine makes errors in this process, the errors accumulate and compound because the machine learns from its own faulty data[cite: 1295, 1296].",1,"The context explains the problem through the concept of 'self-supervised learning,' where a machine creates its own labels. It states that if the machine makes errors in this process, the errors accumulate, and the machine learns these new errors, leading to a 'compounding effect', which matches the description of the selective labels problem."
"According to the text, what is one way to control for gender when analyzing a dataset?","By running the dataset through without including gender, but then rerunning it while including gender to compare performance.","Basierend auf dem bereitgestellten Text gibt es mehrere Möglichkeiten, wie man das Geschlecht bei der Analyse eines Datensatzes berücksichtigen kann, wobei jede Methode ihre eigenen Herausforderungen und Implikationen hat:

1.  **Geschlechtsmerkmale explizit einbeziehen:** Der Text betont, dass selbst wenn das Geschlecht nicht explizit in das System eingegeben wird (wie im Beispiel von Amazon), das System dennoch aufgrund anderer Faktoren (z.B. Korrelationen) Geschlechterdiskriminierung reproduzieren kann.

2.  **Tests mit Geschlechtsgruppen:** Um dies zu erkennen, kann man Tests durchführen, um die Vorhersagegenauigkeit für verschiedene Geschlechtsgruppen (z.B. Männer, Frauen, nonbinär) bei gleichen Qualifikationen zu vergleichen.  Wie im Beispiel, kann man feststellen, dass Frauen systematisch schlechtere Ergebnisse erzielen.

3.  **Berücksichtigung von unrepräsentativen Daten:** Der Text weist darauf hin, dass unbalancierte Datensätze, in denen bestimmte Gruppen (z.B. Frauen) unterrepräsentiert sind, zu Fehlvorhersagen führen können.

4.  **Auseinandersetzung mit technischen Einschränkungen:** Der Text weist darauf hin, dass Bias auch aus technischen Einschränkungen während der Modellentwicklung entstehen kann.

**Wichtig:** Der Text warnt davor, dass selbst wenn man das Geschlecht nicht explizit in das System einfügt, das System dennoch diskriminierende Ergebnisse erzeugen kann. Es ist entscheidend, die potenziellen Auswirkungen von Bias zu erkennen und zu minimieren.

Ich hoffe, diese Zusammenfassung des Textes hilft Ihnen weiter!","Datensatz,
in dem man alles angibt,
außer das Geschlecht und lässt 
das durchlaufen.
Aber hierbei würden sie Gender 
mit rein nehmen.
Also in einem ersten Schritt,
um das zu kontrollieren.
Genau in diesem Beispiel von dem 
Amazon,
das haben Sie schon richtig 
erfasst,
war es so die haben Gender 
rausgelassen,
hatten aber eine Spalte im 
Datensatz,
wo Gender noch drin war,
haben die Maschine dann
basierend auf allen Features 
außer Gender die
Vorhersage machen lassen und 
konnten dann natürlich
innerhalb ihrer Daten trotzdem 
vergleichen.
Wie ist die Performance dort in 
den Einträgen,
wo wir Männer,
Frauen nonbinär hatten und haben 
das dann verglichen?
Praktisch ja.
Aber es gibt viele Argumente 
dafür,
dass wir diese Features, die 
protected sind,
dass wir eigentlich größere 
Probleme erzeugen,
wenn wir sie den Maschinen nicht 
zur Verfügung stellen,
weil diese Maschinen so mächtig 
sind,
Korrelationen herauszufinden,
die letztlich ablesen lassen,
ob es welches Geschlecht es ist 
und das implizit lernen.
Und das ist sehr, sehr, sehr 
versteckt ist,
wo eigentlich jetzt eine 
Diskriminierung herkommt.
Wenn wir es aber drin lassen,
gibt es bestimmte Methoden, das 
direkt abzulesen.
Aber die Frage was will man denn 
da, data (Friedman & Nissenbaum, 1996; Romei & Ruggieri, 
2013; Kleinberg et al., 2018). For example, if a training 
dataset holds more positively labeled examples for men, 
the ML model may predict positive labels less accurately 
for women. Second, it can be created by unrepresentative, 
or imbalanced data (Barocas & Selbst, 2016; Mehrabi et 
al., 2021). When the dataset underrepresents certain 
groups, such as women, the ML model can make more 
errors when predicting for this group. Imbalances occur 
when labels skew significantly within specific subgroups. 
Third, technical constraints or malpractices during model 
development and training may yield discriminatory 
outputs (Friedman & Nissenbaum, 1996; Williams et al., 
2018). Biases may emerge during data integration due to 
inconsistent data formats or when the integration of 
personal information like ethnicity is mishandled (Schelter 
& Stoyanovich, 2020; Williams et al., 2018). It is critical 
to appreciate the sociotechnological nature of algorithmic 
discrimination (Favaretto et al., 2019; Kordzadeh & 
Ghasemaghaei, 2022). The social component often 
originates from societal and economic structural biases, 
which can foster the differential treatment and gesagt Na ja,
per Gesetz dürfen wir nicht auf 
Gender gucken.
Was also gemacht wurde,
ist man hat die Gendermerkmale,
also die selbst angegebenen 
Geschlecht.
Geschlechtsidentifikation hat 
man rausgenommen.
Es war also nicht Teil des 
Systems.
Trotzdem in diesem Testbereich,
wenn wir in dem Crisp an 
Evaluation denken,
bevor das System wirklich live 
gegangen
ist und massiv eben angefangen 
hat,
die neue Einstellungskriterien 
zu beeinflussen,
haben bestimmte Tests gezeigt.
Naja, obwohl ich nicht angegeben 
habe,
ob diese Person, obwohl das 
Modell nicht in der Lage war,
auf Informationen über die
Geschlechtsidentifikation diese 
Person zuzugreifen,
hat das System systematisch
bei Frauen eine geringere 
Wahrscheinlichkeit ausgespuckt.
Woher kann das kommen? Was 
denken Sie?
Ich habe nicht dem Modell Zugang 
zu dem
eigentlichen 
Genderidentification gegeben
und trotzdem in Tests.
Wenn ich dann gesagt habe, naja,
wie hoch ist denn die 
Vorhersagegenauigkeit für 
Frauen,
wie hoch ist denn für Männer?
Wurde dann gesehen,
dass sie für Frauen systematisch
bei gleichen Qualifikationen
systematisch schlechter war.
Woher kann das kommen,
dass das System das trotzdem 
erkannt hat oder
diesen Bias reproduziert hat,",27.90611434,1,The generated answer's description of controlling for gender by running analyses with and without the gender variable is semantically consistent with the ground truth.,1,"The generated answer is faithful. [cite_start]The context describes a process where gender is left out of the feature set for training, but then the model's performance is compared across groups (men, women, nonbinary) using a separate column where gender was kept, which matches the generation's claim[cite: 1313, 1314].",1,"The context explains that in the Amazon hiring tool example, gender was removed as a feature, but the system's performance was still compared across gender groups by looking at the original data where gender was known ."
"According to the text, what is one way large language models can exhibit biased tendencies?",They have been optimized to be overly agreeable and to 'say yes to everything.'.,"Laut dem Text zeigen große Sprachmodelle voreingenommene Tendenzen, weil sie in ihren Trainingsdaten stark von linksgerichteten Inhalten beeinflusst sind, insbesondere durch Wikipedia und andere Internetquellen. Außerdem können die Personen, die die Modelle entwickeln, eigene Überzeugungen haben, die sich in den Modellen widerspiegeln.
","sich nichts vormachen
und das ist eine Sache,
das würde ich jetzt per se 
erstmal nicht,
wenn wir über GPT sprechen,
wenn sie es sehen, ist nicht per 
se Bias,
Es ist ein Fehlverhalten.
Es wurde in eine bestimmte 
Richtung
gedrückt durch bestimmte 
Optimierungsverfahren,
Wenn Sie an Medien
und an politische Einstellungen 
denken.
Es gibt sehr viele Evidenzen 
dafür,
dass viele große Sprachmodelle
eher linksgerichtet sind in 
ihren Antworten.
Dass diese Modelle, wenn man zum 
Beispiel die den
Wahl O Mat mit Chat GPT macht,
dann kommt er raus,
dass Chat Gpt die Meinungen der 
Grünen,
der Linken und der SPD 
unterstützt weniger von den
rechtsgerichteten und 
rechtsradikalen Ansichten.
Was können Sie denken, woran das 
liegt?
Es liegt an den Trainingsdaten. 
Schöne Frage.
Erstmal eine Frage beantworten,
dann können Sie eine Frage 
stellen.
Wahrscheinlich, weil die 
Personen, die dahinter stehen,
die das entwickelt haben,
all diese Überzeugungen haben.
Unklar. Tatsächlich könnte ein 
Faktor sein.
Stimme ich zu.
Problem scheint eher zu sein, 
dass viel aus dem Internet.
Wikipedia ist massiv 
linksgerichtet.
Das hat er diese left leaning 
tendencies.
Auch wieder ein historisches 
Wachstum bestimmter
Tendenzen und Ansichten. eine Prediction zu machen, sind 
massiv gering.
Ja, das ist fast ignorierbar.
Außer wenn wir natürlich 
wirklich
über große Sprachmodelle reden,
wo Milliarden von Menschen jeden
Tag riesige Texte da 
reinknallen.
Aber die marginale Beitrag,
dass sie eine Vorhersage machen 
oder
auch die marginale Beitrag von 
einer weiteren Callum,
einem weiteren Wort in
dem Datensatz, ist vollkommen 
ignorierbar.
Das ist wieder die Masse, die es 
letztlich macht.
Ja, und in dem Fall von Demogons 
Razor
sprechen wir nicht davon,
einen Parameter mehr,
sondern tausende von Parametern 
mehr.
Deswegen ist es für unsere
PC's und auch für die 
Entscheidung,
welche Modelle Unternehmen 
einsetzen,
ob sie bei tabularen Daten immer 
an der Stelle gesagt,
ob ich jetzt einen Random Forest 
einsetze
mit 10.000 Bäumen oder ich
nehme einen ein neuronales 
Netzwerk mit 20 Layern.
Der Verbrauch der Energie ist 
für zumindest Predictions
über Kreditwürdigkeit 
ignorierbar unterschiedlich.
Ich kann Sie an entsprechende 
Quellen verlinken.
Dann frage ich mich, wenn ich 
das.
Wenn ich dieses Argument 
beziehe,
auf das Training des Modells,
dann kann ich ja noch nicht 
werten.
Bevor ich es trainiere, kann ich 
nicht vorhersehen,
ob die zusätzlichen Parameter 
wie ein sehr versteckt eigentlich 
bestimmte diskriminierende
Verhalten auftreten können,
weil wir einfach nicht alle 
diese Measures hier benutzen.
Grundsätzlich können wir aber
zwischen zwei verschiedenen 
Arten
dieser Measurements 
unterscheiden.
Auf der einen Seite nehmen wir 
uns
auf dem Individuen individuellen 
Level angucken.
Wenn wir uns nur in einer 
Dimension
unterscheiden und diese 
Dimension protected ist,
dann sollten unsere Vorhersagen 
möglichst ähnlich sein.
Oder wir gucken uns als Gruppen 
an,
das heißt, es kann bei uns
individuell unterschiedlich 
sein.
Wenn sich aber die 
Studierendengruppe verglichen 
mit
den Professorengruppen alles 
identisch wäre,
außer an dieser Eigenschaft,
dann würden wir im Aggregat 
zumindest erwarten,
dass sich im Durchschnitt diese
bestimmte Prediction Performance 
nicht unterscheidet.
Und umso höher ich im Aggregat 
bin,
umso tiefer versteckt kann
natürlich irgendwelche 
diskriminatorischen Muster
immer noch sein und
über spezielle Beispiele jetzt 
mal sprechen.
So müssen Sie immer über 
Diskriminierung in
Algorithmen nachdenken oder über 
Fairness.
Wir haben einen bestimmten 
Outcome,
nämlich unser Y, das unsere 
Underlying Truth,
ob jemand kreditwürdig ist oder 
nicht.",9.83528614,0,The generated answer incorrectly attributes bias to the models being influenced by left-leaning content. The ground truth provides a different reason: the models have been optimized to be 'overly agreeable'.,0,"The generated answer is unfaithful. [cite_start]The context suggests that large language models may have a left-leaning bias due to their training data (e.g., from Wikipedia)[cite: 1337, 1341]. It does not make the claim that they are optimized to be 'overly agreeable' or to 'say yes to everything'.",1,"The context directly addresses the question, stating there is evidence that many large language models are 'eher linksgerichtet' (more left-leaning) in their answers because their training data, such as Wikipedia, has 'left leaning tendencies'."
What did Google do to address concerns about the representation of nurses in image search results?,Google filtered the results so that both men and women are shown when 'nurse' is entered.,"According to the text, Google has made changes to address the issue of predominantly female nurse image search results. Initially, searches for ""krankenpfleger"" (nurse) showed 99% female results. However, as of two years prior, the system still exhibited this bias. 

More recently, Google has begun to filter results to show both men and women as nurses. This change was driven by PR issues and the need for significant investment in data cleaning.","Das hat Google jetzt anscheinend 
durch Filter so gemacht,
dass wenn man Krankenpfleger 
eingibt,
dass sowohl Männer und Frauen 
gezeigt werden.
Aber bis vor zwei Jahren war
es immer noch ein sehr gutes 
Beispiel.
Wenn ich Sie frage, googeln Sie 
mal bitte nach Images.
Dann war Krankenpfleger zu 99 %
weiblich und Arzt zu 99 % 
männlich,
obwohl diese Bilder natürlich 
von beiden
eigentlich schon vorhanden sein 
sollen.
Das heißt, wir haben hier
irgendwelche gewachsenen 
technischen Grundlagen,
Datenbanken, die das einfach 
noch nicht abbilden können.
Having said that, die 
Unternehmen sind
sehr sensibilisiert durch diese 
ganzen PR Probleme,
die sie damit erlitten haben und 
haben angefangen,
diese Daten zu bereinigen.
Aber das erfordert eben massiv 
viel Investitionen
in Datenbereinigung,
wo wir wieder in dem 
Kriegsmodell,
bei dem Data Preparation sind.
Sie müssen sich klar sein Wie 
sind
Ihre Strukturen der Daten 
eigentlich aufgebaut?
Soweit ich weiß es auch manchmal
das Labeling von Menschen 
gemacht.
Richtig? Genau. Es könnte so 
sein,
dass wir haben eine Gruppe von 
Menschen,
die nicht politisch korrekt 
denken.
Und dann würden sie es bewusst 
falsch.
Richtig. Auch ein massives 
Problem.
Wir haben auf der einen Seite reﬂect the opinions of those who create them. The persistent
underrepresentation of women, African-Americans, and Latino
professionals in the IT workforce leads to biased algorithms. For
instance, a study in 2019 found that only 2.5% of Google ’s
employees were black, while Microsoft and Facebook had only 4%
representation. Another study revealed that 80% of AI professors
in 2018 were male. Involving diverse individuals in data collection
HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS | https://doi.org/10.1057/s41599-023-02079-x REVIEW ARTICLE
HUMANITIES AND SOCIAL SCIENCES COMMUNICATIONS|          (2023) 10:567 | https://doi.org/10.1057/s41599-023-02079-x 7 in discrimination (Miasato and Silva,2019).
Furthermore, personal biases can manifest in the selection of
data characteristics. For example, engineers may prioritize speciﬁc
features or variables based on how they want the machine to
behave (Miasato and Silva, 2019)). The Amazon hiring case
illustrates this, where engineers considered education, occupation,
and gender when assigning labels to the algorithm. When gender
is considered the crucial criterion, it inﬂ
uences how the algorithm
responds to the data.
Theme III. Which algorithmic recruitment discrimination
exists
In the recruitment process, algorithmic bias can be manifested in
terms of gender, race, color, and personality.
Gender. Gender stereotypes have inﬁltrated the “lexical embed-
ding framework” utilized in natural language processing (NLP)
techniques and machine learning (ML). Munson ’s research
indicates that “occupational picture search outcomes slightly
exaggerate gender stereotypes, portraying minority-gender occu-
pations as less professional”((Avery et al.,2023; Kay et al.,2015).
The impact of gender stereotypes on AI hiring poses genuine
risks (Beneduce,2020). In 2014, Amazon developed an ML-based
hiring tool, but it exhibited gender bias. The system did not",10.97064114,1,"The generated answer correctly states that Google filtered image search results for 'nurse' to show both men and women, which is semantically identical to the ground truth.",1,"The generated answer is faithful. [cite_start]The context states that Google applied filters to its image search so that when one enters 'Krankenpfleger' (nurse), 'sowohl MÃ¤nner und Frauen gezeigt werden' (both men and women are shown)[cite: 1359].",1,"The context directly answers the question, stating that Google implemented filters so that when one searches for 'Krankenpfleger' (nurse), 'sowohl MÃ¤nner und Frauen gezeigt werden' (both men and women are shown)."
"According to the document, what was the reason Amazon's AI recruitment system discriminated against women?","It recognized correlations between hobbies, universities attended, and gender due to historical data showing fewer women attending certain universities and pursuing technical fields.","Laut dem Text wurde Amazons KI-Recrutierungssystem Frauen diskriminiert, weil es auf überwiegend männlichen Bewerbungsunterlagen trainiert wurde.","Datensatz,
in dem man alles angibt,
außer das Geschlecht und lässt 
das durchlaufen.
Aber hierbei würden sie Gender 
mit rein nehmen.
Also in einem ersten Schritt,
um das zu kontrollieren.
Genau in diesem Beispiel von dem 
Amazon,
das haben Sie schon richtig 
erfasst,
war es so die haben Gender 
rausgelassen,
hatten aber eine Spalte im 
Datensatz,
wo Gender noch drin war,
haben die Maschine dann
basierend auf allen Features 
außer Gender die
Vorhersage machen lassen und 
konnten dann natürlich
innerhalb ihrer Daten trotzdem 
vergleichen.
Wie ist die Performance dort in 
den Einträgen,
wo wir Männer,
Frauen nonbinär hatten und haben 
das dann verglichen?
Praktisch ja.
Aber es gibt viele Argumente 
dafür,
dass wir diese Features, die 
protected sind,
dass wir eigentlich größere 
Probleme erzeugen,
wenn wir sie den Maschinen nicht 
zur Verfügung stellen,
weil diese Maschinen so mächtig 
sind,
Korrelationen herauszufinden,
die letztlich ablesen lassen,
ob es welches Geschlecht es ist 
und das implizit lernen.
Und das ist sehr, sehr, sehr 
versteckt ist,
wo eigentlich jetzt eine 
Diskriminierung herkommt.
Wenn wir es aber drin lassen,
gibt es bestimmte Methoden, das 
direkt abzulesen.
Aber die Frage was will man denn 
da, und das implizit lernen.
Und das ist sehr, sehr, sehr 
versteckt ist,
wo eigentlich jetzt eine 
Diskriminierung herkommt.
Wenn wir es aber drin lassen,
gibt es bestimmte Methoden, das 
direkt abzulesen.
Aber die Frage was will man denn 
da,
um das zu prüfen?
Alle anderen Faktoren, die
dieses Modell reingehen, 
funktionieren,
weil sonst könnte man ja die
Aussage eigentlich treffen 
Genau,
Sie würden sie würden die 
trainierte Maschine nehmen,
würden Vorhersagen machen für 
alle
Frauen im Raum, für alle Männer 
im Raum,
für alle nonbinäre Gender im
Raum und würden das dann im 
Aggregat hierbei.
Deswegen reden wir über dieses 
Group Fairness Vergleich.
Hierbei. Jetzt haben wir die 
Equal Opportunity.
Schauen Sie sich an, wir haben 
hier die
Wahrscheinlichkeit, dass 
vorhergesagt wird,
jemand ist kreditwürdig,
obwohl diese Person eigentlich 
nicht kreditwürdig ist.
Vorhersage ist eins True Outcome
ist null für alle Personen im 
Raum,
die das weibliche Geschlecht
haben und dass diese Fehlerrate,
weil wir sprechen ja hier von 
der
Vorhersage eins und ist 
eigentlich null.
Das heißt, wir machen eine 
falsche Vorhersage,
dass dieser Fehler,
dieser false positive. Ich sage, 
es ist positiv.
Eigentlich ist es negativ, The impact of gender stereotypes on AI hiring poses genuine
risks (Beneduce,2020). In 2014, Amazon developed an ML-based
hiring tool, but it exhibited gender bias. The system did not
classify candidates neutrally for gender (Miasato and Silva,2019).
The bias stemmed from training the AI system on predominantly
male employees ’ CVs (Beneduce, 2020). Accordingly, the
recruitment algorithm perceived this biased model as indicative
of success, resulting in discrimination against female applicants
(Langenkamp et al. 2019). The algorithm even downgraded
applicants with keywords such as “female” (Faragher, 2019).
These ﬁndings compelled Amazon to withdraw the tool and
develop a new unbiased algorithm. However, this discrimination
was inadvertent, revealing theﬂaws inherent in algorithmic bias
that perpetuates existing gender inequalities and social biases
(O’neil, 2016).
Race. Microsoft’s chatbot Tay learned to produce sexist and racist
remarks on Twitter. By interacting with users on the platform,
Tay absorbed the natural form of human language, using human
tweets as its training data. Unfortunately, the innocent chatbot
quickly adopted hate speech targeting women and black indivi-",7.334885836,0,The generated answer claims the AI recognized correlations between hobbies and gender. The ground truth gives a different reason: the system was trained predominantly on male rÃ©sumÃ©s.,1,The generated answer is faithful. [cite_start]The context explains that Amazon's biased hiring tool 'stemmed from training the AI system on predominantly male employeesâ€™ CVs'[cite: 1400].,0,The context discusses how Amazon's AI hiring tool was biased because it was trained on predominantly male CVs. It does not mention the system recognizing correlations with hobbies or universities.
"According to the lecture, what is the CRISP-DM model and what is its first and most important step?","The CRISP-DM (Cross-Industry Standard Process for Data Mining) is a blueprint for developing machine learning applications. Its first and most important step is Business Understanding, which involves clearly defining the business problem you are trying to solve.","Nein, laut dem Text ist der erste, wichtigste Schritt im CRISP-DM-Modell die „Definition des Problems“ nicht. Der Text beschreibt, dass der erste Schritt die „Business Understanding“ ist, d.h. das Verständnis des Geschäftsproblems und die Definition der Vorhersageziele.","15. Mai 2025
Structuring an AI project: CRISP-DM 
6
1. Business Understanding2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment
Data 
Cross Industry Standard Process for Data Mining 15. Mai 2025
Overview CRISP-DM
9 bekommen,
was diese Daten alles bedeuten.
Sie haben bei mir in der im 
Seminar
gesessen letztes Semester diese 
Daten,
die Sie da erhalten haben, von 
der Firma.
Totales Chaos.
Muss man sich erstmal reindenken 
und
das braucht massiv viel Zeit.
Wenn wir aber dann die Daten 
sauber gemacht haben,
dann geht es endlich an den,
den sag ich mal aus meiner
Sicht coolsten Teil dieses 
Prozesses, wo wir versuchen,
das anfänglich definierte 
Vorhersageproblem
durch Modelle zu lösen.
Hier passiert jetzt in
Anführungsstrichen eigentlich 
die Magic,
Hier haben wir unsere 
Algorithmen,
hier haben wir unsere 
verschiedenen Modelle,
die wir alle ausprobieren,
um zu sehen,
wie können wir denn
eigentlich aus den Daten, die 
wir haben,
unsere Features,
eine möglichst genaue Vorhersage 
über
diesen Teil der Daten,
unser Outcome, unser Label?
Was nutzen wir da?
Welche Modellarchitektur,
um möglichst out of sample gute 
Vorhersagen zu machen?
Wir trainieren dieses Modell und 
in
den meisten Fällen dauert es 
Trainieren
selber gar nicht lange und
wir können sehr viele Kniffe 
benutzen,
wie wir dieses diesen
Trainingsprozess in einer 
gewissen Art
und Weise automatisieren können,
indem wir zum Beispiel
die Modellstruktur, die 
Modellauswahl,",8.773126602,0,The generated answer incorrectly identifies the first step as 'Definition of the problem.' The ground truth correctly identifies the first and most important step as 'Business Understanding'.,0,The generated answer is unfaithful. [cite_start]The context states that the first step is 'Business Understanding'[cite: 1410]. It does not mention that the first and most important step is 'Definition of the problem'.,1,"The context explicitly states that the first step of the CRISP-DM process is 'Business Understanding', and later clarifies this involves identifying the business problem to be solved and defining prediction goals."
The lecture describes three levels of integrating machine learning solutions into an organization. What is a 'System Solution' (the third level)?,"A 'System Solution' is the deepest level of integration, where machine learning fundamentally changes the entire organizational structure and business model, requiring a complete rethinking of processes. The example given is Amazon's 'Anticipatory Shipping' patent.","Laut der Vorlesung ist eine „Systemlösung“ (das dritte Level) eine „umfassende, integrierte Reihe von Anwendungen und Technologien, die zusammenarbeiten, um komplexe, unternehmensweite Probleme zu lösen.“ Sie ist breit gefächert, auf Unternehmensniveau und hoch integriert.
","Systemen
wissen, könnte es sein,
dass Menschen ihre Art und 
Weise,
sich zu verhalten, ändern,
um dieses das System 
auszutricksen,
indem bestimmte neue 
Fachbegriffe,
wo man denkt, das ist, wo die 
Maschine drauf anspricht.
In die Vorhersage oder in
sein Bewerbungsschreiben mit 
rein tut,
damit das System dort eben
was erkennt und eine bessere 
Vorhersage macht,
kommen wir später noch zu.
Ist das für Sie in Ordnung? 
Cool. Andere Fragen.
Dann haben wir die dritte Ebene.
Und das ist dort eigentlich,
wo alle Unternehmen gerne hin 
möchten.
Hier, das sind Quick Wins,
wo ich etwas einführen kann.
Und das ist meistens auch der 
erste Schritt.
Ich fange an, einzelne Sachen zu 
ersetzen,
einzelne Sachen besser zu 
machen.
Dann gehe ich hin und verändere 
meine Arbeitsprozesse.
Und dann haben wir aber die 
sogenannten Systemlösungen,
die dazu führen können, dass 
sich die
gesamte Organisationsstruktur 
ändern muss.
In diesen Lösungen haben wir 
neue Businessmodelle.
Wir müssen die gesamte 
Organisation neu denken.
Einführung von großen 
Sprachmodellen Kann
ich einen anderen Service 
anbieten?
Sind bestimmte Prozesse, die
vorher durchgeführt werden 
mussten,
in bestimmten Workflows komplett 
redundant geworden?
Kann ich das alles hinzubekommen.
Und auf der einen Seite immer
diese technische Perspektive auf 
die Systeme,
die müssen ausreichend 
performant und gut sein.
Aber wir brauchen eben auch
diese Einbettung der Systeme der
technischen Systeme in das Sozio 
system.
Deswegen sprechen wir 
grundsätzlich dann
von diesen soziotechnischen 
Systemen,
wo diese Systeme wirklich 
genutzt
werden und letztlich 
Veränderungen hervorrufen.
Und viel davon passiert eben 
hier
Information Systems auf Deutsch 
aus
der Perspektive der 
Wirtschaftsinformatik.
Was immer so eine 
Schnittstellendisziplin ist,
wo wir aus ganz verschiedenen 
Blickwinkeln Psychologie,
Management, Ökonomie,
Verhaltensökonomie, Neurologie
auf diese Phänomene draufgucken,
wie tatsächlich Menschen, 
Organisationen,
soziale Systeme mit
diesen technischen Systemen 
interagieren.
Und in diesem Sinne, ich denke, 
diejenigen,
die Wirtschaftsinformatik ich 
weiß gar nicht,
wer es gerade gibt,
Peter oder Olli, einer meiner 
Kollegen der Abteilung.
Wenn Sie Wirtschaftsinformatik 
eins
oder zwei besucht haben,
werden Sie bestimmt schon mal 
über das Unified,
also Unified Theory of 
Acceptance
and Use of Technology gehört 
haben.
Wer hier hat das in der 
Vorlesung schon mal gesehen? System solutions•Definition:Comprehensive, integrated set of applications and technologies that work together to address complex, organization-wide problems.•Scope:Broad; enterprise-level•Integration:Highly integrated with multiple components and data flows.•Use case:Innovation must transform or optimize an entire organization•Example:Amazon’s “Ship then Shop” (Prediction + Inventory + Logistics + …)",8.345616102,1,The generated answer's definition of a 'System Solution' is semantically consistent with the ground truth.,1,"The generated answer is faithful. [cite_start]The context defines system solutions as being able to change the 'gesamte Organisationsstruktur' (entire organizational structure) and requiring the organization to be rethought, which aligns with the generation's claims[cite: 1424, 1425].",1,"The context provides a clear definition of a system solution as a level of integration where the entire organizational structure and business model may need to change , and it gives Amazon's 'Ship then Shop' concept as the example."
"According to the text, what is one thing machine learning models currently cannot do?",Machine learning models currently cannot provide a valuation of the consequences of a particular state of the world.,"Laut dem Text können aktuelle Machine-Learning-Modelle nicht:

*   **Mit unstrukturierten Daten umgehen:** Sie benötigen eine große Menge an Datenvorarbeitung.
*   **Kleinste Details in den Daten berücksichtigen:** Neuronale Netze reagieren sehr empfindlich auf kleine Unterschiede in den Daten und müssen diese standardisieren.
*   **Die Daten auf eine bestimmte Weise sampeln:** Es ist notwendig, bestimmte Beobachtungen auszuwählen oder auszuschließen.","Sie müssen das sauber machen.
Maschinen, wie wir sehen werden,
können nicht mit 
unstrukturierten
Daten wie Wörtern einfach so 
umgehen.
Wir haben ganz viel 
Datenvorarbeit zu betreiben
und es gibt bestimmte Machine 
Learning Modelle,
die sind sehr schön,
die viel dieser Arbeit durch
bestimmte algorithmische 
Lernverfahren abfangen.
Zum Beispiel der 
Entscheidungsbaum
oder auch der Random Forest.
Aber es gibt andere Methoden und 
insbesondere die
most sophisticated Methoden wie 
neuronale Netze,
die auf jede Kleinigkeit in
den Daten massiv sensitiv 
reagieren,
müssen Daten standardisieren.
Wir müssen auf eine bestimmte 
Art und
Weise sampeln müssen
bestimmte Observationen 
rausschmeißen.
All das, wie Sie hier sehen,
braucht ungefähr 60 bis
80 % der Zeit eines solchen Data 
Science Projekts.
Es ist teilweise über Wochen, 
Monate.
Wenn wir Daten von Unternehmen 
bekommen,
mit denen wir zusammenarbeiten,
um Forschungsprojekte zu machen,
dass wir erst mal eine Idee 
bekommen,
was diese Daten alles bedeuten.
Sie haben bei mir in der im 
Seminar
gesessen letztes Semester diese 
Daten,
die Sie da erhalten haben, von 
der Firma.
Totales Chaos.
Muss man sich erstmal reindenken 
und
das braucht massiv viel Zeit. Stelle sein.
Sie müssen also identifizieren 
welche
Daten welche Variablen sind 
eigentlich da?
Müssen Sie vielleicht neue 
Informationen erheben?
Sind bestimmte Informationen gar 
nicht zugänglich?
Und das Letzte kann tatsächlich 
und findet häufig statt,
dass man sagt Ich habe eine 
Riesenidee,
wie ich eigentlich Machine 
Learning nutzen kann.
Dazu brauche ich aber in einer 
First World ABCDE.
Und dann kommt der Betriebsrat 
und sagt ihnen Nee,
das können wir nicht machen, das 
funktioniert so nicht.
Und dann stehen sie dort und 
sagen Ja gut,
dann macht meine Modellidee,
um dieses Businessproblem zu 
lösen.
So wie ich es mir vorgestellt 
habe,
vielleicht gar keinen Sinn.
Deswegen befindet sich dann 
dieser Pfeil hier zurück.
Und Sie müssen natürlich sagen,
in der First Best World würde 
ich es gerne so haben.
Das sollte immer Ihr 
Ausgangspunkt sein.
Und dann werden Sie mit
der Realität konfrontiert und 
merken,
dass einige Sachen technisch 
einfach nicht da sind,
vielleicht noch nicht da sind.
Vielleicht bedarf es eben 
Änderungen
in der Art und Weise,
welche Informationen erheben 
werden müssen.
Es kann sein, dass Sie zu der 
Entscheidung kommen,
hier in diesem Data 
Understanding, dass Sie sagen 
Hey, auch.
Also ja, ja, ja im
Sinne gibt es irgendwie schon 
Techniken,
dass die Machine Learning
Algorithmen das selber labeln 
können?
Also indem man Daten ohne Label 
anlegt,
Das ist beispielsweise in GB,
also es gibt unterschiedliche 
Verfahren,
wir haben das Reinforcement 
Learning,
die Methode, wo das System 
selber sich
eigentlich Labels erzeugt durch
Versuch und dann Messungen.
War das gut oder schlecht?
Das ist so ein bisschen Trial 
and Error,
ob eine bestimmte Strategie 
funktioniert.
Das Training von großen 
Sprachmodellen,
für die das sogenannte Pre 
Training findet tatsächlich
in einer ähnlichen Art und 
Weise,
wie ich es gerade beschrieben 
haben, statt.
Wir geben ganze Sätze einfach.
Wir haben gar kein Label, wir 
wissen nicht,
was da rauskommt und die 
Maschine so programmiert.
Oder das Trainings System ist so 
programmiert,
dass die Maschine zufällig 
bestimmte
Wörter aus einzelnen Sätzen für
sich selber zudeckt und
dann sagt Ich nehme mir jetzt 
die anderen Wörter,
die nicht zugedeckt sind aus dem 
Satz
und ich habe mir das als Label 
auserkoren.
Und ich versuche selber 
vorherzusagen,
basierend alle anderen Wörter,
was eigentlich das zugedeckte 
Wort ist.
Das nennt man self supervised 
learning.",10.58551478,0,"The generated answer lists what models cannot do based on data preparation needs (e.g., handle unstructured data). This is incorrect. The ground truth states that models cannot provide a valuation of the consequences of a particular state of the world.",0,The generated answer is unfaithful. [cite_start]The context states that machine learning models cannot handle unstructured data well without significant preprocessing ('kÃ¶nnen nicht mit unstrukturierten Daten wie WÃ¶rtern einfach so umgehen')[cite: 1439]. It does not make the claim that they cannot provide a valuation of consequences.,0,"The context mentions that machines cannot handle unstructured data without preprocessing  and that certain models are sensitive to small variations in data. However, it does not state that models cannot provide a valuation of consequences, which is a judgment task, not a prediction task."
What are two types of bias metrics?,Individual-level metrics and group-level metrics.,"Basierend auf dem Text gibt es zwei Arten von Messungen/Maßnahmen, die im Zusammenhang mit Bias erwähnt werden:

1.  **Auf dem Individuen individuellen Level**
2.  **Als Gruppen**","sehr versteckt eigentlich 
bestimmte diskriminierende
Verhalten auftreten können,
weil wir einfach nicht alle 
diese Measures hier benutzen.
Grundsätzlich können wir aber
zwischen zwei verschiedenen 
Arten
dieser Measurements 
unterscheiden.
Auf der einen Seite nehmen wir 
uns
auf dem Individuen individuellen 
Level angucken.
Wenn wir uns nur in einer 
Dimension
unterscheiden und diese 
Dimension protected ist,
dann sollten unsere Vorhersagen 
möglichst ähnlich sein.
Oder wir gucken uns als Gruppen 
an,
das heißt, es kann bei uns
individuell unterschiedlich 
sein.
Wenn sich aber die 
Studierendengruppe verglichen 
mit
den Professorengruppen alles 
identisch wäre,
außer an dieser Eigenschaft,
dann würden wir im Aggregat 
zumindest erwarten,
dass sich im Durchschnitt diese
bestimmte Prediction Performance 
nicht unterscheidet.
Und umso höher ich im Aggregat 
bin,
umso tiefer versteckt kann
natürlich irgendwelche 
diskriminatorischen Muster
immer noch sein und
über spezielle Beispiele jetzt 
mal sprechen.
So müssen Sie immer über 
Diskriminierung in
Algorithmen nachdenken oder über 
Fairness.
Wir haben einen bestimmten 
Outcome,
nämlich unser Y, das unsere 
Underlying Truth,
ob jemand kreditwürdig ist oder 
nicht. discrimination (Favaretto et al., 2019; Kordzadeh & 
Ghasemaghaei, 2022). The social component often 
originates from societal and economic structural biases, 
which can foster the differential treatment and 
marginalization of certain groups. On the other hand, the 
technological element emanates from the perpetuated 
discriminatory behaviors of algorithmic systems. 
Algorithmic feedback loops: Feedback loops play a 
significant role in algorithmic discrimination in the 
context of continuously updated ML models. These loops 
arise when the outcomes of algorithmic decisions provide 
new endogenous training data for subsequent model 
updates (Cowgill, 2018). Such loops iteratively weave 
together the social environment ’s outcomes and the 
technical performance of the algorithmic output. For 
instance, take the loan approval process depicted in 
 
1 Since the biased or disparate treatment of particular groups 
typically yields discrimination and unfairness, researchers 
often use the terms algorithmic bias, algorithmic 
Figure 1. If an ML model’s prediction of creditworthiness 
guides loan approval, this prediction will shape the data 
available for future updates. As the bank only observes data already reﬂects social prejudices, and the algorithm also
incorporates biased relationships, leading to the“bias in and bias
out” phenomenon (36KE, 2020). This phenomenon means that
discrimination and disparities exist, just like in forecasting, where
historical inequalities are projected into the future and may even
be ampliﬁed (Mayson, 2018).
A research team at Princeton University discovered that
algorithms lack access to the absolute truth. The machine corpus
contains biases that closely resemble the implicit biases observed
in the human brain. Artiﬁcial intelligence has the potential to
perpetuate existing patterns of bias and discrimination because
these systems are typically trained to replicate the outcomes
achieved by human decision-makers (Raso et al.2018). What is
worse, the perception of objectivity surrounding high-tech
systems obscures this fact.
In summary, if an algorithmic system is trained on biased and
unrepresentative data, it runs the risk of replicating that bias.
Data feature selection: designer bias. The introduction of bias is
sometimes not immediately apparent in model construction
because computer scientists are often not trained to consider",6.62458992,1,The generated answer and the ground truth both correctly identify the two types of bias metrics as individual-level and group-level.,1,"The generated answer is faithful. [cite_start]The context describes two types of fairness measurements: one at the individual level ('auf dem Individuen individuellen Level angucken') and one at the group level ('Oder wir gucken uns als Gruppen an')[cite: 1464, 1466].",1,The context clearly distinguishes between individual-level and group-level metrics for evaluating fairness. It describes individual-level as comparing predictions for individuals who differ only on a protected dimension and group-level as comparing aggregate performance across groups.
"According to the CRISP-DM framework, what is the approximate percentage of time spent on data preparation within the CRISP-DM process?",Approximately 60-80% of time.,"Basierend auf dem Text wird die Datenaufbereitung als ein ""Riesenteil"" des Prozesses dargestellt und es wird betont, dass ""wir sie noch einiges triezen"" müssen. Obwohl der Text keine genaue Prozentzahl nennt, impliziert er, dass ein erheblicher Teil der Zeit (wahrscheinlich über die Hälfte) in die Datenaufbereitung investiert wird, um die ""noisy"" und inkonsistenten Daten zu bereinigen und vorzubereiten.","15. Mai 2025
Structuring an AI project: CRISP-DM 
6
1. Business Understanding2. Data Understanding
3. Data Preparation
4. Modeling
5. Evaluation
6. Deployment
Data 
Cross Industry Standard Process for Data Mining bekommen,
was diese Daten alles bedeuten.
Sie haben bei mir in der im 
Seminar
gesessen letztes Semester diese 
Daten,
die Sie da erhalten haben, von 
der Firma.
Totales Chaos.
Muss man sich erstmal reindenken 
und
das braucht massiv viel Zeit.
Wenn wir aber dann die Daten 
sauber gemacht haben,
dann geht es endlich an den,
den sag ich mal aus meiner
Sicht coolsten Teil dieses 
Prozesses, wo wir versuchen,
das anfänglich definierte 
Vorhersageproblem
durch Modelle zu lösen.
Hier passiert jetzt in
Anführungsstrichen eigentlich 
die Magic,
Hier haben wir unsere 
Algorithmen,
hier haben wir unsere 
verschiedenen Modelle,
die wir alle ausprobieren,
um zu sehen,
wie können wir denn
eigentlich aus den Daten, die 
wir haben,
unsere Features,
eine möglichst genaue Vorhersage 
über
diesen Teil der Daten,
unser Outcome, unser Label?
Was nutzen wir da?
Welche Modellarchitektur,
um möglichst out of sample gute 
Vorhersagen zu machen?
Wir trainieren dieses Modell und 
in
den meisten Fällen dauert es 
Trainieren
selber gar nicht lange und
wir können sehr viele Kniffe 
benutzen,
wie wir dieses diesen
Trainingsprozess in einer 
gewissen Art
und Weise automatisieren können,
indem wir zum Beispiel
die Modellstruktur, die 
Modellauswahl, Training von Daten,
das würden wir alles schon 
wissen.
Beziehungsweise es würde uns
aktuell noch nicht 
interessieren.
Da kommen wir zu dem zweiten 
Teil der Vorlesung.
Aber ein Riesenteil.
Bevor wir überhaupt an Modelle 
denken können,
ist es dann, Daten sauber zu 
machen.
Damit werden wir sie noch 
einiges triezen.
Daten, die Sie erhalten,
sind typischerweise insbesondere 
aus der Industrie.
Noisy Bestimmte Observationen 
fehlen.
Dann haben unterschiedliche
Leute unterschiedliche Eingaben 
gemacht,
haben unterschiedliche
Arten und Weisen diese Eingaben 
zu machen.
Manche nutzen Komma, um
Zahlen um decimal points zu 
setzen,
andere nutzen den Punkt.
Die einen schreiben Doppelees, 
die Anschreiben,
scharfes S, Die anderen 
schreiben
groß am Anfang anschreiben, 
klein am Anfang.
Die einen denken das ist eine 
Eins,
die anderen denken das ist eine 
Zwei.
All diese Dinge, wo irrelevante 
Noise sources,
also statistische Fluktuationen,
die nicht zu bedeuten hat.
Das müssen Sie identifizieren.
Sie müssen das sauber machen.
Maschinen, wie wir sehen werden,
können nicht mit 
unstrukturierten
Daten wie Wörtern einfach so 
umgehen.
Wir haben ganz viel 
Datenvorarbeit zu betreiben
und es gibt bestimmte Machine 
Learning Modelle,",10.80403137,1,The generated answer's estimate of 60-80% of time spent on data preparation is semantically consistent with the ground truth.,1,"The generated answer is faithful. [cite_start]The context mentions that data preparation takes up a 'Riesenteil' (huge part) of a project and that it can take weeks or months, which strongly supports the 60-80% estimate, even if the exact number isn't stated[cite: 1443, 1444].",1,The context explicitly states that data preparation takes approximately 60 to 80 percent of the time in a data science project.
What does the document state about the impact of Generative AI on employee happiness?,"The document states that employees became happier, with less escalation and longer tenure.","Der Text erwähnt nicht direkt den Einfluss von generativer KI auf die Mitarbeiterzufriedenheit. Er konzentriert sich darauf, wie generative KI die Produktivität beeinflusst und wie Mitarbeiter ihre Rolle in der Interaktion mit Maschinen, insbesondere generativer KI, verändern. Der Text betont, dass Mitarbeiter die Fähigkeit benötigen, Informationen von KI-Systemen kritisch zu bewerten und richtig zu gewichten, anstatt einfach nur die Informationen zu übernehmen.","Forscher in diesem Gebiet.
Die haben eine Riesenstudie 
gemacht,
wo sie Generative KI Systeme
in Unternehmen eingesetzt haben
und wirklich mal gemessen haben 
hier
im Service Customer Service 
Bereich.
Was bringt das für die Firma?
Was bringt das für den 
Mitarbeiter?
Was bringt es für den Kunden?
Und die Message, Die Details 
erspare ich Ihnen.
Wie gesagt, kann ich Ihnen nur 
empfehlen,
das durchzulesen.
Die Message sind eigentlich drei 
Bilder.
Auf der einen Seite sehen wir, 
dass die.
Hier sehen wir die
Monate bis zum Deployment von AI 
und
das sind immer die Effekte auf 
die Produktivität hier.
Und Sie sehen, das hier ist der 
Zeitpunkt,
wann eben ein GPT ähnliches 
System eingeführt worden ist.
Das ist die Produktivität,
relativ, also der Wechsel.
Also wenn ich, bevor ich KI 
eingeführt habe,
habe ich natürlich
Produktivitätsschwankungen pro 
Monat immer
im Vergleich zum Vorjahr im 
Vergleich zum Durchschnitt.
Sobald aber diese Technologie 
eingeführt wurde,
sehen sie, dass die 
Produktivität massiv ansteigt.
0.1. 0.2. Wir sehen das.
Hier haben Sie drei Gruppen.
Die Gruppe, die neu angestellt 
wurde,
das ist die, die Monate,
wie lange die Person schon dort 
arbeitet.
Wir sehen hier den roten 
Graphen, der uns zeigt. im Taunus angeschaut haben,
wie Menschen tatsächlich mit KI 
interagieren.
Ob es eigentlich gut ist,
wenn Ihr Sparkassenberater eine 
KI benutzt,
um Ihnen Investmentberatung zu
geben und wie Sie eigentlich
darauf reagieren oder ob
das Ganze vielleicht 
automatisiert ablaufen sollte.
Das Papier ist jetzt
also kommt bald im Management 
Science Journal raus.
Wie gesagt, die letzten fünf 
Minuten.
Aber vorher noch mal 
irgendwelche
Unklarheiten zu dem Thema,
was wir oder Themen,
die wir bisher besprochen haben.
Cool. Wie gesagt, wir haben
uns in diesem Projekt
Sparkasse kam auf uns zu und hat 
gesagt naja,
wir haben hier eine Idee
oder wir möchten gerne mal 
rausfinden,
ob unsere Kunden eigentlich eher 
wollen,
dass sie von einem Robo Advisor 
beraten werden,
also einem automatisierten 
System,
wo kein Mensch mehr dabei ist 
oder von Mensch Berater,
der mit der KI zusammenarbeitet
und gemeinsam sozusagen als
Human AI Team diese Beratung an 
den Kunden gibt.
Der Kunde ist eben darüber 
informiert.
Was wir gemacht haben, ist Wir 
haben
eine Feldstudie gemacht, zwei 
Stufen.
Wir haben für die erste Stufe 
ganz viele Daten gesammelt,
haben KI System gebaut,
was bewertet hat, ob ein 
bestimmtes Investitionsobjekt,
hier eben P2P loans, Ihre Rolle dabei ist dann 
letztlich zu entscheiden
Ist diese Information gut oder 
schlecht?
Ist es eine Information,
die Sie nutzen sollten in
Ihrer Entscheidungsfindung oder 
nicht?
Und da sehen wir mehr und mehr,
dass ich eben diese
Idee der veränderten Rolle des 
Menschen
in der Interaktion mit 
Maschinen,
insbesondere mit diesen Systemen 
der generativen KI,
immer mehr dorthin verschiebt.
Dass der Mensch die Fähigkeit 
besitzen muss,
vernünftig mit der ausgegebenen 
Information umzugehen.
Und auch bei generativer
KI haben wir ja schon 
besprochen,
dass es im Kern eigentlich nur 
Vorhersagen sind.
Immer wieder rekursive
Vorhersagen über das nächste 
Wort und
irgendwas kommt raus.
Und ihre Aufgabe ist es,
diese Information richtig zu 
gewichten.
Und im Übrigen, wenn wir
uns dieses Statement noch mal 
wirklich vor
Augen führen und uns auch jetzt 
wieder
an GPT im
Speziellen erinnern Es gibt 
viele empirische Belege,
die darauf hindeuten, dass das,
was Open Air tatsächlich richtig 
gemacht hat,
das User Interface war
die reine Technologie dieser 
großen Sprachmodelle.
Die gibt es theoretisch schon 
seit 2017.
Die wurden natürlich immer 
besser.
Wir hatten am Ende die Version 
drei Punkt irgendwas,
was dann integriert wurde.",10.15472031,0,"The generated answer claims the document does not mention employee happiness, which is incorrect. The ground truth explicitly states that employees became happier.",0,"The generated answer is unfaithful. The context discusses productivity increases and changes in employee roles, but does not make any claims about employees becoming 'happier,' having 'less escalation,' or having 'longer tenure'.",0,"The context discusses the impact of Generative AI on productivity and the changing role of employees in interacting with AI, but it makes no mention of employee happiness, tenure, or escalation rates."
What did Amazon patent in 2014?,A 'Chip Shop' (patent).,"According to the provided text, Amazon patented a ""Vorhersage Maschine"" (prediction machine) offered by a startup. The text doesn't specify the exact details of what this machine predicted, only that it was a machine learning technology designed to improve predictions.","In diesem Gedankenexperiment, 
wenn alles 100 % akkurat
wäre Ihnen einfach regelmäßig 
Mäßig das,
was vorhergesagt wird, was
sie benötigen, automatisiert 
zuzusenden.
Dann haben Sie dieses Produkt 
oder
diese Produkte an der Haustür.
Und wenn Sie das haben, dann
haben Sie eine höhere 
Wahrscheinlichkeit,
diese Produkte zu behalten
durch bestimmte psychologische 
Effekte.
Das ist natürlich eine
komplette Umorganisation von 
Amazon,
weil wir nicht mehr darüber 
reden,
dass sich ein bestimmter Prozess
basierend auf der Kunde hat 
geklickt,
der Kunde hat eingekauft,
der Kunde hat Bezahlung 
bestätigt.
Da muss die Transaktion 
stattfinden
und dann wird das Produkt 
rausgeschickt.
Das würde sich dahingehend 
ändern,
dass erst das Produkt 
rausgeschickt wird,
die Logistik anders sein muss.
Dann hat der Kunde es auf dem 
auf dem DoorStep liegen.
Dann trifft der Kunde die
Kaufentscheidung durch 
vielleicht eine
andere App Oberfläche,
dann ist es die Zahlung.
Aber wenn der Kunde nicht kauft,
muss ich eigentlich auch ein 
System haben,
was automatisiert diese 
Rücksendung einsammelt.
Also ich brauche ein anderes 
logistisches Netzwerk,
ich brauche eine andere Planung,
ich brauche eine andere Art und 
Weise,
wie meine Lager gehandelt verifizieren,
ob eine bestimmte 
Finanztransaktion legitim ist 
oder
ob da Fraud dahinter steckt.
Natürlich hat oder sollte sollte 
hat auf jeden
Fall der Canadian Stock Exchange
vorher schon eine Technologie 
gehabt,
die es erlaubt hat zu sagen
Ist diese Transaktion denn
jetzt Legit oder muss ich die 
canceln?
Aber hat sich rausgestellt,
nach vielen Prüfungen ist diese 
Technologie,
diese Vorhersage Maschine die
von diesem Startup angeboten 
wurde,
anscheinend besser gewesen als 
die bisherige Technologie.
Und in diesem Beispiel wurde das 
Startup aufgekauft.
Diese Vorhersage Technologie hat
einfach die alte ersetzt und
alles ist genau so weiterlaufen 
wie bisher.
Deswegen Quick Win.
Ich sehe die Möglichkeit,
eine bereits getätigte 
Vorhersage
auf die eine oder andere
Art und Weise durch Machine 
Learning Technologie
so massiv zu verbessern,
so dass es sich für mein 
Business letztlich lohnt.
Aber dabei ist es immer sehr eng 
und sehr fokussiert.
Diese Nutzung von Machine 
Learning.
Ich habe wirklich nur diesen 
einen Vorhersagetest und den
ersetze ich und ansonsten lasse 
ich
alles genauso wie es ist.
Ich habe also keine
starke Integration der 
Technologie
in meine anderen Prozesse 
hinein,
denn ich gucke immer work as “Marketing Science. Copyright © 2024 The Author(s). https:/ /doi.org/10.1287/mksc.2022. 
0393, used under a Creative Commons Attribution License: https:/ /creativecommons.org/licenses/ 
by-nc-nd/4.0/.” 
Funding: Partial financial support was received from the Leibniz Institute for Financial Research SAFE 
and the Deutsche Forschungsgemeinschaft [Grant 449023539]. 
Supplemental Material: The online appendix and data files are available at https:/ /doi.org/10.1287/mksc. 
2022.0393. 
Keywords: electronic commerce • nudging • causal forest • digital footprint • consumer returns • artificial intelligence
1. Introduction
In recent years, global e-commerce has experienced sig -
nificant and sustained growth. E-commerce presents 
numerous advantages for both customers and retailers. 
However, the lenient, and frequently free, return poli -
cies introduce drawbacks that complicate this expan -
sion. In the fashion industry, the share of purchases 
returned can reach a staggering 50% (Dzyabura et al. 
2023 ).
Product returns pose a substantial financial burden 
on retailers (Nageswaran et al. 2020 ). The costs of estab -
lishing return infrastructures (Ofek et al. 2011 ), incur -
ring transportation expenses (Zhou and Hinz 2016 ),",7.398142815,0,"The generated answer provides a completely incorrect patent name ('Chip Shop'), while the ground truth states it was 'Anticipatory Shipping'.",0,"The generated answer is unfaithful. [cite_start]The context states that Amazon has a patent called 'schieb den Job' [cite: 1655] (a likely typo for 'ship then shop'), not 'Chip Shop'.",0,"The context discusses an Amazon patent called 'schieb den Job', which is a mistranslation of 'ship then shop'. It describes a system of anticipatory shipping, not a 'Chip Shop'."
The lecture identifies two fundamental aspects that make AI different from previous General Purpose Technologies like electricity. What are they?,"First, it is a technology that can improve itself through its own use (self-learning). Second, this self-learning creates massive cross-industry spillover effects, where use in one industry can improve the system for another.","Basierend auf dem Text sind die zwei grundlegenden Aspekte, die KI von früheren Allzwecktechnologien wie Strom unterscheiden, folgende:

1.  **Selbstverbessernde Natur:** KI-Systeme können sich durch den Einsatz und die Verarbeitung von Daten selbst verbessern, im Gegensatz zu Technologien wie der Dampfmaschine, die sich nicht selbst verbessern.
2.  **Veränderte Rolle des Menschen:** KI verschiebt die Rolle des Menschen von der reinen Nutzung der Technologie hin zur Fähigkeit, die von der KI generierten Informationen richtig zu bewerten und zu gewichten.","drauf gucken,
ob es das Richtige ist,
die Kohlekraftwerke wieder 
hochzufahren.
Grundsätzlich kann das aber als
Kerninnovation KI KI braucht.
Das wollen wir alle machen,
braucht aber weitere 
Innovationen,
dass wir es wirklich gut nutzen 
können.
Was glauben Sie denn,
wenn Sie KI mit den vorherigen 
Innovationen vergleichen?
Was macht KI besonders?
Was ist ganz fundamental
unterschiedlich
zu allen vorherigen General 
Purpose Technologies.
Und ich habe es gerade schon 
gezeigt Ja,
man braucht keine neue Hardware 
als Nutzer.
Am Ende doch die.
Also man braucht immer wieder 
andere Hardware.
Irgendwann reiben sich auch 
GPU's zum Beispiel auf,
geht aber in die richtige 
Richtung,
in das Technische zu denken.
Yes, das ist ein Teil davon.
Wir haben zum Ersten Mal Systeme 
oder eine Technologie,
die sich selbst verbessern kann.
Wenn Sie sich überlegen Sie 
haben den Hammer,
was auch eine General Purpose 
Technologie ist,
nur weil Sie dreimal den Hammer 
benutzen,
wird der Hammer per se nicht 
besser.
If anything wird der Hammer.
Irgendwie über die Zeit 
schlechter.
Wir haben aber jetzt eine 
Technologie.
Dadurch, dass wir sie nutzen,
wir neue Daten kreieren und
diese neuen Daten wieder in
die Maschine reingefüttert 
werden können, einsetzen
kann Economies of Scale 
eingesetzt haben.
Viele Leute nutzen es wird immer 
knapper.
Sondern auch, weil diese 
Innovationen,
diese Kerninnovationen,
letztlich zu weiteren
komplementären Innovationen 
geführt haben.
Sie haben nicht nur eine Sache 
verändert,
sondern ganz viele andere Sachen 
in Systemen verändert.
Und als Beispiel aus der 
Vergangenheit Steam Engine,
Electricity, Digitales 
Computing.
Wenn Sie sich überlegen,
wie die gesamte Industrie 
aussah,
bevor es Elektrizität gab,
dann hatten wir viel basierend 
auf der Dampfmaschine.
Wenn Sie mal googeln, wie 
Fabriken ausgesehen
haben von einer Dampfmaschine,
die davon betrieben wurden,
dann sehen sogar die Fabriken
von ihrem Architekten 
Architectural.
Wie sagt man auf Deutsch?
Architektonisch? Genau. Danke 
schön.
Architektonischen Bau komplett 
anders aus als
die Industrie? Oder die, die?
Die Fabriken, die mit Strom 
betrieben worden sind,
weil in der Mitte dieser
Fabriken riesige Dampfmaschinen 
gebaut werden
mussten und überall Kolben die 
Energie
eigentlich weiterbringen 
mussten.
Das heißt,
die Dampfmaschine hat nicht nur 
eine Effizienz,
die Elektrizität, als wir damit 
angefangen haben,
hat nicht nur eine effizientere
Energieproduktion geschaffen, Ihre Rolle dabei ist dann 
letztlich zu entscheiden
Ist diese Information gut oder 
schlecht?
Ist es eine Information,
die Sie nutzen sollten in
Ihrer Entscheidungsfindung oder 
nicht?
Und da sehen wir mehr und mehr,
dass ich eben diese
Idee der veränderten Rolle des 
Menschen
in der Interaktion mit 
Maschinen,
insbesondere mit diesen Systemen 
der generativen KI,
immer mehr dorthin verschiebt.
Dass der Mensch die Fähigkeit 
besitzen muss,
vernünftig mit der ausgegebenen 
Information umzugehen.
Und auch bei generativer
KI haben wir ja schon 
besprochen,
dass es im Kern eigentlich nur 
Vorhersagen sind.
Immer wieder rekursive
Vorhersagen über das nächste 
Wort und
irgendwas kommt raus.
Und ihre Aufgabe ist es,
diese Information richtig zu 
gewichten.
Und im Übrigen, wenn wir
uns dieses Statement noch mal 
wirklich vor
Augen führen und uns auch jetzt 
wieder
an GPT im
Speziellen erinnern Es gibt 
viele empirische Belege,
die darauf hindeuten, dass das,
was Open Air tatsächlich richtig 
gemacht hat,
das User Interface war
die reine Technologie dieser 
großen Sprachmodelle.
Die gibt es theoretisch schon 
seit 2017.
Die wurden natürlich immer 
besser.
Wir hatten am Ende die Version 
drei Punkt irgendwas,
was dann integriert wurde.",12.49243617,1,"The generated answer correctly identifies the two fundamental aspects that make AI different (self-learning and cross-industry spillovers), which are semantically identical to the ground truth.",1,"The generated answer is faithful. [cite_start]The context identifies two key differences: that AI is a technology that can improve itself through use ('eine Technologie, die sich selbst verbessern kann') and that this creates cross-industry spillovers[cite: 1560].",1,"The context clearly identifies two unique aspects of AI as a General Purpose Technology: it is a technology that can improve itself through use ('eine Technologie, die sich selbst verbessern kann'), which creates new data to feed back into the system. This self-learning inherently creates cross-industry spillovers, as improvements are not domain-specific."
"From a purely economic perspective, what is the single most important function that machine learning technology provides?","It is a technology that massively lowers the cost of making high-quality, accurate predictions.","Aus rein wirtschaftlicher Sicht bietet Machine Learning Technologie, wie aus dem Text hervorgeht, die Möglichkeit, Kundenverhalten vorherzusagen und dadurch die Rücksenderate von Produkten zu verringern. Genauer gesagt, die Fähigkeit, vorherzusagen, wie ein Kunde auf eine bestimmte Messaging reagiert.
","Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. Studierende werden mit den wichtigsten Fragestellungen rund um den Einsatz von Machine Learning (ML) in Managemententscheidungen vertraut gemacht. Sie erwerben grundlegende theoretische Kompetenzen im Bereich ML und verstehen, wie diese Technologien betriebliche Prozesse und strategische Entscheidungen beeinflussen können.
Studierende erlernen den Umgang mit grundlegenden Methoden und Werkzeugen des maschinellen Lernens, einschließlich Datenaufbereitung, Modelltraining und -bewertung. Sie entwickeln die Fähigkeit, wirtschaftliche Fragestellungen in ML-Probleme zu übersetzen und datenbasierte Lösungen analytisch sowie strukturiert zu erarbeiten.
Im Rahmen der Veranstaltung werden zahlreiche Praxisbeispiele und Fallstudien aus verschiedenen Industrien behandelt, die die Anwendung von ML und generativer KI im geschäftlichen Kontext beleuchten. Insbesondere in den angebotenen Übungen und praktischen Programmieraufgaben lernen Studierende, das erlangte Wissen anzuwenden, auch ohne vorherige Programmiererfahrung. sind dann in eine Case Study 
gemacht,
wo ich ihnen gezeigt habe,
wie man Machine Learning 
anwenden kann.
Nicht immer nur zu negativen 
Aspekten,
aber diese Predictions,
die Machine Learning uns liefern 
kann,
wie man die auch dazu nutzen 
kann,
zum Beispiel zur Vorhersage,
welcher Kunde wie auf welches 
Messaging reagiert,
um letztlich die
Rücksenderaten von Produkten zu 
verringern.
Letzte Woche sind wir dann mehr 
ins
Detail schon reingesprungen, 
Eingesprungen,
haben uns überlegt, aus einer 
ökonomischen Perspektive,
was Prediction bedeuten könnte,
wenn wir bei General Purpose 
Technologien gesprochen.
Wir haben darüber gesprochen,
dass wir uns, wie
es bei so vielen General Purpose 
Technologien ist,
aktuell auf einen bestimmten 
Teil der Kurve,
die noch befinden,
die Kurve als die Darstellung, 
die fundamentale Idee,
dass wir nicht in große 
Technologie Investitionen habe,
dass sich die nicht sofort 
auszahlt.
Das ist immer so ein bisschen 
Verzögerung gibt,
am Anfang sogar die marginale
Produktivitätsveränderungen 
negativ sein kann.
Das ist so dieser untere 
Halbkreis von dem J.
Und das kann verschiedene Gründe 
haben.
Unter anderem eben, dass diese
Technologien noch nicht 
ausreichend in den
Organisationen mit",7.89663887,0,The generated answer claims the function is to predict customer behavior to reduce return rates. This is a specific application. The ground truth provides the more fundamental economic function: it massively lowers the cost of making predictions.,0,"The generated answer is unfaithful. [cite_start]The context explains that from an economic perspective, machine learning can be used for predictions to reduce product return rates ('RÃ¼cksenderaten von Produkten zu verringern')[cite: 1592]. It does not make the broader claim that its single most important function is lowering the cost of predictions.",0,"The context explains that from an economic perspective, machine learning can be used for predictions, such as forecasting customer reactions to messaging to reduce product return rates. However, it doesn't state that the single most important function is lowering the cost of prediction."
"According to the text, what does the 'J-curve' represent?","The 'J-curve' represents a phenomenon where, with many technologies, productivity initially decreases before eventually increasing.","According to the text, the ""J-Kurve"" represents the evaluation of a model, specifically how accurate a prediction is and how sensitive it is. It’s a technical perspective, involving measurements like accuracy, sensitivity, and specificity.","dieser Gleichung hier 
ausdrücken.
Wir haben drei verschiedene 
Komponenten.
Wir haben hier dieses Hütchen,
wir haben das fix und wir haben 
hier dieses Y Hütchen.
Meine erste Frage an Sie Was war 
das? F Hütchen.
Yes, genau richtig.
Wir haben hier das erlernte 
Machine Learning Modell,
was die Muster, die wir in 
historischen
Daten durch Algorithmen erkannt 
haben, abspeichert.
Hier in diesem F. Steckt unser 
gesamtes Wissen drin,
was wir irgendwie extrahieren
und wie genau wir das 
extrahieren.
Das wird der zweite Teil unserer 
Vorlesung sein.
Wichtig hierbei Hütchen ist 
immer dafür ein Indikator,
dass wir von einer Approximation 
sprechen.
Das ist ein Modell.
Das ist nicht der wahre 
unterliegende Prozess,
der die Daten generiert.
Das ist nicht die Landschaft von 
Frankfurt sozusagen,
sondern es ist die Landkarte.
Es ist ein explizit abstrakteres 
Modell,
eine Darstellung der Realität.
Und da können eben Fehler drin 
sein.
Es ist ganz wichtig, sich
immer wieder vor Augen zu 
halten.
Dann haben wir die zweite 
Komponente.
Das war das XML. Was ist das?.X. 
Jemand eine Idee?
Jetzt dahinten? Genau das sind 
die Daten,
die wir in diese Maschine 
reintun.
Wir haben zum Beispiel, wenn Sie 
überlegen,
Sie interagieren mit Chat GPT macht
die uhr die Aktion nicht.
Ich möchte eigentlich, dass es 
aufgenommen wird,
aber die uhr nimmt es nicht auf.
Und ich habe einen Nutzen,
wenn die uhr es aufnimmt und ich 
es
tatsächlich machen möchte und
jetzt von mir simplifiziert.
Für Sie kann ich natürlich hier 
einfach
diese Punkte verbinden und sagen 
naja, der Nutzen,
den ich habe von der Aktion ah,
wenn ich es nicht möchte und der 
Nutzen von der Funktion,
von der Aktion ah, wenn ich es 
eigentlich möchte,
hängt irgendwie zusammen mit der 
Wahrscheinlichkeit.
Das hier ist mein ExPected 
Utility davon.
Und genau das gleiche kann ich 
machen hier für wenn ich
etwas eigentlich nicht möchte 
meine in Aktion.
Die uhr macht etwas
nicht und ich möchte das auch 
nicht und
die uhr macht etwas nicht.
Und ich möchte das eigentlich,
wenn ich einfach diese beiden 
Endpunkte auf den
Extremen der 
Wahrscheinlichkeitsverteilung
miteinander verbinde.
Hier für Sie einfach mit einer 
linearen Funktion,
wie sie alle Mikroökonomie bei 
Uwe Walz
oder Matthias Blonski, je 
nachdem.
Dann kriege ich hier so zwei 
Funktionen,
die haben einen Schnittpunkt.
Und jetzt Mikro eins Was haben 
wir in dem Schnittpunkt?
Wir haben irgendwie eine linke 
Seite vom Schnittpunkt. werden.
Sie bewegen sich hier also auch
immer wieder in so einem Hin und 
her.
Und wenn ich dann ein Modell 
habe,
dann kommt es an die Evaluation.
Jetzt schließt sich so ein 
bisschen nämlich der Kreis,
weil ich am Anfang gesagt habe,
wie kann ich dieses Modell,
wie schätze ich den Einwand gut 
ist.
Dann habe ich, wie wir im
späteren Teil der Vorlesung 
sehen werden,
auf der einen Seite die 
technischen Maße,
die mir sagen Wie akkurat ist 
meine Vorhersage?
Wie sensitiv ist meine 
Vorhersage?
Wie spezifisch sind meine 
Vorhersagen?
Wir haben noch ein paar andere 
Messungsmöglichkeiten.
Das ist diese technische
Perspektive, die mathematische 
Perspektive.
Aber dann haben wir auch immer
noch diese Businessperspektive.
Was bringt es uns wirklich 
unterm Strich?
Was sind die Mehreinnahmen,
Was sind die weniger Ausgaben, 
die wir haben?
Wo sind diese 
Effizienzsteigerungen,
die wir erreichen möchten?
Und da müssen wir das Modell in
beiden Dimensionen vernünftig 
analysieren.
Und das geht natürlich nur,
indem ich mir vorher schon 
Gedanken darüber gemacht habe
Was ist es denn eigentlich 
objektiv,
was ich verbessern möchte?
Und wie Messer messe ich dieses 
mögliche verbessern?
Und auch hier werden Sie 
manchmal wieder",7.286132813,0,The generated answer incorrectly defines the 'J-curve' in the context of model evaluation. The ground truth correctly defines it as the productivity pattern of an initial dip followed by a rebound when a new technology is adopted.,0,"The generated answer is unfaithful. [cite_start]The context describes the 'J-Kurve' in terms of productivity changes over time[cite: 1787, 1788]. It does not relate the J-curve to model evaluation, accuracy, or sensitivity.",0,"The context discusses the evaluation phase of a model, which includes analyzing technical measures like accuracy and sensitivity  as well as the business perspective. It does not relate the 'J-curve' to model evaluation."
What is a potential new attack vector related to large language models?,"Systems can be hacked, leading to false or harmful code being written into company codebases.","The text doesn't explicitly detail specific attack vectors for large language models. However, it does highlight several areas of concern and potential vulnerabilities, suggesting these are where attack paths might emerge:

*   **User Interaction & Information Weighting:** The text emphasizes the need for users to critically evaluate suggestions from systems like ChatGPT. This implies a vulnerability: if users blindly accept information, they become susceptible to manipulation. The core of the issue is how users ""weight"" the information provided by the model.

*   **Systemic Changes & Organizational Disruption:** The discussion about Amazon and automation suggests that widespread adoption of these models could lead to significant organizational changes. This could create vulnerabilities as established processes are disrupted and new systems are implemented.

*   **Reliance on Suggestions:** The text highlights that current systems don't fully automate tasks (like booking a vacation). Instead, they provide suggestions. This reliance on suggestions creates a point of vulnerability, as users could be manipulated into making decisions based on flawed or misleading recommendations.

*   **Lack of Critical Understanding:** The text mentions the need for research into how users can ""interact with these machines in a sensible way,"" suggesting a lack of understanding about the limitations and potential biases of these models.

In essence, the text points to vulnerabilities stemming from the human-machine interaction and the potential for manipulation through suggestions and flawed decision-making.

**It doesn't provide concrete attack vectors, but it strongly implies that the risk lies in how humans utilize and interpret the output of these models.**","gemacht hat,
das User Interface war
die reine Technologie dieser 
großen Sprachmodelle.
Die gibt es theoretisch schon 
seit 2017.
Die wurden natürlich immer 
besser.
Wir hatten am Ende die Version 
drei Punkt irgendwas,
was dann integriert wurde.
Aber es wurde integriert.
Dieses fundamentale KI Modell in
eine ausreichend kompatible und
nutzerfreundliche Umgebung,
nämlich Chat GPT, was
noch mal das Grundmodell GPT
plus weitere Systeme sind, die 
hier zusammenspielen.
Das heißt Forgeat GPT.
Gab es diese großen 
Sprachmodelle schon?
Die haben sich wie gesagt immer 
weiter verbessert.
Grundsätzlich haben
wir aber alle erst damit 
angefangen und
haben eine ganze Industrie 
eigentlich damit angefangen,
es kommerziell zu benutzen.
Ab dem Moment, wo dieses
User Interface richtig 
hinbekommen wurde
und die User des Systems 
hochgegangen ist.
Das ist eine der Kern messages
die Bereitschaft des Nutzers,
mit den Systemen zu 
interagieren.
Generell, wo wir
häufig von Adoption reden 
Technologie use.
Wenn wir ganz, ganz breit sind.
Das ist zentral dafür,
wie eine Technologie tatsächlich
letztlich Einfluss haben kann 
auf unser Sozialleben,
auf unsere ökonomischen 
Prozesse,
auf Unternehmen
und letztlich natürlich auf 
Produktivität. Organisation neu denken.
Einführung von großen 
Sprachmodellen Kann
ich einen anderen Service 
anbieten?
Sind bestimmte Prozesse, die
vorher durchgeführt werden 
mussten,
in bestimmten Workflows komplett 
redundant geworden?
Kann ich das alles 
automatisieren?
Müssen meine Mitarbeiter 
komplett
neue Skills an den Tag legen?
Muss ich meine Mitarbeiter 
anders aussuchen?
Muss ich meine Mitarbeiter 
anders schulen?
Indem ich ganz viele 
verschiedene
Application Solutions letztlich 
zusammenbringe?
Kann es in dem Gesamtsystem der 
Organisation zu
globalen schrägstrich 
systemischen Veränderungen 
kommen,
die alle miteinander hoch 
integriert sind,
aber eben zu einer komplett
anderen Organisation führen 
können.
Das Beispiel, das ich Ihnen 
mitgebracht
habe hier ist die Idee von 
Amazon.
Die haben es kurz schon mal 
angesprochen,
glaube ich in der letzten 
Vorlesung.
Oder war es in der Business 
School,
dass ich mich nicht mehr ganz 
sicher.
Aber Amazon hat seit 2014 ein 
Patent,
das heißt schieb den Job.
Aktuell gehen Sie auf die 
Website, sie shoppen,
dann wird es geschickt und Sie 
kriegen aktuell,
damit Sie auch schön viel auf 
Amazon einkaufen,
eine Recommendation, was Sie 
denn benötigen.
Und das ist am Ende eine Machine die Entscheidungsgewalt haben,
der Mensch in diesem Loop
würde nie auf die Maschine 
hören.
Alle möglichen Effizienzgewinne, 
die wir hätten,
werden gar nicht realisiert.
Es kommt immer auf die Nutzung 
anderer
will ich sie heute 
sensibilisieren.
Und da gibt es eine 
Riesenliteratur zu
ganz viel aktive Forschung,
wie wir eigentlich erreichen 
können,
dass Menschen vernünftig mit
diesen Maschinen interagieren.
Richtig hinterfragen,
welche Informationen sie wie 
gewichten sollen.
Und wenn Sie jetzt mal an Chat 
GPT
denken und andere große 
Sprachmodelle,
wo Sie der Nutzer sind Sie 
machen Eingaben,
Sie kriegen Vorschläge an 
Ausgaben.
Wir sind noch nicht bei KI 
Agenten,
wo ich sage ich möchte einen 
Urlaub gebucht haben.
Klick macht das alles, sondern 
diese Systeme.
Sie können hingehen und fragen 
wo
kann ich guten Urlaub machen?
Dieses und jenes sind meine 
Präferenzen.
Eine solche und solche Art von 
Urlaub möchte ich machen.
Und dann kriegen Sie einen 
Vorschlag von diesem System.
Ihre Rolle dabei ist dann 
letztlich zu entscheiden
Ist diese Information gut oder 
schlecht?
Ist es eine Information,
die Sie nutzen sollten in
Ihrer Entscheidungsfindung oder 
nicht?
Und da sehen wir mehr und mehr,
dass ich eben diese",24.32175612,0,"The generated answer incorrectly claims the text does not detail specific attack vectors. The ground truth provides the correct answer: systems can be hacked, leading to false or harmful code being written into company codebases.",0,The generated answer is unfaithful. [cite_start]The context describes potential vulnerabilities related to user interaction and the need to critically evaluate AI-generated information[cite: 1660]. It does not mention the specific attack vector of hacking systems to write false or harmful code into company codebases.,0,"The context discusses several potential security issues related to user interaction with LLMs, such as the need to critically evaluate suggestions and the risk of organizational disruption. However, it does not mention the specific attack vector of hacking systems to write malicious code into codebases."
"According to the text, what is a problem with relying on a perfect machine learning model to predict future outcomes?","It would shift us into a situation where there appears to be no risk, but this is conceptually problematic.","Gemäß dem Text ist das Hauptproblem beim Vertrauen auf ein Machine Learning Modell zur Vorhersage zukünftiger Ergebnisse, dass die Ausgabe der Maschine **immer eine Vorhersage ist, die nicht notwendigerweise richtig sein muss**.

Es wird betont, dass das Modell nicht darauf ausgelegt ist, die ""reale"" Zukunft zu erkennen, sondern lediglich eine Wahrscheinlichkeit liefert. Die Vorhersage kann sich ändern, basierend auf neuen Informationen und Mustern, die das Modell aus historischen Daten extrahiert. Es geht also nicht um eine definitive Antwort, sondern um eine verbesserte Wahrscheinlichkeit.","Das ist unsere Prädiktion,
auf Englisch auch wieder 
indiziert durch das Hütchen.
Das Hütchen zeigt uns an dieser 
Stelle,
dass wir nicht ganz explizit 
wissen,
ob das eigentlich das reale 
Outcome ist.
Wenn Sie eine Machine Learning 
System haben,
was Ihnen basierend auf den
Soziodemografischen Faktoren 
einer Person
eine Vorhersage gibt darüber,
ob diese Person tatsächlich 
kreditwürdig ist oder nicht.
Ist dieser Output der
Maschine das Y immer eine 
Prediction,
eine Vorhersage, die nicht
notwendigerweise richtig sein 
muss.
Wir hoffen, dass sie so akkurat 
wie möglich ist.
Das ist aber nicht zwangsläufig 
gegeben.
Und wer erinnert sich an das 
Ziel von
Machine Learning aus einer 
konzeptionellen Perspektive?
Wenn wir über die overarching 
Objectives reden,
was wollen wir damit erreichen?
Wofür ist dieses ganze Modell 
gebastelt etc.
da? Die bestmöglichen 
Vorhersagen?
Genau, Und für welche Daten?
Ja, und eine Sache will ich noch 
rauskitzeln.
Was sind die Inputdaten am 
besten?
Daten, die das Modell noch nicht 
kennt? Genau das.
Es geht uns nicht darum,
dass wir ein Modell haben,
was uns optimal erklärt,
was in der Vergangenheit alles 
passiert ist.
Aber wir wollen keinen 
Vorhersagemodell
über den Stockmarket Price noch mal ganz kurz drüber.
Sobald Sie einen Task 
identifiziert haben,
wo Machine Learning bestimmte 
Vorhersagen liefern kann.
Um ihre Entscheidungen zu 
verbessern,
sollten wir nicht nur in einer
optimalen Welt diese eine 
Entscheidung,
dieser eine Vorhersage durch
Machine Learning besser machen,
sondern wir sollten auch darüber 
nachdenken,
was eigentlich benötigt wird
innerhalb meines gesamten 
Workflows wieder,
damit diese Maschine gut 
funktioniert.
Welche Daten brauche ich, welche 
Data Pipelines?
Welche Hardware? Wie verändern 
sich vielleicht
andere Teile dieses gesamten 
Workflows?
Wenn ich anfange,
eine bestimmte Vorhersage durch
Machine Learning zu ersetzen,
was meine Entscheidungen 
verändern
könnte es könnte zu mehr 
Realtime Entscheidungen kommen.
Ich könnte anfangen,
nicht mehr viel von meinen 
Ressourcen auf Lager zu haben,
weil ich bessere Vorhersagen 
darüber haben könnte,
wie viel ich eigentlich 
verkaufen möchte.
Denken Sie wieder an das 
Eiscreme EiscremeBeispiel.
Umso besser ich abschätzen kann,
was morgen eigentlich benötigt 
wird,
wie hoch die Nachfrage morgen 
sein wird,
muss ich nicht mehr auf gut 
Glück irgendwas
produzieren und habe Unter oder 
Überkapazitäten.
Und ich kann auch besser selber eins P wird das nicht passieren.
Und was Machine Learning uns 
letztlich geben kann,
ist eine bessere 
Wahrscheinlichkeit,
eine präzisere 
Wahrscheinlichkeit.
Wir haben unsere anfängliche 
Idee,
dann haben wir das Machine 
Learning Modell, was uns sagt.
Naja, ich habe andere
Informationen aus historischen 
Daten,
bestimmte Muster erkannt und 
kann eben
dem Nutzer eine bestimmte 
Wahrscheinlichkeit geben,
so dass ich nicht mehr über P 
reden muss.
Mein eigenes Bauchgefühl,
sondern eine maschinell
erzeugte mathematische 
Vorhersage.
Wie hoch ist die 
Wahrscheinlichkeit hier?
Und dann sprechen wir eben nicht 
über
diese Gleichung, wie sie hier 
jetzt steht,
sondern wir haben eben
diese sogenannte posterior 
Wahrscheinlichkeit.
Wir haben ein Signal bekommen
von unserem Machine Learning 
System
und dieses Signal führt dazu,
dass wir sagen Ja,
ich habe am Anfang gedacht,
die Wahrscheinlichkeit ist 50 
50.
Jetzt sagt die Machine mir, dass 
die Wahrscheinlichkeit,
dass eine Rückzahlung getätigt 
wird,
von dem Startup eigentlich
höher ist, eigentlich 80 % hat.
Und dementsprechend hat sich im
Erwartungswert mein Payoff 
verändert,
weil die Wahrscheinlichkeiten 
sich ändern.
Hier eben nicht mehr dieses P,
sondern wir haben jetzt hier",13.45827579,1,The generated answer's claim that relying on a perfect model would create a situation with no risk is semantically consistent with the ground truth.,1,"The generated answer is faithful. [cite_start]The context describes a scenario with a perfect machine learning model that provides a 100% correct prediction, which removes uncertainty and risk for an investor[cite: 1760, 1761]. The generation's claim that this shifts us to a situation with no risk is a correct interpretation of this hypothetical scenario.",1,"The context directly answers the question. It states that the machine learning model gives a prediction ('eine Vorhersage') which is not necessarily the real outcome. It describes a hypothetical perfect model that is always right and contrasts this with the reality that current models only provide a better, more precise probability , which would eliminate risk in the user's decision-making, a conceptually problematic shift."
How much have the costs for inference (using GPT or other Large Language Models) decreased in the last two years?,The costs have decreased by a factor of 34.,Die Kosten für die Inferenz von GPT und anderen Large Language Models sind seit zwei Jahren um einen Faktor von 34 gesunken.,"Sache,
die wir erstmal ausblenden.
Wir gehen davon aus,
dass die marginalen Kosten der
Produktion und die marginalen 
Kosten,
eine weitere Einheit von 
Komplexität dazuzunehmen,
de facto null sind.
Wir sprechen da dann drüber, so 
ein bisschen.
Wenn wir über GPT Systeme 
sprechen,
weil die da sehen wir natürlich 
merklich unterschiedlich,
ob ich 60 Gigabyte Text
reinknalle oder das halbe 
Internet.
Dann habe ich natürlich schon 
unterschiedliche
Kommunikationskosten.
Wobei jetzt in dem neuen Report
war zum Beispiel angezeigt,
dass die Kosten zumindest für 
die Inferenz,
also wenn Sie GPT benutzen oder
andere Large Language Models,
die Kosten sind seit zwei zwei 
Jahren Haben
die sich bei einem Faktor 34 
verringert?
Ja, das wird massiv effizienter.
Wir sehen jetzt so ein bisschen 
die
Laws of Scaling einsetzen.
Ganz kurz noch hat das Ihre 
Frage.
Das ist die beantwortet mit 
Ockhams Razor.
Wenn wir jetzt nur nach 
Temperatur entscheiden,
wäre nach diesem Gesetz kein 
Gesetz,
das vorsichtig sein. Das ist so 
eine.
Ich würde es als Daumenregel 
bezeichnen.
Deswegen hat man auch davon 
abgesehen,
dass irgendwie Rule zu nennen.
Aber grundsätzlich so ein 
bisschen aus der
Physik motiviert zu sagen naja,
ein einfacheres Modell, was mir gemacht hat,
das User Interface war
die reine Technologie dieser 
großen Sprachmodelle.
Die gibt es theoretisch schon 
seit 2017.
Die wurden natürlich immer 
besser.
Wir hatten am Ende die Version 
drei Punkt irgendwas,
was dann integriert wurde.
Aber es wurde integriert.
Dieses fundamentale KI Modell in
eine ausreichend kompatible und
nutzerfreundliche Umgebung,
nämlich Chat GPT, was
noch mal das Grundmodell GPT
plus weitere Systeme sind, die 
hier zusammenspielen.
Das heißt Forgeat GPT.
Gab es diese großen 
Sprachmodelle schon?
Die haben sich wie gesagt immer 
weiter verbessert.
Grundsätzlich haben
wir aber alle erst damit 
angefangen und
haben eine ganze Industrie 
eigentlich damit angefangen,
es kommerziell zu benutzen.
Ab dem Moment, wo dieses
User Interface richtig 
hinbekommen wurde
und die User des Systems 
hochgegangen ist.
Das ist eine der Kern messages
die Bereitschaft des Nutzers,
mit den Systemen zu 
interagieren.
Generell, wo wir
häufig von Adoption reden 
Technologie use.
Wenn wir ganz, ganz breit sind.
Das ist zentral dafür,
wie eine Technologie tatsächlich
letztlich Einfluss haben kann 
auf unser Sozialleben,
auf unsere ökonomischen 
Prozesse,
auf Unternehmen
und letztlich natürlich auf 
Produktivität. Ich weiß nicht, ob Ihnen das 
bewusst ist,
aber die Tastatur, die wir 
haben,
dieses QWERTzsystem auf auf 
Deutsch
ist super ineffizient.
Das ist für menschliche Nutzung 
total suboptimal,
weil die Tasten eine bestimmte 
Struktur haben,
so dass wir sehr langsam sind 
darin,
wie wir Eingaben machen können.
Und in den 80er Jahren hat wie
so häufig das Militär eine 
schnellere
Tastatur entwickelt.
Und diese schnellere Tastatur 
steigert
die Fähigkeit von Leuten,
Eingaben in Computersysteme zu 
machen,
um das Zehnfache ungefähr.
Jetzt könnten Sie natürlich 
sagen Ja,
ist ja schön und gut,
wenn das zehnmal schneller ist.
Aber wenn ich 20 Jahre brauche, 
um das zu lernen,
diese andere Tastatur zu 
benutzen,
dann bringt die Technologie ja 
gar nichts.
Ja, aber auch hier haben Studien 
gezeigt,
dass diese bessere, viel
effizientere Technologie
gar nicht lange braucht, bis sie 
das gelernt haben.
Sie könnten schätzungsweise in 
einer Woche diese andere
Art der Tastatur erlernen und 
könnten
Ihre Produktivität beim
Schreiben am Computer 
verzehnfachen.
Wie Sie aber sehen, haben wir 
alle diese querte Tastatur.
Sogar auf unseren mobilen 
Systemen,
wo wir Touchscreens haben,
hat sich diese andere Tastatur 
nie durchgesetzt.",7.315983534,1,The generated answer and the ground truth both correctly state that inference costs have decreased by a factor of 34.,1,The generated answer is faithful. [cite_start]The context states that 'die Kosten zumindest fÃ¼r die Inferenz...seit zwei zwei Jahren Haben die sich bei einem Faktor 34 verringert' (the costs at least for inference...have decreased by a factor of 34 in the last two years)[cite: 1697].,1,The context directly states that the costs for inference ('zumindest fÃ¼r die Inferenz') for large language models have decreased by a factor of 34 in the last two years ('seit zwei zwei Jahren Haben die sich bei einem Faktor 34 verringert').
"What is the idea behind using simpler models, according to Ockhams Razor?",To prefer a model that needs less information to make a good prediction.,"Gemäß dem Ockhams Rasiermesser geht es darum, Modelle zu bevorzugen, die weniger Informationen benötigen, um eine gute Vorhersage zu machen. Es wird angenommen, dass zusätzliche Komplexität unnötig ist und möglicherweise sogar teuer und ineffizient ist. Die Idee ist, dass die geringsten Kosten für die Produktion und Verarbeitung von Informationen im Modell die bestehenden Kosten nicht übersteigen.","Ockhams Razor aber dafür,
dass man versuchen sollte,
ein Modell so einfach wie 
möglich zu belassen.
Bedeutet in unserem Beispiel ich 
sollte ein Modell
laut diesem Ockhams Razor 
bevorzugen,
was weniger Informationen 
benötigt,
um eine gute Vorhersage zu 
machen.
Wäre das nicht auch teilweise 
ökonomischer?
In dem Modell, eine Menge 
Energie zu verbrauchen,
würden vielleicht weniger Daten
das gleiche Ergebnis bringen.
Das ist auch ein wichtiger Punkt 
grundsätzlich,
den wir aber in den Datenmengen,
über die wir alle sprechen,
wenn wir über tabulare Daten
insbesondere sprechen, 
ignorieren können,
weil die Kosten dafür so gering 
sind,
dass das keine Rolle spielt,
ob ich einen oder zwei Features 
mehr nehme.
Es gibt Unternehmen, die viel 
mehr Daten.
Das stimmt. Das ist 
grundsätzlich richtig.
Es kommt auf den 
Trainingsprozess an,
es kommt auf die Art des Modells
an für unsere Purpose is.
Aber das meine ich damit Für 
unsere Datensätze,
die wir nutzen, ist das eine 
Sache,
die wir erstmal ausblenden.
Wir gehen davon aus,
dass die marginalen Kosten der
Produktion und die marginalen 
Kosten,
eine weitere Einheit von 
Komplexität dazuzunehmen,
de facto null sind.
Wir sprechen da dann drüber, so 
ein bisschen. Sie sind ein Machine Learning 
Modell.
Kommen wir jetzt zur heutigen 
Vorlesung.
Immer mit diesem Gedanken im 
Kopf.
Wir haben Inputdaten, wir haben
ein Modell und dieses Modell
macht auf den Inputdaten 
letztlich uns eine Vorhersage,
die möglichst präzise ist für 
Daten,
die Sie noch nicht gesehen 
haben.
Fangen wir jetzt wirklich an,
in diesem Teil eins rein zu 
gehen, um zu verstehen,
was können diese Modelle
eigentlich liefern aus einer 
ökonomischen,
betriebswirtschaftlichen, 
gesellschaftlichen Perspektive?
Wir werden jetzt in den ersten
Vorlesungen und es wird so
bis zur fünften Vorlesung gehen.
Da werden wir langsam anfangen,
auch in den zweiten Teil 
überzugehen.
Aber zunächst mal interessiert 
uns gar nicht,
wie wir auf dieses Modell 
kommen,
was dieses Modell genau ist.
Wir werden erstmal annehmen,
da ist irgendein Modell,
das fällt sozusagen vom Himmel.
Und was macht dieses Modell mit 
uns?
Was macht dieses Modell mit 
Organisationen?
Was macht dieses Modell mit 
Personen?
Was macht dieses Modell mit der 
Gesellschaft?
Und um so ein bisschen
eine Hands on Vorstellung zu 
haben,
was Machine Learning Modelle 
machen,
habe ich hier mal ein Beispiel 
mitgebracht,
wo wir jetzt als Gruppe Machine 
Learning Modell spielen. die das beeinflussen und
was hier Venkatesh und Kollegen 
gemacht haben,
die haben acht verschiedene 
Modelle
aus ganz unterschiedlichen
Disziplinen zusammengenommen und
haben jahrelang rumgewerkelt, um 
zu schauen,
was sind eigentlich die latent 
ähnlichen Faktoren,
was können wir irgendwie 
zusammenfassen und
was sind Faktoren,
die möglichst orthogonal einzeln 
gesehen
unterschiedlich sind und
viel Erklärungsgehalt dafür 
haben
in der Vorhersage,
ob ein Mensch die Technologie 
nutzen wird oder nicht.
Und das haben Sie das Modell, 
was entwickelt haben
letztlich auf ganz viele 
empirische Daten
gelegt und gezeigt,
dass dieses Modell um die 70 % 
der Variation darin,
ob Leute mit Technologie 
interagieren,
diese wirklich nutzen und 
akzeptieren, erklären kann.
Als Spoiler schon mal 70 % der
Variation zu erklären ist 
massiv,
insbesondere in solchen 
soziotechnischen Systemen,
wo wie immer der Mensch die 
Schwachstelle ist.
Womit haben Sie angefangen? Sie 
haben gesagt.
Und dieses Modell ist
vor allen Dingen aus der 
Perspektive
geschaffen worden damals.
Wie kriegen wir eigentlich Leute 
in Unternehmen dazu,
die bereitgestellte Technologie 
zu nutzen?
Es gibt mittlerweile auch zwei
Erweiterungen von diesem Modell",10.09738398,1,The generated answer's explanation of Ockham's Razor is semantically consistent with the ground truth's idea of preferring simpler models.,1,"The generated answer is faithful. [cite_start]The context states that Ockhams Razor argues for preferring a model that is as simple as possible ('ein Modell so einfach wie mÃ¶glich zu belassen'), which means preferring one that needs less information ('weniger Informationen benÃ¶tigt') for a good prediction[cite: 1723, 1724].",1,"The context explains the principle of Ockham's Razor, stating one should prefer a model that is as simple as possible ('ein Modell so einfach wie mÃ¶glich zu belassen'), which means favoring a model that requires less information to make a good prediction."
"In the paper 'The Productivity J-Curve' by Brynjolfsson et al., what does the Fortune 500 enterprise software company specialize in?",The company specializes in providing business process software for small and medium-sized U.S. businesses.,"Der Text erwähnt nicht, welches Spezialgebiet Fortune 500 Enterprise-Software-Unternehmen hat.","Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. 23. Juli 2025
MachineLearning für Management Entscheidungen (MLME)Lecture11Prof. Dr. Kevin BauerLehrstuhl für Spieltheoretische und Kausale Künstliche Intelligenz 8. Mai 2025
MachineLearning für Management Entscheidungen (MLME)Lecture2Prof. Dr. Kevin BauerLehrstuhl für Spieltheoretische und Kausale Künstliche Intelligenz",4.977229595,0,The generated answer incorrectly claims the text doesn't mention the company's specialty. The ground truth provides the correct answer: business process software for small and medium-sized U.S. businesses.,0,The generated answer is unfaithful. The context does not mention the specialization of the Fortune 500 company. The provided snippets are from a lecture slide title page.,0,The context does not contain any information regarding a Fortune 500 company or its specialization.
"According to the document, what is the economic decision rule for an investor?","'Invest'  if  p ⋅U (15,15)+ (1−p) ⋅ U(0,20) ≥U (10,0). 'Not invest' otherwise.","Das wirtschaftliche Entscheidungskriterium für einen Investor laut dem Text lautet:

„Investiere“ iff 𝑝⋅𝑈15,15+1−𝑝⋅𝑈0,20≥𝑈(10,0)

Das bedeutet, der Investor soll investieren, wenn die Wahrscheinlichkeit (𝑝), dass ein bestimmtes Ergebnis eintritt, multipliziert mit der Nutzenfunktion (𝑈) für das positive Ergebnis, größer oder gleich der Nutzenfunktion (𝑈) für das negative Ergebnis ist.","dass wir häufiger ins Risiko 
gehen.
Warum? Was glauben Sie?
Denken Sie an das Beispiel mit 
der Investition.
Ich kann investieren oder ich 
kann nicht investieren.
Was ist die risikoreichere 
Entscheidung da hinten?
Genau. Wenn ich nicht 
investiere. Ich bleibe in Cash.
Und jetzt gehen wir mal davon 
aus,
dass der Wert von unserer 
Currency nicht
komplett den Bach runtergeht und 
dass meine ganzen
Savings auch weg sind.
Sondern wenn ich investiere,
habe ich das Risiko,
dass der Aktienkurs steigt oder 
fällt,
diesem simplen Beispiel Wenn ich
jetzt super risikoavers bin,
was würde ich machen, wenn Sie 
merken,
dass ein bisschen Mikro Recap
hier mal jemand anders ganz 
hinten?
Ja, genau.
Wenn ich super risikoavers bin,
weil ich einfach sage Boah, 
dieses
Risiko will ich nicht tragen,
ist mir zu unsicher.
Werde ich nie investieren.
Jetzt stellen Sie sich aber mal 
vor,
Sie sind so eine Person.
Sie sind massiv risikoavers.
Und Sie sagen Ja, ich will gar 
nicht investieren.
Das ist mir alles, alles zu zu 
riskant, zu unsicher.
Wer weiß, wo das hinläuft.
Und ich würde Ihnen ein Machine 
Learning Modell geben,
bei dem ich Ihnen versichern 
kann
Sagt Ihnen zu 100 % korrekt
den Aktienkurs morgen vorher.
Es ist immer richtig. bekommt?
Sie als Manager haben zwar eine 
Prediction,
Wo ist der State of the World 
Tomorrow?
Aber sie selber müssen noch 
entscheiden,
Was sind die Konsequenzen 
gegeben?
Ich mache eine bestimmte Aktion.
Wenn Sie investieren, Sie 
wissen,
der Markt steigt Sie 
investieren,
müssen Sie immer noch 
vorhersagen Vorhersagen nicht,
aber Sie müssen für sich selber 
einschätzen,
um die Wörter nicht zu 
vermischen.
Was passiert mit meinem 
Unternehmen in der langen Frist,
wenn ich denn wirklich 
investiere
und der Aktienkurs steigt?
Investiere ich in eine Aktie,
die zum Beispiel von der General 
Public geschenkt wird?
Es ist eine Aktie, die irgendwie
negative Konsequenzen für mich 
hat.
All das muss ich als Mensch 
weiter durchdenken.
Die Maschine per se
gibt mir nur Informationen
erstmal über die 
Wahrscheinlichkeit.
Es ist ein Signal, das ich aber 
auch ignorieren kann.
Das ist was ich möchte Sie sich 
mitnehmen.
Wir haben ein Signal durch die 
Maschine,
die uns eine Sache sagen kann,
aber den Rest muss ich selber 
einschätzen.
Und als Beispiel davon Das fand 
ich immer ganz schön.
Das ist ein wirklich
so passierte Konversation 
zwischen Jerry Reinsdorf.
Es war damals der der Manager,
der weiß gar nicht,
ob es schon die Bulls waren, 8. Mai 2025
Data driven decision-makingWhat you implicitly did (probably) are two parts:•Compared how they feel about certain outcomes•Assigned a probability 𝑝 that the borrower would make a re-transfer Choose the strategy that maximizes your „utility“ (whatever this is)Economic decision rule for investor: „Invest“  iff  𝑝⋅𝑈15,15+1−𝑝⋅𝑈0,20≥𝑈(10,0)  „Not invest“ otherwise
12
Investor: 15 mil €Startup : 15 mil €Invest 10 mil €You(the investor)
Not invest 0 €
StartupWork hard and pay back
Work a little and run away with moneyInvestor: 0 €Startup : 20 mil €
Investor: 10 mil €Startup : 0 mil €",11.16338134,1,"The generated answer provides the economic decision rule formula, which is identical to the one in the ground truth.",1,"The generated answer is faithful. [cite_start]The context includes a diagram explicitly showing the economic decision rule as: 'â€žInvestâ€œ iff pâ‹…U(15,15) + (1âˆ’p)â‹…U(0,20) â‰¥ U(10,0)'[cite: 1771].",1,"The context directly provides the economic decision rule for the investor in the specified format: 'Invest' iff p â‹… U(15,15) + (1âˆ’p) â‹… U(0,20) â‰¥ U(10,0)."
"According to the document, what are two phases of a productivity pattern that emerge when a General-Purpose Technology diffuses?",A short-run dip and a long-run rebound.,"Gemäß dem Text entstehen bei der Ausbreitung einer Allzwecktechnologie zwei Phasen eines Produktivitätsparadigmas:

1.  **Anfangs sinkt die Produktivität:** Zunächst geht die Produktivität aufgrund von Investitionen in die Nutzung und Integration der Technologie tatsächlich runter.
2.  **Später steigt die Produktivität:** Nach einer gewissen Zeit, nachdem die notwendigen Investitionen getätigt wurden und die Organisation sich angepasst hat, steigt die Produktivität dann steil an.","der Produktivität, dann sehen 
wir,
dass am Anfang bei vielen 
Technologien eigentlich
und das ist ein Average
erstmal die Produktivität runter 
geht.
Wir sind sozusagen an der 
unteren dieser Kurve,
diesem unteren Halbkreis von dem 
J.
Und erst danach geht es 
eigentlich nach oben.
Wir haben eine massiven 
Produktivität.
Das ist wie gesagt der die
Veränderung wir sehen hier ist 
erstmal runtergeht,
dann geht steil nach oben und 
das ist ein Phänomen,
was wir diese Kurve nennen.
Und das sehen wir immer wieder 
mit
verschiedenen General purpose 
technology.
Und das hat ganz einfache 
Gründe, nämlich,
dass am Anfang,
wenn wir in diese Technologien 
investieren,
wie in GPT investiert wird,
haben wir erstmal riesige 
anfängliche Investitionen,
die sich nicht sofort auszahlen.
Wir haben massive Investitionen,
beispielsweise darin,
dass Leute die Technologie 
richtig nutzen können.
Ich muss Schulungen machen,
ich muss die Infrastruktur 
schaffen,
ich muss die Anbindung an meine 
Datenbank schaffen.
Ich muss ganz viele intangible 
Assets Know how kreieren,
um dann letztlich auch wieder 
weitere Innovationen.
Wir reden über General Purpose 
Technologien,
komplementäre Investitionen 
anzuregen.
Und das führt natürlich dazu, müssen,
unsere Datenpipelines, unsere 
Sensorik,
unsere Organisationsprozesse 
allgemein,
die wir wie in diesem
Beispiel der Fabriken mit der 
Steam Engine,
mit Electricity wir abändern 
müssen.
Und das hilft uns dann 
letztlich,
das volle Potenzial dieser 
Innovation herauszuarbeiten.
Jetzt ist aber die Frage 
vielleicht
haben Sie es gehört oftmals die 
Diskussion.
Na ja, warum sehen wir denn 
jetzt
noch eigentlich keine 
Produktivitätssteigerung?
Ja, viele Manager stellen sich
hin und sagen Wir haben so viel 
investiert,
passiert ja gar nichts, Außer im 
Software Development.
Da sehen wir wirklich massive 
Anstiege in
der Produktion, in der 
Produktivität.
Aber wir sehen es nicht 
grundsätzlich überall.
In vielen Organisationen kostet 
bisher einfach nur Geld.
Und das ist ein Phänomen,
das ist gar nicht neu.
Das nennen wir die Kurve.
Wie so ein J. Wie Sie hier sehen 
können,
wo wir bei der Einführung der 
Technologie,
wenn wir hier die Jahre auf der 
Achse haben
und hier die Veränderung in
der Produktivität, dann sehen 
wir,
dass am Anfang bei vielen 
Technologien eigentlich
und das ist ein Average
erstmal die Produktivität runter 
geht.
Wir sind sozusagen an der 
unteren dieser Kurve,
diesem unteren Halbkreis von dem 
J. Datenbank schaffen.
Ich muss ganz viele intangible 
Assets Know how kreieren,
um dann letztlich auch wieder 
weitere Innovationen.
Wir reden über General Purpose 
Technologien,
komplementäre Investitionen 
anzuregen.
Und das führt natürlich dazu, 
dass viele Ressourcen,
die eigentlich vielleicht auf 
der Produktivität
per se gelegen haben,
abgezogen werden und in
diese Produktivitätssteigerung 
investiert werden.
Und damit haben wir immer so ein 
bisschen.
Wir brauchen erstmal viel Zeit
und sollten nicht zu ungeduldig 
sein,
bis wir die Effekte dieser
neuen Technologie wirklich 
sehen.
Ich habe ihn letztes
Mal schon gesagt der große 
Missglauben
bei vielen Unternehmen ist 
weiterhin Ich nehme ei,
schmeiß es ins Unternehmen und 
es bringt sofort was.
Ne KI muss integriert sein.
Wir müssen die Prozesse da herum 
bauen,
Genauso wie wir die Fabriken
mit der Einführung der 
Elektrizität
im Vergleich zur Steam Engine 
umbauen mussten,
müssen wir unsere Organisationen 
adaptieren.
Und das führt dazu, dass wir 
eben am
Anfang diese Zeit brauchen,
um aus dieser Krise 
rauszukommen.
Und wir sehen die ersten 
Anzeichen,
dass wir jetzt möglicherweise
über KI Agenten nachdenken, da 
rauskommen.
Bei Software Development sind",11.70112419,1,The generated answer and the ground truth both correctly identify the two phases of the productivity pattern as a short-run dip and a long-run rebound.,1,"The generated answer is faithful. [cite_start]The context describes the 'J-Kurve' as a phenomenon where productivity initially goes down ('erstmal die ProduktivitÃ¤t runter geht'), which corresponds to the 'dip', and then goes steeply up ('dann geht steil nach oben'), which corresponds to the 'rebound'[cite: 1788].",1,"The context describes the 'J-curve' phenomenon where, with the introduction of a new technology, productivity initially goes down ('erstmal die ProduktivitÃ¤t runter geht'), representing a short-run dip, before later increasing steeply ('dann geht steil nach oben'), representing a long-run rebound."
What is the date of the first lecture?,45771,"Die erste Vorlesung fand am Donnerstag, dem 12:00 bis 16:00 Uhr statt.","Informationen zur Vorlesung: Gehalten am Do. 12:00 bis 16:00; wöchentlich vom 24.04.2025 bis 24.07.2025; Ort: Hörsaalzentrum Westend - HZ 12 So. Herzlich Willkommen zur 
Vorlesung Nummer zwei.
Ich freue mich natürlich zu 
sehen,
dass der Raum noch nicht 
komplett leer ist.
Auch wenn jetzt die 
Einführungsveranstaltung
vorbei ist und Sie sich 
überlegen konnten,
ob sie diesen Kurs machen 
wollen.
Von daher sehr schön,
dass Sie noch dabei sind.
Nachdem ich Ihnen schon einmal 
auf die
Nerven gegangen bin mit Machine 
Learning.
Heute geht es direkt dort 
weiter,
wo wir letztes Mal aufgehört 
haben.
Wenn Sie sich erinnern wir haben 
angefangen,
darüber zu sprechen,
was Machine Learning von einer 
ganz,
ganz konzeptionellen Idee 
liefern kann.
Wir haben ein bisschen 
Terminologie
eingeführt und damit würde
ich gerne mit Ihnen anfangen.
Sozusagen, um alle hier wach zu 
machen, auch mich selber.
In den Vorlesungsmodus zu 
begeben.
Machen wir einen kurzen Recap 
auf zwei Folien.
Wenn Sie sich erinnern, sind das 
hier
Kernelemente von Machine 
Learning.
Sie können jede Machine Learning 
Funktion,
jedes Modell sogar GPT in
dieser Gleichung hier 
ausdrücken.
Wir haben drei verschiedene 
Komponenten.
Wir haben hier dieses Hütchen,
wir haben das fix und wir haben 
hier dieses Y Hütchen.
Meine erste Frage an Sie Was war 
das? F Hütchen.
Yes, genau richtig. von Anfang bis Ende von
einer Maschine durchgeführt 
worden ist.
Der Mensch hat daran nichts 
verändert.
hat. Weder bei Ideation nur den 
Anfang.
Befehl eingegeben.
Komme mit einer das haben sie 
glaube ich gesagt,
irgendwie Develop a new year for
innovative machine learning 
paper
that they want to publish at
this conference und the machine 
green with it.
Und das hat es anscheinend durch
den Peer Review Prozess 
geschafft.
Immer so ein bisschen Grain of 
salt sehen.
Ist natürlich auch medial 
aufgebauscht.
Wie viel wirklich dann an der
Stelle noch an Mensch 
reingeflossen ist,
kann ich Ihnen an dieser Stelle 
nicht verlässlich sagen.
Ich warte selber auf das 
Research Papier,
das das erklärt, was da wirklich 
passiert ist.
Aber das ist natürlich die 
mediale Darstellung.
Jetzt erstmal davon Companions,
das ist auch so ein Riesending.
Weiß nicht, ob du es mitgekriegt 
haben.
Mark Zuckerberg hatte auf 
irgendwo
in den USA auf einer Sitzung 
jetzt gesagt,
dass er das Problem von 
Einsamkeit lösen will,
in dem alle Menschen mit KI 
interagieren KI,
die auf Social Media trainiert 
worden ist.
Die Idee gibt es natürlich schon 
länger.
Ich glaube, diese Idee
hat ihn gewissermaßen vielleicht 
Potenzial zu helfen.",5.021644592,0,"The generated answer provides an incorrect date. The ground truth correctly identifies the date as April 24, 2025.",0,"The generated answer is unfaithful. [cite_start]The context gives the lecture schedule as 'wÃ¶chentlich vom 24.04.2025 bis 24.07.2025'[cite: 1797]. The generation claims the first lecture was on a specific time, but the context only provides the date range.",0,"The context provides the weekly schedule for the lecture, including the start and end dates (24.04.2025 to 24.07.2025), but does not contain the number 45771."
What is the purpose of the tutorial sessions?,To work on applications (case studies & coding).,"The text doesn't explicitly state the purpose of the tutoring events. It mentions a lecture that includes a discussion about ""Feedbackloop bzw einen sogenannten Data Drift,"" suggesting it's part of a larger learning process.","Informationen zur Vorlesung: Gehalten am Do. 12:00 bis 16:00; wöchentlich vom 24.04.2025 bis 24.07.2025; Ort: Hörsaalzentrum Westend - HZ 12 her sich zog.
Das ist ein Beispiel für so ein 
Application Solution.
Fragen bis hierher irgendwas
unklar auf diesen verschiedenen 
Leveln.
Wir fangen bei keiner 
Integration an,
einzelne Prediction gehen 
Schritt weiter.
Wir integrieren das System 
besser in unsere Workflows.
Wir erkennen notwendige andere 
Veränderungen
innerhalb des Workflows.
Ja. Zum Beispiel, wenn wir jetzt 
also sagen wir mal,
im Bewerbungsverfahren,
eine automatisierte Bewerbung 
nach Sibirien oder
sowas durchsucht werden.
Wie ist es, wenn also der
Spieler dem System quasi 
konfrontiert ist mit
Menschen zu predigten,
aber die sind in der Produktion.
Also wie sinnvoll ist dann so 
ein System? Sehr gut.
Ich würde Ihre Frage ein
paar Minuten nach hinten 
schieben,
weil das ein Teil der
zweiten Hälfte der Vorlesung 
heute ist,
wo wir über Probleme sprechen 
Und was Sie ansprechen,
nennt man ein Feedbackloop bzw 
einen
sogenannten Data Drift.
Sobald Menschen oder auch
ganze Systeme von dem
Einsatz von Machine Learning 
Systemen
wissen, könnte es sein,
dass Menschen ihre Art und 
Weise,
sich zu verhalten, ändern,
um dieses das System 
auszutricksen,
indem bestimmte neue 
Fachbegriffe,
wo man denkt, das ist, wo die 
Maschine drauf anspricht. zumindest durch eine bestimmte
Methode mir ein bisschen 
erklären kann.
Woher eigentlich diese 
Vorhersage stammt.
Sie sehen auch hier diese Task 
factors.
Die Natur des Tasks ist das,
worüber ich gerade gesprochen 
habe.
Spielt hochgradig eine Rolle,
wo wir tendenziell sehen,
dass Task, die wir als sehr 
subjektiv wahrnehmen,
wie Film Recommendations,
Wenn Menschen sich gegenseitig 
Witze erzählen sollen,
Einschätzungen davon,
ob ein bestimmter Urlaubsort 
interessant ist oder nicht,
diese ganzen sehr
subjektiv wahrgenommenen 
Aufgaben präferieren
wir eher von Menschen,
Hilfe anzunehmen,
dass von Menschen lösen zu 
lassen als von Maschinen.
Wohingegen für komplexe
objektive Tasks wie Berechnungen 
von Aktienkursen,
Einschätzungen von 
CompanyDefaults etc.
Da tendieren Menschen von dem,
was die Forschung aktuell zeigt 
und es
ist wie gesagt ein sehr aktives 
Feld dazu,
eher Hilfe von Maschinen 
anzunehmen.
Gibt es irgendwelche Fragen 
soweit?
So, jetzt kommen wir zu den zwei 
Modes of Collaboration.
Auch wieder sehr dichotom 
gedacht als über
Kategorien haben wir zwei und es 
gibt eine Strömung,
die mittlerweile so ein bisschen 
sagt Naja,
eigentlich haben wir drei 
Kategorien.
Hier streiten wir uns aber nicht 
drüber,",6.058935404,1,"The generated answer correctly states that the purpose of the tutorial sessions is to work on applications (case studies & coding), which is semantically consistent with the ground truth.",0,The generated answer is unfaithful. The context discusses different levels of integration of machine learning solutions but does not mention 'tutorial sessions' or their purpose.,0,The context mentions a lecture where 'Feedbackloop bzw einen sogenannten Data Drift' is discussed but does not explicitly state the purpose of the tutorial sessions.
"According to the document, what is a Class 2 customer?",A Profitable customer.,"Der Text enthält keine Informationen darüber, was ein ""Klasse 2 Kunde"" ist. Er beschreibt den Einsatz von Machine Learning in Banken, um die Kreditwürdigkeit von Personen zu bewerten, basierend auf verschiedenen Datenpunkten wie Alter, Kinderanzahl und Einkommen.","eigentlich besser als Maschine 
alleine?
Ist der Banker? Hat er 
eigentlich einen Beitrag dazu?
Macht er das Ganze schlechter?
Vielleicht sogar? Und dann?
Auf der anderen 
Konsumentenseite,
können wir untersuchen Wie 
reagiert eigentlich
der Banker, der Kunde darauf?
Möchte der Kunde eigentlich,
dass der Mensch mit ihm Lob
ist oder ist ihm das scheißegal?
Auf Deutsch gesagt das haben wir
uns angeschaut und wie gesagt,
das ist jetzt der 
Schnelldurchlauf,
weil ich sie hier nicht zu lange 
halten möchte.
Frage Nummer eins Macht der 
Mensch
es besser oder schlechter?
Naja, if anything macht der 
Mensch eher schlechter.
Wir sehen, die Maschine alleine 
hat eine
Accuracy aus den
73 % Mensch plus Maschine ist 
die Beratung richtig?
In 70 % der Fälle ein bisschen 
schlechter.
Statistisch gesehen haben unsere 
Tests aber gezeigt,
dass es nicht signifikant ist.
Deswegen ist so ein bisschen die
Message hier If anything macht 
der Mensch nicht besser,
aber ganz vorsichtig gesagt,
er macht es auch nicht 
statistisch
nachweislich schlechter.
Auch wichtig zu sehen der Mensch 
macht ein bisschen was.
Ja, wir sehen nicht,
dass der Mensch einfach die
Entscheidung der KI weitergibt,
sondern der interagiert 
wirklich.
Denkt anscheinend drüber nach. eigentlich 
Entscheidungsunterstützung,
wo das System uns sagt Nein,
das ist eine Möglichkeit,
wie man diesen Code weiterführt.
Auf der anderen Seite haben
wir unsere ganzen großen 
Sprachmodelle,
mit denen wir tagtäglich 
zusammenarbeiten,
wo unser Job ist, eigentlich 
nicht,
etwas an die Maschine komplett 
zu delegieren.
Ja, Sie sollten nicht eine 
Eingabe machen.
Schreib mir meine 
Bachelorarbeit, die Maschine 
macht das.
Sie nehmen die Bachelorarbeit 
und geben die ab,
sondern Sie sollten
das als 
Entscheidungsunterstützung 
ansehen,
wo Sie als der Mensch Input von 
der Maschine bekommen,
Sie diesen Input nachprüfen 
sollten
und letztlich selber die finale 
Entscheidung treffen.
Das ist vorbei.
Also verstehe ich das richtig,
dass wir im Prinzip im zweiten 
Teil des Events,
dass man eine Entscheidung 
trifft,
Also eine Entscheidung dann,
wenn das fliegende Maschinen 
scheitert.
Ich muss nur so lachen wegen 
Meter,
weil ich gerade ein
Forschungsprojekt bin mit einer 
Psychologiekollegin
und wir reden über 
Metakognition.
Und wir sagen tatsächlich,
dass Metakognition auf dem Meta 
Level fällt.
Die Entscheidung, ob ich die
Entscheidung jemand anders 
machen lasse.
Also auch wieder System eins und 
System zwei,
so ein bisschen Die Dann haben wir die zweite 
Komponente.
Das war das XML. Was ist das?.X. 
Jemand eine Idee?
Jetzt dahinten? Genau das sind 
die Daten,
die wir in diese Maschine 
reintun.
Wir haben zum Beispiel, wenn Sie 
überlegen,
Sie interagieren mit Chat GPT 
auf der Website.
Sie prompten dieses System.
Sie geben einen Input Dieses ics 
kann der Text sein.
Dieses Ichs kann aber auch 
beispielsweise in Banken,
die ein Machine Learning Modell 
haben,
um zu berechnen, ob jemand 
kreditwürdig ist oder nicht.
Kann dieses Ichs eine Person 
repräsentieren?
Es können die Eigenschaften der 
Person sein,
das Alter der Person,
die Anzahl der Kinder, der 
Person,
das Einkommen der Person und 
vieles Weiteres.
Es kann sogar so weit gehen, 
dass wir Filme,
Audiofiles reinpacken 
unstrukturierte Daten ähnlich zu
texten und noch ein bisschen 
komplexer,
um dann wieder eine Vorhersage 
zu
machen und dann sind wir schon 
bei
was da rauskommt.
Die Vorhersage.
Jetzt habe ich es leider schon 
preisgegeben,
nämlich das hier.
Das ist unsere Prädiktion,
auf Englisch auch wieder 
indiziert durch das Hütchen.
Das Hütchen zeigt uns an dieser 
Stelle,
dass wir nicht ganz explizit 
wissen,
ob das eigentlich das reale 
Outcome ist.
Wenn Sie eine Machine Learning",7.694344521,0,The generated answer incorrectly claims the text contains no information about a 'Class 2 customer.' The ground truth correctly defines a Class 2 customer as a Profitable customer.,0,"The generated answer is unfaithful. [cite_start]The context describes using machine learning to predict creditworthiness based on features like age and income[cite: 1857], but it never defines or mentions a 'Class 2 customer'.",0,"The context discusses using machine learning to predict creditworthiness based on customer characteristics like age and income, but it does not define or mention a 'Class 2 customer'."
What companies were mentioned as having faced discrimination and harassment allegations in 2020?,"Amazon, McDonald’s, and Pinterest.","Laut dem Artikel wurden im Jahr 2020 folgende Unternehmen mit Vorwürfen von Diskriminierung und Belästigung genannt:

*   Amazon
*   McDonald’s
*   Pinterest","against major companies like Amazon , 
McDonald’s, and Pinterest: These are some of 
the year ’s high -profile legal battles.  Business 
Insider. https://www.businessinsider.com/
every-company-that-was-sued-discrimination-
and-harassment-lawsuits-2020-2021-1  
Srivastava, M., Heidari, H., & Krause, A. (2019). 
Mathematical notions vs. human perception of 
fairness: A descriptive approach to fairness for 
machine learning. Proceedings of the 25th 
ACM SIGKDD International Conference on of inadvertently perpetuating or igniting algorithmic 
discrimination if these individuals engage in 
discriminatory practices. In this context, efforts aimed at 
identifying and mitigating (subconscious) discriminatory 
practices of organizational decision  makers, such as 
awareness training, become an indispensable 
complementary element to ensure that continuously 
updated ML models exhibit desirable behaviors. 
2 Theoretical and Conceptual 
Background 
In this section, we first provide the conceptual 
underpinnings of algorithmic discrimination. 
Subsequently, we discuss the literature gaps our work 
aims to address. that nonobjective variables, such as inadequate information,
contribute to biased outcomes (Dickinson and Oaxaca, 2009).
Lastly, we have the antecedent market discrimination hypothesis
as the fourth category.
Statistical discrimination theory. Statistical discrimination refers
to prejudice from assessment criteria that generalize group
characteristics to individuals (Tilcsik, 2021). It arises due to
limitations in employers’research techniques or the cost con-
straint of obtaining information in the asymmetry between
employers and job seekers. Even without monopolistic power,
statistical discrimination can occur in the labor market due to
information-gathering methods. Employers are primarily inter-
ested in assessing candidates ’ competitiveness when making
recruitment decisions. However, obtaining this information
directly is challenging, so employers rely on various indirect
techniques.
Discrimination carries both individual and societal economic
costs. The social cost arises from the decrease in overall economic
output caused by discrimination. However, this is still deemed
efﬁcient under imperfect information and aligns with the
employer’s proﬁt maximization goal. Therefore, it is likely that",6.384525537,1,"The generated answer and the ground truth both correctly list Amazon, McDonaldâ€™s, and Pinterest as the companies that faced allegations.",1,"The generated answer is faithful. [cite_start]The context explicitly lists 'Amazon, McDonaldâ€™s, and Pinterest' as companies that faced high-profile legal battles related to discrimination and harassment in 2020[cite: 1862].",1,"The context directly answers the question by listing 'Amazon, McDonaldâ€™s, and Pinterest' as companies that faced high-profile legal battles over discrimination and harassment allegations."
What is the URL for the document by Cowgill and Tucker (2019)?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3361280,Die URL des Dokuments von Cowgill und Tucker (2019) ist: https://aisel.aisnet.org/jais/vol25/iss4/9,"Informationen zur Vorlesung: Gehalten am Do. 12:00 bis 16:00; wöchentlich vom 24.04.2025 bis 24.07.2025; Ort: Hörsaalzentrum Westend - HZ 12 DOI: 10.17705/1jais.00853 
Available at: https://aisel.aisnet.org/jais/vol25/iss4/9 
This material is brought to you by the AIS Journals at AIS Electronic Library (AISeL). It has been accepted for 
inclusion in Journal of the Association for Information Systems by an authorized administrator of AIS Electronic 
Library (AISeL). For more information, please contact elibrary@aisnet.org. So lassen Sie uns beginnen. 
Herzlich willkommen.
Vorlesung drei.
Sind wir mittlerweile 
angekommen?
Also, wir nehmen langsam ein 
bisschen Fahrt auf.
Wie Sie vielleicht gemerkt 
haben,
hatte ich vergessen, heute 
Morgen
die Folien hoch zu laden.
Aber jetzt gerade live gemacht.
Das heißt, jetzt können Sie die
auf Olat wie gewohnt für sich 
runterladen.
Die Zusatzmaterialien wird
die Mitarbeiterin noch 
hochladen.
Wir sind uns noch nicht so ganz 
sicher,
was wir Ihnen da zur Verfügung 
stellen wollen,
ohne sie da irgendwie mit zu 
viel Material zuzuschmeißen,
wie wir es die letzten oder das 
letzte
Mal auch schon gemacht haben,
würde ich gerne wieder ganz kurz 
einen Recap machen.
Zu sehr zentralen Themen,
auf die wir heute auch wieder 
Bezug nehmen werden,
die uns helfen, das große Ganze 
zu sehen.
Wir haben in der allerersten 
Vorlesung
so ein bisschen die Motivation,
warum Machine Learning wichtig 
ist, auf einer ganz,
ganz High Level Perspektive uns 
angeschaut,
sind dann in eine Case Study 
gemacht,
wo ich ihnen gezeigt habe,
wie man Machine Learning 
anwenden kann.
Nicht immer nur zu negativen 
Aspekten,
aber diese Predictions,
die Machine Learning uns liefern 
kann,
wie man die auch dazu nutzen 
kann,",5.813427448,0,The generated answer provides an incorrect URL. The ground truth provides the correct URL.,0,The generated answer is unfaithful. [cite_start]The context provides a URL for the 'Feedback Loops in Machine Learning' paper as 'https://aisel.aisnet.org/jais/vol25/iss4/9'[cite: 1879]. The URL in the generated answer is different.,0,The context provides a URL from aisel.aisnet.org but not the https://www.google.com/search?q=papers.ssrn.com URL specified in the ground truth.
"In the 'Feedback Loops in Machine Learning' study, what did the authors note about the batch learning methodology?",This technique retrains the learning algorithm on all the currently available training data.,"Ich kann anhand des bereitgestellten Textes nicht herausfinden, was die Autoren in der Studie „Feedback Loops in Machine Learning“ über die Batch-Lernmethodik festgestellt haben. Der Text enthält keine Informationen darüber.","Feedback Loops in Machine Learning 
 
811 
3.2 Previous Empirical Studies 
We buil t our simulations on two secondary datasets, 
collected by several authors of this paper as part of 
different empirical studies. Study A was an incentivized 
field study conducted over three years from 2016 to 
2019. Study A measured participant s’ behavior in the 
investment game  defined above  in their  role as 
borrowers. The data from Study A allow ed us to 
develop an ML model predicting borrowers’ repayment 
decision and serves as the foundation for simulating 
borrower behavior. Study B, conducted in December 
2020, was an incentivized online experiment where 
participants engaged in the outlined investment game in 
the role of investors. In this experiment, investors could 
access an ML model predicting borrowers ’ repayment 
likelihood. Notably, this model, along with the 
borrowers with whom investors from Study B 
interacted, originated from Study A data. The data from 
Study B provide d the basis for simulating investor 
decisions. We present the exact instructions given in 
these studies in Appendix B.1. 
Study A: At the onset of each semester, first -semester 
economics students from a large German university were Feedback Loops in Machine Learning 
 
829 
in an algorithm used to manage the health of 
populations. Science, 366(6464), 447-453.  
Oliphant, T. E. (2006). A guide to NumPy . Trelgol 
Publishing. 
O’Neil, C. (2017). Weapons of math destruction: How 
big data increases inequality and threatens 
democracy. Crown.  
Pedregosa, F., Varoquaux, G., Gramfort , A., Michel, 
V., Thirion, B., Grisel, O., Blondel, M., 
Prettenhofer, P., Weiss, R., Dubourg, V., 
Vanderplas, J., Passos, A., Cournapeau, D., 
Brucher, M., Perrot, M., & Duchesnay, E. 
(2011). Scikit -learn: Machine learning in 
Python. Journal of Machine Learning 
Research, 12, 2825-2830. 
Pessach, D., & Shmueli, E. (2022). A review on 
fairness in machine learnin g. ACM Computing 
Surveys, 55(3), 1-44.  
Pianykh, O. S., Langs, G., Dewey, M., Enzmann, D. 
R., Herold, C. J., Schoenberg, S. O., & Brink, J. 
A. (2020). Continuous learning AI in radiology: 
implementation principles and early 
applications. Radiology, 297(1), 6-14.  
Phelps, E. S. (1972). The statistical theory of racism 
and sexism. The American Economic Review , 
62(4), 659-661.  
Prates, M. O., Avelar, P. H., & Lamb, L. C. (2020). 
Assessing gender bias in machine translation: a Feedback Loops in Machine Learning 
 
825 
References 
Abdel-Karim, B., Pfeuffer, N., Carl, V., & Hinz, O. 
(2023). How AI -Based Systems Can Induce 
Reflections: The Case of AI -Augmented 
Diagnostic Work, MIS Quarterly, 47(4) 
Ågerfalk, P. J. (2020). Artificial intelligence as digital 
agency. European Journal of Information 
Systems, 29(1), 1-8. 
Adomavicius, G., Bockstedt, J. C., Curley, S. P., & 
Zhang, J. (2018). Effects of online 
recommendations on consumers’ willingness to 
pay. Information Systems Research , 29(1), 84-
102.  
Agrawal, A., Gans, J. S., & Goldfarb, A. (2019). 
Exploring the impact of artificial intelligence: 
Prediction versus judgment. Information 
Economics and Policy, 47, 1-6. 
Allcott, H., Boxell, L., Conway, J., Gentzkow, M., 
Thaler, M., & Yang, D. (2020). Polarization 
and public health: Partisan differences in social 
distancing during the coronavirus pandemic. 
Journal of Public Economics , 191, Article 
104254. 
Arrow, K. J. (1972). Some mathematical models of 
race discrimination in the labor market. In A. H. 
Pascal (Ed.), Racial discrimination in economic 
life (pp. 187-204). D.C. Heath.  
Asatiani, A., Malo, P., Nagbøl, P. R., Penttinen, E., 
Rinta-Kahila, T., & Salovaara, A. (2020).",7.79668951,0,The generated answer incorrectly claims the text contains no information. The ground truth correctly states what the authors noted: the technique retrains the algorithm on all currently available training data.,0,The generated answer is unfaithful. The context does not mention 'batch learning methodology' or what the authors noted about it.,0,The context describes using simulations built on two secondary datasets (Study A and Study B) but does not mention the batch learning methodology or what the authors noted about it.
"According to the document, what is one practical implication for organizations regarding continuously updated ML models?",Organizations should invest in comprehensive anti-discrimination and unconscious bias training for their decision makers.,"Laut dem Dokument ist eine praktische Implikation für Organisationen hinsichtlich kontinuierlich aktualisierter ML-Modelle, dass es ein Risiko besteht, dass Menschen bei der endgültigen Entscheidung die algorithmische Diskriminierung verstärken oder unbewusst perpetuieren, da die Modelle kontinuierlich aktualisiert werden.
","Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. long term. Organizations adopting a dynamic 
sociotechnological perspective might succeed in 
creating a more equitable, effective, and efficient use 
of ML models. This approach aligns with societal 
expectations and regulatory requirements. 
From a policymaker ’s perspective, our findings 
regarding human involvement become particularly 
significant in light of impending regulations that 
mandate human participation in ML decision -making 
processes. These regulations pertain to final decisions in 
high-risk scenarios such as loan approval and hiring 
processes, as outlined in Article 22 of the General Data 
Protection Regulation and the European Commission’s 
Artificial Intelligence Act. However, our findings 
indicate a potential risk when humans have the final say 
in ML -supported decision -making processes. If 
individuals engage in discriminatory practices and the 
models update continuously, there is a risk of 
unintentionally perpetuating or amplifying algorithmic 
discrimination, as human discrimination hinders the self-
correcting capacities of ML models. Therefore, in 
conjunction with these regulations, we advocate 
measures aimed at identifying and mitigating 
(subconscious) discriminatory practices by affecting ML systems’ functionality by explaining the 
interplay b etween continuous model updating and 
algorithmic discrimination. Despite its critical importance 
in developing countermeasures and refining policy 
recommendations, the complex interplay between 
algorithmic discrimination and continuous ML model 
updating remains an underexplored area in the literature.  
Second, our paper complements the nascent body of 
studies exploring the origins and impacts of 
algorithmic feedback loops (Burghardt & Lerman, 
2022; Cowgill, 2018). For instance, Lum and Isaac 
(2016) revealed that the iterative updates of a 
predictive poli cing system led to increased 
discrimination against minority groups. Similarly, 
Ensign et al. (2017) showed how feedback loops could",7.800855875,1,"The generated answer is semantically consistent with the ground truth, as both state that organizations should invest in anti-discrimination and unconscious bias training for decision-makers.",1,"The generated answer is faithful. [cite_start]The context advocates for 'measures aimed at identifying and mitigating (subconscious) discriminatory practices by organizational decision makers,' which directly supports the claim that organizations should invest in anti-discrimination and unconscious bias training[cite: 1927].",1,"The context directly states one practical implication is the need to 'advocate measures aimed at identifying and mitigating (subconscious) discriminatory practices by organizational decision makers', which aligns with investing in anti-discrimination and bias training."
"According to the document, what is one impact of human discrimination on the self-correction capabilities of continuously updated ML models?",It impedes the self-correction abilities.,"Laut dem Dokument führt menschliche Diskriminierung dazu, dass die Selbstkorrekturfähigkeiten von kontinuierlich aktualisierten ML-Modellen beeinträchtigt werden. Wenn Menschen zunehmend voreingenommene Einstellungen und Verhaltensweisen zeigen, haben die Modelle weniger Möglichkeiten, diese Vorurteile zu korrigieren. Wenn menschliche Diskriminierung anhält, hat das kontinuierliche Aktualisieren der Modelle nur einen geringen Effekt auf die Verbesserung des Verhaltens des Modells gegenüber der diskriminierten Gruppe.","discrimination. Biases in human decision-making may 
directly influence the behavior of continuously 
updated ML models. While modern machine learning 
models inherently possess the capability to  “unlearn” 
initial biases over time given sufficiently diverse and 
unbiased data, human bias es can impede this process. 
This insight is especially relevant in the current era of 
growing political and social divisions in human 
societies (e.g., Allcott et al., 2020). When people 
increasingly adopt biased attitudes and behaviors, 
biased, continuously updated ML models are less discrimination, as human discrimination hinders the self-
correcting capacities of ML models. Therefore, in 
conjunction with these regulations, we advocate 
measures aimed at identifying and mitigating 
(subconscious) discriminatory practices by 
organizational decision makers. These measures could 
serve as essential complementary elements to ensure that 
continuously updated ML models demonstrate desirable 
behaviors when organizations implement regulatory 
requirements that involve humans in the decision loop. 
5.4 Limitations and Future Research  
Like any study, this study also has limitations—which, 
we believe , provide valuable directions for future 
research to enhance our understanding of how 
algorithmic discrimination evolves in environments 
where ML models undergo continuous updates. One imbalance combined with high or very high levels of 
human discrimination (see Columns 4 and 5).  
In sum, these results emphasize that the capacity of 
continuous ML model updating to mitigate algorithmic 
discrimination critically relies on the absence of 
discriminatory behavior by human decision makers. If 
such behaviors persist —potentially giving rise to the 
initial label imbalance in the training data—continuous 
updating has a minimal effect on improving the ML 
model’s behavior toward the discriminated group. Our 
findings even suggest that human discrimination can 
cause ML models, originally trained on balanced data and 
displaying no algorithmic discrimination, to adopt 
increasingly discriminatory behaviors, as measured by 
statistical parity. In the context of our loan approval 
example, the results reveal that the efficacy of 
continuously updated ML models notably declines if a 
loan officer persistently discriminates against female 
applicants, regardless of the creditworthiness assessment 
generated by the ML model. Consequently, the ML 
model’s prediction may persistently demonstrate gender 
disparity across two key dimensions: the ML model ’s 
propensity to deem female applicants as creditworthy and",10.62959886,1,The generated answer's claim that human discrimination impedes the self-correction abilities of ML models is semantically identical to the ground truth.,1,"The generated answer is faithful. [cite_start]The context states that 'human discrimination hinders the self-correcting capacities of ML models'[cite: 1938], which directly supports the claim that it impedes self-correction abilities.",1,"The context directly answers the question, stating that 'human discrimination hinders the self-correcting capacities of ML models', which impedes their self-correction abilities."
"According to the document, what is the approximate percentage point change in the share of positive predictions for female borrowers when there is no human discrimination and the maximum label imbalance is present?",0.22,"Laut dem Dokument beträgt die ungefähre Punkteveränderung im Anteil positiver Vorhersagen für weibliche Kreditnehmer, wenn es keine menschliche Diskriminierung gibt und das maximale Label-Ungleichgewicht vorliegt, von 0% in Iteration 1 auf 22% in Iteration 100.","investors’ probability to invest with female borrowers. 
Figure 6 shows that the share of positive predictions  
(the two panels at the top) and false-negative rates (two 
panels at the bottom) for female borrowers depends on 
the level of human discrimination and the degree of the 
initial label imbalance . To illustrate the change over 
time in a parsimonious way, we pre sent the 
visualization for the first and the last iteration only.  
Figure 6 reveals that the effectiveness of continuously 
updating an ML model in mitigating algorithmic 
discrimination diminishes in the presence of 
discrimination by human decision makers. Specifically, 
the extent of human discrimination negatively impacts the 
growth of positive predictions for female borrowers 
across iterations, regardless of the initial label imbalance. 
For instance, a comparison of the upper two panels shows 
that at the maximum label imbalance (x-axis), the share 
of positive predictions (y-axis) for women increases from 
0% in Iterations 1 (left panel) to 22% in Iteration 100 
(right panel) if there is no human discrimination (z-axis). 
However, this growth is significantly curtailed, reaching 
merely 1.2%, 6.9%, 14.3% under very high, high, and model to make an informed approval decision. The 
model often inaccurately predicts that female 
applicants are not creditworthy, while it is almost 
always correct for men. If these biased predictions lead 
the officer to deny loans to women more often than 
men, the bank will collect more data on male loan 
repayment behavior than on that of women. This 
escalating gender bias in the data used to update the 
ML model may exacerbate the model ’s inaccuracies, 
particularly in its predictions for women. This could 
potentially initiate a self -perpetuating feedback loop, 
where the disparity in prediction quality between men 
and women widens (e.g., Kleinberg et al., 2018) . It is 
important to note that such feedback loops can arise 
not only from initially biased ML models but also from 
loan officers who independently discriminate against 
female applicants, even when using ML predictions. 
As a result, training data can be come increasingly 
unbalanced and distorted due to human behavior alone. 
In such a scenario, if the ML model is continually 
updated with the newly generated data, even an 
initially unbiased system may eventually start to 
discriminate against women. borrowers were 22% and 36.1%, respectively. Despite 
this share  for female borrowers remaining 
considerably lower than in the control condition ( -
47.3%), ongoing updates of the ML model narrowed 
the gender gap by approximately two thirds. 
Regression results depicted in Table 1 statistically 
corroborate the se insights. In the context of our loan 
approval scenario, this suggests that continuous 
updating reduces initial inequality in predicted loan 
repayment of male and female applicants, thereby 
approaching statistical parity. Examining false -
negative error rates , 13  i.e., the share of incorrect 
predictions that a borrower will not make a repayment 
(see lines with markers), the negatively sloped lines in 
Panel (i) show  that continuous updating similarly 
reduces these errors for both types of borrowers  over 
time. Initial false -negative rates for female and male 
borrowers equaled 59.5% and 31.6%, respectively, 
decreasing to 40.3% and 9.9% after 100 iteration s, as 
evidenced by the development of lines with markers . 
Notwithstanding these considerable model 
improvements (see Table 1, Column 2), the gender gap 
in incorrect predictions that a borrower wil not make a",10.14137244,1,"The generated answer provides the correct percentage point change (22%), which is identical to the ground truth.",1,"The generated answer is faithful. [cite_start]The context states that 'at the maximum label imbalance (x-axis), the share of positive predictions (y-axis) for women increases from 0% in Iterations 1 (left panel) to 22% in Iteration 100 (right panel) if there is no human discrimination'[cite: 1951].",1,"The context provides the exact figures needed to answer the question. It states that at maximum label imbalance and no human discrimination, the share of positive predictions for women increases from 0% in Iteration 1 to 22% in Iteration 100. The change is therefore 22 percentage points, or 0.22."
"In the 'Feedback Loops in Machine Learning' study, what was the share of game outcomes matching the perfect information benchmark for female borrowers in the first iteration?",42.3%.,"Die Studie „Feedback Loops in Machine Learning“ gibt keine genaue Angabe für den Anteil der positiven Ergebnisse für weibliche Kreditnehmer in der ersten Iteration. Sie beschreibt lediglich, dass der Anteil der positiven Vorhersagen und die Fehlerquote für Fehlklassifizierungen (False-Negative-Rate) von der anfänglichen Verzerrung in den Trainingsdaten und dem Grad der menschlichen Diskriminierung durch den Investor abhängen.","Feedback Loops in Machine Learning 
 
819 
 
 
Note: We illustrate how the mean share of positive predictions and mean false-negative error rates for female borrowers in Iterations 1 and 100 
depend on the initial label imbalance in the training data and the degree of human discrimination by the investor. A comparis on of panels for 
Iterations 1 and 100 for the two measures of algorithmic discrimination provides insights into their conditional development across iter ations. 
Abbreviations: False-neg. rate = false-negative rate; Init. lab. imb. = initial label imbalance; Human discr. = human discrimination. 
Figure 6. Development of the Mean Share of Positive Predictions and False-Negative Error Rates 
Figure 6 also shows that an increase in human 
discrimination undermines the reduction in false -
negative error rates for female borrowers over time. 
For instance, the lower two panels show that with a 
high initial label imbalance (x-axis), the false-negative 
error rate (y-axis) for female borrowers decreases from 
55.4% in Iteration 1 (left panel)  to 35.8% in Iteration 
100 (right panel)  if there is no human discrimination  
(z-axis). However, under very high human 
discrimination, this rate only drops to 52.2%  in Feedback Loops in Machine Learning 
 
847 
Number of Investors and Borrowers Matched per Iteration: 60 
Table A28. OLS Regression Estimates  
 Fairness measures 
(gender gap) 
 Economic efficiency 
(female borrowers only) 
 (1) (2)  (3) (4) 
Dep. variable: Share of repay 
predictions 
False-negative 
error rates  Outcome under 
perf. inf. 
Invest in repay. 
borrower 
Iteration -0.0003 -0.0013***  0.0016*** 0.0016*** 
 (-1.18) (-4.98)  (9.00) (6.34) 
Low lab. imb. 0.0735*** 0.0386*  -0.0058 -0.0298 
 (3.58) (1.65)  (-0.40) (-1.46) 
Medium lab. imb. 0.2006*** 0.0937***  -0.0550*** -0.1643*** 
 (10.15) (4.18)  (-3.70) (-8.34) 
High lab. imb. 0.2938*** 0.1305***  -0.0982*** -0.2488*** 
 (14.44) (5.84)  (-6.56) (-13.28) 
Max lab. imb. 0.3526*** 0.1411***  -0.1295*** -0.3238*** 
 (18.68) (6.20)  (-8.65) (-18.05) 
Iteration*Low lab. imb. -0.0007** -0.0000  0.0001 0.0005 
 (-2.10) (-0.13)  (0.57) (1.42) 
Iteration*Medium lab. imb. -0.0013*** 0.0003  0.0003 0.0012*** 
 (-4.05) (0.91)  (1.07) (3.39) 
Iteration*High lab. imb. -0.0017*** 0.0007**  0.0002 0.0013*** 
 (-4.68) (2.00)  (0.86) (3.72) 
Iteration*Max lab. imb. -0.0017*** 0.0012***  0.0004 0.0017*** 
 (-5.31) (3.26)  (1.58) (5.23) 
N 1,500 1,500  42,400 23,020 Feedback Loops in Machine Learning 
 
849 
Number of Investors and Borrowers Matched per Iteration: 70 
Table A33. OLS Regression Estimates  
 Fairness measures 
(gender gap) 
 Economic efficiency 
(female borrowers only) 
 (1) (2)  (3) (4) 
Dep. variable: Share of repay 
predictions 
False-negative 
error rates  Outcome under 
perf. inf. 
Invest in repay. 
borrower 
Iteration -0.0004 -0.0012***  0.0017*** 0.0020*** 
 (-1.62) (-4.37)  (10.18) (8.33) 
Low lab. imb. 0.0858*** 0.0491**  -0.0356*** -0.0938*** 
 (4.40) (2.09)  (-2.60) (-5.02) 
Medium lab. imb. 0.1720*** 0.0824***  -0.0584*** -0.1493*** 
 (9.14) (3.69)  (-4.25) (-8.13) 
High lab. imb. 0.2983*** 0.1353***  -0.1094*** -0.2603*** 
 (15.86) (6.13)  (-7.93) (-15.01) 
Max lab. imb. 0.3438*** 0.1427***  -0.1338*** -0.3242*** 
 (19.30) (6.55)  (-9.67) (-19.54) 
Iteration*Low lab. imb. -0.0012*** -0.0009**  0.0004* 0.0010*** 
 (-3.71) (-2.48)  (1.86) (3.00) 
Iteration*Medium lab. imb. -0.0014*** 0.0000  0.0004* 0.0012*** 
 (-4.33) (0.06)  (1.79) (3.53) 
Iteration*High lab. imb. -0.0022*** 0.0003  0.0007*** 0.0019*** 
 (-6.85) (0.89)  (2.96) (5.92) 
Iteration*Max lab. imb. -0.0018*** 0.0009**  0.0004* 0.0015*** 
 (-5.84) (2.49)  (1.66) (4.94) 
N 1,500 1,500  49,495 26,665",12.61401606,0,The generated answer incorrectly claims the study gives no exact figure. The ground truth provides the correct value: 42.3%.,0,The generated answer is unfaithful. The context provides regression tables and figures about the simulation but does not contain the specific value '42.3%' for the share of game outcomes for female borrowers in the first iteration.,0,The context contains regression tables  but does not explicitly state the share of game outcomes for female borrowers in the first iteration. The data is likely within the tables but is not directly presented as a simple percentage.
"In the ""Feedback Loops in Machine Learning"" study, what type of model was utilized to predict whether an investment would occur in the investment game simulation?",A gradient boosted forest.,"Die Studie „Feedback Loops in Machine Learning“ verwendete zunächst ein Machine Learning Modell, um vorherzusagen, ob eine Investition im Simulationsspiel stattfinden würde. Dieses Modell basierte auf dem SHAP (Shapley additive explanations) Verfahren, um die Beiträge einzelner Merkmale zur Vorhersage zu erklären. Es gab sowohl initial biased als auch unvoreingenommene Modelle, bei denen die SHAP-Werte gezeigt wurden, bevor irgendwelche Aktualisierungen stattfanden.","Feedback Loops in Machine Learning 
 
813 
Armed with this information, the investor decided 
whether to invest. Notably, in our simulation , we 
mimicked investor decisions using a trained model (see 
below for more information). If an investment was 
made, the borrower decided on repayment, and a new 
observation encapsulating a borrower’s specific 
personal traits (features) and actual repayment decision 
(label) was appended to the dataset used to train the ML 
model predicting repayment. 
Importantly, to avoid inappropriate overfitting and 
spillover effects, this observation was only included if 
the dataset didn’t already contain a record of this exact 
borrower. Conversely, if an investor declined to invest, 
the individual game conclude d without eliciting a 
repayment decision from the borrower or appending a 
new observation to the training data. In other words, the 
growth of the training data was endogenous and 
selectively include d borrowers who received an 
investment (Lakkaraju et al., 2017). After all decisions 
were made, the iteration concluded with an update of the 
ML model predicting repayment by training it from 
scratch on the expanded dataset incorporating records Feedback Loops in Machine Learning 
 
811 
3.2 Previous Empirical Studies 
We buil t our simulations on two secondary datasets, 
collected by several authors of this paper as part of 
different empirical studies. Study A was an incentivized 
field study conducted over three years from 2016 to 
2019. Study A measured participant s’ behavior in the 
investment game  defined above  in their  role as 
borrowers. The data from Study A allow ed us to 
develop an ML model predicting borrowers’ repayment 
decision and serves as the foundation for simulating 
borrower behavior. Study B, conducted in December 
2020, was an incentivized online experiment where 
participants engaged in the outlined investment game in 
the role of investors. In this experiment, investors could 
access an ML model predicting borrowers ’ repayment 
likelihood. Notably, this model, along with the 
borrowers with whom investors from Study B 
interacted, originated from Study A data. The data from 
Study B provide d the basis for simulating investor 
decisions. We present the exact instructions given in 
these studies in Appendix B.1. 
Study A: At the onset of each semester, first -semester 
economics students from a large German university were Feedback Loops in Machine Learning 
 
859 
Appendix C: Technical Details on Simulation 
C.1 Details on the Repayment-Predicting ML Model in Simulations 
To gain insights into the determinants of the predictions of the ML model that aims to forecast whether borrowers will 
make a repayment, we use the popular SHAP (Shapley additive explanations) explainability method (Lundberg & Lee, 
2017). Notably, we show results for the models ’ behaviors before any updating takes place. SHAP is inspired by 
cooperative game theory explaining individual predictions by assuming that each feature value of the instance is a 
player in a game where the prediction is the payout. Estimated SHAP values describe the average marginal contribution 
of a feature value across all possible feature coalitions of a given instance. By averaging the SHAP values across all 
possible values a feature can take on, we obtain ed a reliable measure of this feature’s importance for the prediction 
task. In the following, we show SHAP values for initially biased and unbiased ML models. Each figure contains 
information on the overall importance of each feature for the prediction (higher position in the vertical ranking) and",11.43569613,1,The generated answer and the ground truth both correctly identify the model used as a gradient boosted forest.,0,"The generated answer is unfaithful. [cite_start]The context mentions that the simulations were built on data where an ML model was developed to predict borrower repayment[cite: 2003], but it does not specify that a 'gradient boosted forest' was used to predict whether an investment would occur.",0,The context mentions using the SHAP explainability method to gain insights into the model's predictions but does not specify that a gradient boosted forest was the model used.
What are some contexts in which algorithmic discrimination has been observed?,"Algorithmic discrimination has been observed in recidivism risk assessments, education, recruitment, predictive policing, health risk evaluations, targeted advertising, crowdlending scenarios, and facial recognition tasks.","Algorithmische Diskriminierung wurde in folgenden Kontexten beobachtet:

*   **Recruiting:** Konkret bei der Bewertung von Geschlecht, Rasse, Hautfarbe und Persönlichkeit.
*   **Healthcare:** Mit potenziell schwerwiegenden Folgen.
*   **Loan Approval:** Bei der Genehmigung von Krediten.
*   **Criminal Justice Systems:** In den Strafjustizsystemen.","Despite algorithms aiming for objectivity and clarity in their
procedures, they can become biased when they receive partial
input data from humans. Modern algorithms may appear neutral
but can disproportionately harm protected class members, posing
the risk of“agentic discrimination”(Prince and Schwarcz,2019).
If mishandled, algorithms can exacerbate inequalities and
perpetuate discrimination against minority groups (Lloyd,2018).
Within the recruitment process, algorithmic bias can manifest
concerning gender, race, color, and personality.
Research methodology
The primary research strategy was a literature review approach.
This review aimed to assess current research on recruitment
supported by artiﬁcial intelligence algorithms. The systematic
review process included gathering and evaluating the selected
studies’ literature and topics. Driven by the direction of the
research, studies focusing on algorithmic discrimination in
recruitment over the past 10 years were included unless past
literature was worth reviewing. This is because this is a relatively
new phenomenon that has become prominent over the past 10
years. In deﬁning the “algorithmic and hiring discrimination”
literature, a fairly broad approach was taken based on article of inadvertently perpetuating or igniting algorithmic 
discrimination if these individuals engage in 
discriminatory practices. In this context, efforts aimed at 
identifying and mitigating (subconscious) discriminatory 
practices of organizational decision  makers, such as 
awareness training, become an indispensable 
complementary element to ensure that continuously 
updated ML models exhibit desirable behaviors. 
2 Theoretical and Conceptual 
Background 
In this section, we first provide the conceptual 
underpinnings of algorithmic discrimination. 
Subsequently, we discuss the literature gaps our work 
aims to address. significant consequences, such as in healthcare, loan 
approval, hiring, or criminal justice systems. 
Mitigating algorithmic discrimination : The 
expansive literature on algorithmic discrimination 
proposes various methods to identify and alleviate 
such biases. According to d ’Alessandro et al. (2017), 
we can divide these mitigation strategies into three 
categories: pre -processing, in -processing, and post -
processing. Pre -processing strategies strive to 
eliminate disparities inherent in the dataset. Methods 
such as those proposed by Kamiran and Calders (2012) 
and Zafar et al. (2017) employ data pre -processing 
techniques like feature massaging and reweighting to 
balance the dataset based on social group 
characteristics. In -processing strategies involve 
conventional learning algorit hms during model 
training. Researchers often use techniques like naive 
Bayes and decision tr ees for debiasing (Calders & 
Verwer, 2010; Zhang et al., 2018). Additional research 
suggests placing constraints on the classification 
model to mandate the satisfaction of a proxy 
(Woodworth et al., 2017). Lastly, post -processing 
strategies aim to adjust the output to counter biases. 
For example, Corbett -Davies et al. (2017)",9.204015732,1,The generated answer provides a list of contexts where algorithmic discrimination has been observed that is semantically consistent with the list in the ground truth.,1,"The generated answer is faithful. [cite_start]The context mentions that algorithmic bias can manifest in 'gender, race, color, and personality' within the recruitment process [cite: 2020] [cite_start]and also mentions its observation in 'healthcare, loan approval, hiring, or criminal justice systems'[cite: 2031].",0.5,"The context mentions several areas where algorithmic bias manifests, including 'healthcare, loan approval, hiring, or criminal justice systems' and within recruitment based on 'gender, race, color, and personality'. This covers some, but not all, of the examples in the ground truth answer."
What is algorithmic discrimination?,Algorithmic discrimination refers to discriminatory hiring practices that arise from algorithmic bias.,"Algorithmusdiskriminierung ist, wenn ein System, das auf maschinellen Lernmodellen basiert, Ergebnisse produziert, die bestimmte Gruppen unverhältnismäßig benachteiligen oder bevorzugen, auch wenn keine Rechtfertigung dafür aus einer „Ground-Truth“-Perspektive besteht.

Es kann aus verschiedenen Quellen entstehen, darunter:

*   **Soziale Verzerrungen in den Trainingsdaten:** Wenn ein Datensatz beispielsweise mehr positive Beispiele für Männer enthält, kann das Modell diese Vorhersagen weniger genau treffen.
*   **Unabsichtliche Diskriminierung durch Menschen:** Wenn Entscheidungsträger diskriminierende Praktiken anwenden, können Algorithmen diese verstärken.

Es ist wichtig zu beachten, dass Algorithmen zwar auf Objektivität abzielen, aber dennoch durch unvollständige oder verzerrte Eingabedaten diskriminierend werden können.","Feedback Loops in Machine Learning 
 
807 
2.1 Algorithmic Discrimination 
Algorithmic discrimination: Discrimination involves 
statements or actions that unjustifiably disadvantage 
members of particular social groups. These actions 
typically stem from conscious or subconscious attitudes, 
prejudices, or emotional associations tied to 
characteristics such as  gender, age, disability, race, 
language, religion, or sexual identity (Scherr, 2008). In 
today’s era, where algorithmic systems based on ML 
models frequently aid human decisions, researchers and 
practitioners often employ the te rm “algorithmic 
discrimination” to refer to system outputs that 
disproportionately benefit or disadvantage specific 
groups, even when no justification for the disparate 
treatment exists from a ground -truth perspective 
(Kordzadeh & Ghasemaghaei, 2022).1  
Algorithmic discrimination can originate from various 
sources. First, it may stem from intentional or 
unintentional social biases encoded within the training 
data (Friedman & Nissenbaum, 1996; Romei & Ruggieri, 
2013; Kleinberg et al., 2018). For example, if a training 
dataset holds more positively labeled examples for men, 
the ML model may predict positive labels less accurately Despite algorithms aiming for objectivity and clarity in their
procedures, they can become biased when they receive partial
input data from humans. Modern algorithms may appear neutral
but can disproportionately harm protected class members, posing
the risk of“agentic discrimination”(Prince and Schwarcz,2019).
If mishandled, algorithms can exacerbate inequalities and
perpetuate discrimination against minority groups (Lloyd,2018).
Within the recruitment process, algorithmic bias can manifest
concerning gender, race, color, and personality.
Research methodology
The primary research strategy was a literature review approach.
This review aimed to assess current research on recruitment
supported by artiﬁcial intelligence algorithms. The systematic
review process included gathering and evaluating the selected
studies’ literature and topics. Driven by the direction of the
research, studies focusing on algorithmic discrimination in
recruitment over the past 10 years were included unless past
literature was worth reviewing. This is because this is a relatively
new phenomenon that has become prominent over the past 10
years. In deﬁning the “algorithmic and hiring discrimination”
literature, a fairly broad approach was taken based on article of inadvertently perpetuating or igniting algorithmic 
discrimination if these individuals engage in 
discriminatory practices. In this context, efforts aimed at 
identifying and mitigating (subconscious) discriminatory 
practices of organizational decision  makers, such as 
awareness training, become an indispensable 
complementary element to ensure that continuously 
updated ML models exhibit desirable behaviors. 
2 Theoretical and Conceptual 
Background 
In this section, we first provide the conceptual 
underpinnings of algorithmic discrimination. 
Subsequently, we discuss the literature gaps our work 
aims to address.",14.91115761,0,The generated answer provides an incorrect definition of algorithmic discrimination. The ground truth provides a more accurate and nuanced definition.,1,"The generated answer is faithful. [cite_start]The context defines algorithmic discrimination as system outputs that 'disproportionately benefit or disadvantage specific groups, even when no justification for the disparate treatment exists from a ground-truth perspective'[cite: 2045].",1,"The context provides a clear definition, stating that algorithmic discrimination refers to 'system outputs that disproportionately benefit or disadvantage specific groups, even when no justification for the disparate treatment exists from a ground-truth perspective'."
"According to the document, what software was used as an auxiliary tool to clarify ideas and improve work efficiency?",Nvivo 12.0 Plus qualitative analysis software.,"Basierend auf dem Text wird das ""Scrips Modell"" als Hilfsmittel zur Klärung von Ideen und zur Steigerung der Arbeitsleistung erwähnt.","Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. den besten Bewerber.
Finde aus einer größeren Menge 
von möglichen Bewerbern.
Ich denke also wieder mit Was 
sollte sich innerhalb
meines Prozesses
innerhalb dieses Workflows auch 
verändern?
Integriert mehr Integration?
Und ein Beispiel hierfür ist 
Ada. Kennt das jemand?
Hat jemand schon mal gehört,
es war ein Startup,
was in
der Pre Curve Zeit ein Customer 
Service Angebot hatte?
Die haben die Automatisierung
damals auch nicht mitgenerativen 
KI Systemen.
Aber ein sehr
clever zusammengestelltes 
Applikationssystem,
wo Customer Compliance gehandelt 
worden sind.
Das wurde aufgekauft innerhalb 
der
kurze Zeit von einem uns
allen bekannten großen Provider 
von digitalen Calls,
nämlich Zoom Zoom hat 
festgestellt,
als alle in die digitalen
Räume zu kurze Zeit gegangen 
sind,
dass es sehr viele Beschwerden
insbesondere von bestimmten 
Altersgruppen gab,
die mit dieser Technologie nicht 
klargekommen sind,
was dazu geführt hat,
dass dieser Ansturm, dieser 
Komplements,
die gesamte Service und
die gesamte Marketing Abteilung 
von Zoom
eigentlich den ganzen Tag auf 
Trab gehalten hatten.
Sie konnte trotzdem nicht alles
abarbeiten und dieses System,
was sie installiert haben,
war jetzt nicht einfach nur Ich 
habe ein System, nachzudenken,
ist diese Dekomposition von 
Workflows und die
Organisation von solchen 
Projekten
kann stattfinden über diese 
Scrips Modell.
Und letztlich haben wir 
unterschiedliche Level der
Integration von diesen Machine 
Learning Innovationen
innerhalb der Organisation.
Hört sich alles super an!
Problem ist da kann massiv viel 
schiefgehen.
Selbst wenn ich diesen ganzen 
Prozess durchgedacht habe,
sind es an vielen Ecken immer 
noch Probleme,
die sich beispielsweise hier bei 
Amazon vor einigen
Jahren trotz hochintelligenter 
Leute,
trotz super Strukturen,
trotz tollen technologischen 
Möglichkeiten
ist es da zu einem großen 
Skandal gekommen,
die man von diesem Skandal 
damals gehört.
Müsste ungefähr in die Zeit, wo 
sie alle
Abitur gemacht haben, gewesen 
sein.
Ja, das war weil die.
Also ich bin mir nicht mehr 
sicher.
Ich glaube, da wurden die 
früheren
Recruitingdaten von Amazon 
genommen,
in eine AI eingespeist.
Und da die früheren Recruiter
biased gegenüber Frauen waren,
hat die AI das Muster erkannt 
und ebenso übernommen.
Genau.
Wir haben ein System
gehabt und ich würde gar nicht 
mal sagen,
dass die Recruiter per se 
gebeizt waren.
Ich wahrscheinlich auch ein 
Teil.
Ich will den Leuten da nichts 
unterstellen.",6.813980818,0,The generated answer identifies the wrong software ('Scrips Modell'). The ground truth correctly identifies the software as 'Nvivo 12.0 Plus'.,0,"The generated answer is unfaithful. [cite_start]The context mentions the 'Scrips Modell' in the context of de-composition of workflows[cite: 2069], but does not mention 'Nvivo 12.0 Plus' software.",0,"The context mentions the 'Scrips Modell' as a way to organize projects, but it does not mention 'Nvivo 12.0 Plus qualitative analysis software'."
What was the result of Microsoft revising their dataset for training the Face API?,A 20-fold reduction in the recognition error ratio between men and women with darker skin tones.,"Die Revision des Datensatzes von Microsoft für das Training der Face API führte zu einer 20-fachen Reduzierung des Erkennungsfehlerraten zwischen Männern und Frauen mit dunkler Hautfarbe und einer 9-fachen Reduzierung für Frauen. Dies wurde durch das Ausgleich von Faktoren wie Hautfarbe, Alter und Geschlecht erreicht.","uncover hidden biases and remove them automatically. For
example, Microsoft revised their dataset for training the Face API,
resulting in a 20-fold reduction in the recognition error ratio
between men and women with darker skin tones and a 9-fold
reduction for women by balancing factors such as skin color, age,
and gender (Grabovskyi and Martynovych,2019).
Integrating “small data” and “big data” can enhance accuracy
(36KE, 2020). Data should not solely rely on extensive collections
but also focus on precision. While big data analysis tends to
emphasize correlations, which can lead to errors when inferring
causation, small data, which is more user-speciﬁc, offers detailed
information and helps avoid such mistakes. Combining the
vastness of big data with the precision of small data can help
somewhat mitigate hiring errors (Kitchin and Lauriault,2015).
Biases in datasets can be identi ﬁed through autonomous
testing. The inaccuracies stemming from incomplete past data
can be addressed through “oversampling” (Bornstein, 2018).
Researchers from MIT demonstrated how an AI system called
DB-VEA (unsupervised learning) can automatically reduce bias
by re-sampling data. This approach allows the model to learn neously labeled a photo of two black people as gorillas (Jackson,
2021). The algorithm was insuf
ﬁciently trained to recognize
images with dark skin tones (Yarger et al.,2023). The company
publicly apologized and committed to immediately preventing
such errors. However, three years later, Google discontinued its
facial identiﬁcation service, citing the need to address signiﬁcant
technical and policy issues before resuming this service. Similarly,
in 2017, an algorithm used for a contactless soap dispenser failed
to correctly identify shades of skin color, resulting in the dis-
penser only responding to white hands and not detecting black
and brown ones. These cases serve as examples of algorithmic
bias (Jackson, 2021).
Personality. The algorithm assesses word choice, tone shifts, and
facial expressions (using facial recognition) to determine the
candidate’s “personality” and alignment with the company cul-
ture (Raso et al., 2018). Notable examples include correlating
longer tenure in a speciﬁc job with“high creativity”and linking a
stronger inclination towards curiosity to a higher likelihood of
seeking other opportunities (O’neil, 2016). Additionally, senti-
ment analysis models are employed to gauge the level of positive one model predicts it differently (Gulzar et al.,2019).
Bias detection tool. In September 2018, Google introduced the
innovative What-If tool for detecting bias (Mishra, 2022). It
assists designers in identifying the causes of misclassiﬁcation,
determining decision boundaries, and detecting algorithmic
fairness through interactive visual interfaces. Additionally, Face-
book has developed Fairness Flow, an emerging tool for
correcting algorithmic bias. Fairness Flow automatically notiﬁes
developers if an algorithm makes unfair judgments based on race,
gender, or age (Kessing,2021).
Improving the algorithm ’s ethics from a management
perspective
Internal ethics governance. Several major technology companies
have published AI principles addressing bias governance, sig-
naling the start of self-regulation (36KE, 2020). Microsoft has
formed an AI and ethical standards committee to enforce these
principles, subjecting all future AI products to ethics scrutiny
(Smith and Shum,2018). Google has responded by introducing a
Model Card function, similar to an algorithm manual, that
explains the employed algorithm, highlights strengths and
weaknesses, and even shares operational results from various
datasets (Mitchell et al.,2019).",9.083568335,1,"The generated answer correctly states the result of Microsoft revising their dataset, which is a 20-fold reduction in the error ratio. This is semantically identical to the ground truth.",1,The generated answer is faithful. [cite_start]The context states that Microsoft's revision of their dataset resulted in a '20-fold reduction in the recognition error ratio between men and women with darker skin tones'[cite: 2078].,1,"The context directly answers the question, stating that Microsoft's revision of their dataset resulted in 'a 20-fold reduction in the recognition error ratio between men and women with darker skin tones'."
What did Amazon do with their ML-based hiring tool?,Amazon withdrew the tool and developed a new unbiased algorithm.,"Amazon hat sein ML-basiertes Recruiting-Tool entwickelt, um den Recruitmentprozess zu verbessern, da sie sehr viele Bewerber hatten und nicht manuell alle bearbeiten konnten. Allerdings hat das System aufgrund der Verwendung historischer Daten, die hauptsächlich von männlichen Bewerbern stammten, eine Geschlechterbias entwickelt. Das System hat Bewerberinnen mit Schlüsselwörtern wie ""female"" sogar heruntergestuft. Schließlich musste Amazon das Tool zurückziehen und ein neues, unvoreingenommenes Algorithmus entwickeln.","hat die AI das Muster erkannt 
und ebenso übernommen.
Genau.
Wir haben ein System
gehabt und ich würde gar nicht 
mal sagen,
dass die Recruiter per se 
gebeizt waren.
Ich wahrscheinlich auch ein 
Teil.
Ich will den Leuten da nichts 
unterstellen.
Ich glaube die wir
überschätzen teilweise
die negativen Intentionen von 
einzelnen Individuen.
Ich glaube, wir haben 
strukturelle Probleme,
die auch dazu beigetragen haben,
die einfach dort sind,
mit denen wir auseinandersetzen 
müssen.
Hier in diesem Beispiel war es 
so genau,
wie Sie erklärt haben.
Amazon hat gesagt Naja,
wir wollen unseren 
Recruitmentprozess verbessern.
Wir möchten gerne, weil wir so 
viele Bewerber haben.
Das können wir alles gar nicht 
mehr händisch handeln.
Das heißt, wir möchten Machine 
Learning System haben,
was uns eigentlich sagt.
Wie hoch ist die 
Wahrscheinlichkeit,
dass wir einen guten Mitarbeiter 
gefunden haben?
Und die Entwickler dieses
Softwaresystems haben die 
historischen
Daten genommen und haben sogar 
gesagt Na ja,
per Gesetz dürfen wir nicht auf 
Gender gucken.
Was also gemacht wurde,
ist man hat die Gendermerkmale,
also die selbst angegebenen 
Geschlecht.
Geschlechtsidentifikation hat 
man rausgenommen.
Es war also nicht Teil des 
Systems. Die Digitalisierung und datengetriebene Transformation verändern die Unternehmenswelt grundlegend. Machine Learning (ML) ist dabei zu einem unverzichtbaren Werkzeug geworden, um datenbasierte Entscheidungen zu treffen, Effizienz zu steigern und Innovationen voranzutreiben. Von der Optimierung von Marketingkampagnen über die Analyse von Kundendaten bis hin zur Vorhersage von Markttrends – ML bietet vielfältige Ansätze, um Managemententscheidungen fundierter und effizienter zu gestalten.
Dieser Kurs richtet sich an Studierende der Wirtschaftswissenschaften (WiWi), die die Potenziale von ML verstehen und praktisch anwenden möchten, ohne dass tiefgehende Informatik- oder Programmierkenntnisse vorausgesetzt werden. Die Studierenden lernen nicht nur die grundlegenden Funktionsweisen von ML-Methoden kennen, sondern auch, wie diese in der Praxis zur Lösung unternehmerischer Herausforderungen eingesetzt werden können. The impact of gender stereotypes on AI hiring poses genuine
risks (Beneduce,2020). In 2014, Amazon developed an ML-based
hiring tool, but it exhibited gender bias. The system did not
classify candidates neutrally for gender (Miasato and Silva,2019).
The bias stemmed from training the AI system on predominantly
male employees ’ CVs (Beneduce, 2020). Accordingly, the
recruitment algorithm perceived this biased model as indicative
of success, resulting in discrimination against female applicants
(Langenkamp et al. 2019). The algorithm even downgraded
applicants with keywords such as “female” (Faragher, 2019).
These ﬁndings compelled Amazon to withdraw the tool and
develop a new unbiased algorithm. However, this discrimination
was inadvertent, revealing theﬂaws inherent in algorithmic bias
that perpetuates existing gender inequalities and social biases
(O’neil, 2016).
Race. Microsoft’s chatbot Tay learned to produce sexist and racist
remarks on Twitter. By interacting with users on the platform,
Tay absorbed the natural form of human language, using human
tweets as its training data. Unfortunately, the innocent chatbot
quickly adopted hate speech targeting women and black indivi-",10.76756668,1,The generated answer's statement that Amazon withdrew the tool and developed a new one is semantically identical to the ground truth.,1,"The generated answer is faithful. [cite_start]The context states that Amazon's hiring tool 'exhibited gender bias' because the 'bias stemmed from training the AI system on predominantly male employeesâ€™ CVs'[cite: 1400, 1398].",1,"The context explicitly states that after finding its ML-based hiring tool exhibited gender bias, Amazon was 'compelled to withdraw the tool and develop a new unbiased algorithm'."
"According to the document, what is “agent discrimination”?","When partial human data is provided to a machine, it will eventually lead to the risk of “agent discrimination.”","Laut dem Dokument ist „agentenbedingte Diskriminierung“ die „unbeabsichtigte Perpetuierung oder Auslösung von Diskriminierung, wenn diese Personen diskriminierende Praktiken innerhalb von Entscheidungsfindungsprozessen anwenden“. Es geht um die Gefahr, dass Mitarbeiter (als „Agenten“) diskriminierende Praktiken anwenden und dadurch ML-Modelle beeinflussen.","Theory background
Discrimination theory. Discrimination in the labor market is
deﬁned by the ILO’s Convention 111, which encompasses any
unfavorable treatment based on race, ethnicity, color, and gender
that undermines employment equality (Ruwanpura, 2008).
Economist Samuelson (1952) offers a similar deﬁnition, indicat-
ing that discrimination involves differential treatment based on
personal characteristics, such as ethnic origin, gender, skin color,
and age.
Various perspectives on the causes and manifestations of
discrimination can be broadly categorized into four theoretical
groups. Theﬁrst is the competitive market theory, which explains
discriminatory practices within an equilibrium of perfect
competition (Lundberg and Startz, 1983). This view attributes
discrimination primarily to personal prejudice. The second is the
monopoly model of discrimination, which posits that mono-
polistic power leads to discriminatory behavior (Cain,1986). The
third is the statistical theory of discrimination, which suggests
that nonobjective variables, such as inadequate information,
contribute to biased outcomes (Dickinson and Oaxaca, 2009).
Lastly, we have the antecedent market discrimination hypothesis
as the fourth category. of inadvertently perpetuating or igniting algorithmic 
discrimination if these individuals engage in 
discriminatory practices. In this context, efforts aimed at 
identifying and mitigating (subconscious) discriminatory 
practices of organizational decision  makers, such as 
awareness training, become an indispensable 
complementary element to ensure that continuously 
updated ML models exhibit desirable behaviors. 
2 Theoretical and Conceptual 
Background 
In this section, we first provide the conceptual 
underpinnings of algorithmic discrimination. 
Subsequently, we discuss the literature gaps our work 
aims to address. facial identiﬁcation.
Data protection and non-discrimination laws safeguard against
discriminatory practices in algorithmic decision-making. In the
EU region, Article 14 of the European Convention on Human
Rights (ECHR) guarantees the rights and freedoms outlined in
the Convention, prohibiting direct and indirect discrimination
(Zuiderveen Borgesius, 2020). Non-discrimination laws, particu-
larly those about indirect discrimination, serve as a means to
prevent various forms of algorithmic discrimination. The EU
General Data Protection Regulation (GDPR), implemented in
May 2018, addresses the impact of ML algorithms and offers a
“right to explanation” (e.g., Articles 13–15) (Peña et al., 2020),
enabling individuals to request explanations for algorithmic
decisions and demand measures to avoid discriminatory
inﬂuences when handling sensitive data. The GDPR mandates
organizations to conduct a Data Protection Impact Assessment
(DPIA), with each EU member state must maintain an
independent data protection authority vested with investigative
powers. Under the GDPR, a data protection authority can access
an organization’s premises and computers using personal data
(Zuiderveen Borgesius, 2020).
Investigation and analysis",8.68337965,0,The generated answer provides an incorrect definition of 'agent discrimination.' The ground truth provides the correct definition.,0,"The generated answer is unfaithful. [cite_start]The context mentions 'agentic discrimination'[cite: 2018], but does not define it as the result of partial human data. The provided definition in the generation is an interpolation not present in the context.",0,"The context discusses 'inadvertently perpetuating or igniting algorithmic discrimination if these individuals engage in discriminatory practices'. While this describes the actions of an 'agent' (the employee), it does not match the definition provided in the ground truth answer."
"According to the document, what are some characteristics used in discrimination theory?","Race, ethnicity, color, and gender.",Das ist korrekt. Laut dem Dokument werden in der Diskriminierungstheorie soziale Verzerrungen in den Trainingsdaten und die Anwendung diskriminierender Praktiken durch Mitarbeiter (als „Agenten“) als Charakteristika verwendet.,"of inadvertently perpetuating or igniting algorithmic 
discrimination if these individuals engage in 
discriminatory practices. In this context, efforts aimed at 
identifying and mitigating (subconscious) discriminatory 
practices of organizational decision  makers, such as 
awareness training, become an indispensable 
complementary element to ensure that continuously 
updated ML models exhibit desirable behaviors. 
2 Theoretical and Conceptual 
Background 
In this section, we first provide the conceptual 
underpinnings of algorithmic discrimination. 
Subsequently, we discuss the literature gaps our work 
aims to address. Journal of the Association for Information Systems 
 
824 
Indeed, self-correcting mechanisms may require time 
to take effect, during which disadvantaged social 
groups may continue to endure discriminatory 
practices. Rather, we perceive our findings as a 
testament to the substantial learning capabilities of 
modern ML models undergoing continuous updating. 
We argue that these capabilities can complement other 
interventions aimed at addressing algorithmic 
discrimination, such as the proper preprocessing of 
training data. This approach is particularly effective 
when organizations take measures to ensure that their 
employees do not engage in (subconscious) 
discriminatory practices during ML -supported 
decision-making processes. However, overreliance on 
the self -correcting aspects of continuous updating 
processes could cause significant damage to both an 
organization’s economic performance and reputation if 
ML systems are deployed hastily without rigorous ly 
testing for and addressing algorithmic discrimination. discrimination (Favaretto et al., 2019; Kordzadeh & 
Ghasemaghaei, 2022). The social component often 
originates from societal and economic structural biases, 
which can foster the differential treatment and 
marginalization of certain groups. On the other hand, the 
technological element emanates from the perpetuated 
discriminatory behaviors of algorithmic systems. 
Algorithmic feedback loops: Feedback loops play a 
significant role in algorithmic discrimination in the 
context of continuously updated ML models. These loops 
arise when the outcomes of algorithmic decisions provide 
new endogenous training data for subsequent model 
updates (Cowgill, 2018). Such loops iteratively weave 
together the social environment ’s outcomes and the 
technical performance of the algorithmic output. For 
instance, take the loan approval process depicted in 
 
1 Since the biased or disparate treatment of particular groups 
typically yields discrimination and unfairness, researchers 
often use the terms algorithmic bias, algorithmic 
Figure 1. If an ML model’s prediction of creditworthiness 
guides loan approval, this prediction will shape the data 
available for future updates. As the bank only observes",8.235931396,0,The generated answer provides an incorrect list of characteristics used in discrimination theory. The ground truth provides the correct list.,0,"The generated answer is unfaithful. [cite_start]The context mentions characteristics like race, color, and gender in the context of discrimination theory[cite: 2131], but the generation's claim that social biases in training data and discriminatory practices by employees are 'characteristics used in discrimination theory' is a misinterpretation. They are sources of bias, not characteristics within the theory itself.",0,"The context describes discrimination theory in terms of societal biases and the behaviors of algorithmic systems  but does not explicitly list 'race, ethnicity, color, and gender' as the core characteristics."
What is the generic C R ISP-D M process model useful for?,"Planning, documentation and communication.","Based on the text provided, the answer is:

No, the text does not state that the CRISP-DM process model is useful for management decisions. It describes the model as being too abstract to describe repeatable processes for end users and suggests a specialized process model would be more appropriate.","Plan M onitoring and 
   M aintenance
M onitoring and
   M aintenance Plan
Produce Final R eport
Final Report
Final Presentation
R eview  Project
Experience 
   D ocum entation
 Figure 3: O verview  of the C R ISP-D M  tasks and their outputs.
• Evaluation
A t this stage in the project you have built one or m ore m odels that appear to have high quality,
from  a data analysis perspective. B efore proceeding to final deploym ent of the m odel, it is
im portant to m ore thoroughly evaluate the m odel, and review  the steps executed to construct
the m odel, to be certain it properly achieves the business objectives. A  key objective is to
determ ine if there is som e im portant business issue that has not been sufficiently considered.
A t the end of this phase, a decision on the use of the data m ining results should be reached.
• D eploym ent project w as to specify a process w hich can be reliably and efficiently repeated by different people and adapted to
different situations. The initial projects w ere perform ed by experienced data m ining people; future projects are to be
perform ed by people w ith low er technical skills and w ith very little tim e to experim ent w ith different approaches. It
turned out, that the C R ISP-D M  m ethodology w ith its distinction of generic and specialized process m odels provides
both the structure and the flexibility necessary to suit the needs of both groups.
The generic C R ISP-D M  process m odel is useful for planning, com m unication w ithin and outside the project team , and
docum entation. The generic check-lists are helpful even for experienced people. The generic process m odel provides an
excellent foundation for developing a specialized process m odel w hich prescribes the steps to be taken in detail and
w hich gives practical advice for all these steps.
1 Introduction
D ata m ining is a creative process w hich requires a num ber of different skills and know ledge.
C urrently there is no standard fram ew ork in w hich to carry out data m ining projects. This m eans level description like the generic C R ISP-D M , is not a solution either. W hile it covers the w hole
process and is useful for experienced people, it is not suitable for the kind of users one is
confronted w ith w hen m oving into norm al business processes. The resulting process description
should guide the user as m uch as possible but, at the sam e tim e, enable him  to handle difficult
unexpected situations.
O ne of our basic decisions w as to follow  the C R ISP-D M  m ethodology as m uch as possible. W e
used the generic reference m odel for planning the case studies, for com m unication w ithin the
project team , for com m unication outside the project, and for docum enting results and
experiences. W hile it w as very useful for these purposes, it is too abstract to describe repeatable
processes for our end users. A ccording to C R ISP-D M , the proper level w ould be a specialized
process m odel, w hose context is response m odeling for acquisition cam paigns using C lem entine2.
B asically, w e used tw o resources for the developm ent of the specialized process m odel, the
C R ISP-D M  G eneric U ser G uide and the docum entation of three case studies, w hich correspond
to C R ISP-D M  process instances.",7.644278049,1,"The generated answer's claim that the generic CRISP-DM model is useful for planning, documentation, and communication is semantically identical to the ground truth.",1,"The generated answer is faithful. [cite_start]The context explicitly states that the 'generic C R ISP-D M process m odel is useful for planning, com m unication w ithin and outside the project team , and docum entation'[cite: 2171].",1,"The context directly states that the 'generic CRISP-DM process model is useful for planning, communication ... and documentation'."
"According to the document, what can AI-based recruitment reduce?",Costs.,"That’s correct. According to the document, AI-enabled recruitment has the potential to reduce gender bias.","REVIEW ARTICLE
Ethics and discrimination in artiﬁcial intelligence-
enabled recruitment practices
Zhisheng Chen 1✉
This study aims to address the research gap on algorithmic discrimination caused by AI-
enabled recruitment and explore technical and managerial solutions. The primary research
approach used is a literature review. Theﬁndings suggest that AI-enabled recruitment has
the potential to enhance recruitment quality, increase efﬁciency, and reduce transactional
work. However, algorithmic bias results in discriminatory hiring practices based on gender,
race, color, and personality traits. The study indicates that algorithmic bias stems from
limited raw data sets and biased algorithm designers. To mitigate this issue, it is recom-
mended to implement technical measures, such as unbiased dataset frameworks and
improved algorithmic transparency, as well as management measures like internal corporate
ethical governance and external oversight. Employing Grounded Theory, the study conducted
survey analysis to collectﬁrsthand data on respondents’ experiences and perceptions of AI-
driven recruitment applications and discrimination.
Introduction
T technical and managerial aspects to tackle discrimination in
algorithmic hiring. This study contends that resolving algorithmic
discrimination in recruitment requires technical solutions and the
implementation of internal ethical governance and external
regulations.
The subsequent study is structured intoﬁve parts. The ﬁrst
section provides the theoretical background for this research. The
following section outlines the research methodology employed in
the literature review and identiﬁes four key themes. The third
section delves into a detailed discussion of these four themes:
applications and beneﬁts of AI-based recruitment, factors con-
tributing to algorithmic recruitment discrimination, types of
discrimination in algorithmic recruitment, and measures to
mitigate algorithmic hiring discrimination. The fourth section
involves conducting a survey among respondents and analyzing
the primary data collected to support our study. Theﬁnal section
concludes by suggesting future directions for research.
Theory background
Discrimination theory. Discrimination in the labor market is
deﬁned by the ILO’s Convention 111, which encompasses any
unfavorable treatment based on race, ethnicity, color, and gender Silva (2019), and Beneduce (2020), Johnson et al. (2020).
Claim that AI-supported recruitment can reduce
costs
Hmoud and Laszlo (2019), Johansson and Herranen (2019),
Raveendra et al. (2020), Black and van Esch (2020), and Allal-
Chérif et al. (2021)
Suggests that AI support can save time
Upadhyay and Khandelwal (2018), Johansson and Herranen
(2019)
Propose that AI support can reduce transactional
workload
2. Causes of algorithmic
discrimination
McFarland and McFarland (2015), Mayson (2018), Raso et al.
(2018), Raub (2018), Raghavan et al. (2020), Njoto (2020),
Zixun (2020), and Jackson (2021)
Suggests that the reason for algorithmic
discrimination is related to data selection
Yarger et al. (2019), Miasato and Silva (2019), and Njoto
(2020)
Propose that discrimination is due to the
designer-induced selection of data features
3. Algorithmic recruitment
discrimination
Correll et al. (2007), Kay et al. (2015), O’neil (2016), Raso et al.
(2018), Miasato and Silva (2019), Langenkamp et al. (2019),
Faragher (2019), Ong (2019), Fernández and Fernández (2019),
Beneduce (2020), Jackson (2021), Yarger et al. (2023), and
Avery et al. (2023)
In recruitment, algorithmic bias can manifest in
gender, race, skin color, and personality",5.411281586,0,The generated answer incorrectly claims that AI recruitment can reduce gender bias. The ground truth states it can reduce costs.,0,"The generated answer is unfaithful. [cite_start]The context mentions that AI-supported recruitment can reduce costs[cite: 2197], but the claim about reducing gender bias is not present in the provided snippets.",1,The context explicitly states that AI-supported recruitment can reduce costs.
"According to the document, what is the aim of the C R ISP-D M process model?","To make large data mining projects less costly, more reliable, more repeatable, more manageable, and faster.","Das Ziel des CRISP-D M Prozessmodells ist es, eine umfassende Prozessmodell für die Durchführung von Datenanalyseprojekten zu schaffen. Es soll unabhängig von Branche und Technologie sein und von verschiedenen Personen zuverlässig und effizient wiederholt werden können, um an unterschiedliche Situationen angepasst zu werden.","C R ISP-D M : T ow ards a Standard Process M odel for D ata
M ining
Rüdiger W irth
D aim lerC hrysler R esearch &  Technology FT3/K L
PO  B O X  2360 89013 U lm , G erm any
ruediger.w irth@ daim lerchrysler.com
Jochen H ipp
W ilhelm -Schickard-Institute, U niversity of Tübingen
Sand 13, 72076 Tübingen, G erm any
jochen.hipp@ inform atik.uni-tuebingen.de
A bstract
The C R ISP-D M  (C R oss Industry Standard Process for D ata M ining) project proposed a com prehensive process m odel
for carrying out data m ining projects. The process m odel is independent of both the industry sector and the technology
used. In this paper w e argue in favor of a standard process m odel for data m ining and report som e experiences w ith the
C R ISP-D M  process m odel in practice.
W e applied and tested the C R ISP-D M  m ethodology in a response m odeling application project. The final goal of the
project w as to specify a process w hich can be reliably and efficiently repeated by different people and adapted to
different situations. The initial projects w ere perform ed by experienced data m ining people; future projects are to be Plan M onitoring and 
   M aintenance
M onitoring and
   M aintenance Plan
Produce Final R eport
Final Report
Final Presentation
R eview  Project
Experience 
   D ocum entation
 Figure 3: O verview  of the C R ISP-D M  tasks and their outputs.
• Evaluation
A t this stage in the project you have built one or m ore m odels that appear to have high quality,
from  a data analysis perspective. B efore proceeding to final deploym ent of the m odel, it is
im portant to m ore thoroughly evaluate the m odel, and review  the steps executed to construct
the m odel, to be certain it properly achieves the business objectives. A  key objective is to
determ ine if there is som e im portant business issue that has not been sufficiently considered.
A t the end of this phase, a decision on the use of the data m ining results should be reached.
• D eploym ent level description like the generic C R ISP-D M , is not a solution either. W hile it covers the w hole
process and is useful for experienced people, it is not suitable for the kind of users one is
confronted w ith w hen m oving into norm al business processes. The resulting process description
should guide the user as m uch as possible but, at the sam e tim e, enable him  to handle difficult
unexpected situations.
O ne of our basic decisions w as to follow  the C R ISP-D M  m ethodology as m uch as possible. W e
used the generic reference m odel for planning the case studies, for com m unication w ithin the
project team , for com m unication outside the project, and for docum enting results and
experiences. W hile it w as very useful for these purposes, it is too abstract to describe repeatable
processes for our end users. A ccording to C R ISP-D M , the proper level w ould be a specialized
process m odel, w hose context is response m odeling for acquisition cam paigns using C lem entine2.
B asically, w e used tw o resources for the developm ent of the specialized process m odel, the
C R ISP-D M  G eneric U ser G uide and the docum entation of three case studies, w hich correspond
to C R ISP-D M  process instances.",7.812875986,1,The generated answer's statement about the aim of the CRISP-DM process model is semantically consistent with the ground truth.,1,"The generated answer is faithful. [cite_start]The context explicitly states that the goal of the CRISP-DM project was 'to specify a process which can be reliably and efficiently repeated by different people and adapted to different situations,' which aligns with the generation's claim[cite: 2210].",1,"The context clearly states that the aim of the CRISP-DM project was to propose a 'comprehensive process model for carrying out data mining projects' that can be 'reliably and efficiently repeated by different people and adapted to different situations', which aligns with the ground truth answer."
